{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This version uses only left and right spectrums and input as 2 separate channels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib\n",
    "#matplotlib.use(\"TkAgg\")\n",
    "from scipy.io import wavfile\n",
    "from scipy import signal\n",
    "from scipy.signal import blackman\n",
    "#from matplotlib import mlab\n",
    "from matplotlib import pyplot as plt\n",
    "import numpy as np\n",
    "#from numpy.lib import stride_tricks\n",
    "from pylab import *\n",
    "from struct import pack\n",
    "#import pywt\n",
    "from scipy.fftpack import dct\n",
    "#from struct import pack\n",
    "import wave\n",
    "from scipy.io import wavfile\n",
    "import os\n",
    "#import glob\n",
    "\n",
    "import gc\n",
    "import multiprocessing as mp\n",
    "import resource \n",
    "import csv\n",
    "import itertools\n",
    "\n",
    "import pandas as pd\n",
    "import ipywidgets as widgets\n",
    "\n",
    "gc.enable()\n",
    "\n",
    "flag = 0\n",
    "date = '20210310'\n",
    "dates = ['20210310','20210315','20210319']\n",
    "data_path = 'data/'\n",
    "mono_path = data_path + \"wav/\"\n",
    "stereo_path = data_path + \"stereo/\"\n",
    "\n",
    "mono_file_path = mono_path + date + \"/\"\n",
    "stereo_file_path = stereo_path + date + \"/\"\n",
    "\n",
    "sweep_path = data_path + \"sweep/\"\n",
    "sweep_time_path = sweep_path + date + \"/\"\n",
    "\n",
    "aud_path = data_path + \"aud_times/\"\n",
    "aud_time_path = aud_path + date + \"/\"\n",
    "\n",
    "visual_path = 'visual/'\n",
    "\n",
    "#print os.path.splitext(\"20171025/data/\")[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>.container { width:75% !important; }</style>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from IPython.core.display import display, HTML \n",
    "display(HTML(\"<style>.container { width:75% !important; }</style>\"))\n",
    "\n",
    "%config IPCompleter.greedy=True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Checking memory usage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mem():\n",
    "    print('Memory usage  : %2.2f MB' %round(resource.getrusage(resource.RUSAGE_SELF).ru_maxrss/1024.0,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20210310\n",
      "20210315\n",
      "20210319\n"
     ]
    }
   ],
   "source": [
    "from os import listdir\n",
    "from os.path import isfile, join\n",
    "onlyfiles=[]\n",
    "for d in dates:\n",
    "    print(d)\n",
    "    mypath = \"processed/\" + \"spectrum/\" + d + \"/left\"\n",
    "    of = [f for f in listdir(mypath) if isfile(join(mypath, f))]\n",
    "    onlyfiles.extend(of)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "onlyfiles.sort()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['20210310_15:25:26.159-20210310_15:25:39.816',\n",
       " '20210310_15:25:48.350-20210310_15:25:58.158',\n",
       " '20210310_15:26:14.684-20210310_15:26:25.036',\n",
       " '20210310_15:26:36.351-20210310_15:26:45.720',\n",
       " '20210310_15:26:59.160-20210310_15:27:08.845',\n",
       " '20210310_15:27:20.548-20210310_15:27:30.566',\n",
       " '20210310_15:29:00.353-20210310_15:29:09.829',\n",
       " '20210310_15:29:25.107-20210310_15:29:34.689',\n",
       " '20210310_15:29:41.711-20210310_15:29:51.347',\n",
       " '20210310_15:30:04.369-20210310_15:30:13.898',\n",
       " '20210310_15:30:21.964-20210310_15:30:32.030',\n",
       " '20210310_15:30:50.167-20210310_15:31:01.015',\n",
       " '20210310_15:31:09.318-20210310_15:31:20.694',\n",
       " '20210310_15:31:57.174-20210310_15:32:07.006',\n",
       " '20210310_15:32:14.252-20210310_15:32:24.462',\n",
       " '20210310_15:32:32.730-20210310_15:32:42.915',\n",
       " '20210310_15:32:48.233-20210310_15:32:58.401',\n",
       " '20210310_15:33:58.721-20210310_15:34:08.178',\n",
       " '20210310_15:34:21.045-20210310_15:34:32.102',\n",
       " '20210310_15:34:48.696-20210310_15:34:57.898',\n",
       " '20210310_15:42:00.571-20210310_15:42:11.946',\n",
       " '20210310_15:42:19.717-20210310_15:42:31.077',\n",
       " '20210310_15:42:43.374-20210310_15:42:54.045',\n",
       " '20210310_15:43:03.762-20210310_15:43:16.249',\n",
       " '20210310_15:44:04.924-20210310_15:44:15.189',\n",
       " '20210310_15:45:59.889-20210310_15:46:12.812',\n",
       " '20210310_15:46:20.984-20210310_15:46:32.410',\n",
       " '20210310_15:47:27.823-20210310_15:47:37.342',\n",
       " '20210310_15:49:41.258-20210310_15:49:51.348',\n",
       " '20210310_15:50:03.345-20210310_15:50:15.186',\n",
       " '20210310_15:50:19.873-20210310_15:50:29.207',\n",
       " '20210310_15:51:04.495-20210310_15:51:14.504',\n",
       " '20210310_15:51:22.201-20210310_15:51:34.120',\n",
       " '20210310_15:51:45.847-20210310_15:51:55.083',\n",
       " '20210310_15:52:00.814-20210310_15:52:11.246',\n",
       " '20210310_15:52:24.012-20210310_15:52:34.588',\n",
       " '20210310_15:52:48.777-20210310_15:52:58.321',\n",
       " '20210310_15:54:24.829-20210310_15:54:36.180',\n",
       " '20210310_15:58:17.102-20210310_15:58:34.089',\n",
       " '20210315_17:05:24.467-20210315_17:05:35.463',\n",
       " '20210315_17:05:51.089-20210315_17:06:00.494',\n",
       " '20210315_17:06:18.458-20210315_17:06:28.282',\n",
       " '20210315_17:07:11.513-20210315_17:07:20.684',\n",
       " '20210315_17:07:38.925-20210315_17:07:48.142',\n",
       " '20210315_17:08:00.532-20210315_17:08:09.611',\n",
       " '20210315_17:08:39.633-20210315_17:08:48.837',\n",
       " '20210315_17:09:10.210-20210315_17:09:20.081',\n",
       " '20210315_17:09:47.785-20210315_17:09:56.866',\n",
       " '20210315_17:10:08.695-20210315_17:10:18.533',\n",
       " '20210315_17:10:40.285-20210315_17:10:49.683',\n",
       " '20210315_17:11:54.379-20210315_17:12:04.246',\n",
       " '20210315_17:12:13.407-20210315_17:12:23.341',\n",
       " '20210315_17:13:29.822-20210315_17:13:40.619',\n",
       " '20210315_17:17:00.289-20210315_17:17:10.236',\n",
       " '20210315_17:19:31.337-20210315_17:19:40.940',\n",
       " '20210315_17:20:38.369-20210315_17:20:48.298',\n",
       " '20210315_17:21:29.553-20210315_17:21:39.505',\n",
       " '20210315_17:21:47.752-20210315_17:21:57.917',\n",
       " '20210315_17:23:00.273-20210315_17:23:09.830',\n",
       " '20210319_16:08:41.692-20210319_16:08:51.649',\n",
       " '20210319_16:10:10.704-20210319_16:10:21.506',\n",
       " '20210319_16:10:32.051-20210319_16:10:42.621',\n",
       " '20210319_16:11:12.300-20210319_16:11:24.827',\n",
       " '20210319_16:13:09.655-20210319_16:13:20.391',\n",
       " '20210319_16:14:28.970-20210319_16:14:38.999',\n",
       " '20210319_16:14:50.583-20210319_16:15:00.821',\n",
       " '20210319_16:15:18.712-20210319_16:15:29.511',\n",
       " '20210319_16:15:55.217-20210319_16:16:06.432',\n",
       " '20210319_16:16:17.283-20210319_16:16:28.357',\n",
       " '20210319_16:16:47.785-20210319_16:16:57.626',\n",
       " '20210319_16:17:22.477-20210319_16:17:32.588',\n",
       " '20210319_16:17:45.271-20210319_16:17:57.477',\n",
       " '20210319_16:18:28.688-20210319_16:18:39.650',\n",
       " '20210319_16:19:24.958-20210319_16:19:34.607',\n",
       " '20210319_16:21:29.421-20210319_16:21:39.386',\n",
       " '20210319_16:21:59.598-20210319_16:22:09.200',\n",
       " '20210319_16:23:03.444-20210319_16:23:13.463',\n",
       " '20210319_16:23:44.170-20210319_16:23:54.026',\n",
       " '20210319_16:26:08.675-20210319_16:26:18.199',\n",
       " '20210319_16:26:51.249-20210319_16:27:02.576']"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "onlyfiles"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Label the instances"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "imp_res = pd.DataFrame()\n",
    "for f in onlyfiles:\n",
    "    ir = pd.read_csv(\"processed/\" + \"ir_raw/\" + date + \"/left/\" + f, index_col=False, header=None)\n",
    "    #break\n",
    "    if date == \"20210218\":\n",
    "        if f in {'20210218_16:44:01.177-20210218_16:44:33.943','20210218_16:51:41.403-20210218_16:52:20.100','20210218_16:53:18.712-20210218_16:54:04.193'}:\n",
    "            index = ['no']*len(ir)\n",
    "        if f in {'20210218_16:57:18.254-20210218_16:58:03.582','20210218_17:00:26.185-20210218_17:01:01.872','20210218_17:01:08.542-20210218_17:01:43.332'}:\n",
    "            index = ['up']*len(ir)\n",
    "        if f in {'20210218_17:03:41.837-20210218_17:04:15.747','20210218_17:05:08.986-20210218_17:05:42.206','20210218_17:04:31.485-20210218_17:05:06.079'}:\n",
    "            index = ['side']*len(ir)\n",
    "            \n",
    "    if date == \"20210224\":\n",
    "        if f in {'20210224_17:55:21.433-20210224_17:55:55.191','20210224_17:56:04.294-20210224_17:56:39.426','20210224_17:57:00.457-20210224_17:57:34.537'}:\n",
    "            index = ['up']*len(ir)\n",
    "        if f in {'20210224_17:59:54.251-20210224_18:00:26.660','20210224_18:00:38.187-20210224_18:01:11.561','20210224_18:01:26.215-20210224_18:01:58.796'}:\n",
    "            index = ['side']*len(ir)\n",
    "        if f in {'20210224_18:06:50.537-20210224_18:07:23.479','20210224_18:08:00.368-20210224_18:08:33.322','20210224_18:08:37.805-20210224_18:09:11.272'}:\n",
    "            index = ['no']*len(ir)\n",
    "            \n",
    "    if date == \"20210302\":\n",
    "        if f in {'20210302_18:23:30.772-20210302_18:24:04.601','20210302_18:24:11.484-20210302_18:24:43.738','20210302_18:24:49.526-20210302_18:25:20.850'}:\n",
    "            index = ['up']*len(ir)\n",
    "        if f in {'20210302_18:32:33.332-20210302_18:33:05.962','20210302_18:33:12.699-20210302_18:33:44.740','20210302_18:33:51.921-20210302_18:34:24.773'}:\n",
    "            index = ['side']*len(ir)\n",
    "        if f in {'20210302_18:36:32.772-20210302_18:37:04.393','20210302_18:37:21.275-20210302_18:37:52.954','20210302_18:37:59.677-20210302_18:38:31.361'}:\n",
    "            index = ['no']*len(ir)\n",
    "        \n",
    "    ir.index = index\n",
    "    imp_res = pd.concat([imp_res, ir], axis=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Leave-one-session-out CV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "session_list = onlyfiles"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "session_list = ['20210302_18:23:30.772-20210302_18:24:04.601','20210302_18:24:11.484-20210302_18:24:43.738','20210302_18:24:49.526-20210302_18:25:20.850','20210302_18:32:33.332-20210302_18:33:05.962','20210302_18:33:12.699-20210302_18:33:44.740','20210302_18:33:51.921-20210302_18:34:24.773','20210302_18:36:32.772-20210302_18:37:04.393','20210302_18:37:21.275-20210302_18:37:52.954','20210302_18:37:59.677-20210302_18:38:31.361']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "session_list = ['20210310_15:25:26.159-20210310_15:25:39.816',\n",
    " '20210310_15:25:48.350-20210310_15:25:58.158',\n",
    " '20210310_15:26:14.684-20210310_15:26:25.036',\n",
    " '20210310_15:26:36.351-20210310_15:26:45.720',\n",
    " '20210310_15:26:59.160-20210310_15:27:08.845',\n",
    " '20210310_15:27:20.548-20210310_15:27:30.566',\n",
    " '20210310_15:29:00.353-20210310_15:29:09.829',\n",
    " '20210310_15:29:25.107-20210310_15:29:34.689',\n",
    " '20210310_15:29:41.711-20210310_15:29:51.347',\n",
    " '20210310_15:30:04.369-20210310_15:30:13.898',\n",
    " '20210310_15:30:21.964-20210310_15:30:32.030',\n",
    " '20210310_15:30:50.167-20210310_15:31:01.015',\n",
    " '20210310_15:31:09.318-20210310_15:31:20.694',\n",
    " '20210310_15:31:57.174-20210310_15:32:07.006',\n",
    " '20210310_15:32:14.252-20210310_15:32:24.462',\n",
    " '20210310_15:32:32.730-20210310_15:32:42.915',\n",
    " '20210310_15:32:48.233-20210310_15:32:58.401',\n",
    " '20210310_15:33:58.721-20210310_15:34:08.178',\n",
    " '20210310_15:34:21.045-20210310_15:34:32.102',\n",
    " '20210310_15:34:48.696-20210310_15:34:57.898',\n",
    " '20210310_15:42:00.571-20210310_15:42:11.946',\n",
    " '20210310_15:42:19.717-20210310_15:42:31.077',\n",
    " '20210310_15:42:43.374-20210310_15:42:54.045',\n",
    " '20210310_15:43:03.762-20210310_15:43:16.249',\n",
    " '20210310_15:44:04.924-20210310_15:44:15.189',\n",
    " '20210310_15:45:59.889-20210310_15:46:12.812',\n",
    " '20210310_15:46:20.984-20210310_15:46:32.410',\n",
    " '20210310_15:47:27.823-20210310_15:47:37.342',\n",
    " '20210310_15:49:41.258-20210310_15:49:51.348',\n",
    " '20210310_15:50:03.345-20210310_15:50:15.186',\n",
    " '20210310_15:50:19.873-20210310_15:50:29.207',\n",
    " '20210310_15:51:04.495-20210310_15:51:14.504',\n",
    " '20210310_15:51:22.201-20210310_15:51:34.120',\n",
    " '20210310_15:51:45.847-20210310_15:51:55.083',\n",
    " '20210310_15:52:00.814-20210310_15:52:11.246',\n",
    " '20210310_15:52:24.012-20210310_15:52:34.588',\n",
    " '20210310_15:52:48.777-20210310_15:52:58.321',\n",
    " '20210310_15:54:24.829-20210310_15:54:36.180',\n",
    " '20210310_15:58:17.102-20210310_15:58:34.089',\n",
    " '20210315_17:05:24.467-20210315_17:05:35.463',\n",
    " '20210315_17:05:51.089-20210315_17:06:00.494',\n",
    " '20210315_17:06:18.458-20210315_17:06:28.282',\n",
    " '20210315_17:07:11.513-20210315_17:07:20.684',\n",
    " '20210315_17:07:38.925-20210315_17:07:48.142',\n",
    " '20210315_17:08:00.532-20210315_17:08:09.611',\n",
    " '20210315_17:08:39.633-20210315_17:08:48.837',\n",
    " '20210315_17:09:10.210-20210315_17:09:20.081',\n",
    " '20210315_17:09:47.785-20210315_17:09:56.866',\n",
    " '20210315_17:10:08.695-20210315_17:10:18.533',\n",
    " '20210315_17:10:40.285-20210315_17:10:49.683',\n",
    " '20210315_17:11:54.379-20210315_17:12:04.246',\n",
    " '20210315_17:12:13.407-20210315_17:12:23.341',\n",
    " '20210315_17:13:29.822-20210315_17:13:40.619',\n",
    " '20210315_17:17:00.289-20210315_17:17:10.236',\n",
    " '20210315_17:19:31.337-20210315_17:19:40.940',\n",
    " '20210315_17:20:38.369-20210315_17:20:48.298',\n",
    " '20210315_17:21:29.553-20210315_17:21:39.505',\n",
    " '20210315_17:21:47.752-20210315_17:21:57.917',\n",
    " '20210315_17:23:00.273-20210315_17:23:09.830']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "def label_data(f, ir):\n",
    "\n",
    "    if date == \"20210218\":\n",
    "        if f in {'20210218_16:44:01.177-20210218_16:44:33.943','20210218_16:51:41.403-20210218_16:52:20.100','20210218_16:53:18.712-20210218_16:54:04.193'}:\n",
    "            index = ['no']*len(ir)\n",
    "        if f in {'20210218_16:57:18.254-20210218_16:58:03.582','20210218_17:00:26.185-20210218_17:01:01.872','20210218_17:01:08.542-20210218_17:01:43.332'}:\n",
    "            index = ['up']*len(ir)\n",
    "        if f in {'20210218_17:03:41.837-20210218_17:04:15.747','20210218_17:05:08.986-20210218_17:05:42.206','20210218_17:04:31.485-20210218_17:05:06.079'}:\n",
    "            index = ['side']*len(ir)\n",
    "            \n",
    "    if date == \"20210224\":\n",
    "        if f in {'20210224_17:55:21.433-20210224_17:55:55.191','20210224_17:56:04.294-20210224_17:56:39.426','20210224_17:57:00.457-20210224_17:57:34.537'}:\n",
    "            index = ['up']*len(ir)\n",
    "        if f in {'20210224_17:59:54.251-20210224_18:00:26.660','20210224_18:00:38.187-20210224_18:01:11.561','20210224_18:01:26.215-20210224_18:01:58.796'}:\n",
    "            index = ['side']*len(ir)\n",
    "        if f in {'20210224_18:06:50.537-20210224_18:07:23.479','20210224_18:08:00.368-20210224_18:08:33.322','20210224_18:08:37.805-20210224_18:09:11.272'}:\n",
    "            index = ['no']*len(ir)\n",
    "            \n",
    "    if date == \"20210302\":\n",
    "        if f in {'20210302_18:23:30.772-20210302_18:24:04.601','20210302_18:24:11.484-20210302_18:24:43.738','20210302_18:24:49.526-20210302_18:25:20.850'}:\n",
    "            index = ['up']*len(ir)\n",
    "        if f in {'20210302_18:32:33.332-20210302_18:33:05.962','20210302_18:33:12.699-20210302_18:33:44.740','20210302_18:33:51.921-20210302_18:34:24.773'}:\n",
    "            index = ['side']*len(ir)\n",
    "        if f in {'20210302_18:36:32.772-20210302_18:37:04.393','20210302_18:37:21.275-20210302_18:37:52.954','20210302_18:37:59.677-20210302_18:38:31.361'}:\n",
    "            index = ['no']*len(ir)\n",
    "     \n",
    "    ir.index = index\n",
    "    return ir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "import pickle\n",
    "\n",
    "def randomForest(train, train_labels):\n",
    "    # Create the model with 100 trees\n",
    "    model = RandomForestClassifier(n_estimators=100, criterion=\"entropy\",\n",
    "                                   max_features = 'sqrt')\n",
    "    # Fit on training data\n",
    "    model.fit(train, train_labels)\n",
    "    #pickle.dump(model, open(root + str(test_env) + \"/training_phase/\" + \"randomForest.sav\", 'wb'))\n",
    "    return model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def random_undersampling(mots):\n",
    "    print (\"Undersampling..\")\n",
    "    all_mots = pd.DataFrame()\n",
    "    tr = mots\n",
    "    labels = mots.index.values.reshape(-1)\n",
    "    feature_num = np.unique(labels, return_counts=True)\n",
    "    #print(feature_num)\n",
    "    min_feature_num = min(feature_num[1])\n",
    "    #print(min_feature_num)\n",
    "    feature_num = np.stack(feature_num, axis=1) # label of each cluster and number of instances\n",
    "    for x in feature_num:\n",
    "        #print(x)\n",
    "        #try:\n",
    "        delete_itr = len(mots.loc[mots.index == x[0]]) - min_feature_num\n",
    "        #print(delete_itr)\n",
    "        label_loc = train_data.loc[mots.index == x[0]]\n",
    "        randoms = label_loc.sample(len(label_loc) - delete_itr)\n",
    "        #display(randoms)\n",
    "        all_mots = pd.concat([all_mots,randoms],axis=0)\n",
    "        #display(all_mots) \n",
    "    return all_mots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_mfcc_feat(imp_res):\n",
    "    sample_rate = 192000\n",
    "    lbp_set = pd.DataFrame()\n",
    "    mfcc_set = pd.DataFrame()\n",
    "    for index, row in imp_res.iterrows():\n",
    "        signal = np.array(row)\n",
    "        #formants = get_formants(signal)\n",
    "        mfcc = calc_mfcc(sample_rate,signal)\n",
    "        mfcc_set = pd.concat([mfcc_set,pd.DataFrame(mfcc.flatten()).T],axis=0)\n",
    "        #lbp = lbp_feat_calc(mfcc)\n",
    "        #lbp_set = pd.concat([lbp_set,lbp], axis=0)\n",
    "        #formant_set = pd.concat([formant_set, formants,axis=0])\n",
    "    #lbp_set.index = imp_res.index\n",
    "    mfcc_set.index = imp_res.index\n",
    "    return mfcc_set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def extract_spectral_feat(imp_res):\n",
    "    spectrum_set = pd.DataFrame()\n",
    "    for index, row in imp_res.iterrows():\n",
    "        signal = np.array(row)\n",
    "        f = calculate_spectrum(signal)\n",
    "        spectrum_set = pd.concat([spectrum_set, f],axis=0)\n",
    "\n",
    "    spectrum_set.index = imp_res.index\n",
    "    return spectrum_set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['20210310_15:25:26.159-20210310_15:25:39.816',\n",
       " '20210310_15:25:48.350-20210310_15:25:58.158',\n",
       " '20210310_15:26:14.684-20210310_15:26:25.036',\n",
       " '20210310_15:26:36.351-20210310_15:26:45.720',\n",
       " '20210310_15:26:59.160-20210310_15:27:08.845',\n",
       " '20210310_15:27:20.548-20210310_15:27:30.566',\n",
       " '20210310_15:29:00.353-20210310_15:29:09.829',\n",
       " '20210310_15:29:25.107-20210310_15:29:34.689',\n",
       " '20210310_15:29:41.711-20210310_15:29:51.347',\n",
       " '20210310_15:30:04.369-20210310_15:30:13.898',\n",
       " '20210310_15:30:21.964-20210310_15:30:32.030',\n",
       " '20210310_15:30:50.167-20210310_15:31:01.015',\n",
       " '20210310_15:31:09.318-20210310_15:31:20.694',\n",
       " '20210310_15:31:57.174-20210310_15:32:07.006',\n",
       " '20210310_15:32:14.252-20210310_15:32:24.462',\n",
       " '20210310_15:32:32.730-20210310_15:32:42.915',\n",
       " '20210310_15:32:48.233-20210310_15:32:58.401',\n",
       " '20210310_15:33:58.721-20210310_15:34:08.178',\n",
       " '20210310_15:34:21.045-20210310_15:34:32.102',\n",
       " '20210310_15:34:48.696-20210310_15:34:57.898',\n",
       " '20210310_15:42:00.571-20210310_15:42:11.946',\n",
       " '20210310_15:42:19.717-20210310_15:42:31.077',\n",
       " '20210310_15:42:43.374-20210310_15:42:54.045',\n",
       " '20210310_15:43:03.762-20210310_15:43:16.249',\n",
       " '20210310_15:44:04.924-20210310_15:44:15.189',\n",
       " '20210310_15:45:59.889-20210310_15:46:12.812',\n",
       " '20210310_15:46:20.984-20210310_15:46:32.410',\n",
       " '20210310_15:47:27.823-20210310_15:47:37.342',\n",
       " '20210310_15:49:41.258-20210310_15:49:51.348',\n",
       " '20210310_15:50:03.345-20210310_15:50:15.186',\n",
       " '20210310_15:50:19.873-20210310_15:50:29.207',\n",
       " '20210310_15:51:04.495-20210310_15:51:14.504',\n",
       " '20210310_15:51:22.201-20210310_15:51:34.120',\n",
       " '20210310_15:51:45.847-20210310_15:51:55.083',\n",
       " '20210310_15:52:00.814-20210310_15:52:11.246',\n",
       " '20210310_15:52:24.012-20210310_15:52:34.588',\n",
       " '20210310_15:52:48.777-20210310_15:52:58.321',\n",
       " '20210310_15:54:24.829-20210310_15:54:36.180',\n",
       " '20210310_15:58:17.102-20210310_15:58:34.089',\n",
       " '20210315_17:05:24.467-20210315_17:05:35.463',\n",
       " '20210315_17:05:51.089-20210315_17:06:00.494',\n",
       " '20210315_17:06:18.458-20210315_17:06:28.282',\n",
       " '20210315_17:07:11.513-20210315_17:07:20.684',\n",
       " '20210315_17:07:38.925-20210315_17:07:48.142',\n",
       " '20210315_17:08:00.532-20210315_17:08:09.611',\n",
       " '20210315_17:08:39.633-20210315_17:08:48.837',\n",
       " '20210315_17:09:10.210-20210315_17:09:20.081',\n",
       " '20210315_17:09:47.785-20210315_17:09:56.866',\n",
       " '20210315_17:10:08.695-20210315_17:10:18.533',\n",
       " '20210315_17:10:40.285-20210315_17:10:49.683',\n",
       " '20210315_17:11:54.379-20210315_17:12:04.246',\n",
       " '20210315_17:12:13.407-20210315_17:12:23.341',\n",
       " '20210315_17:13:29.822-20210315_17:13:40.619',\n",
       " '20210315_17:17:00.289-20210315_17:17:10.236',\n",
       " '20210315_17:19:31.337-20210315_17:19:40.940',\n",
       " '20210315_17:20:38.369-20210315_17:20:48.298',\n",
       " '20210315_17:21:29.553-20210315_17:21:39.505',\n",
       " '20210315_17:21:47.752-20210315_17:21:57.917',\n",
       " '20210315_17:23:00.273-20210315_17:23:09.830',\n",
       " '20210319_16:08:41.692-20210319_16:08:51.649',\n",
       " '20210319_16:10:10.704-20210319_16:10:21.506',\n",
       " '20210319_16:10:32.051-20210319_16:10:42.621',\n",
       " '20210319_16:11:12.300-20210319_16:11:24.827',\n",
       " '20210319_16:13:09.655-20210319_16:13:20.391',\n",
       " '20210319_16:14:28.970-20210319_16:14:38.999',\n",
       " '20210319_16:14:50.583-20210319_16:15:00.821',\n",
       " '20210319_16:15:18.712-20210319_16:15:29.511',\n",
       " '20210319_16:15:55.217-20210319_16:16:06.432',\n",
       " '20210319_16:16:17.283-20210319_16:16:28.357',\n",
       " '20210319_16:16:47.785-20210319_16:16:57.626',\n",
       " '20210319_16:17:22.477-20210319_16:17:32.588',\n",
       " '20210319_16:17:45.271-20210319_16:17:57.477',\n",
       " '20210319_16:18:28.688-20210319_16:18:39.650',\n",
       " '20210319_16:19:24.958-20210319_16:19:34.607',\n",
       " '20210319_16:21:29.421-20210319_16:21:39.386',\n",
       " '20210319_16:21:59.598-20210319_16:22:09.200',\n",
       " '20210319_16:23:03.444-20210319_16:23:13.463',\n",
       " '20210319_16:23:44.170-20210319_16:23:54.026',\n",
       " '20210319_16:26:08.675-20210319_16:26:18.199',\n",
       " '20210319_16:26:51.249-20210319_16:27:02.576']"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "session_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_data(data_set):\n",
    "    X = data_set\n",
    "    y = data_set.index\n",
    "    \n",
    "    return X,y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def label_data(f, ir,date):\n",
    "    ir = ir\n",
    "    imp_res = pd.DataFrame()\n",
    "    #print(date)\n",
    "    #for f in onlyfiles:\n",
    "    #ir = pd.read_csv(\"processed/\" + \"mfcc/\" + date + \"/left/\" + f, index_col=False, header=None)\n",
    "    if date == '20210310':\n",
    "        #print(datetime.datetime.strptime(f.split(\"-\")[0],'%Y%m%d_%H:%M:%S.%f'))\n",
    "        if datetime.datetime.strptime(f.split(\"-\")[0],'%Y%m%d_%H:%M:%S.%f') >= datetime.datetime.strptime(\"20210310_15:25:26_159\",'%Y%m%d_%H:%M:%S_%f') and datetime.datetime.strptime(f.split(\"-\")[1],'%Y%m%d_%H:%M:%S.%f') <= datetime.datetime.strptime(\"20210310_15:34:57_898\",'%Y%m%d_%H:%M:%S_%f'):\n",
    "            index = ['tree']*len(ir)\n",
    "            #print(\"tree\")\n",
    "        elif datetime.datetime.strptime(f.split(\"-\")[0],'%Y%m%d_%H:%M:%S.%f') >= datetime.datetime.strptime(\"20210310_15:42:00_571\",'%Y%m%d_%H:%M:%S_%f') and datetime.datetime.strptime(f.split(\"-\")[1],'%Y%m%d_%H:%M:%S.%f') <= datetime.datetime.strptime(\"20210310_15:58:34_089\",'%Y%m%d_%H:%M:%S_%f'):\n",
    "            index = ['car']*len(ir)\n",
    "            #print(\"car\")\n",
    "    elif date == '20210315':\n",
    "        if datetime.datetime.strptime(f.split(\"-\")[0],'%Y%m%d_%H:%M:%S.%f') >= datetime.datetime.strptime(\"20210315_17:05:24_467\",'%Y%m%d_%H:%M:%S_%f') and datetime.datetime.strptime(f.split(\"-\")[1],'%Y%m%d_%H:%M:%S.%f') <= datetime.datetime.strptime(\"20210315_17:23:09_830\",'%Y%m%d_%H:%M:%S_%f'):\n",
    "            index = ['wall']*len(ir)\n",
    "    #print(np.unique(index,return_counts = True))\n",
    "    elif date == '20210319':\n",
    "        if datetime.datetime.strptime(f.split(\"-\")[0],'%Y%m%d_%H:%M:%S.%f') >= datetime.datetime.strptime(\"20210319_13:05:24_467\",'%Y%m%d_%H:%M:%S_%f') and datetime.datetime.strptime(f.split(\"-\")[1],'%Y%m%d_%H:%M:%S.%f') <= datetime.datetime.strptime(\"20210319_18:23:09_830\",'%Y%m%d_%H:%M:%S_%f'):\n",
    "            index = ['signpost']*len(ir)\n",
    "    ir.index = index\n",
    "        \n",
    "    return ir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import OneClassSVM \n",
    "def one_class_svm(training_data):\n",
    "    #temp = pd.concat([training_data,testing_data])\n",
    "    training_len = len(training_data)\n",
    "    #training_data.index = training_labels[1]\n",
    "    \n",
    "    #display(training_data.head())\n",
    "    #display(testing_data.head())\n",
    "    \n",
    "    labels = training_data.index#[1].values.reshape(-1)\n",
    "    feature_num = np.unique(labels, return_counts=True)\n",
    "    locs = feature_num[0]\n",
    "    data = pd.DataFrame()\n",
    "    for l in locs:\n",
    "        #display(training_data.loc[training_data.index == l].head())\n",
    "        print (\"training svm....\", l)\n",
    "        svm = OneClassSVM(kernel='rbf', gamma=0.000001)\n",
    "        svm.fit(training_data.loc[training_data.index == l])\n",
    "        print (\"outlier predicting...\", l) \n",
    "        #display(testing_data.loc[testing_data.index == l])\n",
    "        #try:\n",
    "        out_l = svm.predict(training_data.loc[training_data.index == l])\n",
    "        print (out_l)\n",
    "        #print (np.unique(out_l, return_counts=True))\n",
    "        out_l = pd.DataFrame(out_l,columns = ['out_l']) \n",
    "        out_l.index = training_data.loc[training_data.index == l].index\n",
    "\n",
    "        out = pd.concat([out_l,training_data.loc[training_data.index == l]],axis=1)\n",
    "        data = pd.concat([data,out])\n",
    "        data = data[data.out_l != 1]\n",
    "        data.drop([\"out_l\"],axis=1,inplace=True)\n",
    "        \n",
    "    #data.drop(data['out_l']==-1,axis=0,inplace=True)\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "def pca_calc(training_data, testing_data):\n",
    "    #display(all_acc)\n",
    "    # Concat with keys\n",
    "    train_labels = training_data.index\n",
    "    test_labels = test_data.index\n",
    "    temp = pd.concat([training_data,testing_data])\n",
    "    training_len = len(training_data)\n",
    "    testing_len = len(testing_data)\n",
    "    # Selecting data from multi index \n",
    "    \n",
    "    \n",
    "    #temp = np.array(temp)\n",
    "\n",
    "    pca = PCA(n_components=300)\n",
    "    acc_w = pca.fit_transform(temp)\n",
    "    #display(acc_w)\n",
    "    train = pd.DataFrame(acc_w[0:training_len])\n",
    "    test = pd.DataFrame(acc_w[training_len:])\n",
    "    #train,test = temp.xs(0),temp.xs(1)    \n",
    "    train.index = train_labels\n",
    "    test.index = test_labels\n",
    "    return train,test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torch\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "class DACNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        \n",
    "        #Add more convolution layers and make the input to the FC small\n",
    "        self.frequency_feature_extractor = nn.Sequential(\n",
    "           nn.Conv1d(2, 6, 3, stride=1),\n",
    "           #nn.MaxPool1d(2,2),nn.ReLU(True),\n",
    "          nn.Conv1d(6, 16, 3, stride=1),\n",
    "           #nn.MaxPool1d(2,2),nn.ReLU(True),  \n",
    "          nn.Conv1d(16, 8, 10, stride=1),\n",
    "          # nn.MaxPool1d(2,2), nn.ReLU(True),\n",
    "            nn.Conv1d(8, 10, 3, stride=1),\n",
    "           #nn.MaxPool1d(2,2), nn.ReLU(True)\n",
    "        )\n",
    "        \n",
    "        self.time_feature_extractor = nn.Sequential(\n",
    "           nn.Conv2d(2, 6, 3, stride=1),\n",
    "           nn.MaxPool2d(2,2),nn.ReLU(True),\n",
    "          nn.Conv2d(6, 16, 3, stride=1),\n",
    "           nn.MaxPool2d(2,2),nn.ReLU(True),  \n",
    "          #nn.Conv1d(16, 8, 10, stride=1),\n",
    "          # nn.MaxPool1d(2,2), nn.ReLU(True),\n",
    "          #  nn.Conv1d(20, 10, 3, stride=2),\n",
    "          # nn.MaxPool1d(2,2), nn.ReLU(True)\n",
    "        )\n",
    "        \n",
    "        self.num_cnn_features = 374#932#886#176#496#448#352#94#720\n",
    "        self.class_classifier = nn.Sequential(\n",
    "#          nn.Linear(self.num_cnn_features, 80),nn.BatchNorm1d(80),nn.ReLU(True), nn.Dropout(0.2),\n",
    "#             nn.Linear(80, 20),nn.BatchNorm1d(20),nn.LeakyReLU(True),nn.Dropout(0.2),\n",
    "#             nn.Linear(20, 10),nn.BatchNorm1d(10),nn.LeakyReLU(True),nn.Dropout(0.2),\n",
    "#           nn.Linear(10, 4), nn.LeakyReLU(True),\n",
    "            nn.Linear(self.num_cnn_features, 120),nn.BatchNorm1d(120), nn.LeakyReLU(True),nn.Dropout(0.2),\n",
    "            nn.Linear(120, 40),nn.BatchNorm1d(40), nn.LeakyReLU(True),nn.Dropout(0.2),\n",
    "            nn.Linear(40, 10),nn.BatchNorm1d(10), nn.LeakyReLU(True),nn.Dropout(0.2),\n",
    "            nn.Linear(10, 4), nn.LeakyReLU(True)\n",
    "        )\n",
    "        \n",
    "#         self.domain_classifier = nn.Sequential(\n",
    "#            nn.Linear(self.num_cnn_features, 120),\n",
    "#            nn.ReLU(True),\n",
    "#           nn.Linear(120, 2),\n",
    "#           nn.LogSoftmax(dim=1),\n",
    "#         )\n",
    "        \n",
    "    def forward(self, x):\n",
    "        features = x.view(4,-1)\n",
    "        #print(x.size())\n",
    "        \n",
    "#         frequency_domain, time_domain = torch.split(x,[188,744],dim=2)\n",
    "#         frequency_domain = frequency_domain.view(4,2,int(frequency_domain.size()[2]/2))\n",
    "#         time_domain = time_domain.view(4,2,31,12)\n",
    "#         frequency_features = self.frequency_feature_extractor(frequency_domain)\n",
    "#         time_features = self.time_feature_extractor(time_domain)\n",
    "#         features = torch.cat((frequency_features.view(4,-1),time_features.view(4,-1)),1)\n",
    "        #features_grl = GradientReversalFn.apply(features, grl_lambda)\n",
    "        class_pred = self.class_classifier(features) #classify on regular features\n",
    "        #domain_pred = self.domain_classifier(features_grl) #classify on features after GRL\n",
    "        return class_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = DACNN()\n",
    "device = torch.device('cuda:1')\n",
    "model = model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DACNN(\n",
       "  (frequency_feature_extractor): Sequential(\n",
       "    (0): Conv1d(2, 6, kernel_size=(3,), stride=(1,))\n",
       "    (1): Conv1d(6, 16, kernel_size=(3,), stride=(1,))\n",
       "    (2): Conv1d(16, 8, kernel_size=(10,), stride=(1,))\n",
       "    (3): Conv1d(8, 10, kernel_size=(3,), stride=(1,))\n",
       "  )\n",
       "  (time_feature_extractor): Sequential(\n",
       "    (0): Conv2d(2, 6, kernel_size=(3, 3), stride=(1, 1))\n",
       "    (1): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    (2): ReLU(inplace)\n",
       "    (3): Conv2d(6, 16, kernel_size=(3, 3), stride=(1, 1))\n",
       "    (4): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    (5): ReLU(inplace)\n",
       "  )\n",
       "  (class_classifier): Sequential(\n",
       "    (0): Linear(in_features=186, out_features=100, bias=True)\n",
       "    (1): BatchNorm1d(100, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): LeakyReLU(negative_slope=True)\n",
       "    (3): Dropout(p=0.2)\n",
       "    (4): Linear(in_features=100, out_features=4, bias=True)\n",
       "    (5): LeakyReLU(negative_slope=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def func(epoch):\n",
    "    if epoch < 80:\n",
    "        return 1.0\n",
    "    elif epoch < 110:\n",
    "        return 0.8#0.5**2\n",
    "    elif epoch < 130:\n",
    "        return 0.5#0.5**3\n",
    "    elif epoch < 140:\n",
    "        return 0.1#0.5**3   \n",
    "    elif epoch < 150:\n",
    "        return 0.05#0.5**3  \n",
    "    elif epoch < 160:\n",
    "        return 0.01#0.5**3  \n",
    "    elif epoch < 170:\n",
    "        return 0.005#0.5**3  \n",
    "    elif epoch < 180:\n",
    "        return 0.001#0.5**3  \n",
    "    elif epoch < 180:\n",
    "        return 0.0005#0.5**3 \n",
    "    else:\n",
    "        return 0.0001#0.5**4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.optim as optim\n",
    "\n",
    "lr = 0.0001\n",
    "n_epochs = 150#150\n",
    "\n",
    "#Setup optimizer\n",
    "#class_optimizer = optim.SGD(model.parameters(), lr=lr, momentum=0.9)\n",
    "#disc_optimizer = optim.SGD(model.parameters(), lr=0.00001, momentum=0.9)\n",
    "class_optimizer = optim.Adam(model.parameters())\n",
    "\n",
    "#Separate loss functions for classifier and discriminator\n",
    "#weights = [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.1, 1.0] #20200706\n",
    "#class_weights = torch.FloatTensor(weights)\n",
    "loss_fn_class = nn.CrossEntropyLoss()#weight=class_weights.to(device))\n",
    "\n",
    "#loss_fn_domain = nn.CrossEntropyLoss()\n",
    "class_scheduler = torch.optim.lr_scheduler.LambdaLR(class_optimizer, lr_lambda = func)#lambda epoch: 0.95 ** epoch)\n",
    "#disc_scheduler = torch.optim.lr_scheduler.LambdaLR(disc_optimizer, lr_lambda = func)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.utils.data as data_utils\n",
    "\n",
    "\n",
    "def make_test_dataloader(targets,data):\n",
    "    torch_labels = torch.tensor(targets)\n",
    "    torch_data = torch.tensor(data.values)\n",
    "    dataset = data_utils.TensorDataset(torch_data,torch_labels)\n",
    "    #trainset = torch.stack([torch_training_data,torch_training_labels])\n",
    "    dataloader = torch.utils.data.DataLoader(dataset, batch_size=batch_size,shuffle = False, drop_last=True,num_workers=2)\n",
    "    return dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_train_dataloader(targets,data):\n",
    "    torch_labels = torch.tensor(targets)\n",
    "    torch_data = torch.tensor(data.values)\n",
    "    dataset = data_utils.TensorDataset(torch_data,torch_labels)\n",
    "    #trainset = torch.stack([torch_training_data,torch_training_labels])\n",
    "    dataloader = torch.utils.data.DataLoader(dataset, batch_size=batch_size,shuffle=True, drop_last=True,num_workers=2)\n",
    "    return dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "#train_dataloader, test_dataloader = prep_data(X_train, y_train, X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_cm(confusion_matrix,classes):\n",
    "    import seaborn as sns\n",
    "    plt.figure(figsize=(10,8))\n",
    "    ax= plt.subplot()\n",
    "    #sns.heatmap(confusion_matrix/confusion_matrix.sum(0), annot=True, ax = ax, cmap = \"Greys\", vmin=0, vmax=1)\n",
    "    y_axis_labels = classes\n",
    "    x_axis_labels = classes\n",
    "    sns.heatmap(confusion_matrix, annot=True, fmt = 'g', ax = ax, cmap = \"Greys\", xticklabels=x_axis_labels, yticklabels=y_axis_labels)\n",
    "    #sns.heatmap(confusion_matrix, annot=True, fmt='g', ax = ax, cmap = \"Greys\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_data(dates,session):\n",
    "    data = pd.DataFrame()\n",
    "    for date in dates:\n",
    "        #print(session[:8])\n",
    "        #print(date)\n",
    "        if date == session[:8]:\n",
    "            #print(session)\n",
    "            feature1 = pd.read_csv(\"processed/\" + \"spectra/\" + date + \"/right/\" + session, index_col=False, header=None)\n",
    "            feature2 = pd.read_csv(\"processed/\" + \"spectra/\" + date + \"/left/\" + session, index_col=False, header=None)\n",
    "            #feature3 =pd.read_csv(\"processed/\" + \"mfccs/\" + date + \"/right/\" + session, index_col=False, header=None)\n",
    "            #feature4 = pd.read_csv(\"processed/\" + \"mfccs/\" + date + \"/left/\" + session, index_col=False, header=None)\n",
    "            feature5 = diff_calc(feature1)\n",
    "            feature6 = diff_calc(feature2)\n",
    "            #display(feature6.head())\n",
    "            data = pd.concat([feature1,feature2,feature5,feature6],axis=1,ignore_index=True)\n",
    "            \n",
    "            #data = feature1\n",
    "            #data.dropna(inplace=True,axis=0)\n",
    "            data = label_data(session,data,date)\n",
    "            #print(np.unique(data.index))\n",
    "        #except:print(\"\")#data = pd.DataFrame()\n",
    "    #print(len(data.T))    \n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def diff_calc(df_slize):\n",
    "    df_diff = df_slize.diff(axis=1)\n",
    "    df_diff.dropna(inplace=True,axis=1)\n",
    "    #norm_diff = df_diff / df_diff.max(axis=1).values\n",
    "    norm_diff = df_diff.divide(df_diff.max(axis=1).values, axis=0)\n",
    "    return norm_diff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "def majority_vote(y_pred):\n",
    "    #print(y_pred)\n",
    "#     delete_list = []\n",
    "#     c = 0\n",
    "#     for p in prob:\n",
    "#         if p.max() < 0.5:\n",
    "#             delete_list.append(c)\n",
    "#         c = c + 1\n",
    "#     y_pred = np.delete(y_pred,delete_list)\n",
    "#     if y_pred.size > 0:\n",
    "    maj = Counter(y_pred).most_common(1)[0][0]\n",
    "#     else: return []\n",
    "    return maj "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def weighted_majority_vote(y_pred,prob):\n",
    "    delete_list = []\n",
    "    c = 0\n",
    "    gini = gini_calc(prob)\n",
    "    for g in gini:\n",
    "        if g > 0.5:\n",
    "            delete_list.append(c)\n",
    "        c = c + 1\n",
    "    temp_y_pred = np.delete(y_pred,delete_list)\n",
    "    if temp_y_pred.size > 0:\n",
    "        maj = Counter(temp_y_pred).most_common(1)[0][0]\n",
    "    else: return majority_vote(y_pred)\n",
    "    return maj "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gini_calc(prob):\n",
    "    gini = []\n",
    "    for p in prob:\n",
    "        gini.append(1-np.sum(p**2))\n",
    "    return gini"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import preprocessing\n",
    "def test_nn_model(model):\n",
    "    model.train(False)\n",
    "    model.eval()\n",
    "    test_cpred = []\n",
    "    test_lbl = []\n",
    "    test_total = 0.0\n",
    "    correct = 0.0\n",
    "    running_loss = 0.0\n",
    "    total = 0.0\n",
    "    with torch.no_grad():\n",
    "        confusion_matrix = torch.zeros(nb_classes, nb_classes)\n",
    "        for data in test_dataloader:\n",
    "            seg, labels = data\n",
    "            outputs = model(seg.unsqueeze(1).float().to(device))\n",
    "            _, predicted = torch.max(outputs, 1)\n",
    "            loss = loss_fn_class(outputs.to(device), labels.to(device))\n",
    "\n",
    "            for t, p in zip(labels.view(-1), predicted.view(-1)):\n",
    "                confusion_matrix[t.long(), p.long()] += 1\n",
    "\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels.to(device)).sum().item()\n",
    "            test_total += labels.size(0)\n",
    "            running_loss += loss.item()\n",
    "            #Remove \"other\" from the accuracy\n",
    "\n",
    "            p = predicted.cpu().tolist()\n",
    "            test_cpred.extend(p)\n",
    "            l = labels.cpu().tolist()\n",
    "            test_lbl.extend(l)\n",
    "            #break\n",
    "            #predicted[predicted==le.transform([\"other\"])[0]] = -1\n",
    "            #running_corrects += torch.sum(predicted == labels.to(device)).item()\n",
    "\n",
    "        test_lbl = label_encoder.inverse_transform(test_lbl)\n",
    "        test_cpred = label_encoder.inverse_transform(test_cpred)\n",
    "        class_report = (classification_report(test_lbl, test_cpred))\n",
    "        val_acc = correct/test_total\n",
    "        val_loss = running_loss/test_total\n",
    "        return test_lbl, test_cpred, val_acc, val_loss, confusion_matrix\n",
    "        #print(class_report)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import torch.optim as optim\n",
    "\n",
    "def train_nn_model():\n",
    "    \n",
    "    model = DACNN()\n",
    "    device = torch.device('cuda:1')\n",
    "    model = model.to(device)\n",
    "\n",
    "    lr = 0.0001\n",
    "    n_epochs = 200#150\n",
    "\n",
    "    #Setup optimizer\n",
    "    class_optimizer = optim.SGD(model.parameters(), lr=lr, momentum=0.9)\n",
    "    #disc_optimizer = optim.SGD(model.parameters(), lr=0.00001, momentum=0.9)\n",
    "    #class_optimizer = optim.Adam(model.parameters())\n",
    "\n",
    "    #Separate loss functions for classifier and discriminator\n",
    "    #weights = [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.1, 1.0] #20200706\n",
    "    #class_weights = torch.FloatTensor(weights)\n",
    "    loss_fn_class = nn.CrossEntropyLoss()#weight=class_weights.to(device))\n",
    "\n",
    "    #loss_fn_domain = nn.CrossEntropyLoss()\n",
    "    #class_scheduler = torch.optim.lr_scheduler.LambdaLR(class_optimizer, lr_lambda = func)#lambda epoch: 0.95 ** epoch)\n",
    "    #disc_scheduler = torch.optim.lr_scheduler.LambdaLR(disc_optimizer, lr_lambda = func)\n",
    "    \n",
    "    \n",
    "\n",
    "    #batch_size = batch_size\n",
    "    #max_batches = min(len(train_dataloader),len(test_dataloader))\n",
    "    sdl = []\n",
    "    tdl = []\n",
    "    cl = []\n",
    "    running_corrects = 0.0\n",
    "    total = 0.0\n",
    "    train_running_corrects = 0.0\n",
    "    train_running_loss = 0.0\n",
    "    train_total = 0.0\n",
    "    loss_per_epoch = 0.0\n",
    "    val_losses = []\n",
    "    val_accuracies = []\n",
    "    train_losses = []\n",
    "    train_accuracies = []\n",
    "    learning_rate = []\n",
    "\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    running_loss=0\n",
    "\n",
    "\n",
    "\n",
    "    for epoch_idx in range(n_epochs):\n",
    "\n",
    "\n",
    "        confusion_matrix = torch.zeros(nb_classes, nb_classes)\n",
    "\n",
    "        #class_scheduler.step()\n",
    "        #learning_rate.append(class_scheduler.get_lr())\n",
    "\n",
    "        #print (envs[0])\n",
    "        cpred = []\n",
    "        lbl = []\n",
    "        print(f'Epoch {epoch_idx+1:04d} / {n_epochs:04d}', end='\\n=====================================\\n')\n",
    "        dl_source_iter = iter(train_dataloader)\n",
    "        dl_target_iter = iter(test_dataloader)\n",
    "        model.train()\n",
    "        for batch_idx in range(len(train_dataloader)):#range(len(train_dataloader)):#range(max_batches):\n",
    "            X_s, y_s = next(dl_source_iter)\n",
    "            class_pred = model(X_s.unsqueeze(1).float().to(device))\n",
    "            _, c_pred = torch.max(class_pred, 1)\n",
    "            c_pred.to(device)\n",
    "            #c_pred[c_pred==7] = -1\n",
    "            train_running_corrects += torch.sum(c_pred == y_s.to(device)).item()\n",
    "            train_total += y_s.size(0)\n",
    "\n",
    "            loss_s_label = loss_fn_class(class_pred, y_s.to(device))\n",
    "            train_running_loss += loss_s_label.item()\n",
    "            class_optimizer.zero_grad()\n",
    "            loss_s_label.backward(retain_graph=True)\n",
    "            class_optimizer.step()\n",
    "\n",
    "#             if batch_idx%10 == 9:\n",
    "#                 print(f'[{batch_idx+1}/{batch_size}] '\n",
    "#                       f'class_loss: {loss_s_label.item():.4f} '\n",
    "#                  )\n",
    "            p = c_pred.cpu().tolist()\n",
    "            cpred.extend(p)\n",
    "            l = y_s.cpu().tolist()\n",
    "            lbl.extend(l)\n",
    "\n",
    "            total += y_s.size(0)\n",
    "            correct += (c_pred == y_s.to(device)).sum().item()\n",
    "\n",
    "            running_loss += loss_s_label.item()\n",
    "\n",
    "            for t, p in zip(y_s.view(-1), c_pred.view(-1)):\n",
    "                confusion_matrix[t.long(), p.long()] += 1\n",
    "\n",
    "            class_optimizer.zero_grad()\n",
    "            loss_s_label.backward(retain_graph=True)\n",
    "            class_optimizer.step()\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "        lbl = label_encoder.inverse_transform(lbl)\n",
    "        cpred = label_encoder.inverse_transform(cpred)\n",
    "        class_report = (classification_report(lbl, cpred))\n",
    "        #print(class_report)\n",
    "\n",
    "\n",
    "        #testing the network\n",
    "        test_lbl, test_cpred,val_acc, val_loss, test_confusion_matrix = test_nn_model(model)\n",
    "        val_accuracies.append(val_acc)\n",
    "        val_losses.append(val_loss)\n",
    "\n",
    "        train_epochs_acc = train_running_corrects / train_total\n",
    "        train_epochs_loss = train_running_loss / train_total#(len(train_dataloader)*(epoch_idx+1))\n",
    "        #print(\"Learning_rate = \",class_scheduler.get_lr())\n",
    "        print (\"Training accuracy =\", train_epochs_acc)\n",
    "        print (\"Training loss =\", train_epochs_loss)\n",
    "        print (\"Validation accuracy =\", val_acc)\n",
    "        print (\"Validation loss =\", val_loss)\n",
    "        #print('Accuracy of the network: %d %%' % (\n",
    "            #100 * correct / total))\n",
    "\n",
    "        epoch_loss = running_loss / len(test_dataloader)\n",
    "        epochs_acc = running_corrects / total\n",
    "        #val_losses.append(epoch_loss)\n",
    "        #val_accuracies.append(epochs_acc)\n",
    "        train_losses.append(train_epochs_loss)\n",
    "        train_accuracies.append(train_epochs_acc)\n",
    "        #plot_cm(test_confusion_matrix,label_encoder.classes_)\n",
    "        \n",
    "\n",
    "    return model,val_accuracies,val_losses,train_accuracies,train_losses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "def label_sessions(session_list):\n",
    "    sess_labels = []\n",
    "    for s in session_list:\n",
    "\n",
    "        if datetime.datetime.strptime(s.split(\"-\")[0],'%Y%m%d_%H:%M:%S.%f') >= datetime.datetime.strptime(\"20210310_15:25:26_159\",'%Y%m%d_%H:%M:%S_%f') and datetime.datetime.strptime(s.split(\"-\")[1],'%Y%m%d_%H:%M:%S.%f') <= datetime.datetime.strptime(\"20210310_15:34:57_898\",'%Y%m%d_%H:%M:%S_%f'):\n",
    "            sess_labels.append('tree')\n",
    "\n",
    "        elif datetime.datetime.strptime(s.split(\"-\")[0],'%Y%m%d_%H:%M:%S.%f') >= datetime.datetime.strptime(\"20210310_15:42:00_571\",'%Y%m%d_%H:%M:%S_%f') and datetime.datetime.strptime(s.split(\"-\")[1],'%Y%m%d_%H:%M:%S.%f') <= datetime.datetime.strptime(\"20210310_15:58:34_089\",'%Y%m%d_%H:%M:%S_%f'):\n",
    "            sess_labels.append('car')\n",
    "    \n",
    "        if datetime.datetime.strptime(s.split(\"-\")[0],'%Y%m%d_%H:%M:%S.%f') >= datetime.datetime.strptime(\"20210315_17:05:24_467\",'%Y%m%d_%H:%M:%S_%f') and datetime.datetime.strptime(s.split(\"-\")[1],'%Y%m%d_%H:%M:%S.%f') <= datetime.datetime.strptime(\"20210315_17:23:09_830\",'%Y%m%d_%H:%M:%S_%f'):\n",
    "            sess_labels.append('wall')\n",
    "\n",
    "        if datetime.datetime.strptime(s.split(\"-\")[0],'%Y%m%d_%H:%M:%S.%f') >= datetime.datetime.strptime(\"20210319_13:05:24_467\",'%Y%m%d_%H:%M:%S_%f') and datetime.datetime.strptime(s.split(\"-\")[1],'%Y%m%d_%H:%M:%S.%f') <= datetime.datetime.strptime(\"20210319_18:23:09_830\",'%Y%m%d_%H:%M:%S_%f'):\n",
    "            sess_labels.append('signpost')\n",
    "        \n",
    "    return sess_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "def normalize_data(training_data, testing_data):\n",
    "    train_len = len(training_data)\n",
    "    test_len = len(testing_data)\n",
    "    temp = pd.get_dummies(pd.concat([training_data,testing_data],keys=[0,1]))\n",
    "    temp.dropna(axis=1,inplace=True)\n",
    "    #scaler = MinMaxScaler()\n",
    "    #dt = scaler.fit_transform(temp)\n",
    "    \n",
    "    #temp_min = temp.min().min()\n",
    "    #temp_max = temp.max().max()\n",
    "    \n",
    "    #n_temp = (temp - temp_min)/(temp_max - temp_min)\n",
    "    n_temp=(temp-temp.mean())/temp.std()\n",
    "    \n",
    "    training_data = n_temp[:train_len]\n",
    "    testing_data = n_temp[train_len:]\n",
    "    training_data.reset_index(level=0, drop=True, inplace=True)\n",
    "    testing_data.reset_index(level=0, drop=True, inplace=True)\n",
    "    return pd.DataFrame(training_data), pd.DataFrame(testing_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "def write_test_list(filename, test_list):\n",
    "    with open(model_path + filename + '.txt', 'w') as f:\n",
    "        for item in test_list:\n",
    "            f.write(\"%s\\n\" % item)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_folder_structure():\n",
    "    if not os.path.exists(\"./models/\"+ version):\n",
    "        os.mkdir(\"./models/\"+ version,0o777)\n",
    "        \n",
    "    if not os.path.exists(\"./visual/\"+ version):\n",
    "        os.mkdir(\"./visual/\"+ version,0o777)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DACNN(\n",
       "  (frequency_feature_extractor): Sequential(\n",
       "    (0): Conv1d(2, 6, kernel_size=(3,), stride=(1,))\n",
       "    (1): Conv1d(6, 16, kernel_size=(3,), stride=(1,))\n",
       "    (2): Conv1d(16, 8, kernel_size=(10,), stride=(1,))\n",
       "    (3): Conv1d(8, 10, kernel_size=(3,), stride=(1,))\n",
       "  )\n",
       "  (time_feature_extractor): Sequential(\n",
       "    (0): Conv2d(2, 6, kernel_size=(3, 3), stride=(1, 1))\n",
       "    (1): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    (2): ReLU(inplace)\n",
       "    (3): Conv2d(6, 16, kernel_size=(3, 3), stride=(1, 1))\n",
       "    (4): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    (5): ReLU(inplace)\n",
       "  )\n",
       "  (class_classifier): Sequential(\n",
       "    (0): Linear(in_features=186, out_features=100, bias=True)\n",
       "    (1): BatchNorm1d(100, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): LeakyReLU(negative_slope=True)\n",
       "    (3): Dropout(p=0.2)\n",
       "    (4): Linear(in_features=100, out_features=4, bias=True)\n",
       "    (5): LeakyReLU(negative_slope=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'y_train' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m\u001b[0m",
      "\u001b[0;31mNameError\u001b[0mTraceback (most recent call last)",
      "\u001b[0;32m<ipython-input-43-d89cf80304c7>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munique\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mreturn_counts\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'y_train' is not defined"
     ]
    }
   ],
   "source": [
    "np.unique(y_train,return_counts=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'testy' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m\u001b[0m",
      "\u001b[0;31mNameError\u001b[0mTraceback (most recent call last)",
      "\u001b[0;32m<ipython-input-44-7d56f16da4d8>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munique\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtesty\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mreturn_counts\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'testy' is not defined"
     ]
    }
   ],
   "source": [
    "np.unique(testy,return_counts=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "from imblearn.over_sampling import RandomOverSampler,SMOTE\n",
    "def SMOTE_oversampling(training_data,training_labels):\n",
    "    #training_labels = all_mots[[1]]\n",
    "    #all_mots.drop([0],axis=1,inplace=True)\n",
    "    #all_mots.drop([1],axis=1,inplace=True)\n",
    "    #training_data = all_mots \n",
    "    ros = SMOTE(sampling_strategy={'car':300,'signpost':300,'tree':300,'wall':300},random_state=0)\n",
    "    X_resampled, y_resampled = ros.fit_resample(training_data, training_labels)\n",
    "    return X_resampled, y_resampled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'X_train' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m\u001b[0m",
      "\u001b[0;31mNameError\u001b[0mTraceback (most recent call last)",
      "\u001b[0;32m<ipython-input-46-9717b9e6f6a9>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtestX\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtesty\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mSMOTE_oversampling\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0my_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'X_train' is not defined"
     ]
    }
   ],
   "source": [
    "testX,testy=SMOTE_oversampling(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'testX' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m\u001b[0m",
      "\u001b[0;31mNameError\u001b[0mTraceback (most recent call last)",
      "\u001b[0;32m<ipython-input-47-1e5f01f866b7>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtestX\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'testX' is not defined"
     ]
    }
   ],
   "source": [
    "testX"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'X_train' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m\u001b[0m",
      "\u001b[0;31mNameError\u001b[0mTraceback (most recent call last)",
      "\u001b[0;32m<ipython-input-48-931765772341>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mX_train\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'X_train' is not defined"
     ]
    }
   ],
   "source": [
    "X_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "def pca_calc(data, labels):\n",
    "    pca = PCA(n_components=2)\n",
    "    data = pca.fit_transform(data)\n",
    "    data = pd.DataFrame(data)\n",
    "    data.index = labels\n",
    "    data.columns = ['x','y']\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'X_train' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m\u001b[0m",
      "\u001b[0;31mNameError\u001b[0mTraceback (most recent call last)",
      "\u001b[0;32m<ipython-input-50-8832c5a5f693>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mx1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpca_calc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'X_train' is not defined"
     ]
    }
   ],
   "source": [
    "x1 = pca_calc(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'x1' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m\u001b[0m",
      "\u001b[0;31mNameError\u001b[0mTraceback (most recent call last)",
      "\u001b[0;32m<ipython-input-52-b435b9c8f5fb>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0msns\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mscatterplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'x'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'y'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhue\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mx1\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mx1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgrid\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'x1' is not defined"
     ]
    }
   ],
   "source": [
    "sns.scatterplot(x='x', y='y', hue=x1.index, data=x1) \n",
    "plt.grid()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'testX' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m\u001b[0m",
      "\u001b[0;31mNameError\u001b[0mTraceback (most recent call last)",
      "\u001b[0;32m<ipython-input-53-b16a8478d1d4>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mx2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpca_calc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtestX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtesty\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'testX' is not defined"
     ]
    }
   ],
   "source": [
    "x2 = pca_calc(testX, testy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'x2' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m\u001b[0m",
      "\u001b[0;31mNameError\u001b[0mTraceback (most recent call last)",
      "\u001b[0;32m<ipython-input-54-2f7122b073ae>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0msns\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mscatterplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'x'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'y'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhue\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mx2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mx2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgrid\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'x2' is not defined"
     ]
    }
   ],
   "source": [
    "sns.scatterplot(x='x', y='y', hue=x2.index, data=x2) \n",
    "plt.grid()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Making model for session group 20210310_15:25:26.159-20210319_16:08:41.692\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/imblearn/utils/_validation.py:326: UserWarning: After over-sampling, the number of samples (300) in class car will be larger than the number of samples in the majority class (class #signpost -> 160)\n",
      "  n_samples_majority,\n",
      "/usr/local/lib/python3.6/dist-packages/imblearn/utils/_validation.py:326: UserWarning: After over-sampling, the number of samples (300) in class signpost will be larger than the number of samples in the majority class (class #signpost -> 160)\n",
      "  n_samples_majority,\n",
      "/usr/local/lib/python3.6/dist-packages/imblearn/utils/_validation.py:326: UserWarning: After over-sampling, the number of samples (300) in class tree will be larger than the number of samples in the majority class (class #signpost -> 160)\n",
      "  n_samples_majority,\n",
      "/usr/local/lib/python3.6/dist-packages/imblearn/utils/_validation.py:326: UserWarning: After over-sampling, the number of samples (300) in class wall will be larger than the number of samples in the majority class (class #signpost -> 160)\n",
      "  n_samples_majority,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0001 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.44083333333333335\n",
      "Training loss = 0.3110927981634935\n",
      "Validation accuracy = 0.5625\n",
      "Validation loss = 0.285992082208395\n",
      "Epoch 0002 / 0200\n",
      "=====================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/_classification.py:1221: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training accuracy = 0.47708333333333336\n",
      "Training loss = 0.3002217136820157\n",
      "Validation accuracy = 0.3125\n",
      "Validation loss = 0.2670943271368742\n",
      "Epoch 0003 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.49944444444444447\n",
      "Training loss = 0.2931669922007455\n",
      "Validation accuracy = 0.25\n",
      "Validation loss = 0.28770624473690987\n",
      "Epoch 0004 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.50875\n",
      "Training loss = 0.28826194427907464\n",
      "Validation accuracy = 0.46875\n",
      "Validation loss = 0.2509304154664278\n",
      "Epoch 0005 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.5195\n",
      "Training loss = 0.28470538343985874\n",
      "Validation accuracy = 0.5\n",
      "Validation loss = 0.24898050725460052\n",
      "Epoch 0006 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.5238888888888888\n",
      "Training loss = 0.28207855619490146\n",
      "Validation accuracy = 0.5\n",
      "Validation loss = 0.24754763208329678\n",
      "Epoch 0007 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.5302380952380953\n",
      "Training loss = 0.2795748238265514\n",
      "Validation accuracy = 0.46875\n",
      "Validation loss = 0.2513487311080098\n",
      "Epoch 0008 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.5327083333333333\n",
      "Training loss = 0.2777343236034115\n",
      "Validation accuracy = 0.5625\n",
      "Validation loss = 0.23373657651245594\n",
      "Epoch 0009 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.5343518518518519\n",
      "Training loss = 0.2755330360211708\n",
      "Validation accuracy = 0.3125\n",
      "Validation loss = 0.25979672465473413\n",
      "Epoch 0010 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.5386666666666666\n",
      "Training loss = 0.27374989281843104\n",
      "Validation accuracy = 0.46875\n",
      "Validation loss = 0.24591132439672947\n",
      "Epoch 0011 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.5415909090909091\n",
      "Training loss = 0.27194971653999706\n",
      "Validation accuracy = 0.5625\n",
      "Validation loss = 0.21891282871365547\n",
      "Epoch 0012 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.543125\n",
      "Training loss = 0.27079939604012504\n",
      "Validation accuracy = 0.375\n",
      "Validation loss = 0.25557899568229914\n",
      "Epoch 0013 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.5446794871794872\n",
      "Training loss = 0.2697202638307443\n",
      "Validation accuracy = 0.5\n",
      "Validation loss = 0.24753327388316393\n",
      "Epoch 0014 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.5453571428571429\n",
      "Training loss = 0.2688042093245756\n",
      "Validation accuracy = 0.40625\n",
      "Validation loss = 0.25204100646078587\n",
      "Epoch 0015 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.5481111111111111\n",
      "Training loss = 0.2675962182664209\n",
      "Validation accuracy = 0.4375\n",
      "Validation loss = 0.24576113186776638\n",
      "Epoch 0016 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.5483854166666666\n",
      "Training loss = 0.2670684476631383\n",
      "Validation accuracy = 0.46875\n",
      "Validation loss = 0.23402520269155502\n",
      "Epoch 0017 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.5512254901960785\n",
      "Training loss = 0.26602652546821853\n",
      "Validation accuracy = 0.59375\n",
      "Validation loss = 0.22817127127200365\n",
      "Epoch 0018 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.5517592592592593\n",
      "Training loss = 0.26549347714279536\n",
      "Validation accuracy = 0.46875\n",
      "Validation loss = 0.22949985787272453\n",
      "Epoch 0019 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.552061403508772\n",
      "Training loss = 0.2648355846682139\n",
      "Validation accuracy = 0.53125\n",
      "Validation loss = 0.22978012263774872\n",
      "Epoch 0020 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.5539166666666666\n",
      "Training loss = 0.2641446779233714\n",
      "Validation accuracy = 0.4375\n",
      "Validation loss = 0.23138530179858208\n",
      "Epoch 0021 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.5558730158730159\n",
      "Training loss = 0.2632827044550389\n",
      "Validation accuracy = 0.4375\n",
      "Validation loss = 0.25390575639903545\n",
      "Epoch 0022 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.5584090909090909\n",
      "Training loss = 0.2621193250404163\n",
      "Validation accuracy = 0.53125\n",
      "Validation loss = 0.22592438384890556\n",
      "Epoch 0023 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.5595652173913044\n",
      "Training loss = 0.26148851775820703\n",
      "Validation accuracy = 0.5625\n",
      "Validation loss = 0.20565772615373135\n",
      "Epoch 0024 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.5606944444444445\n",
      "Training loss = 0.26089657929725946\n",
      "Validation accuracy = 0.46875\n",
      "Validation loss = 0.2521583950147033\n",
      "Epoch 0025 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.5623333333333334\n",
      "Training loss = 0.26036993491748966\n",
      "Validation accuracy = 0.375\n",
      "Validation loss = 0.24881422240287066\n",
      "Epoch 0026 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.5636538461538462\n",
      "Training loss = 0.25967149649197474\n",
      "Validation accuracy = 0.46875\n",
      "Validation loss = 0.23357244580984116\n",
      "Epoch 0027 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.5641666666666667\n",
      "Training loss = 0.25935754603993744\n",
      "Validation accuracy = 0.59375\n",
      "Validation loss = 0.20442682038992643\n",
      "Epoch 0028 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.565\n",
      "Training loss = 0.25889487742135925\n",
      "Validation accuracy = 0.375\n",
      "Validation loss = 0.2544465158134699\n",
      "Epoch 0029 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.5661494252873563\n",
      "Training loss = 0.2584622743374657\n",
      "Validation accuracy = 0.59375\n",
      "Validation loss = 0.22059880755841732\n",
      "Epoch 0030 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.5669166666666666\n",
      "Training loss = 0.257732161336475\n",
      "Validation accuracy = 0.65625\n",
      "Validation loss = 0.21687737945467234\n",
      "Epoch 0031 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.5676344086021505\n",
      "Training loss = 0.25733585013337035\n",
      "Validation accuracy = 0.5\n",
      "Validation loss = 0.22026722226291895\n",
      "Epoch 0032 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.568359375\n",
      "Training loss = 0.25690355388137204\n",
      "Validation accuracy = 0.5\n",
      "Validation loss = 0.28593197371810675\n",
      "Epoch 0033 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.5693686868686869\n",
      "Training loss = 0.25656348123168105\n",
      "Validation accuracy = 0.375\n",
      "Validation loss = 0.2587914392352104\n",
      "Epoch 0034 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.5696568627450981\n",
      "Training loss = 0.2563262583768251\n",
      "Validation accuracy = 0.5\n",
      "Validation loss = 0.22467649914324284\n",
      "Epoch 0035 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.5708095238095238\n",
      "Training loss = 0.25577988343437513\n",
      "Validation accuracy = 0.75\n",
      "Validation loss = 0.20066537242382765\n",
      "Epoch 0036 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.5708101851851852\n",
      "Training loss = 0.2555962493898416\n",
      "Validation accuracy = 0.65625\n",
      "Validation loss = 0.21734234504401684\n",
      "Epoch 0037 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.5713288288288288\n",
      "Training loss = 0.2551994181451228\n",
      "Validation accuracy = 0.4375\n",
      "Validation loss = 0.2499332893639803\n",
      "Epoch 0038 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.5719736842105263\n",
      "Training loss = 0.2548105185982167\n",
      "Validation accuracy = 0.6875\n",
      "Validation loss = 0.19237039983272552\n",
      "Epoch 0039 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.5730128205128205\n",
      "Training loss = 0.25439841435951555\n",
      "Validation accuracy = 0.78125\n",
      "Validation loss = 0.20168666634708643\n",
      "Epoch 0040 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.573875\n",
      "Training loss = 0.253877830878521\n",
      "Validation accuracy = 0.375\n",
      "Validation loss = 0.257194509729743\n",
      "Epoch 0041 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.5744512195121951\n",
      "Training loss = 0.25357442806043273\n",
      "Validation accuracy = 0.40625\n",
      "Validation loss = 0.24669959396123886\n",
      "Epoch 0042 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.5754166666666667\n",
      "Training loss = 0.25308784910610743\n",
      "Validation accuracy = 0.53125\n",
      "Validation loss = 0.22223962377756834\n",
      "Epoch 0043 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.5763759689922481\n",
      "Training loss = 0.2527057606778866\n",
      "Validation accuracy = 0.59375\n",
      "Validation loss = 0.21727547608315945\n",
      "Epoch 0044 / 0200\n",
      "=====================================\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training accuracy = 0.5767424242424243\n",
      "Training loss = 0.2522999924895438\n",
      "Validation accuracy = 0.34375\n",
      "Validation loss = 0.2724380511790514\n",
      "Epoch 0045 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.5777407407407408\n",
      "Training loss = 0.25196533167141455\n",
      "Validation accuracy = 0.40625\n",
      "Validation loss = 0.236351209692657\n",
      "Epoch 0046 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.5786231884057971\n",
      "Training loss = 0.2514701428043022\n",
      "Validation accuracy = 0.53125\n",
      "Validation loss = 0.223475425504148\n",
      "Epoch 0047 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.5794680851063829\n",
      "Training loss = 0.25112223925425653\n",
      "Validation accuracy = 0.625\n",
      "Validation loss = 0.19805047940462828\n",
      "Epoch 0048 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.5798090277777778\n",
      "Training loss = 0.25087096059513797\n",
      "Validation accuracy = 0.375\n",
      "Validation loss = 0.2782694920897484\n",
      "Epoch 0049 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.5806122448979592\n",
      "Training loss = 0.2504994832508925\n",
      "Validation accuracy = 0.75\n",
      "Validation loss = 0.19943922758102417\n",
      "Epoch 0050 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.5810333333333333\n",
      "Training loss = 0.2502232044575115\n",
      "Validation accuracy = 0.46875\n",
      "Validation loss = 0.226662190631032\n",
      "Epoch 0051 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.5818954248366013\n",
      "Training loss = 0.24987279963430042\n",
      "Validation accuracy = 0.46875\n",
      "Validation loss = 0.24393855035305023\n",
      "Epoch 0052 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.582275641025641\n",
      "Training loss = 0.2496762948246816\n",
      "Validation accuracy = 0.5625\n",
      "Validation loss = 0.21495643071830273\n",
      "Epoch 0053 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.5831132075471698\n",
      "Training loss = 0.24938534516560018\n",
      "Validation accuracy = 0.78125\n",
      "Validation loss = 0.18985252268612385\n",
      "Epoch 0054 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.5834722222222222\n",
      "Training loss = 0.24919669478004913\n",
      "Validation accuracy = 0.59375\n",
      "Validation loss = 0.2206829907372594\n",
      "Epoch 0055 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.5841363636363637\n",
      "Training loss = 0.2488421130616105\n",
      "Validation accuracy = 0.53125\n",
      "Validation loss = 0.239867121912539\n",
      "Epoch 0056 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.5844345238095238\n",
      "Training loss = 0.24856197765163546\n",
      "Validation accuracy = 0.4375\n",
      "Validation loss = 0.2330782376229763\n",
      "Epoch 0057 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.5845906432748538\n",
      "Training loss = 0.24842824416267767\n",
      "Validation accuracy = 0.40625\n",
      "Validation loss = 0.2667904272675514\n",
      "Epoch 0058 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.5848706896551724\n",
      "Training loss = 0.24817863822004746\n",
      "Validation accuracy = 0.5625\n",
      "Validation loss = 0.21974102221429348\n",
      "Epoch 0059 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.5854237288135593\n",
      "Training loss = 0.2479546000099199\n",
      "Validation accuracy = 0.5\n",
      "Validation loss = 0.21861204504966736\n",
      "Epoch 0060 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.5860277777777778\n",
      "Training loss = 0.247661475615162\n",
      "Validation accuracy = 0.46875\n",
      "Validation loss = 0.21859354432672262\n",
      "Epoch 0061 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.5867486338797814\n",
      "Training loss = 0.24723852913175287\n",
      "Validation accuracy = 0.625\n",
      "Validation loss = 0.20131422765552998\n",
      "Epoch 0062 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.5873924731182796\n",
      "Training loss = 0.2469466269502957\n",
      "Validation accuracy = 0.625\n",
      "Validation loss = 0.220098327845335\n",
      "Epoch 0063 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.5878042328042328\n",
      "Training loss = 0.24670360830587842\n",
      "Validation accuracy = 0.65625\n",
      "Validation loss = 0.20137494336813688\n",
      "Epoch 0064 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.5890104166666666\n",
      "Training loss = 0.24636629566802487\n",
      "Validation accuracy = 0.5\n",
      "Validation loss = 0.27975469175726175\n",
      "Epoch 0065 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.5896153846153847\n",
      "Training loss = 0.2460545692793452\n",
      "Validation accuracy = 0.5625\n",
      "Validation loss = 0.24184592626988888\n",
      "Epoch 0066 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.5900252525252525\n",
      "Training loss = 0.24588454198713103\n",
      "Validation accuracy = 0.59375\n",
      "Validation loss = 0.21423127874732018\n",
      "Epoch 0067 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.5905099502487562\n",
      "Training loss = 0.24560061766492639\n",
      "Validation accuracy = 0.40625\n",
      "Validation loss = 0.26051195710897446\n",
      "Epoch 0068 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.5911029411764706\n",
      "Training loss = 0.24530324493571384\n",
      "Validation accuracy = 0.65625\n",
      "Validation loss = 0.2150999130681157\n",
      "Epoch 0069 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.5919323671497585\n",
      "Training loss = 0.24487712589960886\n",
      "Validation accuracy = 0.53125\n",
      "Validation loss = 0.21905740723013878\n",
      "Epoch 0070 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.5925238095238096\n",
      "Training loss = 0.2446225827788668\n",
      "Validation accuracy = 0.53125\n",
      "Validation loss = 0.2464997135102749\n",
      "Epoch 0071 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.5929694835680751\n",
      "Training loss = 0.2443668792853263\n",
      "Validation accuracy = 0.59375\n",
      "Validation loss = 0.22169850300997496\n",
      "Epoch 0072 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.5933101851851852\n",
      "Training loss = 0.24421533337432064\n",
      "Validation accuracy = 0.59375\n",
      "Validation loss = 0.21136760618537664\n",
      "Epoch 0073 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.5935388127853881\n",
      "Training loss = 0.244118564292006\n",
      "Validation accuracy = 0.53125\n",
      "Validation loss = 0.22653600946068764\n",
      "Epoch 0074 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.5939076576576576\n",
      "Training loss = 0.2439222825343746\n",
      "Validation accuracy = 0.46875\n",
      "Validation loss = 0.26586742512881756\n",
      "Epoch 0075 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.5942777777777778\n",
      "Training loss = 0.24379970107061996\n",
      "Validation accuracy = 0.40625\n",
      "Validation loss = 0.24621116556227207\n",
      "Epoch 0076 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.5944188596491228\n",
      "Training loss = 0.2436214502199896\n",
      "Validation accuracy = 0.6875\n",
      "Validation loss = 0.2084258096292615\n",
      "Epoch 0077 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.5949025974025974\n",
      "Training loss = 0.2434206919622047\n",
      "Validation accuracy = 0.6875\n",
      "Validation loss = 0.21828216966241598\n",
      "Epoch 0078 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.5953846153846154\n",
      "Training loss = 0.24314704884114302\n",
      "Validation accuracy = 0.78125\n",
      "Validation loss = 0.19137390237301588\n",
      "Epoch 0079 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.5959915611814346\n",
      "Training loss = 0.24290875094239345\n",
      "Validation accuracy = 0.6875\n",
      "Validation loss = 0.187936183065176\n",
      "Epoch 0080 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.5968125\n",
      "Training loss = 0.2425947294938378\n",
      "Validation accuracy = 0.65625\n",
      "Validation loss = 0.20194688718765974\n",
      "Epoch 0081 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.5971502057613168\n",
      "Training loss = 0.24240789487176104\n",
      "Validation accuracy = 0.6875\n",
      "Validation loss = 0.19095174688845873\n",
      "Epoch 0082 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.5976930894308943\n",
      "Training loss = 0.24221930549623885\n",
      "Validation accuracy = 0.65625\n",
      "Validation loss = 0.20732274372130632\n",
      "Epoch 0083 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.5981827309236948\n",
      "Training loss = 0.24199369558114484\n",
      "Validation accuracy = 0.71875\n",
      "Validation loss = 0.189814705401659\n",
      "Epoch 0084 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.5985416666666666\n",
      "Training loss = 0.2417521578406117\n",
      "Validation accuracy = 0.59375\n",
      "Validation loss = 0.2182612642645836\n",
      "Epoch 0085 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.599\n",
      "Training loss = 0.2415656245101024\n",
      "Validation accuracy = 0.46875\n",
      "Validation loss = 0.23423619661480188\n",
      "Epoch 0086 / 0200\n",
      "=====================================\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training accuracy = 0.5992732558139535\n",
      "Training loss = 0.24136149410519372\n",
      "Validation accuracy = 0.5625\n",
      "Validation loss = 0.22727246023714542\n",
      "Epoch 0087 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.5995593869731801\n",
      "Training loss = 0.24122955766574292\n",
      "Validation accuracy = 0.5\n",
      "Validation loss = 0.23972904030233622\n",
      "Epoch 0088 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.5997064393939394\n",
      "Training loss = 0.24114233904955626\n",
      "Validation accuracy = 0.5625\n",
      "Validation loss = 0.21508869901299477\n",
      "Epoch 0089 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.600065543071161\n",
      "Training loss = 0.2409549382207601\n",
      "Validation accuracy = 0.46875\n",
      "Validation loss = 0.2505508130416274\n",
      "Epoch 0090 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.6005370370370371\n",
      "Training loss = 0.2406718327374094\n",
      "Validation accuracy = 0.65625\n",
      "Validation loss = 0.22456244751811028\n",
      "Epoch 0091 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.6011721611721612\n",
      "Training loss = 0.24044201149649563\n",
      "Validation accuracy = 0.59375\n",
      "Validation loss = 0.24118211027234793\n",
      "Epoch 0092 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.6014855072463768\n",
      "Training loss = 0.24027539848916882\n",
      "Validation accuracy = 0.65625\n",
      "Validation loss = 0.20255601592361927\n",
      "Epoch 0093 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.602168458781362\n",
      "Training loss = 0.24003435735353754\n",
      "Validation accuracy = 0.59375\n",
      "Validation loss = 0.2146219378337264\n",
      "Epoch 0094 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.6026241134751773\n",
      "Training loss = 0.23982272971513952\n",
      "Validation accuracy = 0.59375\n",
      "Validation loss = 0.23923564329743385\n",
      "Epoch 0095 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.6032017543859649\n",
      "Training loss = 0.23950469283432815\n",
      "Validation accuracy = 0.65625\n",
      "Validation loss = 0.21696042269468307\n",
      "Epoch 0096 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.6036545138888889\n",
      "Training loss = 0.23926525446444025\n",
      "Validation accuracy = 0.75\n",
      "Validation loss = 0.17502406053245068\n",
      "Epoch 0097 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.6040979381443299\n",
      "Training loss = 0.23908628423970282\n",
      "Validation accuracy = 0.65625\n",
      "Validation loss = 0.20289721060544252\n",
      "Epoch 0098 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.6045493197278912\n",
      "Training loss = 0.23884451305138923\n",
      "Validation accuracy = 0.59375\n",
      "Validation loss = 0.21176095586270094\n",
      "Epoch 0099 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.6049747474747474\n",
      "Training loss = 0.23861396903956078\n",
      "Validation accuracy = 0.6875\n",
      "Validation loss = 0.19544904958456755\n",
      "Epoch 0100 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.60565\n",
      "Training loss = 0.2383529733599474\n",
      "Validation accuracy = 0.65625\n",
      "Validation loss = 0.21631112322211266\n",
      "Epoch 0101 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.6061303630363036\n",
      "Training loss = 0.2380763913072621\n",
      "Validation accuracy = 0.65625\n",
      "Validation loss = 0.1964574223384261\n",
      "Epoch 0102 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.6066176470588235\n",
      "Training loss = 0.2378847836295228\n",
      "Validation accuracy = 0.5\n",
      "Validation loss = 0.24776910804212093\n",
      "Epoch 0103 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.6072249190938511\n",
      "Training loss = 0.23766437780811273\n",
      "Validation accuracy = 0.65625\n",
      "Validation loss = 0.21080608665943146\n",
      "Epoch 0104 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.6075320512820512\n",
      "Training loss = 0.2375322840202791\n",
      "Validation accuracy = 0.65625\n",
      "Validation loss = 0.21227222587913275\n",
      "Epoch 0105 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.608015873015873\n",
      "Training loss = 0.23738976873930484\n",
      "Validation accuracy = 0.6875\n",
      "Validation loss = 0.19849567767232656\n",
      "Epoch 0106 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.6084198113207547\n",
      "Training loss = 0.23721785289405278\n",
      "Validation accuracy = 0.6875\n",
      "Validation loss = 0.1964089209213853\n",
      "Epoch 0107 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.6089174454828661\n",
      "Training loss = 0.23704892423688623\n",
      "Validation accuracy = 0.59375\n",
      "Validation loss = 0.21219466160982847\n",
      "Epoch 0108 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.6090509259259259\n",
      "Training loss = 0.2369001736142385\n",
      "Validation accuracy = 0.6875\n",
      "Validation loss = 0.20277231000363827\n",
      "Epoch 0109 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.6094648318042813\n",
      "Training loss = 0.23675565987050715\n",
      "Validation accuracy = 0.65625\n",
      "Validation loss = 0.19451042544096708\n",
      "Epoch 0110 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.6099772727272728\n",
      "Training loss = 0.23654635782133449\n",
      "Validation accuracy = 0.625\n",
      "Validation loss = 0.20253281109035015\n",
      "Epoch 0111 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.6105105105105105\n",
      "Training loss = 0.23629242100470416\n",
      "Validation accuracy = 0.59375\n",
      "Validation loss = 0.2348371660336852\n",
      "Epoch 0112 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.6108928571428571\n",
      "Training loss = 0.23606921923224858\n",
      "Validation accuracy = 0.75\n",
      "Validation loss = 0.19409859739243984\n",
      "Epoch 0113 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.6110914454277286\n",
      "Training loss = 0.23600878708427195\n",
      "Validation accuracy = 0.5625\n",
      "Validation loss = 0.22915281541645527\n",
      "Epoch 0114 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.6113961988304094\n",
      "Training loss = 0.2358375198331972\n",
      "Validation accuracy = 0.71875\n",
      "Validation loss = 0.17512178514152765\n",
      "Epoch 0115 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.6116086956521739\n",
      "Training loss = 0.23566926463045504\n",
      "Validation accuracy = 0.5\n",
      "Validation loss = 0.2156507410109043\n",
      "Epoch 0116 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.6116594827586207\n",
      "Training loss = 0.2356027951411603\n",
      "Validation accuracy = 0.65625\n",
      "Validation loss = 0.19313119631260633\n",
      "Epoch 0117 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.6119088319088319\n",
      "Training loss = 0.23549772076107073\n",
      "Validation accuracy = 0.625\n",
      "Validation loss = 0.21145489159971476\n",
      "Epoch 0118 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.6122669491525424\n",
      "Training loss = 0.23534720204065496\n",
      "Validation accuracy = 0.46875\n",
      "Validation loss = 0.2726743072271347\n",
      "Epoch 0119 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.6126190476190476\n",
      "Training loss = 0.2352292052993462\n",
      "Validation accuracy = 0.5\n",
      "Validation loss = 0.22018810082226992\n",
      "Epoch 0120 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.6130763888888889\n",
      "Training loss = 0.235030550177623\n",
      "Validation accuracy = 0.6875\n",
      "Validation loss = 0.18475640006363392\n",
      "Epoch 0121 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.6133126721763086\n",
      "Training loss = 0.23494228531783523\n",
      "Validation accuracy = 0.71875\n",
      "Validation loss = 0.18976721912622452\n",
      "Epoch 0122 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.613558743169399\n",
      "Training loss = 0.23480924887216237\n",
      "Validation accuracy = 0.53125\n",
      "Validation loss = 0.2172520738095045\n",
      "Epoch 0123 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.6138279132791328\n",
      "Training loss = 0.23470255256012124\n",
      "Validation accuracy = 0.65625\n",
      "Validation loss = 0.20820092782378197\n",
      "Epoch 0124 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.6141666666666666\n",
      "Training loss = 0.23458879607429187\n",
      "Validation accuracy = 0.53125\n",
      "Validation loss = 0.23273032251745462\n",
      "Epoch 0125 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.6147933333333333\n",
      "Training loss = 0.23434084848215184\n",
      "Validation accuracy = 0.75\n",
      "Validation loss = 0.20924250781536102\n",
      "Epoch 0126 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.6149933862433863\n",
      "Training loss = 0.23421192930755083\n",
      "Validation accuracy = 0.53125\n",
      "Validation loss = 0.21585525199770927\n",
      "Epoch 0127 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.6152165354330709\n",
      "Training loss = 0.234096581861279\n",
      "Validation accuracy = 0.59375\n",
      "Validation loss = 0.2168427137658\n",
      "Epoch 0128 / 0200\n",
      "=====================================\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training accuracy = 0.6156510416666666\n",
      "Training loss = 0.2339478577870371\n",
      "Validation accuracy = 0.625\n",
      "Validation loss = 0.1952831055969\n",
      "Epoch 0129 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.6158720930232559\n",
      "Training loss = 0.23384041794096855\n",
      "Validation accuracy = 0.6875\n",
      "Validation loss = 0.22281683795154095\n",
      "Epoch 0130 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.6161089743589744\n",
      "Training loss = 0.23370158266801483\n",
      "Validation accuracy = 0.5625\n",
      "Validation loss = 0.22985083144158125\n",
      "Epoch 0131 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.6161323155216285\n",
      "Training loss = 0.23365967771848878\n",
      "Validation accuracy = 0.59375\n",
      "Validation loss = 0.22188207134604454\n",
      "Epoch 0132 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.6165277777777778\n",
      "Training loss = 0.23346149148824014\n",
      "Validation accuracy = 0.65625\n",
      "Validation loss = 0.20106760039925575\n",
      "Epoch 0133 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.6168421052631579\n",
      "Training loss = 0.2333345300029207\n",
      "Validation accuracy = 0.5\n",
      "Validation loss = 0.21645058877766132\n",
      "Epoch 0134 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.6169776119402985\n",
      "Training loss = 0.2332209644424011\n",
      "Validation accuracy = 0.5625\n",
      "Validation loss = 0.22302967123687267\n",
      "Epoch 0135 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.6172098765432099\n",
      "Training loss = 0.23311363107058\n",
      "Validation accuracy = 0.53125\n",
      "Validation loss = 0.21936583891510963\n",
      "Epoch 0136 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.6175\n",
      "Training loss = 0.23299629523473628\n",
      "Validation accuracy = 0.53125\n",
      "Validation loss = 0.21190332062542439\n",
      "Epoch 0137 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.6178649635036496\n",
      "Training loss = 0.2328308920283097\n",
      "Validation accuracy = 0.5625\n",
      "Validation loss = 0.22858596313744783\n",
      "Epoch 0138 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.6182789855072464\n",
      "Training loss = 0.23265697306462965\n",
      "Validation accuracy = 0.59375\n",
      "Validation loss = 0.2081054849550128\n",
      "Epoch 0139 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.6186930455635492\n",
      "Training loss = 0.23247415342651825\n",
      "Validation accuracy = 0.53125\n",
      "Validation loss = 0.2295544035732746\n",
      "Epoch 0140 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.6190178571428572\n",
      "Training loss = 0.23234214926670704\n",
      "Validation accuracy = 0.59375\n",
      "Validation loss = 0.23958077654242516\n",
      "Epoch 0141 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.6191962174940898\n",
      "Training loss = 0.2322852526763652\n",
      "Validation accuracy = 0.46875\n",
      "Validation loss = 0.31026065070182085\n",
      "Epoch 0142 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.6194542253521127\n",
      "Training loss = 0.2321288052243246\n",
      "Validation accuracy = 0.5625\n",
      "Validation loss = 0.20854304730892181\n",
      "Epoch 0143 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.6195804195804195\n",
      "Training loss = 0.23207910161439355\n",
      "Validation accuracy = 0.59375\n",
      "Validation loss = 0.20408848114311695\n",
      "Epoch 0144 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.6198958333333333\n",
      "Training loss = 0.23191274138874615\n",
      "Validation accuracy = 0.625\n",
      "Validation loss = 0.20635139849036932\n",
      "Epoch 0145 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.620132183908046\n",
      "Training loss = 0.231779686043146\n",
      "Validation accuracy = 0.5\n",
      "Validation loss = 0.2340475283563137\n",
      "Epoch 0146 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.6203995433789954\n",
      "Training loss = 0.23166536981350483\n",
      "Validation accuracy = 0.59375\n",
      "Validation loss = 0.211245559155941\n",
      "Epoch 0147 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.6206009070294785\n",
      "Training loss = 0.23155947520653136\n",
      "Validation accuracy = 0.65625\n",
      "Validation loss = 0.21247316896915436\n",
      "Epoch 0148 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.6210078828828829\n",
      "Training loss = 0.2313848067617027\n",
      "Validation accuracy = 0.625\n",
      "Validation loss = 0.22831479832530022\n",
      "Epoch 0149 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.6213031319910515\n",
      "Training loss = 0.23127968076274832\n",
      "Validation accuracy = 0.59375\n",
      "Validation loss = 0.208676902577281\n",
      "Epoch 0150 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.6216111111111111\n",
      "Training loss = 0.23107339764965906\n",
      "Validation accuracy = 0.59375\n",
      "Validation loss = 0.24770026840269566\n",
      "Epoch 0151 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.6219701986754967\n",
      "Training loss = 0.2309166586177041\n",
      "Validation accuracy = 0.5625\n",
      "Validation loss = 0.23802618402987719\n",
      "Epoch 0152 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.6223629385964913\n",
      "Training loss = 0.23075548265864582\n",
      "Validation accuracy = 0.5625\n",
      "Validation loss = 0.22697719559073448\n",
      "Epoch 0153 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.6225217864923748\n",
      "Training loss = 0.2306552676065198\n",
      "Validation accuracy = 0.625\n",
      "Validation loss = 0.20595414470881224\n",
      "Epoch 0154 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.6227597402597402\n",
      "Training loss = 0.2305219823384085\n",
      "Validation accuracy = 0.6875\n",
      "Validation loss = 0.2058427957817912\n",
      "Epoch 0155 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.6229086021505377\n",
      "Training loss = 0.23046440316440278\n",
      "Validation accuracy = 0.625\n",
      "Validation loss = 0.21081328205764294\n",
      "Epoch 0156 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.6232532051282051\n",
      "Training loss = 0.2303081617024369\n",
      "Validation accuracy = 0.5625\n",
      "Validation loss = 0.2378900945186615\n",
      "Epoch 0157 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.6234978768577495\n",
      "Training loss = 0.2301964837609298\n",
      "Validation accuracy = 0.5\n",
      "Validation loss = 0.2345607690513134\n",
      "Epoch 0158 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.6237183544303797\n",
      "Training loss = 0.23008929671994743\n",
      "Validation accuracy = 0.71875\n",
      "Validation loss = 0.19384830445051193\n",
      "Epoch 0159 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.6239727463312369\n",
      "Training loss = 0.22995534064525452\n",
      "Validation accuracy = 0.71875\n",
      "Validation loss = 0.1872387295588851\n",
      "Epoch 0160 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.624140625\n",
      "Training loss = 0.2298290288123923\n",
      "Validation accuracy = 0.8125\n",
      "Validation loss = 0.16926108114421368\n",
      "Epoch 0161 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.6244979296066253\n",
      "Training loss = 0.22966180595382277\n",
      "Validation accuracy = 0.59375\n",
      "Validation loss = 0.2073041144758463\n",
      "Epoch 0162 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.6248765432098765\n",
      "Training loss = 0.2294820656308544\n",
      "Validation accuracy = 0.46875\n",
      "Validation loss = 0.2540110368281603\n",
      "Epoch 0163 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.6251993865030675\n",
      "Training loss = 0.22934440518525603\n",
      "Validation accuracy = 0.71875\n",
      "Validation loss = 0.17294166516512632\n",
      "Epoch 0164 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.6254776422764228\n",
      "Training loss = 0.22921289641455542\n",
      "Validation accuracy = 0.65625\n",
      "Validation loss = 0.19597962871193886\n",
      "Epoch 0165 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.6257626262626262\n",
      "Training loss = 0.2290819828227313\n",
      "Validation accuracy = 0.65625\n",
      "Validation loss = 0.1849869629368186\n",
      "Epoch 0166 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.6260291164658635\n",
      "Training loss = 0.22894335601583543\n",
      "Validation accuracy = 0.5625\n",
      "Validation loss = 0.25594186782836914\n",
      "Epoch 0167 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.6263223552894212\n",
      "Training loss = 0.22882540710240662\n",
      "Validation accuracy = 0.65625\n",
      "Validation loss = 0.20959097892045975\n",
      "Epoch 0168 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.6266269841269841\n",
      "Training loss = 0.22868384661581662\n",
      "Validation accuracy = 0.53125\n",
      "Validation loss = 0.23391825705766678\n",
      "Epoch 0169 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.6269033530571992\n",
      "Training loss = 0.22855923213094062\n",
      "Validation accuracy = 0.625\n",
      "Validation loss = 0.20121743623167276\n",
      "Epoch 0170 / 0200\n",
      "=====================================\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training accuracy = 0.6270735294117648\n",
      "Training loss = 0.22843027786581832\n",
      "Validation accuracy = 0.65625\n",
      "Validation loss = 0.20564347319304943\n",
      "Epoch 0171 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.627285575048733\n",
      "Training loss = 0.22830499932453124\n",
      "Validation accuracy = 0.59375\n",
      "Validation loss = 0.23350395821034908\n",
      "Epoch 0172 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.6275048449612403\n",
      "Training loss = 0.22820675869934376\n",
      "Validation accuracy = 0.6875\n",
      "Validation loss = 0.1728282468393445\n",
      "Epoch 0173 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.6277360308285164\n",
      "Training loss = 0.22806720956506815\n",
      "Validation accuracy = 0.75\n",
      "Validation loss = 0.17227624356746674\n",
      "Epoch 0174 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.6279501915708813\n",
      "Training loss = 0.22793594158879013\n",
      "Validation accuracy = 0.59375\n",
      "Validation loss = 0.21877488680183887\n",
      "Epoch 0175 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.6282\n",
      "Training loss = 0.2278190958293421\n",
      "Validation accuracy = 0.5625\n",
      "Validation loss = 0.2102945325896144\n",
      "Epoch 0176 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.6284090909090909\n",
      "Training loss = 0.2277230813021941\n",
      "Validation accuracy = 0.625\n",
      "Validation loss = 0.20150725916028023\n",
      "Epoch 0177 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.6286252354048965\n",
      "Training loss = 0.22763024754387287\n",
      "Validation accuracy = 0.75\n",
      "Validation loss = 0.17803902179002762\n",
      "Epoch 0178 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.6287687265917603\n",
      "Training loss = 0.22755235174203411\n",
      "Validation accuracy = 0.5625\n",
      "Validation loss = 0.23278658464550972\n",
      "Epoch 0179 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.628929236499069\n",
      "Training loss = 0.22745892906287474\n",
      "Validation accuracy = 0.59375\n",
      "Validation loss = 0.20959161408245564\n",
      "Epoch 0180 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.6292407407407408\n",
      "Training loss = 0.22732712581581263\n",
      "Validation accuracy = 0.59375\n",
      "Validation loss = 0.2228071391582489\n",
      "Epoch 0181 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.6294198895027624\n",
      "Training loss = 0.227230599373236\n",
      "Validation accuracy = 0.6875\n",
      "Validation loss = 0.21059138886630535\n",
      "Epoch 0182 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.6295467032967033\n",
      "Training loss = 0.22718337614805653\n",
      "Validation accuracy = 0.46875\n",
      "Validation loss = 0.26371982879936695\n",
      "Epoch 0183 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.6297950819672131\n",
      "Training loss = 0.22706632465443052\n",
      "Validation accuracy = 0.625\n",
      "Validation loss = 0.20369151048362255\n",
      "Epoch 0184 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.6300135869565218\n",
      "Training loss = 0.22694393431747575\n",
      "Validation accuracy = 0.46875\n",
      "Validation loss = 0.28817511536180973\n",
      "Epoch 0185 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.6302477477477477\n",
      "Training loss = 0.22681015206759308\n",
      "Validation accuracy = 0.75\n",
      "Validation loss = 0.18641897663474083\n",
      "Epoch 0186 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.6305600358422939\n",
      "Training loss = 0.22664222136787457\n",
      "Validation accuracy = 0.5\n",
      "Validation loss = 0.2255041617900133\n",
      "Epoch 0187 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.6308155080213904\n",
      "Training loss = 0.22650039202289626\n",
      "Validation accuracy = 0.625\n",
      "Validation loss = 0.19725877232849598\n",
      "Epoch 0188 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.6310328014184398\n",
      "Training loss = 0.2263691988112471\n",
      "Validation accuracy = 0.59375\n",
      "Validation loss = 0.22032626066356897\n",
      "Epoch 0189 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.631305114638448\n",
      "Training loss = 0.2262477064112323\n",
      "Validation accuracy = 0.5\n",
      "Validation loss = 0.23652123659849167\n",
      "Epoch 0190 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.6315087719298246\n",
      "Training loss = 0.22615287993665328\n",
      "Validation accuracy = 0.6875\n",
      "Validation loss = 0.1970875021070242\n",
      "Epoch 0191 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.6317713787085515\n",
      "Training loss = 0.2260209498614281\n",
      "Validation accuracy = 0.625\n",
      "Validation loss = 0.20301775634288788\n",
      "Epoch 0192 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.6321050347222222\n",
      "Training loss = 0.2258909407377036\n",
      "Validation accuracy = 0.625\n",
      "Validation loss = 0.20218949671834707\n",
      "Epoch 0193 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.632318652849741\n",
      "Training loss = 0.22581427445490435\n",
      "Validation accuracy = 0.5625\n",
      "Validation loss = 0.24090124480426311\n",
      "Epoch 0194 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.6325644329896907\n",
      "Training loss = 0.22567767669142727\n",
      "Validation accuracy = 0.5625\n",
      "Validation loss = 0.19605356361716986\n",
      "Epoch 0195 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.6327692307692308\n",
      "Training loss = 0.22558541379868985\n",
      "Validation accuracy = 0.625\n",
      "Validation loss = 0.26456187572330236\n",
      "Epoch 0196 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.6329931972789116\n",
      "Training loss = 0.22549271673432925\n",
      "Validation accuracy = 0.5625\n",
      "Validation loss = 0.21991300024092197\n",
      "Epoch 0197 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.6331175972927242\n",
      "Training loss = 0.22544575000588363\n",
      "Validation accuracy = 0.71875\n",
      "Validation loss = 0.20019297301769257\n",
      "Epoch 0198 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.6332828282828283\n",
      "Training loss = 0.2253690720487524\n",
      "Validation accuracy = 0.71875\n",
      "Validation loss = 0.18330787774175406\n",
      "Epoch 0199 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.6335427135678392\n",
      "Training loss = 0.22522313323739285\n",
      "Validation accuracy = 0.59375\n",
      "Validation loss = 0.2376148235052824\n",
      "Epoch 0200 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.6338541666666667\n",
      "Training loss = 0.22509954483310382\n",
      "Validation accuracy = 0.71875\n",
      "Validation loss = 0.19915825873613358\n",
      "Making model for session group 20210310_15:25:48.350-20210319_16:10:10.704\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/imblearn/utils/_validation.py:326: UserWarning: After over-sampling, the number of samples (300) in class car will be larger than the number of samples in the majority class (class #signpost -> 160)\n",
      "  n_samples_majority,\n",
      "/usr/local/lib/python3.6/dist-packages/imblearn/utils/_validation.py:326: UserWarning: After over-sampling, the number of samples (300) in class signpost will be larger than the number of samples in the majority class (class #signpost -> 160)\n",
      "  n_samples_majority,\n",
      "/usr/local/lib/python3.6/dist-packages/imblearn/utils/_validation.py:326: UserWarning: After over-sampling, the number of samples (300) in class tree will be larger than the number of samples in the majority class (class #signpost -> 160)\n",
      "  n_samples_majority,\n",
      "/usr/local/lib/python3.6/dist-packages/imblearn/utils/_validation.py:326: UserWarning: After over-sampling, the number of samples (300) in class wall will be larger than the number of samples in the majority class (class #signpost -> 160)\n",
      "  n_samples_majority,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0001 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.41333333333333333\n",
      "Training loss = 0.31853447074691454\n",
      "Validation accuracy = 0.625\n",
      "Validation loss = 0.28750913590192795\n",
      "Epoch 0002 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.46375\n",
      "Training loss = 0.30500007507701715\n",
      "Validation accuracy = 0.65625\n",
      "Validation loss = 0.2807022091001272\n",
      "Epoch 0003 / 0200\n",
      "=====================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/_classification.py:1221: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training accuracy = 0.49666666666666665\n",
      "Training loss = 0.29476396332184474\n",
      "Validation accuracy = 0.625\n",
      "Validation loss = 0.2694101631641388\n",
      "Epoch 0004 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.5089583333333333\n",
      "Training loss = 0.28969763599336146\n",
      "Validation accuracy = 0.5625\n",
      "Validation loss = 0.2817184869199991\n",
      "Epoch 0005 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.5153333333333333\n",
      "Training loss = 0.28646713818113007\n",
      "Validation accuracy = 0.4375\n",
      "Validation loss = 0.2648978866636753\n",
      "Epoch 0006 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.5195833333333333\n",
      "Training loss = 0.2838916549169355\n",
      "Validation accuracy = 0.65625\n",
      "Validation loss = 0.2789005693048239\n",
      "Epoch 0007 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.5286904761904762\n",
      "Training loss = 0.28030823559278534\n",
      "Validation accuracy = 0.59375\n",
      "Validation loss = 0.27083830535411835\n",
      "Epoch 0008 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.5352083333333333\n",
      "Training loss = 0.2778170332685113\n",
      "Validation accuracy = 0.65625\n",
      "Validation loss = 0.25646064430475235\n",
      "Epoch 0009 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.5410185185185186\n",
      "Training loss = 0.27531544477851305\n",
      "Validation accuracy = 0.6875\n",
      "Validation loss = 0.2526407316327095\n",
      "Epoch 0010 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.5431666666666667\n",
      "Training loss = 0.2737819795360168\n",
      "Validation accuracy = 0.59375\n",
      "Validation loss = 0.23156637698411942\n",
      "Epoch 0011 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.5471969696969697\n",
      "Training loss = 0.2718996082991362\n",
      "Validation accuracy = 0.625\n",
      "Validation loss = 0.2419361937791109\n",
      "Epoch 0012 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.5502777777777778\n",
      "Training loss = 0.2701251887157559\n",
      "Validation accuracy = 0.59375\n",
      "Validation loss = 0.24470174685120583\n",
      "Epoch 0013 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.5521153846153846\n",
      "Training loss = 0.26900380744574925\n",
      "Validation accuracy = 0.53125\n",
      "Validation loss = 0.2592767234891653\n",
      "Epoch 0014 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.5532142857142858\n",
      "Training loss = 0.267803790787501\n",
      "Validation accuracy = 0.5625\n",
      "Validation loss = 0.2604238521307707\n",
      "Epoch 0015 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.555\n",
      "Training loss = 0.26669154106577236\n",
      "Validation accuracy = 0.59375\n",
      "Validation loss = 0.24996213801205158\n",
      "Epoch 0016 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.5586458333333333\n",
      "Training loss = 0.26542241470733036\n",
      "Validation accuracy = 0.6875\n",
      "Validation loss = 0.23851240798830986\n",
      "Epoch 0017 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.5594117647058824\n",
      "Training loss = 0.26458998830733343\n",
      "Validation accuracy = 0.71875\n",
      "Validation loss = 0.2222411148250103\n",
      "Epoch 0018 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.5597685185185185\n",
      "Training loss = 0.2642693399651735\n",
      "Validation accuracy = 0.4375\n",
      "Validation loss = 0.24491080362349749\n",
      "Epoch 0019 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.5619298245614035\n",
      "Training loss = 0.2635178609035517\n",
      "Validation accuracy = 0.59375\n",
      "Validation loss = 0.23884180560708046\n",
      "Epoch 0020 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.5620833333333334\n",
      "Training loss = 0.26293964709093176\n",
      "Validation accuracy = 0.65625\n",
      "Validation loss = 0.23797293938696384\n",
      "Epoch 0021 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.5626984126984127\n",
      "Training loss = 0.2624777722855409\n",
      "Validation accuracy = 0.59375\n",
      "Validation loss = 0.24819792807102203\n",
      "Epoch 0022 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.5637878787878788\n",
      "Training loss = 0.2617828672142191\n",
      "Validation accuracy = 0.5625\n",
      "Validation loss = 0.22547853365540504\n",
      "Epoch 0023 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.5647463768115942\n",
      "Training loss = 0.2611533707293911\n",
      "Validation accuracy = 0.59375\n",
      "Validation loss = 0.23125222511589527\n",
      "Epoch 0024 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.5667361111111111\n",
      "Training loss = 0.2602928562048409\n",
      "Validation accuracy = 0.625\n",
      "Validation loss = 0.24565297923982143\n",
      "Epoch 0025 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.5683\n",
      "Training loss = 0.2594006164153417\n",
      "Validation accuracy = 0.65625\n",
      "Validation loss = 0.2352010663598776\n",
      "Epoch 0026 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.5688141025641026\n",
      "Training loss = 0.25915974480028336\n",
      "Validation accuracy = 0.59375\n",
      "Validation loss = 0.25939985550940037\n",
      "Epoch 0027 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.5694444444444444\n",
      "Training loss = 0.25888307673419697\n",
      "Validation accuracy = 0.46875\n",
      "Validation loss = 0.24027513526380062\n",
      "Epoch 0028 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.5702083333333333\n",
      "Training loss = 0.2583309761816192\n",
      "Validation accuracy = 0.71875\n",
      "Validation loss = 0.22712780628353357\n",
      "Epoch 0029 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.5712643678160919\n",
      "Training loss = 0.2578135527336392\n",
      "Validation accuracy = 0.375\n",
      "Validation loss = 0.2578284591436386\n",
      "Epoch 0030 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.5721388888888889\n",
      "Training loss = 0.2572362756008903\n",
      "Validation accuracy = 0.65625\n",
      "Validation loss = 0.22123154252767563\n",
      "Epoch 0031 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.573252688172043\n",
      "Training loss = 0.25669715744433225\n",
      "Validation accuracy = 0.59375\n",
      "Validation loss = 0.231736171990633\n",
      "Epoch 0032 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.5741145833333333\n",
      "Training loss = 0.25631434585976726\n",
      "Validation accuracy = 0.65625\n",
      "Validation loss = 0.2350858822464943\n",
      "Epoch 0033 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.5753030303030303\n",
      "Training loss = 0.25562123661992525\n",
      "Validation accuracy = 0.53125\n",
      "Validation loss = 0.233314860612154\n",
      "Epoch 0034 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.5764460784313725\n",
      "Training loss = 0.25513304146627586\n",
      "Validation accuracy = 0.65625\n",
      "Validation loss = 0.24322250671684742\n",
      "Epoch 0035 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.5767857142857142\n",
      "Training loss = 0.25487457958218596\n",
      "Validation accuracy = 0.59375\n",
      "Validation loss = 0.2512077484279871\n",
      "Epoch 0036 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.5770601851851852\n",
      "Training loss = 0.25467563302773566\n",
      "Validation accuracy = 0.5\n",
      "Validation loss = 0.2570067271590233\n",
      "Epoch 0037 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.5774549549549549\n",
      "Training loss = 0.25421282158510106\n",
      "Validation accuracy = 0.59375\n",
      "Validation loss = 0.24853316880762577\n",
      "Epoch 0038 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.5780263157894737\n",
      "Training loss = 0.25371259121387674\n",
      "Validation accuracy = 0.46875\n",
      "Validation loss = 0.22799514327198267\n",
      "Epoch 0039 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.5790598290598291\n",
      "Training loss = 0.25325542787838184\n",
      "Validation accuracy = 0.5\n",
      "Validation loss = 0.24514051340520382\n",
      "Epoch 0040 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.5798541666666667\n",
      "Training loss = 0.25280014621963104\n",
      "Validation accuracy = 0.40625\n",
      "Validation loss = 0.2535729166120291\n",
      "Epoch 0041 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.5807926829268293\n",
      "Training loss = 0.25241532511403403\n",
      "Validation accuracy = 0.53125\n",
      "Validation loss = 0.24941141717135906\n",
      "Epoch 0042 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.5814087301587302\n",
      "Training loss = 0.25217138920866305\n",
      "Validation accuracy = 0.53125\n",
      "Validation loss = 0.2366143949329853\n",
      "Epoch 0043 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.5822480620155038\n",
      "Training loss = 0.25172739618104095\n",
      "Validation accuracy = 0.65625\n",
      "Validation loss = 0.23149501532316208\n",
      "Epoch 0044 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.5827462121212121\n",
      "Training loss = 0.2513583276144257\n",
      "Validation accuracy = 0.53125\n",
      "Validation loss = 0.24086138233542442\n",
      "Epoch 0045 / 0200\n",
      "=====================================\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training accuracy = 0.5832407407407407\n",
      "Training loss = 0.2511202940841516\n",
      "Validation accuracy = 0.46875\n",
      "Validation loss = 0.2325176727026701\n",
      "Epoch 0046 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.5834057971014492\n",
      "Training loss = 0.25082135391408117\n",
      "Validation accuracy = 0.59375\n",
      "Validation loss = 0.24812223203480244\n",
      "Epoch 0047 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.5840780141843972\n",
      "Training loss = 0.25044386078491276\n",
      "Validation accuracy = 0.5\n",
      "Validation loss = 0.22742526698857546\n",
      "Epoch 0048 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.5846527777777778\n",
      "Training loss = 0.2500542509612731\n",
      "Validation accuracy = 0.46875\n",
      "Validation loss = 0.2426696978509426\n",
      "Epoch 0049 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.5854421768707483\n",
      "Training loss = 0.24956744180751494\n",
      "Validation accuracy = 0.625\n",
      "Validation loss = 0.24159338511526585\n",
      "Epoch 0050 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.58585\n",
      "Training loss = 0.24932194921473663\n",
      "Validation accuracy = 0.59375\n",
      "Validation loss = 0.22217135690152645\n",
      "Epoch 0051 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.5867483660130719\n",
      "Training loss = 0.24889525416240194\n",
      "Validation accuracy = 0.53125\n",
      "Validation loss = 0.2392672672867775\n",
      "Epoch 0052 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.5873717948717949\n",
      "Training loss = 0.24851854640369614\n",
      "Validation accuracy = 0.65625\n",
      "Validation loss = 0.21746942587196827\n",
      "Epoch 0053 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.5879874213836478\n",
      "Training loss = 0.2482996739625181\n",
      "Validation accuracy = 0.59375\n",
      "Validation loss = 0.23879483435302973\n",
      "Epoch 0054 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.5887808641975308\n",
      "Training loss = 0.24792381002165284\n",
      "Validation accuracy = 0.3125\n",
      "Validation loss = 0.25741665065288544\n",
      "Epoch 0055 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.5892727272727273\n",
      "Training loss = 0.2475504352075584\n",
      "Validation accuracy = 0.59375\n",
      "Validation loss = 0.221468236297369\n",
      "Epoch 0056 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.5901041666666667\n",
      "Training loss = 0.24724353265904245\n",
      "Validation accuracy = 0.59375\n",
      "Validation loss = 0.2412001732736826\n",
      "Epoch 0057 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.5905847953216374\n",
      "Training loss = 0.24693466202470293\n",
      "Validation accuracy = 0.53125\n",
      "Validation loss = 0.2676758151501417\n",
      "Epoch 0058 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.5908620689655173\n",
      "Training loss = 0.24669734571214721\n",
      "Validation accuracy = 0.65625\n",
      "Validation loss = 0.23129545710980892\n",
      "Epoch 0059 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.5913700564971751\n",
      "Training loss = 0.24642711560099811\n",
      "Validation accuracy = 0.625\n",
      "Validation loss = 0.23293717950582504\n",
      "Epoch 0060 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.5915972222222222\n",
      "Training loss = 0.2462849172929095\n",
      "Validation accuracy = 0.625\n",
      "Validation loss = 0.22733392659574747\n",
      "Epoch 0061 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.5918852459016394\n",
      "Training loss = 0.24599872812262324\n",
      "Validation accuracy = 0.34375\n",
      "Validation loss = 0.2570838090032339\n",
      "Epoch 0062 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.5925268817204301\n",
      "Training loss = 0.24565588448917675\n",
      "Validation accuracy = 0.625\n",
      "Validation loss = 0.22142781503498554\n",
      "Epoch 0063 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.5928703703703704\n",
      "Training loss = 0.24539860837989383\n",
      "Validation accuracy = 0.65625\n",
      "Validation loss = 0.23738558404147625\n",
      "Epoch 0064 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.5936328125\n",
      "Training loss = 0.24508610391135638\n",
      "Validation accuracy = 0.53125\n",
      "Validation loss = 0.2440473297610879\n",
      "Epoch 0065 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.5942179487179488\n",
      "Training loss = 0.2447816211076883\n",
      "Validation accuracy = 0.53125\n",
      "Validation loss = 0.22555362805724144\n",
      "Epoch 0066 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.5948106060606061\n",
      "Training loss = 0.24454328948650697\n",
      "Validation accuracy = 0.65625\n",
      "Validation loss = 0.23410682566463947\n",
      "Epoch 0067 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.5953731343283583\n",
      "Training loss = 0.24436191071362343\n",
      "Validation accuracy = 0.65625\n",
      "Validation loss = 0.23011593334376812\n",
      "Epoch 0068 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.5963480392156862\n",
      "Training loss = 0.24394505740052053\n",
      "Validation accuracy = 0.59375\n",
      "Validation loss = 0.25469062104821205\n",
      "Epoch 0069 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.5968236714975845\n",
      "Training loss = 0.2437922617699501\n",
      "Validation accuracy = 0.625\n",
      "Validation loss = 0.22020061127841473\n",
      "Epoch 0070 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.5976666666666667\n",
      "Training loss = 0.243582847067288\n",
      "Validation accuracy = 0.625\n",
      "Validation loss = 0.23319113813340664\n",
      "Epoch 0071 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.5984272300469483\n",
      "Training loss = 0.24335144220488453\n",
      "Validation accuracy = 0.34375\n",
      "Validation loss = 0.26797161623835564\n",
      "Epoch 0072 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.5988657407407407\n",
      "Training loss = 0.24316972544796214\n",
      "Validation accuracy = 0.5\n",
      "Validation loss = 0.30788103956729174\n",
      "Epoch 0073 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.5994406392694064\n",
      "Training loss = 0.24291173862574036\n",
      "Validation accuracy = 0.59375\n",
      "Validation loss = 0.24163746554404497\n",
      "Epoch 0074 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.6000225225225225\n",
      "Training loss = 0.2426726925131437\n",
      "Validation accuracy = 0.625\n",
      "Validation loss = 0.23303520679473877\n",
      "Epoch 0075 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.6004888888888888\n",
      "Training loss = 0.24244838802218438\n",
      "Validation accuracy = 0.5\n",
      "Validation loss = 0.2572431042790413\n",
      "Epoch 0076 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.6006688596491228\n",
      "Training loss = 0.24232871852521048\n",
      "Validation accuracy = 0.65625\n",
      "Validation loss = 0.2263998407870531\n",
      "Epoch 0077 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.6010822510822511\n",
      "Training loss = 0.24207374143523055\n",
      "Validation accuracy = 0.4375\n",
      "Validation loss = 0.2570000244304538\n",
      "Epoch 0078 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.601474358974359\n",
      "Training loss = 0.24176096294871252\n",
      "Validation accuracy = 0.625\n",
      "Validation loss = 0.24463181756436825\n",
      "Epoch 0079 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.6017299578059072\n",
      "Training loss = 0.2416322833714606\n",
      "Validation accuracy = 0.46875\n",
      "Validation loss = 0.23967908695340157\n",
      "Epoch 0080 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.6021875\n",
      "Training loss = 0.24141969211306422\n",
      "Validation accuracy = 0.65625\n",
      "Validation loss = 0.21421279199421406\n",
      "Epoch 0081 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.6022942386831276\n",
      "Training loss = 0.24130630679060647\n",
      "Validation accuracy = 0.65625\n",
      "Validation loss = 0.22244234010577202\n",
      "Epoch 0082 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.6029674796747968\n",
      "Training loss = 0.24107107818338686\n",
      "Validation accuracy = 0.53125\n",
      "Validation loss = 0.22913735918700695\n",
      "Epoch 0083 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.6034036144578313\n",
      "Training loss = 0.24084438601052427\n",
      "Validation accuracy = 0.53125\n",
      "Validation loss = 0.2853717440739274\n",
      "Epoch 0084 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.6036111111111111\n",
      "Training loss = 0.24072261677108822\n",
      "Validation accuracy = 0.59375\n",
      "Validation loss = 0.24710065685212612\n",
      "Epoch 0085 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.6038725490196079\n",
      "Training loss = 0.2405682117456899\n",
      "Validation accuracy = 0.625\n",
      "Validation loss = 0.21910339780151844\n",
      "Epoch 0086 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.6043023255813953\n",
      "Training loss = 0.2403919573281278\n",
      "Validation accuracy = 0.59375\n",
      "Validation loss = 0.24678729847073555\n",
      "Epoch 0087 / 0200\n",
      "=====================================\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training accuracy = 0.6048563218390804\n",
      "Training loss = 0.24016980624861187\n",
      "Validation accuracy = 0.3125\n",
      "Validation loss = 0.2782458607107401\n",
      "Epoch 0088 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.6052840909090909\n",
      "Training loss = 0.23995011749028256\n",
      "Validation accuracy = 0.53125\n",
      "Validation loss = 0.23750678449869156\n",
      "Epoch 0089 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.6055337078651686\n",
      "Training loss = 0.2397483194186893\n",
      "Validation accuracy = 0.5\n",
      "Validation loss = 0.2437044382095337\n",
      "Epoch 0090 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.605925925925926\n",
      "Training loss = 0.23953348028439062\n",
      "Validation accuracy = 0.625\n",
      "Validation loss = 0.22735321335494518\n",
      "Epoch 0091 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.6062179487179488\n",
      "Training loss = 0.23930010323559409\n",
      "Validation accuracy = 0.59375\n",
      "Validation loss = 0.23150553554296494\n",
      "Epoch 0092 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.6064492753623189\n",
      "Training loss = 0.23913371661381014\n",
      "Validation accuracy = 0.53125\n",
      "Validation loss = 0.2269686460494995\n",
      "Epoch 0093 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.6067473118279569\n",
      "Training loss = 0.23897175657412698\n",
      "Validation accuracy = 0.5625\n",
      "Validation loss = 0.24339207634329796\n",
      "Epoch 0094 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.6071542553191489\n",
      "Training loss = 0.23879754195637104\n",
      "Validation accuracy = 0.71875\n",
      "Validation loss = 0.2169515797868371\n",
      "Epoch 0095 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.607640350877193\n",
      "Training loss = 0.23858829480775615\n",
      "Validation accuracy = 0.53125\n",
      "Validation loss = 0.22786560840904713\n",
      "Epoch 0096 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.6078645833333334\n",
      "Training loss = 0.23844909886131063\n",
      "Validation accuracy = 0.5\n",
      "Validation loss = 0.2467000111937523\n",
      "Epoch 0097 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.6084020618556701\n",
      "Training loss = 0.23822951379203305\n",
      "Validation accuracy = 0.59375\n",
      "Validation loss = 0.22569821495562792\n",
      "Epoch 0098 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.6089115646258504\n",
      "Training loss = 0.23791792314955776\n",
      "Validation accuracy = 0.5625\n",
      "Validation loss = 0.23171072453260422\n",
      "Epoch 0099 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.6091161616161617\n",
      "Training loss = 0.23778302734046672\n",
      "Validation accuracy = 0.53125\n",
      "Validation loss = 0.23302052356302738\n",
      "Epoch 0100 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.6095666666666667\n",
      "Training loss = 0.23762219539135696\n",
      "Validation accuracy = 0.5\n",
      "Validation loss = 0.2538200067356229\n",
      "Epoch 0101 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.6100907590759076\n",
      "Training loss = 0.23741074662003975\n",
      "Validation accuracy = 0.5\n",
      "Validation loss = 0.26439146883785725\n",
      "Epoch 0102 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.6104901960784314\n",
      "Training loss = 0.23725504745942316\n",
      "Validation accuracy = 0.65625\n",
      "Validation loss = 0.22188081592321396\n",
      "Epoch 0103 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.6108495145631068\n",
      "Training loss = 0.2370632851215435\n",
      "Validation accuracy = 0.5\n",
      "Validation loss = 0.25301924999803305\n",
      "Epoch 0104 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.6110977564102564\n",
      "Training loss = 0.23698941337565582\n",
      "Validation accuracy = 0.65625\n",
      "Validation loss = 0.21127621922641993\n",
      "Epoch 0105 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.6113968253968254\n",
      "Training loss = 0.23683538761664005\n",
      "Validation accuracy = 0.53125\n",
      "Validation loss = 0.2334467861801386\n",
      "Epoch 0106 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.6119732704402516\n",
      "Training loss = 0.23660782086024496\n",
      "Validation accuracy = 0.59375\n",
      "Validation loss = 0.22436118591576815\n",
      "Epoch 0107 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.6120638629283489\n",
      "Training loss = 0.23653466708586782\n",
      "Validation accuracy = 0.46875\n",
      "Validation loss = 0.2533990740776062\n",
      "Epoch 0108 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.6122530864197531\n",
      "Training loss = 0.23638846952836087\n",
      "Validation accuracy = 0.4375\n",
      "Validation loss = 0.2346123866736889\n",
      "Epoch 0109 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.6126834862385321\n",
      "Training loss = 0.23618642567357886\n",
      "Validation accuracy = 0.625\n",
      "Validation loss = 0.22473547514528036\n",
      "Epoch 0110 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.6131363636363636\n",
      "Training loss = 0.23597141437503424\n",
      "Validation accuracy = 0.4375\n",
      "Validation loss = 0.2578912004828453\n",
      "Epoch 0111 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.6131606606606607\n",
      "Training loss = 0.23593828501375588\n",
      "Validation accuracy = 0.5625\n",
      "Validation loss = 0.2336967708542943\n",
      "Epoch 0112 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.6136607142857143\n",
      "Training loss = 0.23574399508136723\n",
      "Validation accuracy = 0.65625\n",
      "Validation loss = 0.23433986213058233\n",
      "Epoch 0113 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.6139970501474926\n",
      "Training loss = 0.2356175545638202\n",
      "Validation accuracy = 0.5625\n",
      "Validation loss = 0.22854322008788586\n",
      "Epoch 0114 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.614188596491228\n",
      "Training loss = 0.23548010097413558\n",
      "Validation accuracy = 0.5625\n",
      "Validation loss = 0.2291120532900095\n",
      "Epoch 0115 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.614463768115942\n",
      "Training loss = 0.23535116966889388\n",
      "Validation accuracy = 0.59375\n",
      "Validation loss = 0.2296821903437376\n",
      "Epoch 0116 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.6149640804597701\n",
      "Training loss = 0.23520949738549776\n",
      "Validation accuracy = 0.5625\n",
      "Validation loss = 0.2834271267056465\n",
      "Epoch 0117 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.6152279202279203\n",
      "Training loss = 0.23516011874114517\n",
      "Validation accuracy = 0.46875\n",
      "Validation loss = 0.2513640485703945\n",
      "Epoch 0118 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.615473163841808\n",
      "Training loss = 0.2350434702424343\n",
      "Validation accuracy = 0.59375\n",
      "Validation loss = 0.20933613367378712\n",
      "Epoch 0119 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.6158543417366947\n",
      "Training loss = 0.23489960580918134\n",
      "Validation accuracy = 0.625\n",
      "Validation loss = 0.22929731011390686\n",
      "Epoch 0120 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.6162361111111111\n",
      "Training loss = 0.23472496720320649\n",
      "Validation accuracy = 0.53125\n",
      "Validation loss = 0.23341763764619827\n",
      "Epoch 0121 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.616659779614325\n",
      "Training loss = 0.23451659728406055\n",
      "Validation accuracy = 0.71875\n",
      "Validation loss = 0.17538010608404875\n",
      "Epoch 0122 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.6170491803278688\n",
      "Training loss = 0.2343595493945186\n",
      "Validation accuracy = 0.46875\n",
      "Validation loss = 0.2583787478506565\n",
      "Epoch 0123 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.6172628726287263\n",
      "Training loss = 0.23425579100524183\n",
      "Validation accuracy = 0.625\n",
      "Validation loss = 0.23418954201042652\n",
      "Epoch 0124 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.6175201612903226\n",
      "Training loss = 0.23413617288713814\n",
      "Validation accuracy = 0.625\n",
      "Validation loss = 0.24022330716252327\n",
      "Epoch 0125 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.6177133333333333\n",
      "Training loss = 0.2339802550560236\n",
      "Validation accuracy = 0.625\n",
      "Validation loss = 0.24444899708032608\n",
      "Epoch 0126 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.6178835978835979\n",
      "Training loss = 0.23385715920635788\n",
      "Validation accuracy = 0.59375\n",
      "Validation loss = 0.21991416811943054\n",
      "Epoch 0127 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.6180643044619423\n",
      "Training loss = 0.23377483978339536\n",
      "Validation accuracy = 0.59375\n",
      "Validation loss = 0.2270632591098547\n",
      "Epoch 0128 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.6184309895833333\n",
      "Training loss = 0.23358936508613018\n",
      "Validation accuracy = 0.625\n",
      "Validation loss = 0.2552637495100498\n",
      "Epoch 0129 / 0200\n",
      "=====================================\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training accuracy = 0.6186950904392765\n",
      "Training loss = 0.23350320068363686\n",
      "Validation accuracy = 0.5\n",
      "Validation loss = 0.24200116656720638\n",
      "Epoch 0130 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.6189679487179487\n",
      "Training loss = 0.23337212220808634\n",
      "Validation accuracy = 0.6875\n",
      "Validation loss = 0.2250908650457859\n",
      "Epoch 0131 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.6193956743002544\n",
      "Training loss = 0.23314497543787988\n",
      "Validation accuracy = 0.65625\n",
      "Validation loss = 0.22871782071888447\n",
      "Epoch 0132 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.619665404040404\n",
      "Training loss = 0.23298512348171435\n",
      "Validation accuracy = 0.59375\n",
      "Validation loss = 0.23220625333487988\n",
      "Epoch 0133 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.620093984962406\n",
      "Training loss = 0.23281972695001982\n",
      "Validation accuracy = 0.4375\n",
      "Validation loss = 0.2627169396728277\n",
      "Epoch 0134 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.6203109452736318\n",
      "Training loss = 0.23271029181704295\n",
      "Validation accuracy = 0.375\n",
      "Validation loss = 0.2657991945743561\n",
      "Epoch 0135 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.6206481481481482\n",
      "Training loss = 0.23256157536399955\n",
      "Validation accuracy = 0.65625\n",
      "Validation loss = 0.22405424527823925\n",
      "Epoch 0136 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.6210355392156863\n",
      "Training loss = 0.23246201757268578\n",
      "Validation accuracy = 0.6875\n",
      "Validation loss = 0.2218859288841486\n",
      "Epoch 0137 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.6214111922141119\n",
      "Training loss = 0.23229684547514376\n",
      "Validation accuracy = 0.65625\n",
      "Validation loss = 0.2122823903337121\n",
      "Epoch 0138 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.6215821256038647\n",
      "Training loss = 0.2321869429965742\n",
      "Validation accuracy = 0.5625\n",
      "Validation loss = 0.2381438333541155\n",
      "Epoch 0139 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.6218585131894484\n",
      "Training loss = 0.232094826840704\n",
      "Validation accuracy = 0.4375\n",
      "Validation loss = 0.23311282135546207\n",
      "Epoch 0140 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.6220297619047619\n",
      "Training loss = 0.23197294682619118\n",
      "Validation accuracy = 0.6875\n",
      "Validation loss = 0.21589447744190693\n",
      "Epoch 0141 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.6223345153664303\n",
      "Training loss = 0.23183212512086893\n",
      "Validation accuracy = 0.46875\n",
      "Validation loss = 0.2379041165113449\n",
      "Epoch 0142 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.6226115023474178\n",
      "Training loss = 0.2317365697157425\n",
      "Validation accuracy = 0.53125\n",
      "Validation loss = 0.23196284286677837\n",
      "Epoch 0143 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.6228263403263403\n",
      "Training loss = 0.23164804901276434\n",
      "Validation accuracy = 0.46875\n",
      "Validation loss = 0.2354648821055889\n",
      "Epoch 0144 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.6232060185185185\n",
      "Training loss = 0.2314657968982916\n",
      "Validation accuracy = 0.65625\n",
      "Validation loss = 0.20185464806854725\n",
      "Epoch 0145 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.6236379310344827\n",
      "Training loss = 0.23127894470455318\n",
      "Validation accuracy = 0.625\n",
      "Validation loss = 0.2272245679050684\n",
      "Epoch 0146 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.6237328767123288\n",
      "Training loss = 0.23117878623902116\n",
      "Validation accuracy = 0.65625\n",
      "Validation loss = 0.21341417636722326\n",
      "Epoch 0147 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.6240816326530613\n",
      "Training loss = 0.23104740328495466\n",
      "Validation accuracy = 0.4375\n",
      "Validation loss = 0.31034839898347855\n",
      "Epoch 0148 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.6243975225225226\n",
      "Training loss = 0.23089850568355202\n",
      "Validation accuracy = 0.5625\n",
      "Validation loss = 0.2128271060064435\n",
      "Epoch 0149 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.6248769574944072\n",
      "Training loss = 0.23070586857963063\n",
      "Validation accuracy = 0.53125\n",
      "Validation loss = 0.2400669101625681\n",
      "Epoch 0150 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.6251277777777777\n",
      "Training loss = 0.23056720371196668\n",
      "Validation accuracy = 0.65625\n",
      "Validation loss = 0.2105533666908741\n",
      "Epoch 0151 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.6253587196467991\n",
      "Training loss = 0.23038874897110803\n",
      "Validation accuracy = 0.5625\n",
      "Validation loss = 0.21705619804561138\n",
      "Epoch 0152 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.6256962719298246\n",
      "Training loss = 0.2302675771517189\n",
      "Validation accuracy = 0.375\n",
      "Validation loss = 0.2765817642211914\n",
      "Epoch 0153 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.6259368191721133\n",
      "Training loss = 0.23014016504072807\n",
      "Validation accuracy = 0.53125\n",
      "Validation loss = 0.22061813436448574\n",
      "Epoch 0154 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.6261904761904762\n",
      "Training loss = 0.23000312522085972\n",
      "Validation accuracy = 0.59375\n",
      "Validation loss = 0.2855645976960659\n",
      "Epoch 0155 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.6264838709677419\n",
      "Training loss = 0.22981487187022162\n",
      "Validation accuracy = 0.75\n",
      "Validation loss = 0.20203603524714708\n",
      "Epoch 0156 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.6268482905982906\n",
      "Training loss = 0.22964677000609346\n",
      "Validation accuracy = 0.6875\n",
      "Validation loss = 0.21592019964009523\n",
      "Epoch 0157 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.6271231422505308\n",
      "Training loss = 0.2295180723039461\n",
      "Validation accuracy = 0.53125\n",
      "Validation loss = 0.25777982641011477\n",
      "Epoch 0158 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.627289029535865\n",
      "Training loss = 0.22941968162005713\n",
      "Validation accuracy = 0.6875\n",
      "Validation loss = 0.231202844530344\n",
      "Epoch 0159 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.627562893081761\n",
      "Training loss = 0.2292893653006861\n",
      "Validation accuracy = 0.5\n",
      "Validation loss = 0.2283970918506384\n",
      "Epoch 0160 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.6278333333333334\n",
      "Training loss = 0.22916476660671956\n",
      "Validation accuracy = 0.625\n",
      "Validation loss = 0.24369419179856777\n",
      "Epoch 0161 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.6280538302277433\n",
      "Training loss = 0.22904534881838112\n",
      "Validation accuracy = 0.625\n",
      "Validation loss = 0.22242811415344477\n",
      "Epoch 0162 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.6281995884773662\n",
      "Training loss = 0.22892806400717408\n",
      "Validation accuracy = 0.34375\n",
      "Validation loss = 0.268703605979681\n",
      "Epoch 0163 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.6283282208588957\n",
      "Training loss = 0.22887149433432058\n",
      "Validation accuracy = 0.65625\n",
      "Validation loss = 0.22946873679757118\n",
      "Epoch 0164 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.6285569105691057\n",
      "Training loss = 0.2287715622190598\n",
      "Validation accuracy = 0.71875\n",
      "Validation loss = 0.20607682690024376\n",
      "Epoch 0165 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.6288484848484849\n",
      "Training loss = 0.22862205004947955\n",
      "Validation accuracy = 0.46875\n",
      "Validation loss = 0.2350362353026867\n",
      "Epoch 0166 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.6289809236947791\n",
      "Training loss = 0.22857396771660052\n",
      "Validation accuracy = 0.625\n",
      "Validation loss = 0.23949017468839884\n",
      "Epoch 0167 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.6292065868263473\n",
      "Training loss = 0.22844849283451923\n",
      "Validation accuracy = 0.5\n",
      "Validation loss = 0.2942979373037815\n",
      "Epoch 0168 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.629265873015873\n",
      "Training loss = 0.2283950451541219\n",
      "Validation accuracy = 0.53125\n",
      "Validation loss = 0.26447574235498905\n",
      "Epoch 0169 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.6294378698224852\n",
      "Training loss = 0.2282978581341766\n",
      "Validation accuracy = 0.5\n",
      "Validation loss = 0.21621379163116217\n",
      "Epoch 0170 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.6297156862745098\n",
      "Training loss = 0.22818204668222689\n",
      "Validation accuracy = 0.59375\n",
      "Validation loss = 0.23228962998837233\n",
      "Epoch 0171 / 0200\n",
      "=====================================\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training accuracy = 0.6299025341130604\n",
      "Training loss = 0.22808964996644046\n",
      "Validation accuracy = 0.5625\n",
      "Validation loss = 0.21716080233454704\n",
      "Epoch 0172 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.6302761627906976\n",
      "Training loss = 0.22797116615917792\n",
      "Validation accuracy = 0.65625\n",
      "Validation loss = 0.23841443844139576\n",
      "Epoch 0173 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.6303998073217726\n",
      "Training loss = 0.22785019996868508\n",
      "Validation accuracy = 0.625\n",
      "Validation loss = 0.22541492246091366\n",
      "Epoch 0174 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.6307040229885057\n",
      "Training loss = 0.22773924979584656\n",
      "Validation accuracy = 0.40625\n",
      "Validation loss = 0.2622363343834877\n",
      "Epoch 0175 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.6308523809523809\n",
      "Training loss = 0.2276329574594895\n",
      "Validation accuracy = 0.625\n",
      "Validation loss = 0.26309653650969267\n",
      "Epoch 0176 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.6308522727272727\n",
      "Training loss = 0.22762045914180237\n",
      "Validation accuracy = 0.53125\n",
      "Validation loss = 0.22170555405318737\n",
      "Epoch 0177 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.6310969868173258\n",
      "Training loss = 0.2275075454719491\n",
      "Validation accuracy = 0.59375\n",
      "Validation loss = 0.2277271281927824\n",
      "Epoch 0178 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.6312968164794007\n",
      "Training loss = 0.22740696041018105\n",
      "Validation accuracy = 0.40625\n",
      "Validation loss = 0.2584001403301954\n",
      "Epoch 0179 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.631596834264432\n",
      "Training loss = 0.227277040168421\n",
      "Validation accuracy = 0.5\n",
      "Validation loss = 0.21084117889404297\n",
      "Epoch 0180 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.631824074074074\n",
      "Training loss = 0.22716227515966253\n",
      "Validation accuracy = 0.65625\n",
      "Validation loss = 0.24231430515646935\n",
      "Epoch 0181 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.6320718232044199\n",
      "Training loss = 0.22710455433000737\n",
      "Validation accuracy = 0.59375\n",
      "Validation loss = 0.2251338344067335\n",
      "Epoch 0182 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.632293956043956\n",
      "Training loss = 0.2270269789190574\n",
      "Validation accuracy = 0.5625\n",
      "Validation loss = 0.2455277917906642\n",
      "Epoch 0183 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.6326502732240438\n",
      "Training loss = 0.2268782867546887\n",
      "Validation accuracy = 0.65625\n",
      "Validation loss = 0.21220209915190935\n",
      "Epoch 0184 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.6327672101449275\n",
      "Training loss = 0.2267686573434891\n",
      "Validation accuracy = 0.59375\n",
      "Validation loss = 0.21130512468516827\n",
      "Epoch 0185 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.6329774774774775\n",
      "Training loss = 0.2266647831368017\n",
      "Validation accuracy = 0.65625\n",
      "Validation loss = 0.22786054015159607\n",
      "Epoch 0186 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.6332347670250896\n",
      "Training loss = 0.22653175768058573\n",
      "Validation accuracy = 0.625\n",
      "Validation loss = 0.2548410929739475\n",
      "Epoch 0187 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.6334848484848485\n",
      "Training loss = 0.22646170326081932\n",
      "Validation accuracy = 0.5625\n",
      "Validation loss = 0.22805193066596985\n",
      "Epoch 0188 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.6335859929078014\n",
      "Training loss = 0.226370117820086\n",
      "Validation accuracy = 0.625\n",
      "Validation loss = 0.23875048756599426\n",
      "Epoch 0189 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.6337874779541446\n",
      "Training loss = 0.2262897402678848\n",
      "Validation accuracy = 0.4375\n",
      "Validation loss = 0.22087899688631296\n",
      "Epoch 0190 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.6339473684210526\n",
      "Training loss = 0.22617489940816896\n",
      "Validation accuracy = 0.5\n",
      "Validation loss = 0.2198859415948391\n",
      "Epoch 0191 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.6341273996509599\n",
      "Training loss = 0.2260642726571148\n",
      "Validation accuracy = 0.59375\n",
      "Validation loss = 0.24628086388111115\n",
      "Epoch 0192 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.6341796875\n",
      "Training loss = 0.22604782959575662\n",
      "Validation accuracy = 0.65625\n",
      "Validation loss = 0.20890653505921364\n",
      "Epoch 0193 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.6344170984455959\n",
      "Training loss = 0.22594447481405755\n",
      "Validation accuracy = 0.6875\n",
      "Validation loss = 0.23648992739617825\n",
      "Epoch 0194 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.634639175257732\n",
      "Training loss = 0.22585449548559808\n",
      "Validation accuracy = 0.5625\n",
      "Validation loss = 0.23178721219301224\n",
      "Epoch 0195 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.6347692307692308\n",
      "Training loss = 0.22577221697989183\n",
      "Validation accuracy = 0.46875\n",
      "Validation loss = 0.22866836190223694\n",
      "Epoch 0196 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.634906462585034\n",
      "Training loss = 0.2257266534040017\n",
      "Validation accuracy = 0.5\n",
      "Validation loss = 0.243234533816576\n",
      "Epoch 0197 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.6350761421319797\n",
      "Training loss = 0.22565233988482536\n",
      "Validation accuracy = 0.53125\n",
      "Validation loss = 0.27579844929277897\n",
      "Epoch 0198 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.6352272727272728\n",
      "Training loss = 0.22555428031505861\n",
      "Validation accuracy = 0.59375\n",
      "Validation loss = 0.21467429772019386\n",
      "Epoch 0199 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.6354480737018425\n",
      "Training loss = 0.22542071119088125\n",
      "Validation accuracy = 0.65625\n",
      "Validation loss = 0.24525793176144361\n",
      "Epoch 0200 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.63565\n",
      "Training loss = 0.22532016570754348\n",
      "Validation accuracy = 0.6875\n",
      "Validation loss = 0.20547120738774538\n",
      "Making model for session group 20210310_15:26:14.684-20210319_16:10:32.051\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/imblearn/utils/_validation.py:326: UserWarning: After over-sampling, the number of samples (300) in class car will be larger than the number of samples in the majority class (class #signpost -> 160)\n",
      "  n_samples_majority,\n",
      "/usr/local/lib/python3.6/dist-packages/imblearn/utils/_validation.py:326: UserWarning: After over-sampling, the number of samples (300) in class signpost will be larger than the number of samples in the majority class (class #signpost -> 160)\n",
      "  n_samples_majority,\n",
      "/usr/local/lib/python3.6/dist-packages/imblearn/utils/_validation.py:326: UserWarning: After over-sampling, the number of samples (300) in class tree will be larger than the number of samples in the majority class (class #signpost -> 160)\n",
      "  n_samples_majority,\n",
      "/usr/local/lib/python3.6/dist-packages/imblearn/utils/_validation.py:326: UserWarning: After over-sampling, the number of samples (300) in class wall will be larger than the number of samples in the majority class (class #signpost -> 160)\n",
      "  n_samples_majority,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0001 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.41083333333333333\n",
      "Training loss = 0.3115326898296674\n",
      "Validation accuracy = 0.5\n",
      "Validation loss = 0.3133013900369406\n",
      "Epoch 0002 / 0200\n",
      "=====================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/_classification.py:1221: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training accuracy = 0.4575\n",
      "Training loss = 0.29902391783893106\n",
      "Validation accuracy = 0.46875\n",
      "Validation loss = 0.3003778923302889\n",
      "Epoch 0003 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.4736111111111111\n",
      "Training loss = 0.2921102728446325\n",
      "Validation accuracy = 0.5\n",
      "Validation loss = 0.2948833592236042\n",
      "Epoch 0004 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.488125\n",
      "Training loss = 0.28715266078710555\n",
      "Validation accuracy = 0.5\n",
      "Validation loss = 0.286527493968606\n",
      "Epoch 0005 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.497\n",
      "Training loss = 0.2837890414496263\n",
      "Validation accuracy = 0.5\n",
      "Validation loss = 0.2869065199047327\n",
      "Epoch 0006 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.5073611111111112\n",
      "Training loss = 0.2805718239148458\n",
      "Validation accuracy = 0.5\n",
      "Validation loss = 0.27861650474369526\n",
      "Epoch 0007 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.5145238095238095\n",
      "Training loss = 0.27826178423705555\n",
      "Validation accuracy = 0.5\n",
      "Validation loss = 0.2781662065535784\n",
      "Epoch 0008 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.5229166666666667\n",
      "Training loss = 0.2754376269939045\n",
      "Validation accuracy = 0.5\n",
      "Validation loss = 0.27009313087910414\n",
      "Epoch 0009 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.5275925925925926\n",
      "Training loss = 0.27357596469146234\n",
      "Validation accuracy = 0.5\n",
      "Validation loss = 0.29236280359327793\n",
      "Epoch 0010 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.5314166666666666\n",
      "Training loss = 0.27213687695314487\n",
      "Validation accuracy = 0.5\n",
      "Validation loss = 0.2727007754147053\n",
      "Epoch 0011 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.5356060606060606\n",
      "Training loss = 0.2698659389059652\n",
      "Validation accuracy = 0.53125\n",
      "Validation loss = 0.25966624543070793\n",
      "Epoch 0012 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.5378472222222223\n",
      "Training loss = 0.26831634831925233\n",
      "Validation accuracy = 0.5\n",
      "Validation loss = 0.28119626734405756\n",
      "Epoch 0013 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.5409615384615385\n",
      "Training loss = 0.2670174430539975\n",
      "Validation accuracy = 0.5\n",
      "Validation loss = 0.26357607264071703\n",
      "Epoch 0014 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.5430357142857143\n",
      "Training loss = 0.26550012706823295\n",
      "Validation accuracy = 0.5\n",
      "Validation loss = 0.26495264656841755\n",
      "Epoch 0015 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.5455\n",
      "Training loss = 0.2643919500940376\n",
      "Validation accuracy = 0.53125\n",
      "Validation loss = 0.26878392696380615\n",
      "Epoch 0016 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.54734375\n",
      "Training loss = 0.2633812483043099\n",
      "Validation accuracy = 0.59375\n",
      "Validation loss = 0.2500262148678303\n",
      "Epoch 0017 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.5498039215686275\n",
      "Training loss = 0.2621094278143902\n",
      "Validation accuracy = 0.53125\n",
      "Validation loss = 0.2705915495753288\n",
      "Epoch 0018 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.5528240740740741\n",
      "Training loss = 0.26103167372169317\n",
      "Validation accuracy = 0.5\n",
      "Validation loss = 0.26806258503347635\n",
      "Epoch 0019 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.5546491228070175\n",
      "Training loss = 0.2601336599533495\n",
      "Validation accuracy = 0.46875\n",
      "Validation loss = 0.24585986509919167\n",
      "Epoch 0020 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.557\n",
      "Training loss = 0.2587925139504174\n",
      "Validation accuracy = 0.5\n",
      "Validation loss = 0.28083045966923237\n",
      "Epoch 0021 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.5584126984126984\n",
      "Training loss = 0.258171820945683\n",
      "Validation accuracy = 0.5\n",
      "Validation loss = 0.26973466109484434\n",
      "Epoch 0022 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.5598106060606061\n",
      "Training loss = 0.25733860526459684\n",
      "Validation accuracy = 0.5\n",
      "Validation loss = 0.2716855276376009\n",
      "Epoch 0023 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.561231884057971\n",
      "Training loss = 0.2566506928723791\n",
      "Validation accuracy = 0.5625\n",
      "Validation loss = 0.25349991489201784\n",
      "Epoch 0024 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.5619791666666667\n",
      "Training loss = 0.25626588886500234\n",
      "Validation accuracy = 0.65625\n",
      "Validation loss = 0.2535631963983178\n",
      "Epoch 0025 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.5632666666666667\n",
      "Training loss = 0.2558421353896459\n",
      "Validation accuracy = 0.5\n",
      "Validation loss = 0.24244436714798212\n",
      "Epoch 0026 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.5648717948717948\n",
      "Training loss = 0.25509004447418143\n",
      "Validation accuracy = 0.5\n",
      "Validation loss = 0.25836371909826994\n",
      "Epoch 0027 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.565462962962963\n",
      "Training loss = 0.25472495856936334\n",
      "Validation accuracy = 0.46875\n",
      "Validation loss = 0.29032333940267563\n",
      "Epoch 0028 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.5671726190476191\n",
      "Training loss = 0.2540001552472157\n",
      "Validation accuracy = 0.53125\n",
      "Validation loss = 0.28113271202892065\n",
      "Epoch 0029 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.5683620689655172\n",
      "Training loss = 0.2535711696538432\n",
      "Validation accuracy = 0.53125\n",
      "Validation loss = 0.26539666298776865\n",
      "Epoch 0030 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.5691944444444444\n",
      "Training loss = 0.25305635739531784\n",
      "Validation accuracy = 0.59375\n",
      "Validation loss = 0.24200379475951195\n",
      "Epoch 0031 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.5706720430107527\n",
      "Training loss = 0.2526760527731911\n",
      "Validation accuracy = 0.5625\n",
      "Validation loss = 0.25640042312443256\n",
      "Epoch 0032 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.571328125\n",
      "Training loss = 0.2522109354000228\n",
      "Validation accuracy = 0.5625\n",
      "Validation loss = 0.24864810705184937\n",
      "Epoch 0033 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.5726515151515151\n",
      "Training loss = 0.2516446177924823\n",
      "Validation accuracy = 0.5625\n",
      "Validation loss = 0.2526037469506264\n",
      "Epoch 0034 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.5737990196078432\n",
      "Training loss = 0.2511289652919068\n",
      "Validation accuracy = 0.53125\n",
      "Validation loss = 0.2533075464889407\n",
      "Epoch 0035 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.5748333333333333\n",
      "Training loss = 0.2505340437974249\n",
      "Validation accuracy = 0.5625\n",
      "Validation loss = 0.23414455354213715\n",
      "Epoch 0036 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.5750462962962963\n",
      "Training loss = 0.25023931761237755\n",
      "Validation accuracy = 0.5625\n",
      "Validation loss = 0.23446813877671957\n",
      "Epoch 0037 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.5761711711711712\n",
      "Training loss = 0.24991123826050007\n",
      "Validation accuracy = 0.53125\n",
      "Validation loss = 0.23442604299634695\n",
      "Epoch 0038 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.577280701754386\n",
      "Training loss = 0.2492739255778622\n",
      "Validation accuracy = 0.59375\n",
      "Validation loss = 0.2250932427123189\n",
      "Epoch 0039 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.5778846153846153\n",
      "Training loss = 0.2488945921523194\n",
      "Validation accuracy = 0.59375\n",
      "Validation loss = 0.23291248828172684\n",
      "Epoch 0040 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.5787291666666666\n",
      "Training loss = 0.24848228426463903\n",
      "Validation accuracy = 0.59375\n",
      "Validation loss = 0.2360764741897583\n",
      "Epoch 0041 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.5793292682926829\n",
      "Training loss = 0.24812794792215997\n",
      "Validation accuracy = 0.5\n",
      "Validation loss = 0.2611570321023464\n",
      "Epoch 0042 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.5804166666666667\n",
      "Training loss = 0.24784135643274538\n",
      "Validation accuracy = 0.53125\n",
      "Validation loss = 0.27642903197556734\n",
      "Epoch 0043 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.5814728682170542\n",
      "Training loss = 0.2475925366684448\n",
      "Validation accuracy = 0.65625\n",
      "Validation loss = 0.22193207778036594\n",
      "Epoch 0044 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.5822916666666667\n",
      "Training loss = 0.24721191847076018\n",
      "Validation accuracy = 0.5625\n",
      "Validation loss = 0.2720800116658211\n",
      "Epoch 0045 / 0200\n",
      "=====================================\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training accuracy = 0.5828333333333333\n",
      "Training loss = 0.246969225195271\n",
      "Validation accuracy = 0.53125\n",
      "Validation loss = 0.25862702168524265\n",
      "Epoch 0046 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.5834963768115942\n",
      "Training loss = 0.24672239275136287\n",
      "Validation accuracy = 0.5625\n",
      "Validation loss = 0.23714107181876898\n",
      "Epoch 0047 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.5844680851063829\n",
      "Training loss = 0.24639088282876825\n",
      "Validation accuracy = 0.5625\n",
      "Validation loss = 0.2487379675731063\n",
      "Epoch 0048 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.5856423611111111\n",
      "Training loss = 0.24600958202551637\n",
      "Validation accuracy = 0.59375\n",
      "Validation loss = 0.2384548792615533\n",
      "Epoch 0049 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.5857993197278911\n",
      "Training loss = 0.24581332357866423\n",
      "Validation accuracy = 0.5625\n",
      "Validation loss = 0.24240044504404068\n",
      "Epoch 0050 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.5863333333333334\n",
      "Training loss = 0.24551522365560136\n",
      "Validation accuracy = 0.5625\n",
      "Validation loss = 0.24268191866576672\n",
      "Epoch 0051 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.586781045751634\n",
      "Training loss = 0.24526740127626587\n",
      "Validation accuracy = 0.59375\n",
      "Validation loss = 0.23471953719854355\n",
      "Epoch 0052 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.5874519230769231\n",
      "Training loss = 0.24491583451771964\n",
      "Validation accuracy = 0.5\n",
      "Validation loss = 0.23391238041222095\n",
      "Epoch 0053 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.5880817610062893\n",
      "Training loss = 0.24472554623284054\n",
      "Validation accuracy = 0.59375\n",
      "Validation loss = 0.22144604288041592\n",
      "Epoch 0054 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.5889197530864198\n",
      "Training loss = 0.24423087282083283\n",
      "Validation accuracy = 0.59375\n",
      "Validation loss = 0.2179416948929429\n",
      "Epoch 0055 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.5896969696969697\n",
      "Training loss = 0.24395328099483793\n",
      "Validation accuracy = 0.53125\n",
      "Validation loss = 0.23606567177921534\n",
      "Epoch 0056 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.590297619047619\n",
      "Training loss = 0.24365220941071\n",
      "Validation accuracy = 0.53125\n",
      "Validation loss = 0.23915342520922422\n",
      "Epoch 0057 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.5909795321637427\n",
      "Training loss = 0.24331775033639538\n",
      "Validation accuracy = 0.53125\n",
      "Validation loss = 0.24594305083155632\n",
      "Epoch 0058 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.5914367816091954\n",
      "Training loss = 0.24305337920913409\n",
      "Validation accuracy = 0.5\n",
      "Validation loss = 0.27965747751295567\n",
      "Epoch 0059 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.5918502824858757\n",
      "Training loss = 0.24281795917510313\n",
      "Validation accuracy = 0.53125\n",
      "Validation loss = 0.23772906512022018\n",
      "Epoch 0060 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.5924583333333333\n",
      "Training loss = 0.2425597571792702\n",
      "Validation accuracy = 0.53125\n",
      "Validation loss = 0.23351862840354443\n",
      "Epoch 0061 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.5931420765027322\n",
      "Training loss = 0.24223278781755375\n",
      "Validation accuracy = 0.5625\n",
      "Validation loss = 0.2540478613227606\n",
      "Epoch 0062 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.5935483870967742\n",
      "Training loss = 0.24209651009249752\n",
      "Validation accuracy = 0.53125\n",
      "Validation loss = 0.265833443030715\n",
      "Epoch 0063 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.5938359788359788\n",
      "Training loss = 0.2419447740309295\n",
      "Validation accuracy = 0.5625\n",
      "Validation loss = 0.24353744834661484\n",
      "Epoch 0064 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.5942578125\n",
      "Training loss = 0.24180137662178217\n",
      "Validation accuracy = 0.5625\n",
      "Validation loss = 0.24600376468151808\n",
      "Epoch 0065 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.5949230769230769\n",
      "Training loss = 0.24157736847645198\n",
      "Validation accuracy = 0.5625\n",
      "Validation loss = 0.23220395483076572\n",
      "Epoch 0066 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.595239898989899\n",
      "Training loss = 0.24140237886533894\n",
      "Validation accuracy = 0.53125\n",
      "Validation loss = 0.2536215540021658\n",
      "Epoch 0067 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.5953482587064677\n",
      "Training loss = 0.24133220224238153\n",
      "Validation accuracy = 0.59375\n",
      "Validation loss = 0.23298626858741045\n",
      "Epoch 0068 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.5957475490196078\n",
      "Training loss = 0.24106836563304943\n",
      "Validation accuracy = 0.5625\n",
      "Validation loss = 0.22865739557892084\n",
      "Epoch 0069 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.596159420289855\n",
      "Training loss = 0.24096259606021325\n",
      "Validation accuracy = 0.625\n",
      "Validation loss = 0.24273546785116196\n",
      "Epoch 0070 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.5967738095238095\n",
      "Training loss = 0.24071622309088708\n",
      "Validation accuracy = 0.5\n",
      "Validation loss = 0.258700892329216\n",
      "Epoch 0071 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.5969014084507043\n",
      "Training loss = 0.24056752255929748\n",
      "Validation accuracy = 0.625\n",
      "Validation loss = 0.23621361888945103\n",
      "Epoch 0072 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.5974652777777778\n",
      "Training loss = 0.24039572557296465\n",
      "Validation accuracy = 0.53125\n",
      "Validation loss = 0.2295667426660657\n",
      "Epoch 0073 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.5980936073059361\n",
      "Training loss = 0.2400438482413009\n",
      "Validation accuracy = 0.53125\n",
      "Validation loss = 0.24656521994620562\n",
      "Epoch 0074 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.5985022522522523\n",
      "Training loss = 0.23988726476660452\n",
      "Validation accuracy = 0.5625\n",
      "Validation loss = 0.2401231713593006\n",
      "Epoch 0075 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.5989888888888889\n",
      "Training loss = 0.2396577757520808\n",
      "Validation accuracy = 0.53125\n",
      "Validation loss = 0.2618278870359063\n",
      "Epoch 0076 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.5992324561403509\n",
      "Training loss = 0.23957718583804213\n",
      "Validation accuracy = 0.59375\n",
      "Validation loss = 0.2322864569723606\n",
      "Epoch 0077 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.5999783549783549\n",
      "Training loss = 0.2392366627958559\n",
      "Validation accuracy = 0.59375\n",
      "Validation loss = 0.2395834820345044\n",
      "Epoch 0078 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.6003205128205128\n",
      "Training loss = 0.2390889833593725\n",
      "Validation accuracy = 0.59375\n",
      "Validation loss = 0.23677142150700092\n",
      "Epoch 0079 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.600590717299578\n",
      "Training loss = 0.23893737888914623\n",
      "Validation accuracy = 0.59375\n",
      "Validation loss = 0.21885258797556162\n",
      "Epoch 0080 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.6009895833333333\n",
      "Training loss = 0.2387780617720758\n",
      "Validation accuracy = 0.5625\n",
      "Validation loss = 0.23714499548077583\n",
      "Epoch 0081 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.6012037037037037\n",
      "Training loss = 0.2386445469626919\n",
      "Validation accuracy = 0.625\n",
      "Validation loss = 0.2320743827149272\n",
      "Epoch 0082 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.6014634146341463\n",
      "Training loss = 0.23852902096128317\n",
      "Validation accuracy = 0.5625\n",
      "Validation loss = 0.2385883927345276\n",
      "Epoch 0083 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.6019176706827309\n",
      "Training loss = 0.2383145261642684\n",
      "Validation accuracy = 0.5625\n",
      "Validation loss = 0.2435824852436781\n",
      "Epoch 0084 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.6024702380952381\n",
      "Training loss = 0.23813598403884542\n",
      "Validation accuracy = 0.65625\n",
      "Validation loss = 0.22782348468899727\n",
      "Epoch 0085 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.6029117647058824\n",
      "Training loss = 0.23792913706133179\n",
      "Validation accuracy = 0.5625\n",
      "Validation loss = 0.25966920517385006\n",
      "Epoch 0086 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.603468992248062\n",
      "Training loss = 0.23764080966830023\n",
      "Validation accuracy = 0.53125\n",
      "Validation loss = 0.27107720263302326\n",
      "Epoch 0087 / 0200\n",
      "=====================================\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training accuracy = 0.6036973180076628\n",
      "Training loss = 0.2375331308144605\n",
      "Validation accuracy = 0.5625\n",
      "Validation loss = 0.2265597591176629\n",
      "Epoch 0088 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.6042992424242424\n",
      "Training loss = 0.23726935410646327\n",
      "Validation accuracy = 0.5\n",
      "Validation loss = 0.24264999199658632\n",
      "Epoch 0089 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.604559925093633\n",
      "Training loss = 0.23705571776332704\n",
      "Validation accuracy = 0.5625\n",
      "Validation loss = 0.2459082007408142\n",
      "Epoch 0090 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.605\n",
      "Training loss = 0.23686626384766013\n",
      "Validation accuracy = 0.5\n",
      "Validation loss = 0.4280321318656206\n",
      "Epoch 0091 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.6052747252747253\n",
      "Training loss = 0.23669309966457197\n",
      "Validation accuracy = 0.5625\n",
      "Validation loss = 0.21868717204779387\n",
      "Epoch 0092 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.6054619565217392\n",
      "Training loss = 0.2365650943191587\n",
      "Validation accuracy = 0.625\n",
      "Validation loss = 0.22947491705417633\n",
      "Epoch 0093 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.6059229390681004\n",
      "Training loss = 0.23632314037411445\n",
      "Validation accuracy = 0.5625\n",
      "Validation loss = 0.23880037013441324\n",
      "Epoch 0094 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.6063741134751773\n",
      "Training loss = 0.23617043067536034\n",
      "Validation accuracy = 0.59375\n",
      "Validation loss = 0.23007434327155352\n",
      "Epoch 0095 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.6068157894736842\n",
      "Training loss = 0.23600336355415352\n",
      "Validation accuracy = 0.5625\n",
      "Validation loss = 0.2484895270317793\n",
      "Epoch 0096 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.6072309027777778\n",
      "Training loss = 0.2358870803945077\n",
      "Validation accuracy = 0.5625\n",
      "Validation loss = 0.23110991343855858\n",
      "Epoch 0097 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.6074742268041237\n",
      "Training loss = 0.2357404228289615\n",
      "Validation accuracy = 0.5625\n",
      "Validation loss = 0.24825828149914742\n",
      "Epoch 0098 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.6077551020408163\n",
      "Training loss = 0.23554009312548402\n",
      "Validation accuracy = 0.5625\n",
      "Validation loss = 0.2376235043630004\n",
      "Epoch 0099 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.6079461279461279\n",
      "Training loss = 0.23546869460731645\n",
      "Validation accuracy = 0.5\n",
      "Validation loss = 0.283116671256721\n",
      "Epoch 0100 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.6079583333333334\n",
      "Training loss = 0.23539119622881213\n",
      "Validation accuracy = 0.5625\n",
      "Validation loss = 0.23614741303026676\n",
      "Epoch 0101 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.6083415841584159\n",
      "Training loss = 0.23525922102503258\n",
      "Validation accuracy = 0.5625\n",
      "Validation loss = 0.2381467493250966\n",
      "Epoch 0102 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.608921568627451\n",
      "Training loss = 0.23500573606224232\n",
      "Validation accuracy = 0.53125\n",
      "Validation loss = 0.24776382371783257\n",
      "Epoch 0103 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.6091666666666666\n",
      "Training loss = 0.23487161062055034\n",
      "Validation accuracy = 0.5625\n",
      "Validation loss = 0.2528022462502122\n",
      "Epoch 0104 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.6092628205128205\n",
      "Training loss = 0.2348923933878541\n",
      "Validation accuracy = 0.59375\n",
      "Validation loss = 0.23676113318651915\n",
      "Epoch 0105 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.609531746031746\n",
      "Training loss = 0.23475494237504307\n",
      "Validation accuracy = 0.5\n",
      "Validation loss = 0.24250657949596643\n",
      "Epoch 0106 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.6100235849056603\n",
      "Training loss = 0.23452981898033956\n",
      "Validation accuracy = 0.5625\n",
      "Validation loss = 0.22711890377104282\n",
      "Epoch 0107 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.6104205607476636\n",
      "Training loss = 0.2344186048639062\n",
      "Validation accuracy = 0.59375\n",
      "Validation loss = 0.23111954145133495\n",
      "Epoch 0108 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.6107638888888889\n",
      "Training loss = 0.2342529072612524\n",
      "Validation accuracy = 0.5\n",
      "Validation loss = 0.28583639301359653\n",
      "Epoch 0109 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.6111544342507645\n",
      "Training loss = 0.23412869262585947\n",
      "Validation accuracy = 0.5\n",
      "Validation loss = 0.23739702999591827\n",
      "Epoch 0110 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.6113409090909091\n",
      "Training loss = 0.2340406368144534\n",
      "Validation accuracy = 0.5625\n",
      "Validation loss = 0.23290144000202417\n",
      "Epoch 0111 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.611433933933934\n",
      "Training loss = 0.23399107406134004\n",
      "Validation accuracy = 0.59375\n",
      "Validation loss = 0.2341807335615158\n",
      "Epoch 0112 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.6116071428571429\n",
      "Training loss = 0.2338955073455526\n",
      "Validation accuracy = 0.625\n",
      "Validation loss = 0.2482203859835863\n",
      "Epoch 0113 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.61202802359882\n",
      "Training loss = 0.2336813612422936\n",
      "Validation accuracy = 0.53125\n",
      "Validation loss = 0.26277545746415854\n",
      "Epoch 0114 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.6124926900584795\n",
      "Training loss = 0.23349309355020523\n",
      "Validation accuracy = 0.5625\n",
      "Validation loss = 0.2182897124439478\n",
      "Epoch 0115 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.6127826086956522\n",
      "Training loss = 0.23333146542526673\n",
      "Validation accuracy = 0.53125\n",
      "Validation loss = 0.24835155718028545\n",
      "Epoch 0116 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.6132543103448276\n",
      "Training loss = 0.23310899531468748\n",
      "Validation accuracy = 0.625\n",
      "Validation loss = 0.20874894689768553\n",
      "Epoch 0117 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.6134116809116809\n",
      "Training loss = 0.23294962136770075\n",
      "Validation accuracy = 0.625\n",
      "Validation loss = 0.23595787212252617\n",
      "Epoch 0118 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.613933615819209\n",
      "Training loss = 0.23276993153858824\n",
      "Validation accuracy = 0.625\n",
      "Validation loss = 0.21579747274518013\n",
      "Epoch 0119 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.6143417366946778\n",
      "Training loss = 0.2325947344376176\n",
      "Validation accuracy = 0.59375\n",
      "Validation loss = 0.22399908863008022\n",
      "Epoch 0120 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.6146527777777778\n",
      "Training loss = 0.23245317149410646\n",
      "Validation accuracy = 0.5625\n",
      "Validation loss = 0.24915509950369596\n",
      "Epoch 0121 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.6147589531680441\n",
      "Training loss = 0.23239404374553974\n",
      "Validation accuracy = 0.59375\n",
      "Validation loss = 0.21562206838279963\n",
      "Epoch 0122 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.6151639344262295\n",
      "Training loss = 0.23222359267088885\n",
      "Validation accuracy = 0.5625\n",
      "Validation loss = 0.20102882478386164\n",
      "Epoch 0123 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.6151964769647696\n",
      "Training loss = 0.23221063862001992\n",
      "Validation accuracy = 0.59375\n",
      "Validation loss = 0.23995008040219545\n",
      "Epoch 0124 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.6154233870967742\n",
      "Training loss = 0.23206907236788382\n",
      "Validation accuracy = 0.53125\n",
      "Validation loss = 0.23094992525875568\n",
      "Epoch 0125 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.6157533333333334\n",
      "Training loss = 0.23196037983973822\n",
      "Validation accuracy = 0.5625\n",
      "Validation loss = 0.2315230928361416\n",
      "Epoch 0126 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.6158465608465609\n",
      "Training loss = 0.23185843847613172\n",
      "Validation accuracy = 0.5625\n",
      "Validation loss = 0.24554931093007326\n",
      "Epoch 0127 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.6160498687664042\n",
      "Training loss = 0.23175001778979626\n",
      "Validation accuracy = 0.5\n",
      "Validation loss = 0.24979461636394262\n",
      "Epoch 0128 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.6163216145833333\n",
      "Training loss = 0.23159877030547554\n",
      "Validation accuracy = 0.53125\n",
      "Validation loss = 0.23681284114718437\n",
      "Epoch 0129 / 0200\n",
      "=====================================\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training accuracy = 0.6165697674418604\n",
      "Training loss = 0.23143784113209068\n",
      "Validation accuracy = 0.65625\n",
      "Validation loss = 0.21593606751412153\n",
      "Epoch 0130 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.6168717948717949\n",
      "Training loss = 0.23132634548403513\n",
      "Validation accuracy = 0.5625\n",
      "Validation loss = 0.22493908368051052\n",
      "Epoch 0131 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.617118320610687\n",
      "Training loss = 0.23125191860355948\n",
      "Validation accuracy = 0.53125\n",
      "Validation loss = 0.2323811436071992\n",
      "Epoch 0132 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.6173926767676767\n",
      "Training loss = 0.23114158367644055\n",
      "Validation accuracy = 0.59375\n",
      "Validation loss = 0.22355528734624386\n",
      "Epoch 0133 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.6175689223057644\n",
      "Training loss = 0.23103742293341267\n",
      "Validation accuracy = 0.5625\n",
      "Validation loss = 0.23332750611007214\n",
      "Epoch 0134 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.617773631840796\n",
      "Training loss = 0.23098388666426067\n",
      "Validation accuracy = 0.65625\n",
      "Validation loss = 0.2043364467099309\n",
      "Epoch 0135 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.6179382716049383\n",
      "Training loss = 0.23092028522969765\n",
      "Validation accuracy = 0.59375\n",
      "Validation loss = 0.23770572897046804\n",
      "Epoch 0136 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.6183333333333333\n",
      "Training loss = 0.23074748835362055\n",
      "Validation accuracy = 0.59375\n",
      "Validation loss = 0.2274792743846774\n",
      "Epoch 0137 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.6186435523114355\n",
      "Training loss = 0.23060194078352475\n",
      "Validation accuracy = 0.5625\n",
      "Validation loss = 0.23714100755751133\n",
      "Epoch 0138 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.6189794685990339\n",
      "Training loss = 0.2304265976589227\n",
      "Validation accuracy = 0.625\n",
      "Validation loss = 0.19983887020498514\n",
      "Epoch 0139 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.6191486810551559\n",
      "Training loss = 0.23035952531623183\n",
      "Validation accuracy = 0.53125\n",
      "Validation loss = 0.25626836623996496\n",
      "Epoch 0140 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.6194226190476191\n",
      "Training loss = 0.2302373970576695\n",
      "Validation accuracy = 0.53125\n",
      "Validation loss = 0.2384941764175892\n",
      "Epoch 0141 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.61975768321513\n",
      "Training loss = 0.23012367756707025\n",
      "Validation accuracy = 0.53125\n",
      "Validation loss = 0.22627224400639534\n",
      "Epoch 0142 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.6200352112676056\n",
      "Training loss = 0.2299718344363738\n",
      "Validation accuracy = 0.5625\n",
      "Validation loss = 0.23783964477479458\n",
      "Epoch 0143 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.6203088578088578\n",
      "Training loss = 0.22987228581208588\n",
      "Validation accuracy = 0.5625\n",
      "Validation loss = 0.23931963928043842\n",
      "Epoch 0144 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.6207175925925926\n",
      "Training loss = 0.2297352562730925\n",
      "Validation accuracy = 0.53125\n",
      "Validation loss = 0.23485201504081488\n",
      "Epoch 0145 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.6209597701149425\n",
      "Training loss = 0.22959038375574967\n",
      "Validation accuracy = 0.5625\n",
      "Validation loss = 0.24193169083446264\n",
      "Epoch 0146 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.6210673515981735\n",
      "Training loss = 0.22953514267337513\n",
      "Validation accuracy = 0.65625\n",
      "Validation loss = 0.21894899290055037\n",
      "Epoch 0147 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.6213038548752835\n",
      "Training loss = 0.22936099274730196\n",
      "Validation accuracy = 0.59375\n",
      "Validation loss = 0.22810771688818932\n",
      "Epoch 0148 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.6215878378378379\n",
      "Training loss = 0.22921363302967973\n",
      "Validation accuracy = 0.53125\n",
      "Validation loss = 0.24993011634796858\n",
      "Epoch 0149 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.6218288590604026\n",
      "Training loss = 0.22908921634874221\n",
      "Validation accuracy = 0.53125\n",
      "Validation loss = 0.25516012590378523\n",
      "Epoch 0150 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.6221111111111111\n",
      "Training loss = 0.22897211396843195\n",
      "Validation accuracy = 0.625\n",
      "Validation loss = 0.19542909786105156\n",
      "Epoch 0151 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.6225055187637969\n",
      "Training loss = 0.22881689944261352\n",
      "Validation accuracy = 0.53125\n",
      "Validation loss = 0.21906322799623013\n",
      "Epoch 0152 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.6228289473684211\n",
      "Training loss = 0.22869196851214948\n",
      "Validation accuracy = 0.5\n",
      "Validation loss = 0.2684412179514766\n",
      "Epoch 0153 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.623099128540305\n",
      "Training loss = 0.22861396908062087\n",
      "Validation accuracy = 0.5625\n",
      "Validation loss = 0.21405638381838799\n",
      "Epoch 0154 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.6234415584415585\n",
      "Training loss = 0.22848331758776655\n",
      "Validation accuracy = 0.53125\n",
      "Validation loss = 0.22585418540984392\n",
      "Epoch 0155 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.623747311827957\n",
      "Training loss = 0.2283760855236361\n",
      "Validation accuracy = 0.59375\n",
      "Validation loss = 0.2253101672977209\n",
      "Epoch 0156 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.6240865384615385\n",
      "Training loss = 0.2282569048499577\n",
      "Validation accuracy = 0.5625\n",
      "Validation loss = 0.2212646221742034\n",
      "Epoch 0157 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.6241029723991507\n",
      "Training loss = 0.22817784071569736\n",
      "Validation accuracy = 0.59375\n",
      "Validation loss = 0.2443153578788042\n",
      "Epoch 0158 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.6243776371308016\n",
      "Training loss = 0.22802436803023524\n",
      "Validation accuracy = 0.5625\n",
      "Validation loss = 0.2564055249094963\n",
      "Epoch 0159 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.6245492662473795\n",
      "Training loss = 0.22788975214792623\n",
      "Validation accuracy = 0.5625\n",
      "Validation loss = 0.22042406257241964\n",
      "Epoch 0160 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.6248125\n",
      "Training loss = 0.2277587178228423\n",
      "Validation accuracy = 0.625\n",
      "Validation loss = 0.22099359333515167\n",
      "Epoch 0161 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.6251552795031056\n",
      "Training loss = 0.22760082291088243\n",
      "Validation accuracy = 0.6875\n",
      "Validation loss = 0.21144791319966316\n",
      "Epoch 0162 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.6252572016460906\n",
      "Training loss = 0.2275530042651075\n",
      "Validation accuracy = 0.5625\n",
      "Validation loss = 0.20730589982122183\n",
      "Epoch 0163 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.6256646216768916\n",
      "Training loss = 0.2274001752160078\n",
      "Validation accuracy = 0.5625\n",
      "Validation loss = 0.2265731543302536\n",
      "Epoch 0164 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.6258841463414634\n",
      "Training loss = 0.22725940131726183\n",
      "Validation accuracy = 0.5625\n",
      "Validation loss = 0.2452720459550619\n",
      "Epoch 0165 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.6260858585858586\n",
      "Training loss = 0.22713477358899334\n",
      "Validation accuracy = 0.59375\n",
      "Validation loss = 0.2094398271292448\n",
      "Epoch 0166 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.6264307228915663\n",
      "Training loss = 0.22699616617107965\n",
      "Validation accuracy = 0.65625\n",
      "Validation loss = 0.22138765454292297\n",
      "Epoch 0167 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.6268063872255489\n",
      "Training loss = 0.22682598886702826\n",
      "Validation accuracy = 0.53125\n",
      "Validation loss = 0.2379537196829915\n",
      "Epoch 0168 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.6269890873015873\n",
      "Training loss = 0.22676650428627101\n",
      "Validation accuracy = 0.5625\n",
      "Validation loss = 0.2353593809530139\n",
      "Epoch 0169 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.6272090729783037\n",
      "Training loss = 0.22662300163134197\n",
      "Validation accuracy = 0.59375\n",
      "Validation loss = 0.19276614114642143\n",
      "Epoch 0170 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.6274264705882353\n",
      "Training loss = 0.22654082005134984\n",
      "Validation accuracy = 0.5\n",
      "Validation loss = 0.23887017089873552\n",
      "Epoch 0171 / 0200\n",
      "=====================================\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training accuracy = 0.627504873294347\n",
      "Training loss = 0.2264531231992542\n",
      "Validation accuracy = 0.5625\n",
      "Validation loss = 0.22918958961963654\n",
      "Epoch 0172 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.6277083333333333\n",
      "Training loss = 0.2263414272933101\n",
      "Validation accuracy = 0.5625\n",
      "Validation loss = 0.2263497794046998\n",
      "Epoch 0173 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.6279865125240848\n",
      "Training loss = 0.2261893348928419\n",
      "Validation accuracy = 0.59375\n",
      "Validation loss = 0.19795197248458862\n",
      "Epoch 0174 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.6281130268199234\n",
      "Training loss = 0.22609696987359804\n",
      "Validation accuracy = 0.5\n",
      "Validation loss = 0.24852805212140083\n",
      "Epoch 0175 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.6283571428571428\n",
      "Training loss = 0.22601018612299648\n",
      "Validation accuracy = 0.65625\n",
      "Validation loss = 0.2100735967978835\n",
      "Epoch 0176 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.6285511363636364\n",
      "Training loss = 0.22587719593373495\n",
      "Validation accuracy = 0.59375\n",
      "Validation loss = 0.2372080385684967\n",
      "Epoch 0177 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.6288418079096045\n",
      "Training loss = 0.22577703205689703\n",
      "Validation accuracy = 0.59375\n",
      "Validation loss = 0.23205684032291174\n",
      "Epoch 0178 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.6289466292134831\n",
      "Training loss = 0.22571296339449978\n",
      "Validation accuracy = 0.625\n",
      "Validation loss = 0.24787069391459227\n",
      "Epoch 0179 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.6292597765363128\n",
      "Training loss = 0.22555641050479988\n",
      "Validation accuracy = 0.65625\n",
      "Validation loss = 0.22900820430368185\n",
      "Epoch 0180 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.6294814814814815\n",
      "Training loss = 0.22544180799599875\n",
      "Validation accuracy = 0.625\n",
      "Validation loss = 0.20583119243383408\n",
      "Epoch 0181 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.6296639042357275\n",
      "Training loss = 0.22532555711292704\n",
      "Validation accuracy = 0.59375\n",
      "Validation loss = 0.2024748371914029\n",
      "Epoch 0182 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.6299130036630036\n",
      "Training loss = 0.22518074276417002\n",
      "Validation accuracy = 0.5625\n",
      "Validation loss = 0.23498576413840055\n",
      "Epoch 0183 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.6300182149362478\n",
      "Training loss = 0.22516758563977501\n",
      "Validation accuracy = 0.5625\n",
      "Validation loss = 0.2376186065375805\n",
      "Epoch 0184 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.6302762681159421\n",
      "Training loss = 0.22505042773529726\n",
      "Validation accuracy = 0.59375\n",
      "Validation loss = 0.23231367953121662\n",
      "Epoch 0185 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.630472972972973\n",
      "Training loss = 0.22495081304141262\n",
      "Validation accuracy = 0.59375\n",
      "Validation loss = 0.24147032666951418\n",
      "Epoch 0186 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.6307168458781361\n",
      "Training loss = 0.22483462766754211\n",
      "Validation accuracy = 0.5625\n",
      "Validation loss = 0.24279067665338516\n",
      "Epoch 0187 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.6310160427807486\n",
      "Training loss = 0.22470716961571505\n",
      "Validation accuracy = 0.59375\n",
      "Validation loss = 0.2088239286094904\n",
      "Epoch 0188 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.6312101063829787\n",
      "Training loss = 0.22465358382639153\n",
      "Validation accuracy = 0.5625\n",
      "Validation loss = 0.2130439830943942\n",
      "Epoch 0189 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.6313977072310406\n",
      "Training loss = 0.2245720981828198\n",
      "Validation accuracy = 0.625\n",
      "Validation loss = 0.22507345210760832\n",
      "Epoch 0190 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.631578947368421\n",
      "Training loss = 0.22449763271258327\n",
      "Validation accuracy = 0.65625\n",
      "Validation loss = 0.21363955084234476\n",
      "Epoch 0191 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.631609947643979\n",
      "Training loss = 0.22444577148258946\n",
      "Validation accuracy = 0.5625\n",
      "Validation loss = 0.2159767085686326\n",
      "Epoch 0192 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.6318880208333333\n",
      "Training loss = 0.22432859318945297\n",
      "Validation accuracy = 0.625\n",
      "Validation loss = 0.22659614216536283\n",
      "Epoch 0193 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.6321113989637306\n",
      "Training loss = 0.22420929347353125\n",
      "Validation accuracy = 0.59375\n",
      "Validation loss = 0.22622672747820616\n",
      "Epoch 0194 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.6323969072164949\n",
      "Training loss = 0.22408777488728415\n",
      "Validation accuracy = 0.53125\n",
      "Validation loss = 0.22310215793550014\n",
      "Epoch 0195 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.6326410256410256\n",
      "Training loss = 0.22398318616581014\n",
      "Validation accuracy = 0.59375\n",
      "Validation loss = 0.22491234354674816\n",
      "Epoch 0196 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.6327636054421769\n",
      "Training loss = 0.22392883073633574\n",
      "Validation accuracy = 0.5625\n",
      "Validation loss = 0.23047861270606518\n",
      "Epoch 0197 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.6330160744500846\n",
      "Training loss = 0.22383451149554673\n",
      "Validation accuracy = 0.5\n",
      "Validation loss = 0.3289470262825489\n",
      "Epoch 0198 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.633236531986532\n",
      "Training loss = 0.22373547782958406\n",
      "Validation accuracy = 0.53125\n",
      "Validation loss = 0.22868421766906977\n",
      "Epoch 0199 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.633425460636516\n",
      "Training loss = 0.22363127790759607\n",
      "Validation accuracy = 0.625\n",
      "Validation loss = 0.22443967405706644\n",
      "Epoch 0200 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.6335416666666667\n",
      "Training loss = 0.2235529684610044\n",
      "Validation accuracy = 0.625\n",
      "Validation loss = 0.21673128940165043\n",
      "Making model for session group 20210310_15:26:36.351-20210319_16:11:12.300\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/imblearn/utils/_validation.py:326: UserWarning: After over-sampling, the number of samples (300) in class car will be larger than the number of samples in the majority class (class #signpost -> 160)\n",
      "  n_samples_majority,\n",
      "/usr/local/lib/python3.6/dist-packages/imblearn/utils/_validation.py:326: UserWarning: After over-sampling, the number of samples (300) in class signpost will be larger than the number of samples in the majority class (class #signpost -> 160)\n",
      "  n_samples_majority,\n",
      "/usr/local/lib/python3.6/dist-packages/imblearn/utils/_validation.py:326: UserWarning: After over-sampling, the number of samples (300) in class tree will be larger than the number of samples in the majority class (class #signpost -> 160)\n",
      "  n_samples_majority,\n",
      "/usr/local/lib/python3.6/dist-packages/imblearn/utils/_validation.py:326: UserWarning: After over-sampling, the number of samples (300) in class wall will be larger than the number of samples in the majority class (class #signpost -> 160)\n",
      "  n_samples_majority,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0001 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.4091666666666667\n",
      "Training loss = 0.3072168976565202\n",
      "Validation accuracy = 0.625\n",
      "Validation loss = 0.2762775178998709\n",
      "Epoch 0002 / 0200\n",
      "=====================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/_classification.py:1221: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training accuracy = 0.44916666666666666\n",
      "Training loss = 0.29581730420390767\n",
      "Validation accuracy = 0.5\n",
      "Validation loss = 0.28640185110270977\n",
      "Epoch 0003 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.47305555555555556\n",
      "Training loss = 0.28821501308017305\n",
      "Validation accuracy = 0.46875\n",
      "Validation loss = 0.26888144575059414\n",
      "Epoch 0004 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.493125\n",
      "Training loss = 0.2832156123345097\n",
      "Validation accuracy = 0.5\n",
      "Validation loss = 0.2677844539284706\n",
      "Epoch 0005 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.5063333333333333\n",
      "Training loss = 0.2798522323866685\n",
      "Validation accuracy = 0.53125\n",
      "Validation loss = 0.27739677857607603\n",
      "Epoch 0006 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.5147222222222222\n",
      "Training loss = 0.27734591020892063\n",
      "Validation accuracy = 0.34375\n",
      "Validation loss = 0.27933224104344845\n",
      "Epoch 0007 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.5264285714285715\n",
      "Training loss = 0.2737052963212842\n",
      "Validation accuracy = 0.4375\n",
      "Validation loss = 0.28210203908383846\n",
      "Epoch 0008 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.5365625\n",
      "Training loss = 0.2699782257589201\n",
      "Validation accuracy = 0.4375\n",
      "Validation loss = 0.2551083452999592\n",
      "Epoch 0009 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.5404629629629629\n",
      "Training loss = 0.268486212020119\n",
      "Validation accuracy = 0.46875\n",
      "Validation loss = 0.2791207395493984\n",
      "Epoch 0010 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.5444166666666667\n",
      "Training loss = 0.26681329881896576\n",
      "Validation accuracy = 0.4375\n",
      "Validation loss = 0.28012012504041195\n",
      "Epoch 0011 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.5471212121212121\n",
      "Training loss = 0.2656901875770453\n",
      "Validation accuracy = 0.4375\n",
      "Validation loss = 0.271175985224545\n",
      "Epoch 0012 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.5504861111111111\n",
      "Training loss = 0.26450592214448587\n",
      "Validation accuracy = 0.5\n",
      "Validation loss = 0.2630179822444916\n",
      "Epoch 0013 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.5537179487179488\n",
      "Training loss = 0.2631050064930549\n",
      "Validation accuracy = 0.5625\n",
      "Validation loss = 0.25620848406106234\n",
      "Epoch 0014 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.5566666666666666\n",
      "Training loss = 0.26174002153532844\n",
      "Validation accuracy = 0.40625\n",
      "Validation loss = 0.2629265617579222\n",
      "Epoch 0015 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.5586666666666666\n",
      "Training loss = 0.26050894133415486\n",
      "Validation accuracy = 0.34375\n",
      "Validation loss = 0.2898135222494602\n",
      "Epoch 0016 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.5609375\n",
      "Training loss = 0.25981899608081827\n",
      "Validation accuracy = 0.46875\n",
      "Validation loss = 0.26375486236065626\n",
      "Epoch 0017 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.5625980392156863\n",
      "Training loss = 0.2593522080194716\n",
      "Validation accuracy = 0.40625\n",
      "Validation loss = 0.2560728220269084\n",
      "Epoch 0018 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.5637962962962964\n",
      "Training loss = 0.2585894739172525\n",
      "Validation accuracy = 0.40625\n",
      "Validation loss = 0.2581453761085868\n",
      "Epoch 0019 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.5664473684210526\n",
      "Training loss = 0.2575100824720504\n",
      "Validation accuracy = 0.375\n",
      "Validation loss = 0.2752795033156872\n",
      "Epoch 0020 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.56825\n",
      "Training loss = 0.25658475250254076\n",
      "Validation accuracy = 0.4375\n",
      "Validation loss = 0.27153309248387814\n",
      "Epoch 0021 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.5706746031746032\n",
      "Training loss = 0.2556132109238515\n",
      "Validation accuracy = 0.375\n",
      "Validation loss = 0.2653023134917021\n",
      "Epoch 0022 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.5720833333333334\n",
      "Training loss = 0.25504150551941357\n",
      "Validation accuracy = 0.59375\n",
      "Validation loss = 0.2708279713988304\n",
      "Epoch 0023 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.5727536231884058\n",
      "Training loss = 0.2548070087327041\n",
      "Validation accuracy = 0.40625\n",
      "Validation loss = 0.2776497360318899\n",
      "Epoch 0024 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.5739930555555556\n",
      "Training loss = 0.25433996457606556\n",
      "Validation accuracy = 0.40625\n",
      "Validation loss = 0.287632854655385\n",
      "Epoch 0025 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.5749333333333333\n",
      "Training loss = 0.25401430979768436\n",
      "Validation accuracy = 0.28125\n",
      "Validation loss = 0.27135604433715343\n",
      "Epoch 0026 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.5765705128205129\n",
      "Training loss = 0.2533842896679655\n",
      "Validation accuracy = 0.53125\n",
      "Validation loss = 0.26886983029544353\n",
      "Epoch 0027 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.5782716049382716\n",
      "Training loss = 0.2524225019001298\n",
      "Validation accuracy = 0.5\n",
      "Validation loss = 0.26226999051868916\n",
      "Epoch 0028 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.5797023809523809\n",
      "Training loss = 0.2516616252650108\n",
      "Validation accuracy = 0.46875\n",
      "Validation loss = 0.26614340022206306\n",
      "Epoch 0029 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.5815229885057471\n",
      "Training loss = 0.2510212837133942\n",
      "Validation accuracy = 0.5\n",
      "Validation loss = 0.2811592724174261\n",
      "Epoch 0030 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.5824722222222222\n",
      "Training loss = 0.2506203484924303\n",
      "Validation accuracy = 0.40625\n",
      "Validation loss = 0.27208856865763664\n",
      "Epoch 0031 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.5833064516129032\n",
      "Training loss = 0.25032141774412126\n",
      "Validation accuracy = 0.75\n",
      "Validation loss = 0.2501464821398258\n",
      "Epoch 0032 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.5837760416666666\n",
      "Training loss = 0.250002558202638\n",
      "Validation accuracy = 0.4375\n",
      "Validation loss = 0.2623252868652344\n",
      "Epoch 0033 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.5846969696969697\n",
      "Training loss = 0.24957210640639368\n",
      "Validation accuracy = 0.40625\n",
      "Validation loss = 0.2615923546254635\n",
      "Epoch 0034 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.585514705882353\n",
      "Training loss = 0.24901030647696235\n",
      "Validation accuracy = 0.4375\n",
      "Validation loss = 0.27141168899834156\n",
      "Epoch 0035 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.5865238095238096\n",
      "Training loss = 0.24856248527481442\n",
      "Validation accuracy = 0.40625\n",
      "Validation loss = 0.25698437727987766\n",
      "Epoch 0036 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.5872222222222222\n",
      "Training loss = 0.2481563960553871\n",
      "Validation accuracy = 0.40625\n",
      "Validation loss = 0.2620725445449352\n",
      "Epoch 0037 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.5877702702702703\n",
      "Training loss = 0.24781377206111813\n",
      "Validation accuracy = 0.46875\n",
      "Validation loss = 0.27308806497603655\n",
      "Epoch 0038 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.5888815789473684\n",
      "Training loss = 0.2473507211128609\n",
      "Validation accuracy = 0.40625\n",
      "Validation loss = 0.269589401781559\n",
      "Epoch 0039 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.5896367521367522\n",
      "Training loss = 0.2470564040624433\n",
      "Validation accuracy = 0.375\n",
      "Validation loss = 0.27287518605589867\n",
      "Epoch 0040 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.5905208333333334\n",
      "Training loss = 0.2466477323596676\n",
      "Validation accuracy = 0.40625\n",
      "Validation loss = 0.27981093619018793\n",
      "Epoch 0041 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.5910162601626017\n",
      "Training loss = 0.2464318932707959\n",
      "Validation accuracy = 0.4375\n",
      "Validation loss = 0.26986394450068474\n",
      "Epoch 0042 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.5916468253968254\n",
      "Training loss = 0.2460736137729079\n",
      "Validation accuracy = 0.53125\n",
      "Validation loss = 0.2402400877326727\n",
      "Epoch 0043 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.5925193798449613\n",
      "Training loss = 0.24577301498820153\n",
      "Validation accuracy = 0.53125\n",
      "Validation loss = 0.2585089411586523\n",
      "Epoch 0044 / 0200\n",
      "=====================================\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training accuracy = 0.592935606060606\n",
      "Training loss = 0.24544561794197017\n",
      "Validation accuracy = 0.5\n",
      "Validation loss = 0.2678898870944977\n",
      "Epoch 0045 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.5933703703703703\n",
      "Training loss = 0.24535461250113116\n",
      "Validation accuracy = 0.375\n",
      "Validation loss = 0.26906339079141617\n",
      "Epoch 0046 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.5941666666666666\n",
      "Training loss = 0.24501522517560617\n",
      "Validation accuracy = 0.4375\n",
      "Validation loss = 0.2607721909880638\n",
      "Epoch 0047 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.5947517730496454\n",
      "Training loss = 0.24483604991901006\n",
      "Validation accuracy = 0.40625\n",
      "Validation loss = 0.26850578747689724\n",
      "Epoch 0048 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.5961631944444444\n",
      "Training loss = 0.24431080690015936\n",
      "Validation accuracy = 0.53125\n",
      "Validation loss = 0.26383247412741184\n",
      "Epoch 0049 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.5962244897959184\n",
      "Training loss = 0.2442046853712424\n",
      "Validation accuracy = 0.59375\n",
      "Validation loss = 0.24102051183581352\n",
      "Epoch 0050 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.5969666666666666\n",
      "Training loss = 0.24401610549688338\n",
      "Validation accuracy = 0.40625\n",
      "Validation loss = 0.27482178062200546\n",
      "Epoch 0051 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.5970915032679739\n",
      "Training loss = 0.24385717912729268\n",
      "Validation accuracy = 0.5625\n",
      "Validation loss = 0.2449487168341875\n",
      "Epoch 0052 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.5979326923076923\n",
      "Training loss = 0.24346968047320844\n",
      "Validation accuracy = 0.6875\n",
      "Validation loss = 0.24196681194007397\n",
      "Epoch 0053 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.5983176100628931\n",
      "Training loss = 0.2431709656897206\n",
      "Validation accuracy = 0.375\n",
      "Validation loss = 0.2725045159459114\n",
      "Epoch 0054 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.5994444444444444\n",
      "Training loss = 0.2426782698303829\n",
      "Validation accuracy = 0.46875\n",
      "Validation loss = 0.2897390518337488\n",
      "Epoch 0055 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.5998787878787879\n",
      "Training loss = 0.24243139329823582\n",
      "Validation accuracy = 0.40625\n",
      "Validation loss = 0.25861729122698307\n",
      "Epoch 0056 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.6009523809523809\n",
      "Training loss = 0.24200142556801438\n",
      "Validation accuracy = 0.46875\n",
      "Validation loss = 0.31194295175373554\n",
      "Epoch 0057 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.6012280701754386\n",
      "Training loss = 0.24180532357497522\n",
      "Validation accuracy = 0.4375\n",
      "Validation loss = 0.2605138337239623\n",
      "Epoch 0058 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.6019540229885058\n",
      "Training loss = 0.24141877333537257\n",
      "Validation accuracy = 0.375\n",
      "Validation loss = 0.28235799074172974\n",
      "Epoch 0059 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.6022598870056497\n",
      "Training loss = 0.24135774257871728\n",
      "Validation accuracy = 0.4375\n",
      "Validation loss = 0.267349349334836\n",
      "Epoch 0060 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.6023472222222223\n",
      "Training loss = 0.24125928427858484\n",
      "Validation accuracy = 0.4375\n",
      "Validation loss = 0.26632583513855934\n",
      "Epoch 0061 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.6030327868852459\n",
      "Training loss = 0.24094301675146068\n",
      "Validation accuracy = 0.4375\n",
      "Validation loss = 0.24757244531065226\n",
      "Epoch 0062 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.6034408602150537\n",
      "Training loss = 0.24076528250129633\n",
      "Validation accuracy = 0.4375\n",
      "Validation loss = 0.2698581647127867\n",
      "Epoch 0063 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.6040608465608466\n",
      "Training loss = 0.24046506692650457\n",
      "Validation accuracy = 0.40625\n",
      "Validation loss = 0.2544984742999077\n",
      "Epoch 0064 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.6044010416666666\n",
      "Training loss = 0.240293594316657\n",
      "Validation accuracy = 0.5\n",
      "Validation loss = 0.25411688163876534\n",
      "Epoch 0065 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.6050769230769231\n",
      "Training loss = 0.24004632437076323\n",
      "Validation accuracy = 0.5\n",
      "Validation loss = 0.2515428811311722\n",
      "Epoch 0066 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.6054419191919191\n",
      "Training loss = 0.23989256009610013\n",
      "Validation accuracy = 0.46875\n",
      "Validation loss = 0.26297806296497583\n",
      "Epoch 0067 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.6060820895522389\n",
      "Training loss = 0.23954486877059758\n",
      "Validation accuracy = 0.40625\n",
      "Validation loss = 0.2623965870589018\n",
      "Epoch 0068 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.6069607843137255\n",
      "Training loss = 0.2390994689248356\n",
      "Validation accuracy = 0.40625\n",
      "Validation loss = 0.26350027322769165\n",
      "Epoch 0069 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.6073309178743961\n",
      "Training loss = 0.23888271151245505\n",
      "Validation accuracy = 0.4375\n",
      "Validation loss = 0.26035376638174057\n",
      "Epoch 0070 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.6077619047619047\n",
      "Training loss = 0.23870916101159084\n",
      "Validation accuracy = 0.4375\n",
      "Validation loss = 0.2576684635132551\n",
      "Epoch 0071 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.608356807511737\n",
      "Training loss = 0.23848821857480657\n",
      "Validation accuracy = 0.53125\n",
      "Validation loss = 0.2713209427893162\n",
      "Epoch 0072 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.6088310185185185\n",
      "Training loss = 0.23818149388008925\n",
      "Validation accuracy = 0.5625\n",
      "Validation loss = 0.2479314124211669\n",
      "Epoch 0073 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.609337899543379\n",
      "Training loss = 0.23790615519091962\n",
      "Validation accuracy = 0.46875\n",
      "Validation loss = 0.2455335920676589\n",
      "Epoch 0074 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.6097184684684684\n",
      "Training loss = 0.2376689533211358\n",
      "Validation accuracy = 0.3125\n",
      "Validation loss = 0.26254608668386936\n",
      "Epoch 0075 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.6102666666666666\n",
      "Training loss = 0.23750137194030815\n",
      "Validation accuracy = 0.65625\n",
      "Validation loss = 0.240648927167058\n",
      "Epoch 0076 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.6106030701754386\n",
      "Training loss = 0.23724629779820117\n",
      "Validation accuracy = 0.4375\n",
      "Validation loss = 0.25408815033733845\n",
      "Epoch 0077 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.6109523809523809\n",
      "Training loss = 0.23716215591539036\n",
      "Validation accuracy = 0.4375\n",
      "Validation loss = 0.2579049225896597\n",
      "Epoch 0078 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.6115277777777778\n",
      "Training loss = 0.23685273320660888\n",
      "Validation accuracy = 0.46875\n",
      "Validation loss = 0.2368653891608119\n",
      "Epoch 0079 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.6120358649789029\n",
      "Training loss = 0.23659621630068317\n",
      "Validation accuracy = 0.4375\n",
      "Validation loss = 0.25920988060534\n",
      "Epoch 0080 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.61240625\n",
      "Training loss = 0.23643362744587162\n",
      "Validation accuracy = 0.40625\n",
      "Validation loss = 0.2681249622255564\n",
      "Epoch 0081 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.6128395061728396\n",
      "Training loss = 0.2362109619615132\n",
      "Validation accuracy = 0.4375\n",
      "Validation loss = 0.27898265793919563\n",
      "Epoch 0082 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.6131605691056911\n",
      "Training loss = 0.2360829665045428\n",
      "Validation accuracy = 0.40625\n",
      "Validation loss = 0.2632191330194473\n",
      "Epoch 0083 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.6136244979919678\n",
      "Training loss = 0.2359004854039854\n",
      "Validation accuracy = 0.5625\n",
      "Validation loss = 0.2506341952830553\n",
      "Epoch 0084 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.6141170634920635\n",
      "Training loss = 0.2357020603064152\n",
      "Validation accuracy = 0.5\n",
      "Validation loss = 0.24795567244291306\n",
      "Epoch 0085 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.6146372549019608\n",
      "Training loss = 0.235483497557979\n",
      "Validation accuracy = 0.46875\n",
      "Validation loss = 0.25159855000674725\n",
      "Epoch 0086 / 0200\n",
      "=====================================\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training accuracy = 0.6150096899224806\n",
      "Training loss = 0.2353357554498569\n",
      "Validation accuracy = 0.4375\n",
      "Validation loss = 0.2573054116219282\n",
      "Epoch 0087 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.6153639846743295\n",
      "Training loss = 0.23516460073234022\n",
      "Validation accuracy = 0.5\n",
      "Validation loss = 0.2597010210156441\n",
      "Epoch 0088 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.6159753787878788\n",
      "Training loss = 0.23491790776225654\n",
      "Validation accuracy = 0.5625\n",
      "Validation loss = 0.24419079814106226\n",
      "Epoch 0089 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.6163951310861423\n",
      "Training loss = 0.23472818204944723\n",
      "Validation accuracy = 0.46875\n",
      "Validation loss = 0.2657782956957817\n",
      "Epoch 0090 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.6167777777777778\n",
      "Training loss = 0.23458200131522283\n",
      "Validation accuracy = 0.375\n",
      "Validation loss = 0.2732702549546957\n",
      "Epoch 0091 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.6171336996336997\n",
      "Training loss = 0.2344721783643022\n",
      "Validation accuracy = 0.5625\n",
      "Validation loss = 0.25918169133365154\n",
      "Epoch 0092 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.6175996376811594\n",
      "Training loss = 0.2342214588129866\n",
      "Validation accuracy = 0.4375\n",
      "Validation loss = 0.26176539715379477\n",
      "Epoch 0093 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.6179032258064516\n",
      "Training loss = 0.2341431902829678\n",
      "Validation accuracy = 0.40625\n",
      "Validation loss = 0.25908683612942696\n",
      "Epoch 0094 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.6183421985815603\n",
      "Training loss = 0.23403522096600726\n",
      "Validation accuracy = 0.3125\n",
      "Validation loss = 0.2736295470967889\n",
      "Epoch 0095 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.6185877192982456\n",
      "Training loss = 0.23386297778968226\n",
      "Validation accuracy = 0.4375\n",
      "Validation loss = 0.23253825679421425\n",
      "Epoch 0096 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.6188020833333333\n",
      "Training loss = 0.23371777425468382\n",
      "Validation accuracy = 0.59375\n",
      "Validation loss = 0.23744030017405748\n",
      "Epoch 0097 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.6190893470790378\n",
      "Training loss = 0.2335492918729987\n",
      "Validation accuracy = 0.4375\n",
      "Validation loss = 0.26142021734267473\n",
      "Epoch 0098 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.6193112244897959\n",
      "Training loss = 0.23335893319324166\n",
      "Validation accuracy = 0.4375\n",
      "Validation loss = 0.2563529219478369\n",
      "Epoch 0099 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.6196464646464647\n",
      "Training loss = 0.23314454874105325\n",
      "Validation accuracy = 0.53125\n",
      "Validation loss = 0.24841764941811562\n",
      "Epoch 0100 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.6201416666666667\n",
      "Training loss = 0.23289526633570592\n",
      "Validation accuracy = 0.46875\n",
      "Validation loss = 0.24370044842362404\n",
      "Epoch 0101 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.6203630363036303\n",
      "Training loss = 0.23274190912447354\n",
      "Validation accuracy = 0.46875\n",
      "Validation loss = 0.26891426742076874\n",
      "Epoch 0102 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.6207271241830066\n",
      "Training loss = 0.23255892268315054\n",
      "Validation accuracy = 0.5\n",
      "Validation loss = 0.301950141787529\n",
      "Epoch 0103 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.6209870550161812\n",
      "Training loss = 0.23243741385277036\n",
      "Validation accuracy = 0.5625\n",
      "Validation loss = 0.26359423622488976\n",
      "Epoch 0104 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.6212660256410256\n",
      "Training loss = 0.23235544339371605\n",
      "Validation accuracy = 0.46875\n",
      "Validation loss = 0.25225295312702656\n",
      "Epoch 0105 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.6215714285714286\n",
      "Training loss = 0.23222319582388515\n",
      "Validation accuracy = 0.4375\n",
      "Validation loss = 0.2519205464050174\n",
      "Epoch 0106 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.6218867924528302\n",
      "Training loss = 0.23202037222566282\n",
      "Validation accuracy = 0.5\n",
      "Validation loss = 0.24443339556455612\n",
      "Epoch 0107 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.622196261682243\n",
      "Training loss = 0.23190548593520746\n",
      "Validation accuracy = 0.53125\n",
      "Validation loss = 0.2550463583320379\n",
      "Epoch 0108 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.6227391975308642\n",
      "Training loss = 0.23165352268535414\n",
      "Validation accuracy = 0.4375\n",
      "Validation loss = 0.2799875736236572\n",
      "Epoch 0109 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.6230045871559633\n",
      "Training loss = 0.2315648720411168\n",
      "Validation accuracy = 0.59375\n",
      "Validation loss = 0.23771971464157104\n",
      "Epoch 0110 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.6230984848484848\n",
      "Training loss = 0.23149188947496993\n",
      "Validation accuracy = 0.53125\n",
      "Validation loss = 0.29401812236756086\n",
      "Epoch 0111 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.6233783783783784\n",
      "Training loss = 0.23132142270492898\n",
      "Validation accuracy = 0.4375\n",
      "Validation loss = 0.24536085315048695\n",
      "Epoch 0112 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.6236904761904762\n",
      "Training loss = 0.231233858928927\n",
      "Validation accuracy = 0.53125\n",
      "Validation loss = 0.2542282845824957\n",
      "Epoch 0113 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.6239749262536873\n",
      "Training loss = 0.23108018300020766\n",
      "Validation accuracy = 0.46875\n",
      "Validation loss = 0.2717819446697831\n",
      "Epoch 0114 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.6240789473684211\n",
      "Training loss = 0.23095044124675423\n",
      "Validation accuracy = 0.59375\n",
      "Validation loss = 0.23260038811713457\n",
      "Epoch 0115 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.6243115942028985\n",
      "Training loss = 0.23076358367697053\n",
      "Validation accuracy = 0.28125\n",
      "Validation loss = 0.2618318134918809\n",
      "Epoch 0116 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.6246479885057471\n",
      "Training loss = 0.23070395794964726\n",
      "Validation accuracy = 0.375\n",
      "Validation loss = 0.26593070197850466\n",
      "Epoch 0117 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.6249430199430199\n",
      "Training loss = 0.23054026413804446\n",
      "Validation accuracy = 0.5\n",
      "Validation loss = 0.25695470813661814\n",
      "Epoch 0118 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.6253601694915254\n",
      "Training loss = 0.23039167243524292\n",
      "Validation accuracy = 0.46875\n",
      "Validation loss = 0.2530236914753914\n",
      "Epoch 0119 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.6257352941176471\n",
      "Training loss = 0.2302568394836842\n",
      "Validation accuracy = 0.46875\n",
      "Validation loss = 0.2541919555515051\n",
      "Epoch 0120 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.6259444444444444\n",
      "Training loss = 0.23014607168878945\n",
      "Validation accuracy = 0.3125\n",
      "Validation loss = 0.26798125356435776\n",
      "Epoch 0121 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.6262052341597796\n",
      "Training loss = 0.22995591745334715\n",
      "Validation accuracy = 0.4375\n",
      "Validation loss = 0.250028514303267\n",
      "Epoch 0122 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.6266734972677596\n",
      "Training loss = 0.22976366474797003\n",
      "Validation accuracy = 0.4375\n",
      "Validation loss = 0.2589584654197097\n",
      "Epoch 0123 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.6269308943089431\n",
      "Training loss = 0.22961591072158438\n",
      "Validation accuracy = 0.5\n",
      "Validation loss = 0.2672667456790805\n",
      "Epoch 0124 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.6270497311827957\n",
      "Training loss = 0.2295263834089361\n",
      "Validation accuracy = 0.5\n",
      "Validation loss = 0.24452290497720242\n",
      "Epoch 0125 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.6274666666666666\n",
      "Training loss = 0.22934058593352635\n",
      "Validation accuracy = 0.46875\n",
      "Validation loss = 0.25910826958715916\n",
      "Epoch 0126 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.6277711640211641\n",
      "Training loss = 0.2291286857891335\n",
      "Validation accuracy = 0.46875\n",
      "Validation loss = 0.29709925036877394\n",
      "Epoch 0127 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.6282414698162729\n",
      "Training loss = 0.2288629879125851\n",
      "Validation accuracy = 0.4375\n",
      "Validation loss = 0.2596950624138117\n",
      "Epoch 0128 / 0200\n",
      "=====================================\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training accuracy = 0.628515625\n",
      "Training loss = 0.22868522735487204\n",
      "Validation accuracy = 0.4375\n",
      "Validation loss = 0.25378691870719194\n",
      "Epoch 0129 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.6288372093023256\n",
      "Training loss = 0.22852084820719498\n",
      "Validation accuracy = 0.46875\n",
      "Validation loss = 0.2428154107183218\n",
      "Epoch 0130 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.6291666666666667\n",
      "Training loss = 0.22836399052807918\n",
      "Validation accuracy = 0.53125\n",
      "Validation loss = 0.26753797102719545\n",
      "Epoch 0131 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.6294529262086515\n",
      "Training loss = 0.2282827890438736\n",
      "Validation accuracy = 0.53125\n",
      "Validation loss = 0.23765950836241245\n",
      "Epoch 0132 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.6297032828282828\n",
      "Training loss = 0.22814881730730635\n",
      "Validation accuracy = 0.46875\n",
      "Validation loss = 0.2533400524407625\n",
      "Epoch 0133 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.6300187969924812\n",
      "Training loss = 0.22802750207801212\n",
      "Validation accuracy = 0.5\n",
      "Validation loss = 0.23922720178961754\n",
      "Epoch 0134 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.6302487562189055\n",
      "Training loss = 0.2279305967156641\n",
      "Validation accuracy = 0.46875\n",
      "Validation loss = 0.2477403236553073\n",
      "Epoch 0135 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.630425925925926\n",
      "Training loss = 0.22783847516057668\n",
      "Validation accuracy = 0.4375\n",
      "Validation loss = 0.23869813978672028\n",
      "Epoch 0136 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.6305514705882352\n",
      "Training loss = 0.22770307586126615\n",
      "Validation accuracy = 0.375\n",
      "Validation loss = 0.29381449706852436\n",
      "Epoch 0137 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.6308637469586375\n",
      "Training loss = 0.22751631421021157\n",
      "Validation accuracy = 0.46875\n",
      "Validation loss = 0.28275493532419205\n",
      "Epoch 0138 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.6311473429951691\n",
      "Training loss = 0.22741838784321494\n",
      "Validation accuracy = 0.40625\n",
      "Validation loss = 0.26695132069289684\n",
      "Epoch 0139 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.631552757793765\n",
      "Training loss = 0.22727112048857218\n",
      "Validation accuracy = 0.4375\n",
      "Validation loss = 0.24801595229655504\n",
      "Epoch 0140 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.6317678571428571\n",
      "Training loss = 0.22716740306573255\n",
      "Validation accuracy = 0.5\n",
      "Validation loss = 0.28054535761475563\n",
      "Epoch 0141 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.6319208037825059\n",
      "Training loss = 0.22708061286673195\n",
      "Validation accuracy = 0.46875\n",
      "Validation loss = 0.25504439882934093\n",
      "Epoch 0142 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.6321068075117371\n",
      "Training loss = 0.22693018032036757\n",
      "Validation accuracy = 0.40625\n",
      "Validation loss = 0.2647339291870594\n",
      "Epoch 0143 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.6324125874125874\n",
      "Training loss = 0.22679063729142948\n",
      "Validation accuracy = 0.4375\n",
      "Validation loss = 0.2535426141694188\n",
      "Epoch 0144 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.6326215277777778\n",
      "Training loss = 0.22667659829077483\n",
      "Validation accuracy = 0.53125\n",
      "Validation loss = 0.2448441917076707\n",
      "Epoch 0145 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.6329195402298851\n",
      "Training loss = 0.22655993876203723\n",
      "Validation accuracy = 0.40625\n",
      "Validation loss = 0.2504777396097779\n",
      "Epoch 0146 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.6330650684931507\n",
      "Training loss = 0.22644776810862158\n",
      "Validation accuracy = 0.4375\n",
      "Validation loss = 0.243100818246603\n",
      "Epoch 0147 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.633344671201814\n",
      "Training loss = 0.22632628508503475\n",
      "Validation accuracy = 0.5\n",
      "Validation loss = 0.2572063198313117\n",
      "Epoch 0148 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.6337105855855856\n",
      "Training loss = 0.22619110291488134\n",
      "Validation accuracy = 0.46875\n",
      "Validation loss = 0.2633108161389828\n",
      "Epoch 0149 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.6340492170022372\n",
      "Training loss = 0.22604004243026243\n",
      "Validation accuracy = 0.46875\n",
      "Validation loss = 0.25381237268447876\n",
      "Epoch 0150 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.6343388888888889\n",
      "Training loss = 0.2259240765793456\n",
      "Validation accuracy = 0.53125\n",
      "Validation loss = 0.24257885199040174\n",
      "Epoch 0151 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.6345916114790286\n",
      "Training loss = 0.22577547492175704\n",
      "Validation accuracy = 0.53125\n",
      "Validation loss = 0.25059327110648155\n",
      "Epoch 0152 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.6348519736842105\n",
      "Training loss = 0.22566957082991537\n",
      "Validation accuracy = 0.46875\n",
      "Validation loss = 0.26919581461697817\n",
      "Epoch 0153 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.6350980392156863\n",
      "Training loss = 0.2255901242162797\n",
      "Validation accuracy = 0.34375\n",
      "Validation loss = 0.2744027618318796\n",
      "Epoch 0154 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.635443722943723\n",
      "Training loss = 0.22543287674182808\n",
      "Validation accuracy = 0.46875\n",
      "Validation loss = 0.25215091928839684\n",
      "Epoch 0155 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.6358172043010752\n",
      "Training loss = 0.2252670601873949\n",
      "Validation accuracy = 0.53125\n",
      "Validation loss = 0.2839527493342757\n",
      "Epoch 0156 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.6359188034188035\n",
      "Training loss = 0.22521378865656563\n",
      "Validation accuracy = 0.375\n",
      "Validation loss = 0.2883745264261961\n",
      "Epoch 0157 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.6360774946921444\n",
      "Training loss = 0.2251396465075307\n",
      "Validation accuracy = 0.46875\n",
      "Validation loss = 0.2733838763087988\n",
      "Epoch 0158 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.6363502109704642\n",
      "Training loss = 0.22502113067808283\n",
      "Validation accuracy = 0.46875\n",
      "Validation loss = 0.250111180357635\n",
      "Epoch 0159 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.6366666666666667\n",
      "Training loss = 0.22489619870324554\n",
      "Validation accuracy = 0.46875\n",
      "Validation loss = 0.25393748842179775\n",
      "Epoch 0160 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.636765625\n",
      "Training loss = 0.2247996040339737\n",
      "Validation accuracy = 0.5\n",
      "Validation loss = 0.2748920526355505\n",
      "Epoch 0161 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.6370186335403727\n",
      "Training loss = 0.2246780037707948\n",
      "Validation accuracy = 0.5\n",
      "Validation loss = 0.25070841796696186\n",
      "Epoch 0162 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.6371039094650206\n",
      "Training loss = 0.22461688432420907\n",
      "Validation accuracy = 0.5\n",
      "Validation loss = 0.27187362127006054\n",
      "Epoch 0163 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.6373517382413088\n",
      "Training loss = 0.22450196875285944\n",
      "Validation accuracy = 0.4375\n",
      "Validation loss = 0.25363623164594173\n",
      "Epoch 0164 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.6376168699186991\n",
      "Training loss = 0.22438390963089963\n",
      "Validation accuracy = 0.5\n",
      "Validation loss = 0.26969708129763603\n",
      "Epoch 0165 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.6377828282828283\n",
      "Training loss = 0.2242718074390232\n",
      "Validation accuracy = 0.34375\n",
      "Validation loss = 0.28789591044187546\n",
      "Epoch 0166 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.6380421686746988\n",
      "Training loss = 0.22414527379552343\n",
      "Validation accuracy = 0.3125\n",
      "Validation loss = 0.2729499116539955\n",
      "Epoch 0167 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.6382385229540918\n",
      "Training loss = 0.22404514409817325\n",
      "Validation accuracy = 0.5\n",
      "Validation loss = 0.24583097454160452\n",
      "Epoch 0168 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.6384424603174603\n",
      "Training loss = 0.22398793256937688\n",
      "Validation accuracy = 0.40625\n",
      "Validation loss = 0.25218544714152813\n",
      "Epoch 0169 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.6384960552268245\n",
      "Training loss = 0.22394715306314197\n",
      "Validation accuracy = 0.53125\n",
      "Validation loss = 0.23175473511219025\n",
      "Epoch 0170 / 0200\n",
      "=====================================\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training accuracy = 0.6387205882352941\n",
      "Training loss = 0.22385618027642953\n",
      "Validation accuracy = 0.59375\n",
      "Validation loss = 0.23577589262276888\n",
      "Epoch 0171 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.6388937621832359\n",
      "Training loss = 0.2237880343161741\n",
      "Validation accuracy = 0.59375\n",
      "Validation loss = 0.23300259374082088\n",
      "Epoch 0172 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.6390794573643411\n",
      "Training loss = 0.2237135829976507\n",
      "Validation accuracy = 0.4375\n",
      "Validation loss = 0.25470330007374287\n",
      "Epoch 0173 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.6392870905587669\n",
      "Training loss = 0.22364301599727257\n",
      "Validation accuracy = 0.5\n",
      "Validation loss = 0.2427967730909586\n",
      "Epoch 0174 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.6394636015325671\n",
      "Training loss = 0.22358432720397453\n",
      "Validation accuracy = 0.46875\n",
      "Validation loss = 0.2526884935796261\n",
      "Epoch 0175 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.6397809523809523\n",
      "Training loss = 0.22341341998683556\n",
      "Validation accuracy = 0.34375\n",
      "Validation loss = 0.2721791937947273\n",
      "Epoch 0176 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.6399763257575758\n",
      "Training loss = 0.2233070971032915\n",
      "Validation accuracy = 0.4375\n",
      "Validation loss = 0.2820181231945753\n",
      "Epoch 0177 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.6403248587570621\n",
      "Training loss = 0.22317491893104072\n",
      "Validation accuracy = 0.46875\n",
      "Validation loss = 0.25150195229798555\n",
      "Epoch 0178 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.6405196629213483\n",
      "Training loss = 0.22307611568527444\n",
      "Validation accuracy = 0.4375\n",
      "Validation loss = 0.24287391640245914\n",
      "Epoch 0179 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.6406424581005586\n",
      "Training loss = 0.2229905518410065\n",
      "Validation accuracy = 0.53125\n",
      "Validation loss = 0.25447573605924845\n",
      "Epoch 0180 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.6406805555555556\n",
      "Training loss = 0.22294763496552628\n",
      "Validation accuracy = 0.40625\n",
      "Validation loss = 0.24603905156254768\n",
      "Epoch 0181 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.640658379373849\n",
      "Training loss = 0.222920239960936\n",
      "Validation accuracy = 0.5\n",
      "Validation loss = 0.2375743668526411\n",
      "Epoch 0182 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.640764652014652\n",
      "Training loss = 0.2228434702109259\n",
      "Validation accuracy = 0.625\n",
      "Validation loss = 0.24751475639641285\n",
      "Epoch 0183 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.6408834244080146\n",
      "Training loss = 0.22278451768087668\n",
      "Validation accuracy = 0.625\n",
      "Validation loss = 0.2292687389999628\n",
      "Epoch 0184 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.6410009057971015\n",
      "Training loss = 0.22271976815644598\n",
      "Validation accuracy = 0.375\n",
      "Validation loss = 0.266436617821455\n",
      "Epoch 0185 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.6411846846846847\n",
      "Training loss = 0.22262898189460373\n",
      "Validation accuracy = 0.625\n",
      "Validation loss = 0.22999614104628563\n",
      "Epoch 0186 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.6414202508960574\n",
      "Training loss = 0.22250257710348748\n",
      "Validation accuracy = 0.71875\n",
      "Validation loss = 0.23783755116164684\n",
      "Epoch 0187 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.6416176470588235\n",
      "Training loss = 0.22239357658886016\n",
      "Validation accuracy = 0.5\n",
      "Validation loss = 0.24202286917716265\n",
      "Epoch 0188 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.6417641843971631\n",
      "Training loss = 0.22232033178500885\n",
      "Validation accuracy = 0.46875\n",
      "Validation loss = 0.24488164857029915\n",
      "Epoch 0189 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.6420502645502646\n",
      "Training loss = 0.2222025677518397\n",
      "Validation accuracy = 0.5625\n",
      "Validation loss = 0.24067859817296267\n",
      "Epoch 0190 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.6422938596491228\n",
      "Training loss = 0.2220709700849757\n",
      "Validation accuracy = 0.65625\n",
      "Validation loss = 0.22957594506442547\n",
      "Epoch 0191 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.6424956369982548\n",
      "Training loss = 0.2220200969810625\n",
      "Validation accuracy = 0.46875\n",
      "Validation loss = 0.248601452447474\n",
      "Epoch 0192 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.6427473958333333\n",
      "Training loss = 0.22189273468011783\n",
      "Validation accuracy = 0.40625\n",
      "Validation loss = 0.26424276176840067\n",
      "Epoch 0193 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.6428886010362694\n",
      "Training loss = 0.22178891583994056\n",
      "Validation accuracy = 0.46875\n",
      "Validation loss = 0.25698580127209425\n",
      "Epoch 0194 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.6431615120274914\n",
      "Training loss = 0.221685928319328\n",
      "Validation accuracy = 0.5\n",
      "Validation loss = 0.2538189496845007\n",
      "Epoch 0195 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.6432008547008548\n",
      "Training loss = 0.2216624396289261\n",
      "Validation accuracy = 0.53125\n",
      "Validation loss = 0.23666974436491728\n",
      "Epoch 0196 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.6434693877551021\n",
      "Training loss = 0.22154530779578957\n",
      "Validation accuracy = 0.5\n",
      "Validation loss = 0.33227691147476435\n",
      "Epoch 0197 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.6437648054145516\n",
      "Training loss = 0.2214350407726924\n",
      "Validation accuracy = 0.46875\n",
      "Validation loss = 0.2668126365169883\n",
      "Epoch 0198 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.6440446127946128\n",
      "Training loss = 0.2212841816260307\n",
      "Validation accuracy = 0.4375\n",
      "Validation loss = 0.2726456020027399\n",
      "Epoch 0199 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.6442797319932998\n",
      "Training loss = 0.22117852955207953\n",
      "Validation accuracy = 0.5\n",
      "Validation loss = 0.24284612387418747\n",
      "Epoch 0200 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.6444291666666667\n",
      "Training loss = 0.22108690843520065\n",
      "Validation accuracy = 0.4375\n",
      "Validation loss = 0.24534158036112785\n",
      "Making model for session group 20210310_15:26:59.160-20210319_16:13:09.655\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/imblearn/utils/_validation.py:326: UserWarning: After over-sampling, the number of samples (300) in class car will be larger than the number of samples in the majority class (class #signpost -> 160)\n",
      "  n_samples_majority,\n",
      "/usr/local/lib/python3.6/dist-packages/imblearn/utils/_validation.py:326: UserWarning: After over-sampling, the number of samples (300) in class signpost will be larger than the number of samples in the majority class (class #signpost -> 160)\n",
      "  n_samples_majority,\n",
      "/usr/local/lib/python3.6/dist-packages/imblearn/utils/_validation.py:326: UserWarning: After over-sampling, the number of samples (300) in class tree will be larger than the number of samples in the majority class (class #signpost -> 160)\n",
      "  n_samples_majority,\n",
      "/usr/local/lib/python3.6/dist-packages/imblearn/utils/_validation.py:326: UserWarning: After over-sampling, the number of samples (300) in class wall will be larger than the number of samples in the majority class (class #signpost -> 160)\n",
      "  n_samples_majority,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0001 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.43583333333333335\n",
      "Training loss = 0.311976466178894\n",
      "Validation accuracy = 0.6875\n",
      "Validation loss = 0.2708177771419287\n",
      "Epoch 0002 / 0200\n",
      "=====================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/_classification.py:1221: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training accuracy = 0.4625\n",
      "Training loss = 0.30158473091820875\n",
      "Validation accuracy = 0.625\n",
      "Validation loss = 0.25851921923458576\n",
      "Epoch 0003 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.4727777777777778\n",
      "Training loss = 0.2957942891286479\n",
      "Validation accuracy = 0.71875\n",
      "Validation loss = 0.2354056928306818\n",
      "Epoch 0004 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.483125\n",
      "Training loss = 0.29033565462877353\n",
      "Validation accuracy = 0.6875\n",
      "Validation loss = 0.2110231714323163\n",
      "Epoch 0005 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.49433333333333335\n",
      "Training loss = 0.2858197544614474\n",
      "Validation accuracy = 0.8125\n",
      "Validation loss = 0.22727740928530693\n",
      "Epoch 0006 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.50375\n",
      "Training loss = 0.28222933769639996\n",
      "Validation accuracy = 0.875\n",
      "Validation loss = 0.2249633688479662\n",
      "Epoch 0007 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.5120238095238095\n",
      "Training loss = 0.2797648115988289\n",
      "Validation accuracy = 0.875\n",
      "Validation loss = 0.2103787437081337\n",
      "Epoch 0008 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.5191666666666667\n",
      "Training loss = 0.27729654652687413\n",
      "Validation accuracy = 0.84375\n",
      "Validation loss = 0.2208906225860119\n",
      "Epoch 0009 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.5248148148148148\n",
      "Training loss = 0.27536291011781605\n",
      "Validation accuracy = 0.84375\n",
      "Validation loss = 0.20877759158611298\n",
      "Epoch 0010 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.52825\n",
      "Training loss = 0.2736123194446166\n",
      "Validation accuracy = 0.75\n",
      "Validation loss = 0.22237488254904747\n",
      "Epoch 0011 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.5332575757575757\n",
      "Training loss = 0.2719150886504036\n",
      "Validation accuracy = 0.8125\n",
      "Validation loss = 0.20103938318789005\n",
      "Epoch 0012 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.5372916666666666\n",
      "Training loss = 0.27029024777520033\n",
      "Validation accuracy = 0.90625\n",
      "Validation loss = 0.21329642459750175\n",
      "Epoch 0013 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.5402564102564102\n",
      "Training loss = 0.26897747073227013\n",
      "Validation accuracy = 0.84375\n",
      "Validation loss = 0.21546432748436928\n",
      "Epoch 0014 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.5419047619047619\n",
      "Training loss = 0.2680594505742192\n",
      "Validation accuracy = 0.875\n",
      "Validation loss = 0.22467686794698238\n",
      "Epoch 0015 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.5443333333333333\n",
      "Training loss = 0.2670176799827152\n",
      "Validation accuracy = 0.78125\n",
      "Validation loss = 0.2117852121591568\n",
      "Epoch 0016 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.5476041666666667\n",
      "Training loss = 0.26588565262189756\n",
      "Validation accuracy = 0.90625\n",
      "Validation loss = 0.22189812175929546\n",
      "Epoch 0017 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.548921568627451\n",
      "Training loss = 0.26508766213468477\n",
      "Validation accuracy = 0.6875\n",
      "Validation loss = 0.20522202923893929\n",
      "Epoch 0018 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.55\n",
      "Training loss = 0.2642974166861839\n",
      "Validation accuracy = 0.84375\n",
      "Validation loss = 0.20347229577600956\n",
      "Epoch 0019 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.5511403508771929\n",
      "Training loss = 0.26355544990091995\n",
      "Validation accuracy = 0.8125\n",
      "Validation loss = 0.19435841031372547\n",
      "Epoch 0020 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.5537083333333334\n",
      "Training loss = 0.2625333988380929\n",
      "Validation accuracy = 0.875\n",
      "Validation loss = 0.20872197300195694\n",
      "Epoch 0021 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.5550396825396825\n",
      "Training loss = 0.26179794157189984\n",
      "Validation accuracy = 0.84375\n",
      "Validation loss = 0.17784523777663708\n",
      "Epoch 0022 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.5567424242424243\n",
      "Training loss = 0.26107581534394714\n",
      "Validation accuracy = 0.875\n",
      "Validation loss = 0.1950897742062807\n",
      "Epoch 0023 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.5567028985507246\n",
      "Training loss = 0.2606951951905005\n",
      "Validation accuracy = 0.78125\n",
      "Validation loss = 0.1789618320763111\n",
      "Epoch 0024 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.5574305555555555\n",
      "Training loss = 0.26035083753056826\n",
      "Validation accuracy = 0.8125\n",
      "Validation loss = 0.19690946023911238\n",
      "Epoch 0025 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.5590333333333334\n",
      "Training loss = 0.2597511113007863\n",
      "Validation accuracy = 0.90625\n",
      "Validation loss = 0.18424397334456444\n",
      "Epoch 0026 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.5593269230769231\n",
      "Training loss = 0.2595904699789408\n",
      "Validation accuracy = 0.875\n",
      "Validation loss = 0.19214759208261967\n",
      "Epoch 0027 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.5604012345679013\n",
      "Training loss = 0.2591479014697266\n",
      "Validation accuracy = 0.875\n",
      "Validation loss = 0.17585048452019691\n",
      "Epoch 0028 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.5619047619047619\n",
      "Training loss = 0.2586740880636942\n",
      "Validation accuracy = 0.71875\n",
      "Validation loss = 0.21720420010387897\n",
      "Epoch 0029 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.564051724137931\n",
      "Training loss = 0.25802675453753304\n",
      "Validation accuracy = 0.9375\n",
      "Validation loss = 0.19337093643844128\n",
      "Epoch 0030 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.5655555555555556\n",
      "Training loss = 0.25749875828127067\n",
      "Validation accuracy = 0.875\n",
      "Validation loss = 0.18865479435771704\n",
      "Epoch 0031 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.5665591397849462\n",
      "Training loss = 0.256999265469851\n",
      "Validation accuracy = 0.75\n",
      "Validation loss = 0.2146710827946663\n",
      "Epoch 0032 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.5677083333333334\n",
      "Training loss = 0.25668022356616954\n",
      "Validation accuracy = 0.875\n",
      "Validation loss = 0.1746505256742239\n",
      "Epoch 0033 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.5684848484848485\n",
      "Training loss = 0.25626643807900074\n",
      "Validation accuracy = 0.90625\n",
      "Validation loss = 0.1901583317667246\n",
      "Epoch 0034 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.5692892156862746\n",
      "Training loss = 0.2558725232287657\n",
      "Validation accuracy = 0.84375\n",
      "Validation loss = 0.20611698739230633\n",
      "Epoch 0035 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.5701190476190476\n",
      "Training loss = 0.2554131032987719\n",
      "Validation accuracy = 0.84375\n",
      "Validation loss = 0.19730417057871819\n",
      "Epoch 0036 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.5712962962962963\n",
      "Training loss = 0.254843389077319\n",
      "Validation accuracy = 0.71875\n",
      "Validation loss = 0.2059862781316042\n",
      "Epoch 0037 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.5722297297297297\n",
      "Training loss = 0.2544756697581427\n",
      "Validation accuracy = 0.90625\n",
      "Validation loss = 0.18837877921760082\n",
      "Epoch 0038 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.5729166666666666\n",
      "Training loss = 0.2540745020866917\n",
      "Validation accuracy = 0.5\n",
      "Validation loss = 0.23844799026846886\n",
      "Epoch 0039 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.573440170940171\n",
      "Training loss = 0.2538697946230825\n",
      "Validation accuracy = 0.8125\n",
      "Validation loss = 0.18443347699940205\n",
      "Epoch 0040 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.5740416666666667\n",
      "Training loss = 0.25354321075355013\n",
      "Validation accuracy = 0.84375\n",
      "Validation loss = 0.19881977513432503\n",
      "Epoch 0041 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.5748373983739837\n",
      "Training loss = 0.2531112343660457\n",
      "Validation accuracy = 0.78125\n",
      "Validation loss = 0.20893992483615875\n",
      "Epoch 0042 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.575218253968254\n",
      "Training loss = 0.2528114529243774\n",
      "Validation accuracy = 0.875\n",
      "Validation loss = 0.18995587714016438\n",
      "Epoch 0043 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.5757170542635659\n",
      "Training loss = 0.2526257508652386\n",
      "Validation accuracy = 0.71875\n",
      "Validation loss = 0.1977858506143093\n",
      "Epoch 0044 / 0200\n",
      "=====================================\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training accuracy = 0.5761931818181818\n",
      "Training loss = 0.2524573230873229\n",
      "Validation accuracy = 0.8125\n",
      "Validation loss = 0.18866343796253204\n",
      "Epoch 0045 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.5773888888888888\n",
      "Training loss = 0.2519873312043923\n",
      "Validation accuracy = 0.84375\n",
      "Validation loss = 0.1849392093718052\n",
      "Epoch 0046 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.5782427536231884\n",
      "Training loss = 0.25157263960365367\n",
      "Validation accuracy = 0.71875\n",
      "Validation loss = 0.19592046085745096\n",
      "Epoch 0047 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.5787765957446809\n",
      "Training loss = 0.2512591420182734\n",
      "Validation accuracy = 0.65625\n",
      "Validation loss = 0.20803594309836626\n",
      "Epoch 0048 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.5796701388888889\n",
      "Training loss = 0.25086235377368415\n",
      "Validation accuracy = 0.84375\n",
      "Validation loss = 0.18458347860723734\n",
      "Epoch 0049 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.5803231292517007\n",
      "Training loss = 0.25057657468481126\n",
      "Validation accuracy = 0.84375\n",
      "Validation loss = 0.18893301486968994\n",
      "Epoch 0050 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.5813666666666667\n",
      "Training loss = 0.25008033785621325\n",
      "Validation accuracy = 0.78125\n",
      "Validation loss = 0.1859002634882927\n",
      "Epoch 0051 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.5824183006535948\n",
      "Training loss = 0.24956089481419208\n",
      "Validation accuracy = 0.59375\n",
      "Validation loss = 0.20039460621774197\n",
      "Epoch 0052 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.583173076923077\n",
      "Training loss = 0.24912629862005511\n",
      "Validation accuracy = 0.78125\n",
      "Validation loss = 0.18890083208680153\n",
      "Epoch 0053 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.5836477987421383\n",
      "Training loss = 0.24892333586448392\n",
      "Validation accuracy = 0.78125\n",
      "Validation loss = 0.18800949305295944\n",
      "Epoch 0054 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.5841358024691358\n",
      "Training loss = 0.24864816855041333\n",
      "Validation accuracy = 0.78125\n",
      "Validation loss = 0.18615919072180986\n",
      "Epoch 0055 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.5849090909090909\n",
      "Training loss = 0.24832551004128023\n",
      "Validation accuracy = 0.71875\n",
      "Validation loss = 0.1869648303836584\n",
      "Epoch 0056 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.585922619047619\n",
      "Training loss = 0.24795434869604097\n",
      "Validation accuracy = 0.75\n",
      "Validation loss = 0.19310836493968964\n",
      "Epoch 0057 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.5864473684210526\n",
      "Training loss = 0.24766978622833538\n",
      "Validation accuracy = 0.75\n",
      "Validation loss = 0.19238934200257063\n",
      "Epoch 0058 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.5869252873563219\n",
      "Training loss = 0.24739911069087256\n",
      "Validation accuracy = 0.625\n",
      "Validation loss = 0.20877053774893284\n",
      "Epoch 0059 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.5877259887005649\n",
      "Training loss = 0.2470562872551592\n",
      "Validation accuracy = 0.875\n",
      "Validation loss = 0.17055760510265827\n",
      "Epoch 0060 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.5882916666666667\n",
      "Training loss = 0.2467746881461806\n",
      "Validation accuracy = 0.84375\n",
      "Validation loss = 0.18136276490986347\n",
      "Epoch 0061 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.588811475409836\n",
      "Training loss = 0.2465022018901963\n",
      "Validation accuracy = 0.78125\n",
      "Validation loss = 0.19038132298737764\n",
      "Epoch 0062 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.5890860215053764\n",
      "Training loss = 0.24627507389152561\n",
      "Validation accuracy = 0.6875\n",
      "Validation loss = 0.19770104624330997\n",
      "Epoch 0063 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.589484126984127\n",
      "Training loss = 0.24611696677312017\n",
      "Validation accuracy = 0.875\n",
      "Validation loss = 0.17464686278253794\n",
      "Epoch 0064 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.5899869791666666\n",
      "Training loss = 0.24576317560238142\n",
      "Validation accuracy = 0.8125\n",
      "Validation loss = 0.19428450800478458\n",
      "Epoch 0065 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.590551282051282\n",
      "Training loss = 0.24552235136696926\n",
      "Validation accuracy = 0.75\n",
      "Validation loss = 0.18340375646948814\n",
      "Epoch 0066 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.5911616161616161\n",
      "Training loss = 0.24533663322415317\n",
      "Validation accuracy = 0.65625\n",
      "Validation loss = 0.2141482187435031\n",
      "Epoch 0067 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.5916666666666667\n",
      "Training loss = 0.24513520479906553\n",
      "Validation accuracy = 0.75\n",
      "Validation loss = 0.1923905946314335\n",
      "Epoch 0068 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.5924509803921568\n",
      "Training loss = 0.24479469586090713\n",
      "Validation accuracy = 0.75\n",
      "Validation loss = 0.2137692403048277\n",
      "Epoch 0069 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.5928985507246377\n",
      "Training loss = 0.24454081528248706\n",
      "Validation accuracy = 0.875\n",
      "Validation loss = 0.18212909065186977\n",
      "Epoch 0070 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.5931190476190477\n",
      "Training loss = 0.24432097260973284\n",
      "Validation accuracy = 0.78125\n",
      "Validation loss = 0.18942396994680166\n",
      "Epoch 0071 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.5936854460093897\n",
      "Training loss = 0.2439897207635949\n",
      "Validation accuracy = 0.8125\n",
      "Validation loss = 0.17274234630167484\n",
      "Epoch 0072 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.5942939814814815\n",
      "Training loss = 0.24363127646553848\n",
      "Validation accuracy = 0.84375\n",
      "Validation loss = 0.16865068208426237\n",
      "Epoch 0073 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.5948059360730593\n",
      "Training loss = 0.2434299967819017\n",
      "Validation accuracy = 0.875\n",
      "Validation loss = 0.17661640234291553\n",
      "Epoch 0074 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.5955405405405405\n",
      "Training loss = 0.24319866274525453\n",
      "Validation accuracy = 0.84375\n",
      "Validation loss = 0.18136624619364738\n",
      "Epoch 0075 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.5959666666666666\n",
      "Training loss = 0.24297746653589938\n",
      "Validation accuracy = 0.8125\n",
      "Validation loss = 0.16657243017107248\n",
      "Epoch 0076 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.5963486842105263\n",
      "Training loss = 0.24280273555532883\n",
      "Validation accuracy = 0.84375\n",
      "Validation loss = 0.17741769179701805\n",
      "Epoch 0077 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.596482683982684\n",
      "Training loss = 0.24274206949615634\n",
      "Validation accuracy = 0.75\n",
      "Validation loss = 0.1835660943761468\n",
      "Epoch 0078 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.5969871794871795\n",
      "Training loss = 0.24255505030130983\n",
      "Validation accuracy = 0.59375\n",
      "Validation loss = 0.2257017195224762\n",
      "Epoch 0079 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.5976054852320675\n",
      "Training loss = 0.2422686019989383\n",
      "Validation accuracy = 0.8125\n",
      "Validation loss = 0.17888689041137695\n",
      "Epoch 0080 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.5983125\n",
      "Training loss = 0.24200078898109495\n",
      "Validation accuracy = 0.84375\n",
      "Validation loss = 0.17336136661469936\n",
      "Epoch 0081 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.598775720164609\n",
      "Training loss = 0.24174676782739016\n",
      "Validation accuracy = 0.8125\n",
      "Validation loss = 0.17796962521970272\n",
      "Epoch 0082 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.599308943089431\n",
      "Training loss = 0.24150291343681454\n",
      "Validation accuracy = 0.875\n",
      "Validation loss = 0.17155426554381847\n",
      "Epoch 0083 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.5996787148594378\n",
      "Training loss = 0.24125351783651186\n",
      "Validation accuracy = 0.78125\n",
      "Validation loss = 0.1958117950707674\n",
      "Epoch 0084 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.6001587301587301\n",
      "Training loss = 0.24099572352946752\n",
      "Validation accuracy = 0.75\n",
      "Validation loss = 0.1886904677376151\n",
      "Epoch 0085 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.6006862745098039\n",
      "Training loss = 0.2407235154515388\n",
      "Validation accuracy = 0.90625\n",
      "Validation loss = 0.17254022974520922\n",
      "Epoch 0086 / 0200\n",
      "=====================================\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training accuracy = 0.6011531007751938\n",
      "Training loss = 0.24048433318300996\n",
      "Validation accuracy = 0.8125\n",
      "Validation loss = 0.18672780692577362\n",
      "Epoch 0087 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.601580459770115\n",
      "Training loss = 0.24030463585280368\n",
      "Validation accuracy = 0.84375\n",
      "Validation loss = 0.1740483297035098\n",
      "Epoch 0088 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.6018181818181818\n",
      "Training loss = 0.24012748111152288\n",
      "Validation accuracy = 0.875\n",
      "Validation loss = 0.17674953304231167\n",
      "Epoch 0089 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.6024625468164794\n",
      "Training loss = 0.23987390463132313\n",
      "Validation accuracy = 0.8125\n",
      "Validation loss = 0.1952069764956832\n",
      "Epoch 0090 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.6030555555555556\n",
      "Training loss = 0.2396559996858791\n",
      "Validation accuracy = 0.53125\n",
      "Validation loss = 0.22577915992587805\n",
      "Epoch 0091 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.603489010989011\n",
      "Training loss = 0.23938608469898665\n",
      "Validation accuracy = 0.84375\n",
      "Validation loss = 0.18453633971512318\n",
      "Epoch 0092 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.6036503623188406\n",
      "Training loss = 0.23927796686041183\n",
      "Validation accuracy = 0.59375\n",
      "Validation loss = 0.20285896304994822\n",
      "Epoch 0093 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.6043100358422939\n",
      "Training loss = 0.2389835035656729\n",
      "Validation accuracy = 0.84375\n",
      "Validation loss = 0.1794786872342229\n",
      "Epoch 0094 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.6045656028368794\n",
      "Training loss = 0.23886203766239028\n",
      "Validation accuracy = 0.78125\n",
      "Validation loss = 0.1805242234840989\n",
      "Epoch 0095 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.6049298245614035\n",
      "Training loss = 0.23869370287029368\n",
      "Validation accuracy = 0.65625\n",
      "Validation loss = 0.20415924862027168\n",
      "Epoch 0096 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.6052083333333333\n",
      "Training loss = 0.2386163360490981\n",
      "Validation accuracy = 0.6875\n",
      "Validation loss = 0.20236968994140625\n",
      "Epoch 0097 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.6057044673539519\n",
      "Training loss = 0.2383265787588362\n",
      "Validation accuracy = 0.875\n",
      "Validation loss = 0.17921585030853748\n",
      "Epoch 0098 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.6061309523809524\n",
      "Training loss = 0.2381252542140634\n",
      "Validation accuracy = 0.90625\n",
      "Validation loss = 0.16064318642020226\n",
      "Epoch 0099 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.6065319865319865\n",
      "Training loss = 0.23800415805017305\n",
      "Validation accuracy = 0.90625\n",
      "Validation loss = 0.18825062364339828\n",
      "Epoch 0100 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.6068\n",
      "Training loss = 0.23784925795147815\n",
      "Validation accuracy = 0.71875\n",
      "Validation loss = 0.1829878706485033\n",
      "Epoch 0101 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.6072029702970297\n",
      "Training loss = 0.23768952127951798\n",
      "Validation accuracy = 0.75\n",
      "Validation loss = 0.17518375441432\n",
      "Epoch 0102 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.6074754901960784\n",
      "Training loss = 0.23752950874565085\n",
      "Validation accuracy = 0.8125\n",
      "Validation loss = 0.17611603066325188\n",
      "Epoch 0103 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.6079449838187703\n",
      "Training loss = 0.2373540212932528\n",
      "Validation accuracy = 0.78125\n",
      "Validation loss = 0.19064436480402946\n",
      "Epoch 0104 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.6084535256410256\n",
      "Training loss = 0.23715154158715637\n",
      "Validation accuracy = 0.6875\n",
      "Validation loss = 0.19981690496206284\n",
      "Epoch 0105 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.6087936507936508\n",
      "Training loss = 0.2370061311939406\n",
      "Validation accuracy = 0.875\n",
      "Validation loss = 0.16950918920338154\n",
      "Epoch 0106 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.6089701257861635\n",
      "Training loss = 0.23693833311773696\n",
      "Validation accuracy = 0.84375\n",
      "Validation loss = 0.16085041593760252\n",
      "Epoch 0107 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.6093302180685358\n",
      "Training loss = 0.23682330237231522\n",
      "Validation accuracy = 0.84375\n",
      "Validation loss = 0.18510757759213448\n",
      "Epoch 0108 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.6095833333333334\n",
      "Training loss = 0.23666355727792338\n",
      "Validation accuracy = 0.8125\n",
      "Validation loss = 0.18185963481664658\n",
      "Epoch 0109 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.609854740061162\n",
      "Training loss = 0.23654642233881382\n",
      "Validation accuracy = 0.875\n",
      "Validation loss = 0.16353799030184746\n",
      "Epoch 0110 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.6102348484848484\n",
      "Training loss = 0.23638430686272455\n",
      "Validation accuracy = 0.8125\n",
      "Validation loss = 0.1852384703233838\n",
      "Epoch 0111 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.610503003003003\n",
      "Training loss = 0.23626046177883586\n",
      "Validation accuracy = 0.90625\n",
      "Validation loss = 0.16973698884248734\n",
      "Epoch 0112 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.6108630952380952\n",
      "Training loss = 0.23607560933057573\n",
      "Validation accuracy = 0.8125\n",
      "Validation loss = 0.18663611076772213\n",
      "Epoch 0113 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.6112389380530974\n",
      "Training loss = 0.2359329939377563\n",
      "Validation accuracy = 0.84375\n",
      "Validation loss = 0.17301702965050936\n",
      "Epoch 0114 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.6115862573099415\n",
      "Training loss = 0.23579414622945308\n",
      "Validation accuracy = 0.84375\n",
      "Validation loss = 0.16989484429359436\n",
      "Epoch 0115 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.6117898550724638\n",
      "Training loss = 0.2356834589783912\n",
      "Validation accuracy = 0.65625\n",
      "Validation loss = 0.20959539338946342\n",
      "Epoch 0116 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.6119468390804598\n",
      "Training loss = 0.23557348699094835\n",
      "Validation accuracy = 0.84375\n",
      "Validation loss = 0.1619001403450966\n",
      "Epoch 0117 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.6123076923076923\n",
      "Training loss = 0.2354147869929077\n",
      "Validation accuracy = 0.8125\n",
      "Validation loss = 0.17905618995428085\n",
      "Epoch 0118 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.6125564971751413\n",
      "Training loss = 0.23529765109947257\n",
      "Validation accuracy = 0.90625\n",
      "Validation loss = 0.17676751874387264\n",
      "Epoch 0119 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.6128571428571429\n",
      "Training loss = 0.23519800826980203\n",
      "Validation accuracy = 0.78125\n",
      "Validation loss = 0.1940734824165702\n",
      "Epoch 0120 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.6130416666666667\n",
      "Training loss = 0.23505241343637723\n",
      "Validation accuracy = 0.84375\n",
      "Validation loss = 0.18619996681809425\n",
      "Epoch 0121 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.6134297520661157\n",
      "Training loss = 0.23487409273198404\n",
      "Validation accuracy = 0.8125\n",
      "Validation loss = 0.17293103877454996\n",
      "Epoch 0122 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.6136748633879782\n",
      "Training loss = 0.23475913127354991\n",
      "Validation accuracy = 0.90625\n",
      "Validation loss = 0.1504398826509714\n",
      "Epoch 0123 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.6138821138211382\n",
      "Training loss = 0.23460440628846405\n",
      "Validation accuracy = 0.84375\n",
      "Validation loss = 0.17816783115267754\n",
      "Epoch 0124 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.614119623655914\n",
      "Training loss = 0.23449387634984187\n",
      "Validation accuracy = 0.625\n",
      "Validation loss = 0.2011730493977666\n",
      "Epoch 0125 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.61442\n",
      "Training loss = 0.23436522302101057\n",
      "Validation accuracy = 0.78125\n",
      "Validation loss = 0.17095320858061314\n",
      "Epoch 0126 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.6147685185185185\n",
      "Training loss = 0.23421578049571032\n",
      "Validation accuracy = 0.59375\n",
      "Validation loss = 0.20203947741538286\n",
      "Epoch 0127 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.6150065616797901\n",
      "Training loss = 0.23403274272419414\n",
      "Validation accuracy = 0.84375\n",
      "Validation loss = 0.17023062519729137\n",
      "Epoch 0128 / 0200\n",
      "=====================================\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training accuracy = 0.6152994791666667\n",
      "Training loss = 0.2339068564820142\n",
      "Validation accuracy = 0.875\n",
      "Validation loss = 0.14874130953103304\n",
      "Epoch 0129 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.6157558139534883\n",
      "Training loss = 0.23373226806839076\n",
      "Validation accuracy = 0.8125\n",
      "Validation loss = 0.1616732869297266\n",
      "Epoch 0130 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.6159743589743589\n",
      "Training loss = 0.2336348154515219\n",
      "Validation accuracy = 0.875\n",
      "Validation loss = 0.18944806046783924\n",
      "Epoch 0131 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.6162468193384224\n",
      "Training loss = 0.23351752197308318\n",
      "Validation accuracy = 0.625\n",
      "Validation loss = 0.20869268756359816\n",
      "Epoch 0132 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.616199494949495\n",
      "Training loss = 0.23348240201004\n",
      "Validation accuracy = 0.71875\n",
      "Validation loss = 0.20738201029598713\n",
      "Epoch 0133 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.6163220551378447\n",
      "Training loss = 0.2334174615179275\n",
      "Validation accuracy = 0.625\n",
      "Validation loss = 0.1836392553523183\n",
      "Epoch 0134 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.616660447761194\n",
      "Training loss = 0.23326299547676496\n",
      "Validation accuracy = 0.875\n",
      "Validation loss = 0.1489397371187806\n",
      "Epoch 0135 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.6168333333333333\n",
      "Training loss = 0.23317399944668565\n",
      "Validation accuracy = 0.90625\n",
      "Validation loss = 0.1693111164495349\n",
      "Epoch 0136 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.6172549019607844\n",
      "Training loss = 0.23297490495503606\n",
      "Validation accuracy = 0.75\n",
      "Validation loss = 0.18178520910441875\n",
      "Epoch 0137 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.6174513381995134\n",
      "Training loss = 0.2328783228706088\n",
      "Validation accuracy = 0.90625\n",
      "Validation loss = 0.1808603974059224\n",
      "Epoch 0138 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.6176630434782608\n",
      "Training loss = 0.2328468514389498\n",
      "Validation accuracy = 0.84375\n",
      "Validation loss = 0.18017270509153605\n",
      "Epoch 0139 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.6179436450839328\n",
      "Training loss = 0.23269542568727292\n",
      "Validation accuracy = 0.75\n",
      "Validation loss = 0.1840228233486414\n",
      "Epoch 0140 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.6182857142857143\n",
      "Training loss = 0.2325731563038592\n",
      "Validation accuracy = 0.5625\n",
      "Validation loss = 0.24484833143651485\n",
      "Epoch 0141 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.618628841607565\n",
      "Training loss = 0.23244659716910715\n",
      "Validation accuracy = 0.875\n",
      "Validation loss = 0.18423083797097206\n",
      "Epoch 0142 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.6188556338028169\n",
      "Training loss = 0.23232055943607935\n",
      "Validation accuracy = 0.84375\n",
      "Validation loss = 0.1656418787315488\n",
      "Epoch 0143 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.6191550116550116\n",
      "Training loss = 0.23215399640449486\n",
      "Validation accuracy = 0.84375\n",
      "Validation loss = 0.15584321413189173\n",
      "Epoch 0144 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.6194039351851852\n",
      "Training loss = 0.23203201843106566\n",
      "Validation accuracy = 0.59375\n",
      "Validation loss = 0.20170145109295845\n",
      "Epoch 0145 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.6197471264367816\n",
      "Training loss = 0.23184993542482454\n",
      "Validation accuracy = 0.625\n",
      "Validation loss = 0.1799944620579481\n",
      "Epoch 0146 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.6198858447488584\n",
      "Training loss = 0.23180001293679012\n",
      "Validation accuracy = 0.78125\n",
      "Validation loss = 0.17800194397568703\n",
      "Epoch 0147 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.6201360544217687\n",
      "Training loss = 0.23170243694187223\n",
      "Validation accuracy = 0.84375\n",
      "Validation loss = 0.18373201321810484\n",
      "Epoch 0148 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.6202195945945946\n",
      "Training loss = 0.23160670598742325\n",
      "Validation accuracy = 0.875\n",
      "Validation loss = 0.16578114964067936\n",
      "Epoch 0149 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.6203635346756152\n",
      "Training loss = 0.23150345225387173\n",
      "Validation accuracy = 0.84375\n",
      "Validation loss = 0.1668706927448511\n",
      "Epoch 0150 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.6206333333333334\n",
      "Training loss = 0.23138718803665703\n",
      "Validation accuracy = 0.71875\n",
      "Validation loss = 0.18186038080602884\n",
      "Epoch 0151 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.6209933774834437\n",
      "Training loss = 0.2312285961917135\n",
      "Validation accuracy = 0.84375\n",
      "Validation loss = 0.1610080385580659\n",
      "Epoch 0152 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.6212225877192983\n",
      "Training loss = 0.2311574086871227\n",
      "Validation accuracy = 0.625\n",
      "Validation loss = 0.20795841701328754\n",
      "Epoch 0153 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.6214596949891068\n",
      "Training loss = 0.23101426876878492\n",
      "Validation accuracy = 0.875\n",
      "Validation loss = 0.15968754328787327\n",
      "Epoch 0154 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.6216829004329004\n",
      "Training loss = 0.23089174997214695\n",
      "Validation accuracy = 0.71875\n",
      "Validation loss = 0.17876119166612625\n",
      "Epoch 0155 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.6219677419354839\n",
      "Training loss = 0.23077116044065965\n",
      "Validation accuracy = 0.84375\n",
      "Validation loss = 0.18714094534516335\n",
      "Epoch 0156 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.6222596153846154\n",
      "Training loss = 0.23060525632813636\n",
      "Validation accuracy = 0.65625\n",
      "Validation loss = 0.18554141838103533\n",
      "Epoch 0157 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.6225530785562633\n",
      "Training loss = 0.23042644047093302\n",
      "Validation accuracy = 0.84375\n",
      "Validation loss = 0.1751920972019434\n",
      "Epoch 0158 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.6229694092827004\n",
      "Training loss = 0.23028140653435628\n",
      "Validation accuracy = 0.84375\n",
      "Validation loss = 0.1765606887638569\n",
      "Epoch 0159 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.6231813417190776\n",
      "Training loss = 0.2301735739018651\n",
      "Validation accuracy = 0.8125\n",
      "Validation loss = 0.17253650166094303\n",
      "Epoch 0160 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.623234375\n",
      "Training loss = 0.2301499439899344\n",
      "Validation accuracy = 0.71875\n",
      "Validation loss = 0.20923335291445255\n",
      "Epoch 0161 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.623416149068323\n",
      "Training loss = 0.23002066660965514\n",
      "Validation accuracy = 0.75\n",
      "Validation loss = 0.17010572738945484\n",
      "Epoch 0162 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.6236471193415638\n",
      "Training loss = 0.2299050095888169\n",
      "Validation accuracy = 0.84375\n",
      "Validation loss = 0.1670155329629779\n",
      "Epoch 0163 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.6239059304703477\n",
      "Training loss = 0.2297852684578007\n",
      "Validation accuracy = 0.46875\n",
      "Validation loss = 0.24837838485836983\n",
      "Epoch 0164 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.6241768292682927\n",
      "Training loss = 0.2296128415371617\n",
      "Validation accuracy = 0.84375\n",
      "Validation loss = 0.1646092375740409\n",
      "Epoch 0165 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.624469696969697\n",
      "Training loss = 0.2294461797598486\n",
      "Validation accuracy = 0.78125\n",
      "Validation loss = 0.1805123183876276\n",
      "Epoch 0166 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.6247289156626507\n",
      "Training loss = 0.22932871878019956\n",
      "Validation accuracy = 0.65625\n",
      "Validation loss = 0.25611937418580055\n",
      "Epoch 0167 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.6249101796407186\n",
      "Training loss = 0.22921147145249113\n",
      "Validation accuracy = 0.84375\n",
      "Validation loss = 0.17295542545616627\n",
      "Epoch 0168 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.6251934523809524\n",
      "Training loss = 0.22906770141181787\n",
      "Validation accuracy = 0.84375\n",
      "Validation loss = 0.1685953876003623\n",
      "Epoch 0169 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.625379684418146\n",
      "Training loss = 0.22896788322221656\n",
      "Validation accuracy = 0.8125\n",
      "Validation loss = 0.17002193350344896\n",
      "Epoch 0170 / 0200\n",
      "=====================================\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training accuracy = 0.6256666666666667\n",
      "Training loss = 0.2288276134570878\n",
      "Validation accuracy = 0.78125\n",
      "Validation loss = 0.1606625309213996\n",
      "Epoch 0171 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.6257651072124756\n",
      "Training loss = 0.22875221714007052\n",
      "Validation accuracy = 0.8125\n",
      "Validation loss = 0.1645523700863123\n",
      "Epoch 0172 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.6259205426356589\n",
      "Training loss = 0.22865118392887562\n",
      "Validation accuracy = 0.84375\n",
      "Validation loss = 0.17256123945116997\n",
      "Epoch 0173 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.6261464354527938\n",
      "Training loss = 0.22854375115601142\n",
      "Validation accuracy = 0.84375\n",
      "Validation loss = 0.17193968128412962\n",
      "Epoch 0174 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.6264942528735632\n",
      "Training loss = 0.22841750030437935\n",
      "Validation accuracy = 0.875\n",
      "Validation loss = 0.1639395486563444\n",
      "Epoch 0175 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.6267285714285714\n",
      "Training loss = 0.22833474795342912\n",
      "Validation accuracy = 0.84375\n",
      "Validation loss = 0.16787737235426903\n",
      "Epoch 0176 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.6270028409090909\n",
      "Training loss = 0.22820953300751914\n",
      "Validation accuracy = 0.875\n",
      "Validation loss = 0.16015413962304592\n",
      "Epoch 0177 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.6272645951035781\n",
      "Training loss = 0.22808180491276886\n",
      "Validation accuracy = 0.84375\n",
      "Validation loss = 0.17677966691553593\n",
      "Epoch 0178 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.6274531835205992\n",
      "Training loss = 0.22798444159866105\n",
      "Validation accuracy = 0.84375\n",
      "Validation loss = 0.17211948707699776\n",
      "Epoch 0179 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.6276722532588455\n",
      "Training loss = 0.22792556062319924\n",
      "Validation accuracy = 0.8125\n",
      "Validation loss = 0.18375926185399294\n",
      "Epoch 0180 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.6278611111111111\n",
      "Training loss = 0.22782692992211215\n",
      "Validation accuracy = 0.875\n",
      "Validation loss = 0.16009282041341066\n",
      "Epoch 0181 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.6280478821362799\n",
      "Training loss = 0.22768282903938059\n",
      "Validation accuracy = 0.78125\n",
      "Validation loss = 0.19409562554210424\n",
      "Epoch 0182 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.628246336996337\n",
      "Training loss = 0.22758900274949032\n",
      "Validation accuracy = 0.90625\n",
      "Validation loss = 0.1566502545028925\n",
      "Epoch 0183 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.6286338797814207\n",
      "Training loss = 0.2274304365186879\n",
      "Validation accuracy = 0.84375\n",
      "Validation loss = 0.1623668260872364\n",
      "Epoch 0184 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.628876811594203\n",
      "Training loss = 0.22732957158041983\n",
      "Validation accuracy = 0.8125\n",
      "Validation loss = 0.15585317369550467\n",
      "Epoch 0185 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.6292342342342342\n",
      "Training loss = 0.2271793367913043\n",
      "Validation accuracy = 0.90625\n",
      "Validation loss = 0.15307504311203957\n",
      "Epoch 0186 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.629399641577061\n",
      "Training loss = 0.2271127965913478\n",
      "Validation accuracy = 0.84375\n",
      "Validation loss = 0.16822167672216892\n",
      "Epoch 0187 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.6296524064171123\n",
      "Training loss = 0.22700941553150109\n",
      "Validation accuracy = 0.84375\n",
      "Validation loss = 0.15641362685710192\n",
      "Epoch 0188 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.6297562056737589\n",
      "Training loss = 0.2269185466416418\n",
      "Validation accuracy = 0.875\n",
      "Validation loss = 0.16928790230304003\n",
      "Epoch 0189 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.6299074074074074\n",
      "Training loss = 0.22679913377156072\n",
      "Validation accuracy = 0.78125\n",
      "Validation loss = 0.17754560057073832\n",
      "Epoch 0190 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.6300964912280702\n",
      "Training loss = 0.22673860692788372\n",
      "Validation accuracy = 0.78125\n",
      "Validation loss = 0.1795954927802086\n",
      "Epoch 0191 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.6302748691099477\n",
      "Training loss = 0.22669121410528661\n",
      "Validation accuracy = 0.8125\n",
      "Validation loss = 0.17917862813919783\n",
      "Epoch 0192 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.6304774305555556\n",
      "Training loss = 0.22660097005796465\n",
      "Validation accuracy = 0.84375\n",
      "Validation loss = 0.16119019873440266\n",
      "Epoch 0193 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.6306692573402418\n",
      "Training loss = 0.2265165854607659\n",
      "Validation accuracy = 0.59375\n",
      "Validation loss = 0.21146305371075869\n",
      "Epoch 0194 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.6308161512027491\n",
      "Training loss = 0.2264586528551307\n",
      "Validation accuracy = 0.875\n",
      "Validation loss = 0.16014327015727758\n",
      "Epoch 0195 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.631034188034188\n",
      "Training loss = 0.2263860751754071\n",
      "Validation accuracy = 0.8125\n",
      "Validation loss = 0.16521674115210772\n",
      "Epoch 0196 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.6312840136054422\n",
      "Training loss = 0.22624197595740106\n",
      "Validation accuracy = 0.625\n",
      "Validation loss = 0.20547950081527233\n",
      "Epoch 0197 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.6315862944162437\n",
      "Training loss = 0.22611465690673255\n",
      "Validation accuracy = 0.875\n",
      "Validation loss = 0.15518281143158674\n",
      "Epoch 0198 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.6317550505050505\n",
      "Training loss = 0.22602228580682415\n",
      "Validation accuracy = 0.84375\n",
      "Validation loss = 0.1664280155673623\n",
      "Epoch 0199 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.631859296482412\n",
      "Training loss = 0.22594834137183786\n",
      "Validation accuracy = 0.8125\n",
      "Validation loss = 0.16719559580087662\n",
      "Epoch 0200 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.6319916666666666\n",
      "Training loss = 0.22588773222708453\n",
      "Validation accuracy = 0.75\n",
      "Validation loss = 0.173785287886858\n",
      "Making model for session group 20210310_15:27:20.548-20210319_16:14:28.970\n",
      "Epoch 0001 / 0200\n",
      "=====================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/imblearn/utils/_validation.py:326: UserWarning: After over-sampling, the number of samples (300) in class car will be larger than the number of samples in the majority class (class #signpost -> 160)\n",
      "  n_samples_majority,\n",
      "/usr/local/lib/python3.6/dist-packages/imblearn/utils/_validation.py:326: UserWarning: After over-sampling, the number of samples (300) in class signpost will be larger than the number of samples in the majority class (class #signpost -> 160)\n",
      "  n_samples_majority,\n",
      "/usr/local/lib/python3.6/dist-packages/imblearn/utils/_validation.py:326: UserWarning: After over-sampling, the number of samples (300) in class tree will be larger than the number of samples in the majority class (class #signpost -> 160)\n",
      "  n_samples_majority,\n",
      "/usr/local/lib/python3.6/dist-packages/imblearn/utils/_validation.py:326: UserWarning: After over-sampling, the number of samples (300) in class wall will be larger than the number of samples in the majority class (class #signpost -> 160)\n",
      "  n_samples_majority,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training accuracy = 0.4141666666666667\n",
      "Training loss = 0.3176784444351991\n",
      "Validation accuracy = 0.39285714285714285\n",
      "Validation loss = 0.3108066533293043\n",
      "Epoch 0002 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.4554166666666667\n",
      "Training loss = 0.30705040675898393\n",
      "Validation accuracy = 0.6428571428571429\n",
      "Validation loss = 0.2972908339330128\n",
      "Epoch 0003 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.4752777777777778\n",
      "Training loss = 0.3012398063143094\n",
      "Validation accuracy = 0.39285714285714285\n",
      "Validation loss = 0.30761383899620603\n",
      "Epoch 0004 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.49125\n",
      "Training loss = 0.29701049006233615\n",
      "Validation accuracy = 0.5357142857142857\n",
      "Validation loss = 0.2960751120533262\n",
      "Epoch 0005 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.49716666666666665\n",
      "Training loss = 0.29357904464999834\n",
      "Validation accuracy = 0.5357142857142857\n",
      "Validation loss = 0.28475055524281095\n",
      "Epoch 0006 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.5018055555555555\n",
      "Training loss = 0.2906295043395625\n",
      "Validation accuracy = 0.5357142857142857\n",
      "Validation loss = 0.28187744532312664\n",
      "Epoch 0007 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.5066666666666667\n",
      "Training loss = 0.287445187994412\n",
      "Validation accuracy = 0.4642857142857143\n",
      "Validation loss = 0.29011337033339907\n",
      "Epoch 0008 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.5153125\n",
      "Training loss = 0.2839816850423813\n",
      "Validation accuracy = 0.5\n",
      "Validation loss = 0.2793661079236439\n",
      "Epoch 0009 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.5212962962962963\n",
      "Training loss = 0.2810261890126599\n",
      "Validation accuracy = 0.5357142857142857\n",
      "Validation loss = 0.28379599324294497\n",
      "Epoch 0010 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.5255\n",
      "Training loss = 0.278959084490935\n",
      "Validation accuracy = 0.6428571428571429\n",
      "Validation loss = 0.29117026712213245\n",
      "Epoch 0011 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.5281060606060606\n",
      "Training loss = 0.2776936460850817\n",
      "Validation accuracy = 0.5357142857142857\n",
      "Validation loss = 0.27212500997952055\n",
      "Epoch 0012 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.5322222222222223\n",
      "Training loss = 0.2762718624476757\n",
      "Validation accuracy = 0.5\n",
      "Validation loss = 0.28986139595508575\n",
      "Epoch 0013 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.5349358974358974\n",
      "Training loss = 0.27501198566494844\n",
      "Validation accuracy = 0.5\n",
      "Validation loss = 0.2746414159025465\n",
      "Epoch 0014 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.5386309523809524\n",
      "Training loss = 0.27374088165483307\n",
      "Validation accuracy = 0.6785714285714286\n",
      "Validation loss = 0.2841028358255114\n",
      "Epoch 0015 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.5418888888888889\n",
      "Training loss = 0.27225296260582077\n",
      "Validation accuracy = 0.5357142857142857\n",
      "Validation loss = 0.26520230940410067\n",
      "Epoch 0016 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.54484375\n",
      "Training loss = 0.27094528579774\n",
      "Validation accuracy = 0.39285714285714285\n",
      "Validation loss = 0.2761032538754599\n",
      "Epoch 0017 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.5469117647058823\n",
      "Training loss = 0.26998555588517703\n",
      "Validation accuracy = 0.6428571428571429\n",
      "Validation loss = 0.2658778003283909\n",
      "Epoch 0018 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.5483333333333333\n",
      "Training loss = 0.269355966862705\n",
      "Validation accuracy = 0.4642857142857143\n",
      "Validation loss = 0.2811830235379083\n",
      "Epoch 0019 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.5507456140350877\n",
      "Training loss = 0.26826860461580126\n",
      "Validation accuracy = 0.6428571428571429\n",
      "Validation loss = 0.2706586846283504\n",
      "Epoch 0020 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.5518333333333333\n",
      "Training loss = 0.26771711004773774\n",
      "Validation accuracy = 0.6428571428571429\n",
      "Validation loss = 0.2828052703823362\n",
      "Epoch 0021 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.5529761904761905\n",
      "Training loss = 0.26696649854263615\n",
      "Validation accuracy = 0.6785714285714286\n",
      "Validation loss = 0.28122708201408386\n",
      "Epoch 0022 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.5545075757575758\n",
      "Training loss = 0.2660873076714801\n",
      "Validation accuracy = 0.6071428571428571\n",
      "Validation loss = 0.27662040080342976\n",
      "Epoch 0023 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.557536231884058\n",
      "Training loss = 0.26468545635217344\n",
      "Validation accuracy = 0.6785714285714286\n",
      "Validation loss = 0.2641485780477524\n",
      "Epoch 0024 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.5579166666666666\n",
      "Training loss = 0.2643195954203192\n",
      "Validation accuracy = 0.5\n",
      "Validation loss = 0.2658751755952835\n",
      "Epoch 0025 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.5591333333333334\n",
      "Training loss = 0.2637138543476661\n",
      "Validation accuracy = 0.5714285714285714\n",
      "Validation loss = 0.2647520069565092\n",
      "Epoch 0026 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.5601923076923077\n",
      "Training loss = 0.26306566743514476\n",
      "Validation accuracy = 0.6071428571428571\n",
      "Validation loss = 0.27974577248096466\n",
      "Epoch 0027 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.5611111111111111\n",
      "Training loss = 0.26278412130051926\n",
      "Validation accuracy = 0.5357142857142857\n",
      "Validation loss = 0.27218461675303324\n",
      "Epoch 0028 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.5625595238095238\n",
      "Training loss = 0.2620767524625574\n",
      "Validation accuracy = 0.6428571428571429\n",
      "Validation loss = 0.26564906324659077\n",
      "Epoch 0029 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.5645689655172413\n",
      "Training loss = 0.2611990677942147\n",
      "Validation accuracy = 0.6785714285714286\n",
      "Validation loss = 0.2590983957052231\n",
      "Epoch 0030 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.5660277777777778\n",
      "Training loss = 0.26043517114387615\n",
      "Validation accuracy = 0.6785714285714286\n",
      "Validation loss = 0.2604316898754665\n",
      "Epoch 0031 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.5671236559139785\n",
      "Training loss = 0.26002089737564005\n",
      "Validation accuracy = 0.6785714285714286\n",
      "Validation loss = 0.2645516459430967\n",
      "Epoch 0032 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.568046875\n",
      "Training loss = 0.2595223452329325\n",
      "Validation accuracy = 0.7142857142857143\n",
      "Validation loss = 0.25949118605681826\n",
      "Epoch 0033 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.5689141414141414\n",
      "Training loss = 0.2590360749384972\n",
      "Validation accuracy = 0.6785714285714286\n",
      "Validation loss = 0.2514364229781287\n",
      "Epoch 0034 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.5699754901960784\n",
      "Training loss = 0.25854826904833317\n",
      "Validation accuracy = 0.6785714285714286\n",
      "Validation loss = 0.2707948365381786\n",
      "Epoch 0035 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.571\n",
      "Training loss = 0.2580491316197884\n",
      "Validation accuracy = 0.6071428571428571\n",
      "Validation loss = 0.26554846444300245\n",
      "Epoch 0036 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.5715509259259259\n",
      "Training loss = 0.25758439302720404\n",
      "Validation accuracy = 0.5\n",
      "Validation loss = 0.2578013709613255\n",
      "Epoch 0037 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.5720945945945946\n",
      "Training loss = 0.25726459196089085\n",
      "Validation accuracy = 0.6428571428571429\n",
      "Validation loss = 0.2611535723720278\n",
      "Epoch 0038 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.5729605263157894\n",
      "Training loss = 0.2568337501964548\n",
      "Validation accuracy = 0.6071428571428571\n",
      "Validation loss = 0.26853546500205994\n",
      "Epoch 0039 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.5732905982905983\n",
      "Training loss = 0.25661625450365566\n",
      "Validation accuracy = 0.75\n",
      "Validation loss = 0.2728836344821112\n",
      "Epoch 0040 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.5738125\n",
      "Training loss = 0.25645702273150284\n",
      "Validation accuracy = 0.5714285714285714\n",
      "Validation loss = 0.26360208221844267\n",
      "Epoch 0041 / 0200\n",
      "=====================================\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training accuracy = 0.5743089430894309\n",
      "Training loss = 0.25613754040160314\n",
      "Validation accuracy = 0.5357142857142857\n",
      "Validation loss = 0.27120489946433474\n",
      "Epoch 0042 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.575515873015873\n",
      "Training loss = 0.2555426689385185\n",
      "Validation accuracy = 0.6071428571428571\n",
      "Validation loss = 0.26115077095372335\n",
      "Epoch 0043 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.5763565891472868\n",
      "Training loss = 0.2552175653858702\n",
      "Validation accuracy = 0.4642857142857143\n",
      "Validation loss = 0.2752012887171337\n",
      "Epoch 0044 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.5771022727272728\n",
      "Training loss = 0.2549062544598498\n",
      "Validation accuracy = 0.6071428571428571\n",
      "Validation loss = 0.2661075230155672\n",
      "Epoch 0045 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.5778703703703704\n",
      "Training loss = 0.25447351365619236\n",
      "Validation accuracy = 0.6428571428571429\n",
      "Validation loss = 0.27422033676079344\n",
      "Epoch 0046 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.5781521739130435\n",
      "Training loss = 0.25418391808597507\n",
      "Validation accuracy = 0.6071428571428571\n",
      "Validation loss = 0.26579633568014416\n",
      "Epoch 0047 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.5791666666666667\n",
      "Training loss = 0.25369110144938983\n",
      "Validation accuracy = 0.5357142857142857\n",
      "Validation loss = 0.2557455450296402\n",
      "Epoch 0048 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.5802604166666666\n",
      "Training loss = 0.2532450849464577\n",
      "Validation accuracy = 0.6428571428571429\n",
      "Validation loss = 0.26600365340709686\n",
      "Epoch 0049 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.5806632653061224\n",
      "Training loss = 0.2530319552042452\n",
      "Validation accuracy = 0.5357142857142857\n",
      "Validation loss = 0.2697623712675912\n",
      "Epoch 0050 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.5812\n",
      "Training loss = 0.2526990187823772\n",
      "Validation accuracy = 0.5714285714285714\n",
      "Validation loss = 0.26200111848967417\n",
      "Epoch 0051 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.5815359477124183\n",
      "Training loss = 0.252417169930109\n",
      "Validation accuracy = 0.5\n",
      "Validation loss = 0.26411005428859163\n",
      "Epoch 0052 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.5821314102564102\n",
      "Training loss = 0.25208462534997705\n",
      "Validation accuracy = 0.5714285714285714\n",
      "Validation loss = 0.2570734662669046\n",
      "Epoch 0053 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.5829402515723271\n",
      "Training loss = 0.2516951784683661\n",
      "Validation accuracy = 0.5714285714285714\n",
      "Validation loss = 0.26128459189619335\n",
      "Epoch 0054 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.5834413580246913\n",
      "Training loss = 0.25143090993763856\n",
      "Validation accuracy = 0.6785714285714286\n",
      "Validation loss = 0.26161664937223705\n",
      "Epoch 0055 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.5838939393939394\n",
      "Training loss = 0.2511709551350637\n",
      "Validation accuracy = 0.5714285714285714\n",
      "Validation loss = 0.2599737218448094\n",
      "Epoch 0056 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.5847321428571428\n",
      "Training loss = 0.2508480672897505\n",
      "Validation accuracy = 0.5357142857142857\n",
      "Validation loss = 0.26950973698071073\n",
      "Epoch 0057 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.5858187134502923\n",
      "Training loss = 0.25031400866675796\n",
      "Validation accuracy = 0.5714285714285714\n",
      "Validation loss = 0.2725747951439449\n",
      "Epoch 0058 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.5867097701149425\n",
      "Training loss = 0.2499961188619678\n",
      "Validation accuracy = 0.5714285714285714\n",
      "Validation loss = 0.25706468735422405\n",
      "Epoch 0059 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.5873022598870057\n",
      "Training loss = 0.24969481571035534\n",
      "Validation accuracy = 0.39285714285714285\n",
      "Validation loss = 0.26731189233916147\n",
      "Epoch 0060 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.58775\n",
      "Training loss = 0.24946599360058705\n",
      "Validation accuracy = 0.6428571428571429\n",
      "Validation loss = 0.25613934653145926\n",
      "Epoch 0061 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.5883196721311476\n",
      "Training loss = 0.24926991473537324\n",
      "Validation accuracy = 0.6071428571428571\n",
      "Validation loss = 0.2635494066136224\n",
      "Epoch 0062 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.5885618279569892\n",
      "Training loss = 0.24907748975400482\n",
      "Validation accuracy = 0.6428571428571429\n",
      "Validation loss = 0.27385708902563366\n",
      "Epoch 0063 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.5889550264550265\n",
      "Training loss = 0.24884108742334382\n",
      "Validation accuracy = 0.5\n",
      "Validation loss = 0.2786507180758885\n",
      "Epoch 0064 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.5895703125\n",
      "Training loss = 0.24855883152282332\n",
      "Validation accuracy = 0.5714285714285714\n",
      "Validation loss = 0.267486504146031\n",
      "Epoch 0065 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.5901666666666666\n",
      "Training loss = 0.24835050603307976\n",
      "Validation accuracy = 0.5714285714285714\n",
      "Validation loss = 0.2881781544004168\n",
      "Epoch 0066 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.5905176767676767\n",
      "Training loss = 0.24827929744007762\n",
      "Validation accuracy = 0.6785714285714286\n",
      "Validation loss = 0.26173949028764454\n",
      "Epoch 0067 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.5910199004975124\n",
      "Training loss = 0.24802535093375552\n",
      "Validation accuracy = 0.5714285714285714\n",
      "Validation loss = 0.2754307453121458\n",
      "Epoch 0068 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.5914093137254902\n",
      "Training loss = 0.2479225783866337\n",
      "Validation accuracy = 0.6428571428571429\n",
      "Validation loss = 0.26766940525599886\n",
      "Epoch 0069 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.5920410628019324\n",
      "Training loss = 0.24760732469981275\n",
      "Validation accuracy = 0.6785714285714286\n",
      "Validation loss = 0.2746339568070003\n",
      "Epoch 0070 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.5924285714285714\n",
      "Training loss = 0.24751150022606763\n",
      "Validation accuracy = 0.6428571428571429\n",
      "Validation loss = 0.2729038340704782\n",
      "Epoch 0071 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.5929342723004695\n",
      "Training loss = 0.24721280870670584\n",
      "Validation accuracy = 0.6071428571428571\n",
      "Validation loss = 0.28311991904463085\n",
      "Epoch 0072 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.5934490740740741\n",
      "Training loss = 0.24694144028394172\n",
      "Validation accuracy = 0.5357142857142857\n",
      "Validation loss = 0.28108520805835724\n",
      "Epoch 0073 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.5939840182648402\n",
      "Training loss = 0.24674638922407066\n",
      "Validation accuracy = 0.6071428571428571\n",
      "Validation loss = 0.24997153878211975\n",
      "Epoch 0074 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.594527027027027\n",
      "Training loss = 0.2465550107661601\n",
      "Validation accuracy = 0.5714285714285714\n",
      "Validation loss = 0.2534288338252476\n",
      "Epoch 0075 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.5952333333333333\n",
      "Training loss = 0.24623172657539447\n",
      "Validation accuracy = 0.5714285714285714\n",
      "Validation loss = 0.27122133544513155\n",
      "Epoch 0076 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.5958881578947368\n",
      "Training loss = 0.2459435884894705\n",
      "Validation accuracy = 0.5357142857142857\n",
      "Validation loss = 0.27195948575224194\n",
      "Epoch 0077 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.5961580086580086\n",
      "Training loss = 0.24569857715544374\n",
      "Validation accuracy = 0.39285714285714285\n",
      "Validation loss = 0.284653796681336\n",
      "Epoch 0078 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.5969444444444445\n",
      "Training loss = 0.24537670057855993\n",
      "Validation accuracy = 0.6785714285714286\n",
      "Validation loss = 0.2823810215507235\n",
      "Epoch 0079 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.5974050632911393\n",
      "Training loss = 0.24516955488891917\n",
      "Validation accuracy = 0.5\n",
      "Validation loss = 0.29847376687186106\n",
      "Epoch 0080 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.59775\n",
      "Training loss = 0.2450408026900453\n",
      "Validation accuracy = 0.5357142857142857\n",
      "Validation loss = 0.27207685155527933\n",
      "Epoch 0081 / 0200\n",
      "=====================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/_classification.py:1221: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training accuracy = 0.5980967078189301\n",
      "Training loss = 0.24482259664408587\n",
      "Validation accuracy = 0.5\n",
      "Validation loss = 0.2915260600192206\n",
      "Epoch 0082 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.5984451219512195\n",
      "Training loss = 0.24461220467675143\n",
      "Validation accuracy = 0.6071428571428571\n",
      "Validation loss = 0.2758092326777322\n",
      "Epoch 0083 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.5989658634538153\n",
      "Training loss = 0.24437372960494344\n",
      "Validation accuracy = 0.6071428571428571\n",
      "Validation loss = 0.2703537004334586\n",
      "Epoch 0084 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.5995337301587301\n",
      "Training loss = 0.24415807842661347\n",
      "Validation accuracy = 0.5357142857142857\n",
      "Validation loss = 0.2707279601267406\n",
      "Epoch 0085 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.6000196078431372\n",
      "Training loss = 0.24397269659167994\n",
      "Validation accuracy = 0.5357142857142857\n",
      "Validation loss = 0.28337360279900686\n",
      "Epoch 0086 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.6005717054263566\n",
      "Training loss = 0.24368442602325663\n",
      "Validation accuracy = 0.6071428571428571\n",
      "Validation loss = 0.26415095371859415\n",
      "Epoch 0087 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.601044061302682\n",
      "Training loss = 0.24346592450664303\n",
      "Validation accuracy = 0.6428571428571429\n",
      "Validation loss = 0.27829500500644955\n",
      "Epoch 0088 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.6014393939393939\n",
      "Training loss = 0.24325536923440683\n",
      "Validation accuracy = 0.5357142857142857\n",
      "Validation loss = 0.2814026815550668\n",
      "Epoch 0089 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.6017977528089887\n",
      "Training loss = 0.24312370634690095\n",
      "Validation accuracy = 0.6428571428571429\n",
      "Validation loss = 0.2765312599284308\n",
      "Epoch 0090 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.6021203703703704\n",
      "Training loss = 0.24294529317057242\n",
      "Validation accuracy = 0.5\n",
      "Validation loss = 0.26437629972185406\n",
      "Epoch 0091 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.6021611721611722\n",
      "Training loss = 0.2428182929976683\n",
      "Validation accuracy = 0.5\n",
      "Validation loss = 0.29186344359602245\n",
      "Epoch 0092 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.602518115942029\n",
      "Training loss = 0.24263283993144505\n",
      "Validation accuracy = 0.5357142857142857\n",
      "Validation loss = 0.26567856115954264\n",
      "Epoch 0093 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.6031899641577061\n",
      "Training loss = 0.24230741387052881\n",
      "Validation accuracy = 0.42857142857142855\n",
      "Validation loss = 0.27591228804418017\n",
      "Epoch 0094 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.6036436170212766\n",
      "Training loss = 0.24199824938180706\n",
      "Validation accuracy = 0.6071428571428571\n",
      "Validation loss = 0.2774552245225225\n",
      "Epoch 0095 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.6038771929824561\n",
      "Training loss = 0.24188152786840994\n",
      "Validation accuracy = 0.42857142857142855\n",
      "Validation loss = 0.2848511061498097\n",
      "Epoch 0096 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.6039930555555556\n",
      "Training loss = 0.2417483489790983\n",
      "Validation accuracy = 0.5714285714285714\n",
      "Validation loss = 0.25608174928597044\n",
      "Epoch 0097 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.604372852233677\n",
      "Training loss = 0.24154077903575608\n",
      "Validation accuracy = 0.6428571428571429\n",
      "Validation loss = 0.27206987036126\n",
      "Epoch 0098 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.6044982993197279\n",
      "Training loss = 0.24141122198517934\n",
      "Validation accuracy = 0.7142857142857143\n",
      "Validation loss = 0.26040270711694447\n",
      "Epoch 0099 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.6048737373737374\n",
      "Training loss = 0.24122623143184566\n",
      "Validation accuracy = 0.5357142857142857\n",
      "Validation loss = 0.27214930738721577\n",
      "Epoch 0100 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.6052833333333333\n",
      "Training loss = 0.24104199519443015\n",
      "Validation accuracy = 0.5357142857142857\n",
      "Validation loss = 0.27143215920243946\n",
      "Epoch 0101 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.6056105610561056\n",
      "Training loss = 0.24090315169098453\n",
      "Validation accuracy = 0.7142857142857143\n",
      "Validation loss = 0.26672631927898954\n",
      "Epoch 0102 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.6060049019607843\n",
      "Training loss = 0.2407054790850802\n",
      "Validation accuracy = 0.6071428571428571\n",
      "Validation loss = 0.26504527245249065\n",
      "Epoch 0103 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.6063106796116505\n",
      "Training loss = 0.24054940537642988\n",
      "Validation accuracy = 0.5357142857142857\n",
      "Validation loss = 0.26313068185533794\n",
      "Epoch 0104 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.6064903846153846\n",
      "Training loss = 0.24042686104667016\n",
      "Validation accuracy = 0.5714285714285714\n",
      "Validation loss = 0.26893067147050587\n",
      "Epoch 0105 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.6068253968253968\n",
      "Training loss = 0.2402413351915422\n",
      "Validation accuracy = 0.6071428571428571\n",
      "Validation loss = 0.2570065153496606\n",
      "Epoch 0106 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.6070518867924528\n",
      "Training loss = 0.24008444762489986\n",
      "Validation accuracy = 0.5357142857142857\n",
      "Validation loss = 0.26158816048077177\n",
      "Epoch 0107 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.6074766355140186\n",
      "Training loss = 0.2398816249344347\n",
      "Validation accuracy = 0.6785714285714286\n",
      "Validation loss = 0.27556364451135906\n",
      "Epoch 0108 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.6078626543209876\n",
      "Training loss = 0.23967346665472436\n",
      "Validation accuracy = 0.5357142857142857\n",
      "Validation loss = 0.26656070351600647\n",
      "Epoch 0109 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.608065749235474\n",
      "Training loss = 0.23956447940399522\n",
      "Validation accuracy = 0.6428571428571429\n",
      "Validation loss = 0.257660054734775\n",
      "Epoch 0110 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.6084621212121212\n",
      "Training loss = 0.23934699304311566\n",
      "Validation accuracy = 0.6071428571428571\n",
      "Validation loss = 0.250991695693561\n",
      "Epoch 0111 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.6088438438438438\n",
      "Training loss = 0.2391366242897045\n",
      "Validation accuracy = 0.4642857142857143\n",
      "Validation loss = 0.2861459510666983\n",
      "Epoch 0112 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.6090252976190477\n",
      "Training loss = 0.2390189026169745\n",
      "Validation accuracy = 0.6785714285714286\n",
      "Validation loss = 0.2526746988296509\n",
      "Epoch 0113 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.6093879056047198\n",
      "Training loss = 0.23888617594882977\n",
      "Validation accuracy = 0.7142857142857143\n",
      "Validation loss = 0.26585386587040766\n",
      "Epoch 0114 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.609656432748538\n",
      "Training loss = 0.23872945613200552\n",
      "Validation accuracy = 0.6785714285714286\n",
      "Validation loss = 0.26806871805872234\n",
      "Epoch 0115 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.6100507246376812\n",
      "Training loss = 0.23849507055463998\n",
      "Validation accuracy = 0.5714285714285714\n",
      "Validation loss = 0.2634793881859098\n",
      "Epoch 0116 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.6104813218390804\n",
      "Training loss = 0.23827063732834042\n",
      "Validation accuracy = 0.6428571428571429\n",
      "Validation loss = 0.26891571496214184\n",
      "Epoch 0117 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.6109259259259259\n",
      "Training loss = 0.23813138931055694\n",
      "Validation accuracy = 0.5357142857142857\n",
      "Validation loss = 0.2675811861242567\n",
      "Epoch 0118 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.61125\n",
      "Training loss = 0.23795883991455627\n",
      "Validation accuracy = 0.6071428571428571\n",
      "Validation loss = 0.26741149382931845\n",
      "Epoch 0119 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.6114845938375351\n",
      "Training loss = 0.2378144511718209\n",
      "Validation accuracy = 0.5357142857142857\n",
      "Validation loss = 0.2743872914995466\n",
      "Epoch 0120 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.6118402777777778\n",
      "Training loss = 0.23761485386391482\n",
      "Validation accuracy = 0.6785714285714286\n",
      "Validation loss = 0.2822221006665911\n",
      "Epoch 0121 / 0200\n",
      "=====================================\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training accuracy = 0.6121763085399449\n",
      "Training loss = 0.237413708146446\n",
      "Validation accuracy = 0.6785714285714286\n",
      "Validation loss = 0.25563820345061167\n",
      "Epoch 0122 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.6124726775956284\n",
      "Training loss = 0.23725756495682104\n",
      "Validation accuracy = 0.6428571428571429\n",
      "Validation loss = 0.26461754739284515\n",
      "Epoch 0123 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.6127981029810298\n",
      "Training loss = 0.23709785771483005\n",
      "Validation accuracy = 0.6071428571428571\n",
      "Validation loss = 0.2652215893779482\n",
      "Epoch 0124 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.6133064516129032\n",
      "Training loss = 0.23682092438502017\n",
      "Validation accuracy = 0.6428571428571429\n",
      "Validation loss = 0.25954200114522663\n",
      "Epoch 0125 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.6138733333333334\n",
      "Training loss = 0.23661681595782438\n",
      "Validation accuracy = 0.5357142857142857\n",
      "Validation loss = 0.2840076493365424\n",
      "Epoch 0126 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.6142195767195767\n",
      "Training loss = 0.2364507518127245\n",
      "Validation accuracy = 0.6071428571428571\n",
      "Validation loss = 0.27351652298654827\n",
      "Epoch 0127 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.614507874015748\n",
      "Training loss = 0.23630985281403297\n",
      "Validation accuracy = 0.6071428571428571\n",
      "Validation loss = 0.28062267175742556\n",
      "Epoch 0128 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.615\n",
      "Training loss = 0.23609019694888653\n",
      "Validation accuracy = 0.6785714285714286\n",
      "Validation loss = 0.2626599222421646\n",
      "Epoch 0129 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.6153229974160207\n",
      "Training loss = 0.23588672074255862\n",
      "Validation accuracy = 0.6785714285714286\n",
      "Validation loss = 0.2754521689244679\n",
      "Epoch 0130 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.6154871794871795\n",
      "Training loss = 0.23579885120957325\n",
      "Validation accuracy = 0.5714285714285714\n",
      "Validation loss = 0.2548580595425197\n",
      "Epoch 0131 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.6158969465648855\n",
      "Training loss = 0.2355978326330734\n",
      "Validation accuracy = 0.5714285714285714\n",
      "Validation loss = 0.2594884250845228\n",
      "Epoch 0132 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.6161742424242425\n",
      "Training loss = 0.23542833852101908\n",
      "Validation accuracy = 0.5357142857142857\n",
      "Validation loss = 0.2743523653064455\n",
      "Epoch 0133 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.6165664160401002\n",
      "Training loss = 0.23526569037509143\n",
      "Validation accuracy = 0.5357142857142857\n",
      "Validation loss = 0.2580236920288631\n",
      "Epoch 0134 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.6171268656716418\n",
      "Training loss = 0.235032017565893\n",
      "Validation accuracy = 0.5357142857142857\n",
      "Validation loss = 0.26483230931418283\n",
      "Epoch 0135 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.6174074074074074\n",
      "Training loss = 0.2348908036192994\n",
      "Validation accuracy = 0.42857142857142855\n",
      "Validation loss = 0.2870456171887262\n",
      "Epoch 0136 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.6176348039215687\n",
      "Training loss = 0.23477396976367076\n",
      "Validation accuracy = 0.5714285714285714\n",
      "Validation loss = 0.2633556340421949\n",
      "Epoch 0137 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.6180048661800487\n",
      "Training loss = 0.23459610868254427\n",
      "Validation accuracy = 0.6071428571428571\n",
      "Validation loss = 0.25804244194711956\n",
      "Epoch 0138 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.6181763285024154\n",
      "Training loss = 0.2345079791529671\n",
      "Validation accuracy = 0.5714285714285714\n",
      "Validation loss = 0.2733271313565118\n",
      "Epoch 0139 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.6184712230215827\n",
      "Training loss = 0.23432566033135788\n",
      "Validation accuracy = 0.6071428571428571\n",
      "Validation loss = 0.2641145714691707\n",
      "Epoch 0140 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.6187083333333333\n",
      "Training loss = 0.23425707207655622\n",
      "Validation accuracy = 0.5357142857142857\n",
      "Validation loss = 0.26930429680006845\n",
      "Epoch 0141 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.6187765957446808\n",
      "Training loss = 0.23421473616861846\n",
      "Validation accuracy = 0.6071428571428571\n",
      "Validation loss = 0.2586548626422882\n",
      "Epoch 0142 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.6189260563380282\n",
      "Training loss = 0.23412426826784588\n",
      "Validation accuracy = 0.5\n",
      "Validation loss = 0.2707687424761908\n",
      "Epoch 0143 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.6192890442890443\n",
      "Training loss = 0.23399074350603116\n",
      "Validation accuracy = 0.5\n",
      "Validation loss = 0.2779235520533153\n",
      "Epoch 0144 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.6196875\n",
      "Training loss = 0.23383647365857743\n",
      "Validation accuracy = 0.4642857142857143\n",
      "Validation loss = 0.33330869887556347\n",
      "Epoch 0145 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.6198218390804597\n",
      "Training loss = 0.2336971466897548\n",
      "Validation accuracy = 0.5714285714285714\n",
      "Validation loss = 0.2740162100110735\n",
      "Epoch 0146 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.6200456621004566\n",
      "Training loss = 0.23357541371307008\n",
      "Validation accuracy = 0.5357142857142857\n",
      "Validation loss = 0.2595899339233126\n",
      "Epoch 0147 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.6203061224489796\n",
      "Training loss = 0.23344877758770843\n",
      "Validation accuracy = 0.6071428571428571\n",
      "Validation loss = 0.2801282980612346\n",
      "Epoch 0148 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.6205011261261262\n",
      "Training loss = 0.2333577915469\n",
      "Validation accuracy = 0.5714285714285714\n",
      "Validation loss = 0.2631241977214813\n",
      "Epoch 0149 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.6207382550335571\n",
      "Training loss = 0.23323041346549186\n",
      "Validation accuracy = 0.5714285714285714\n",
      "Validation loss = 0.25536469902311054\n",
      "Epoch 0150 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.6209444444444444\n",
      "Training loss = 0.23313438196099467\n",
      "Validation accuracy = 0.6071428571428571\n",
      "Validation loss = 0.2529268243483135\n",
      "Epoch 0151 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.6211479028697572\n",
      "Training loss = 0.23303971836109036\n",
      "Validation accuracy = 0.6071428571428571\n",
      "Validation loss = 0.2612116869006838\n",
      "Epoch 0152 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.6214528508771929\n",
      "Training loss = 0.23287717032164595\n",
      "Validation accuracy = 0.5714285714285714\n",
      "Validation loss = 0.26054950058460236\n",
      "Epoch 0153 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.6216339869281046\n",
      "Training loss = 0.232752517266828\n",
      "Validation accuracy = 0.5714285714285714\n",
      "Validation loss = 0.26376424942697796\n",
      "Epoch 0154 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.6220725108225108\n",
      "Training loss = 0.23256530501238712\n",
      "Validation accuracy = 0.7142857142857143\n",
      "Validation loss = 0.25549631885119845\n",
      "Epoch 0155 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.6223602150537635\n",
      "Training loss = 0.2323954028101057\n",
      "Validation accuracy = 0.5714285714285714\n",
      "Validation loss = 0.2505124104874475\n",
      "Epoch 0156 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.6227403846153846\n",
      "Training loss = 0.2322012171889536\n",
      "Validation accuracy = 0.6071428571428571\n",
      "Validation loss = 0.2858186885714531\n",
      "Epoch 0157 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.6229458598726114\n",
      "Training loss = 0.23205922056677614\n",
      "Validation accuracy = 0.6071428571428571\n",
      "Validation loss = 0.2635217138699123\n",
      "Epoch 0158 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.6231962025316455\n",
      "Training loss = 0.23196894472645682\n",
      "Validation accuracy = 0.6071428571428571\n",
      "Validation loss = 0.26582348559583935\n",
      "Epoch 0159 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.6233962264150943\n",
      "Training loss = 0.23184519942795206\n",
      "Validation accuracy = 0.6071428571428571\n",
      "Validation loss = 0.25788179891450064\n",
      "Epoch 0160 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.623546875\n",
      "Training loss = 0.23175407712782423\n",
      "Validation accuracy = 0.7142857142857143\n",
      "Validation loss = 0.2578277119568416\n",
      "Epoch 0161 / 0200\n",
      "=====================================\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training accuracy = 0.6236542443064182\n",
      "Training loss = 0.23167073568911534\n",
      "Validation accuracy = 0.7142857142857143\n",
      "Validation loss = 0.26440374340329853\n",
      "Epoch 0162 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.6239557613168725\n",
      "Training loss = 0.23157733689027804\n",
      "Validation accuracy = 0.6071428571428571\n",
      "Validation loss = 0.2597067079373768\n",
      "Epoch 0163 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.6241973415132924\n",
      "Training loss = 0.23144452916302077\n",
      "Validation accuracy = 0.6071428571428571\n",
      "Validation loss = 0.2565437874623707\n",
      "Epoch 0164 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.6242632113821138\n",
      "Training loss = 0.2313774567082282\n",
      "Validation accuracy = 0.6071428571428571\n",
      "Validation loss = 0.2614948792116983\n",
      "Epoch 0165 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.6246565656565657\n",
      "Training loss = 0.2311934925800923\n",
      "Validation accuracy = 0.6428571428571429\n",
      "Validation loss = 0.2545484347002847\n",
      "Epoch 0166 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.6248744979919679\n",
      "Training loss = 0.2310566003954255\n",
      "Validation accuracy = 0.6785714285714286\n",
      "Validation loss = 0.24296510006700242\n",
      "Epoch 0167 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.6250948103792415\n",
      "Training loss = 0.23094112766464195\n",
      "Validation accuracy = 0.5357142857142857\n",
      "Validation loss = 0.2641728286232267\n",
      "Epoch 0168 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.6254265873015873\n",
      "Training loss = 0.23080623085196647\n",
      "Validation accuracy = 0.6071428571428571\n",
      "Validation loss = 0.2504554625068392\n",
      "Epoch 0169 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.6255226824457594\n",
      "Training loss = 0.23076254338937163\n",
      "Validation accuracy = 0.6428571428571429\n",
      "Validation loss = 0.26646299234458376\n",
      "Epoch 0170 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.6256911764705883\n",
      "Training loss = 0.23068427632427682\n",
      "Validation accuracy = 0.6785714285714286\n",
      "Validation loss = 0.26411340704986025\n",
      "Epoch 0171 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.6258284600389864\n",
      "Training loss = 0.2306200952642029\n",
      "Validation accuracy = 0.6785714285714286\n",
      "Validation loss = 0.25103458762168884\n",
      "Epoch 0172 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.6260755813953488\n",
      "Training loss = 0.2305354136056736\n",
      "Validation accuracy = 0.5357142857142857\n",
      "Validation loss = 0.26780012037072864\n",
      "Epoch 0173 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.6263102119460501\n",
      "Training loss = 0.23042480459260917\n",
      "Validation accuracy = 0.6071428571428571\n",
      "Validation loss = 0.26085133850574493\n",
      "Epoch 0174 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.6264990421455938\n",
      "Training loss = 0.23033112968749928\n",
      "Validation accuracy = 0.6071428571428571\n",
      "Validation loss = 0.26588558724948336\n",
      "Epoch 0175 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.6266142857142857\n",
      "Training loss = 0.23025744877613727\n",
      "Validation accuracy = 0.6071428571428571\n",
      "Validation loss = 0.2721414587327412\n",
      "Epoch 0176 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.6267897727272728\n",
      "Training loss = 0.23014419849693887\n",
      "Validation accuracy = 0.6428571428571429\n",
      "Validation loss = 0.2616088188120297\n",
      "Epoch 0177 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.6271468926553673\n",
      "Training loss = 0.2299893808418187\n",
      "Validation accuracy = 0.6071428571428571\n",
      "Validation loss = 0.2663621838603701\n",
      "Epoch 0178 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.6273923220973783\n",
      "Training loss = 0.2298404534470834\n",
      "Validation accuracy = 0.5714285714285714\n",
      "Validation loss = 0.27947135056768146\n",
      "Epoch 0179 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.6275093109869646\n",
      "Training loss = 0.22977674742428728\n",
      "Validation accuracy = 0.6071428571428571\n",
      "Validation loss = 0.314151117844241\n",
      "Epoch 0180 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.6276481481481482\n",
      "Training loss = 0.2296959784511063\n",
      "Validation accuracy = 0.6428571428571429\n",
      "Validation loss = 0.2631242424249649\n",
      "Epoch 0181 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.6277255985267035\n",
      "Training loss = 0.22963101316936327\n",
      "Validation accuracy = 0.5357142857142857\n",
      "Validation loss = 0.27070399267332895\n",
      "Epoch 0182 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.6280082417582418\n",
      "Training loss = 0.2294909849906197\n",
      "Validation accuracy = 0.6428571428571429\n",
      "Validation loss = 0.2531488218477794\n",
      "Epoch 0183 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.628224043715847\n",
      "Training loss = 0.22940279225983362\n",
      "Validation accuracy = 0.6785714285714286\n",
      "Validation loss = 0.26930456714970724\n",
      "Epoch 0184 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.6283786231884058\n",
      "Training loss = 0.2293307023204566\n",
      "Validation accuracy = 0.6785714285714286\n",
      "Validation loss = 0.2573815350021635\n",
      "Epoch 0185 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.6287297297297297\n",
      "Training loss = 0.22917913214291807\n",
      "Validation accuracy = 0.5714285714285714\n",
      "Validation loss = 0.2656678110361099\n",
      "Epoch 0186 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.6289381720430107\n",
      "Training loss = 0.22907597805590346\n",
      "Validation accuracy = 0.6785714285714286\n",
      "Validation loss = 0.2549145945480892\n",
      "Epoch 0187 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.6292424242424243\n",
      "Training loss = 0.22896252315690652\n",
      "Validation accuracy = 0.6071428571428571\n",
      "Validation loss = 0.2554351623569216\n",
      "Epoch 0188 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.629636524822695\n",
      "Training loss = 0.22874930965159326\n",
      "Validation accuracy = 0.6428571428571429\n",
      "Validation loss = 0.24635867774486542\n",
      "Epoch 0189 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.6298853615520282\n",
      "Training loss = 0.228576731888193\n",
      "Validation accuracy = 0.6785714285714286\n",
      "Validation loss = 0.25327255363975254\n",
      "Epoch 0190 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.63\n",
      "Training loss = 0.22849874019367913\n",
      "Validation accuracy = 0.6785714285714286\n",
      "Validation loss = 0.25527626488889965\n",
      "Epoch 0191 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.6302268760907505\n",
      "Training loss = 0.22837180546590535\n",
      "Validation accuracy = 0.6785714285714286\n",
      "Validation loss = 0.24268979685647146\n",
      "Epoch 0192 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.6304730902777778\n",
      "Training loss = 0.22825572699230784\n",
      "Validation accuracy = 0.6071428571428571\n",
      "Validation loss = 0.267405313040529\n",
      "Epoch 0193 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.630772884283247\n",
      "Training loss = 0.22812651736028042\n",
      "Validation accuracy = 0.6428571428571429\n",
      "Validation loss = 0.24345783463546208\n",
      "Epoch 0194 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.6309707903780069\n",
      "Training loss = 0.22804304975196976\n",
      "Validation accuracy = 0.6071428571428571\n",
      "Validation loss = 0.265543920653207\n",
      "Epoch 0195 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.6311196581196581\n",
      "Training loss = 0.22796201000712876\n",
      "Validation accuracy = 0.5357142857142857\n",
      "Validation loss = 0.2860863304563931\n",
      "Epoch 0196 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.6313095238095238\n",
      "Training loss = 0.22787106872479224\n",
      "Validation accuracy = 0.6428571428571429\n",
      "Validation loss = 0.26568250570978436\n",
      "Epoch 0197 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.6315439932318105\n",
      "Training loss = 0.2277272237723854\n",
      "Validation accuracy = 0.6428571428571429\n",
      "Validation loss = 0.2638673335313797\n",
      "Epoch 0198 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.6317550505050505\n",
      "Training loss = 0.22762647530390107\n",
      "Validation accuracy = 0.6785714285714286\n",
      "Validation loss = 0.25739191685404095\n",
      "Epoch 0199 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.6320142378559463\n",
      "Training loss = 0.22748994377833265\n",
      "Validation accuracy = 0.6785714285714286\n",
      "Validation loss = 0.25879562965461184\n",
      "Epoch 0200 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.6322041666666667\n",
      "Training loss = 0.2274074511171008\n",
      "Validation accuracy = 0.6071428571428571\n",
      "Validation loss = 0.2633705032723291\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Making model for session group 20210310_15:29:00.353-20210319_16:14:50.583\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/imblearn/utils/_validation.py:326: UserWarning: After over-sampling, the number of samples (300) in class car will be larger than the number of samples in the majority class (class #signpost -> 160)\n",
      "  n_samples_majority,\n",
      "/usr/local/lib/python3.6/dist-packages/imblearn/utils/_validation.py:326: UserWarning: After over-sampling, the number of samples (300) in class signpost will be larger than the number of samples in the majority class (class #signpost -> 160)\n",
      "  n_samples_majority,\n",
      "/usr/local/lib/python3.6/dist-packages/imblearn/utils/_validation.py:326: UserWarning: After over-sampling, the number of samples (300) in class tree will be larger than the number of samples in the majority class (class #signpost -> 160)\n",
      "  n_samples_majority,\n",
      "/usr/local/lib/python3.6/dist-packages/imblearn/utils/_validation.py:326: UserWarning: After over-sampling, the number of samples (300) in class wall will be larger than the number of samples in the majority class (class #signpost -> 160)\n",
      "  n_samples_majority,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0001 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.43083333333333335\n",
      "Training loss = 0.3117734525601069\n",
      "Validation accuracy = 0.59375\n",
      "Validation loss = 0.29876931942999363\n",
      "Epoch 0002 / 0200\n",
      "=====================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/_classification.py:1221: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training accuracy = 0.4525\n",
      "Training loss = 0.3035655821859837\n",
      "Validation accuracy = 0.4375\n",
      "Validation loss = 0.30763696879148483\n",
      "Epoch 0003 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.4702777777777778\n",
      "Training loss = 0.2959062949485249\n",
      "Validation accuracy = 0.46875\n",
      "Validation loss = 0.28729360550642014\n",
      "Epoch 0004 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.486875\n",
      "Training loss = 0.29018993823478617\n",
      "Validation accuracy = 0.59375\n",
      "Validation loss = 0.28815556317567825\n",
      "Epoch 0005 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.49483333333333335\n",
      "Training loss = 0.2869603282312552\n",
      "Validation accuracy = 0.53125\n",
      "Validation loss = 0.29080312699079514\n",
      "Epoch 0006 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.5022222222222222\n",
      "Training loss = 0.28411825268632834\n",
      "Validation accuracy = 0.46875\n",
      "Validation loss = 0.29168013855814934\n",
      "Epoch 0007 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.5072619047619048\n",
      "Training loss = 0.28225477796225323\n",
      "Validation accuracy = 0.8125\n",
      "Validation loss = 0.2578729875385761\n",
      "Epoch 0008 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.5145833333333333\n",
      "Training loss = 0.27968217980737486\n",
      "Validation accuracy = 0.5625\n",
      "Validation loss = 0.29151646606624126\n",
      "Epoch 0009 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.5199074074074074\n",
      "Training loss = 0.27761053156521587\n",
      "Validation accuracy = 0.5\n",
      "Validation loss = 0.28531673923134804\n",
      "Epoch 0010 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.5216666666666666\n",
      "Training loss = 0.27618130116413037\n",
      "Validation accuracy = 0.46875\n",
      "Validation loss = 0.2915652487426996\n",
      "Epoch 0011 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.5257575757575758\n",
      "Training loss = 0.27466463570567695\n",
      "Validation accuracy = 0.625\n",
      "Validation loss = 0.26688831113278866\n",
      "Epoch 0012 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.5279861111111112\n",
      "Training loss = 0.2733110978744096\n",
      "Validation accuracy = 0.53125\n",
      "Validation loss = 0.28286537900567055\n",
      "Epoch 0013 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.5303846153846153\n",
      "Training loss = 0.27199868166102814\n",
      "Validation accuracy = 0.53125\n",
      "Validation loss = 0.26698937825858593\n",
      "Epoch 0014 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.5342261904761905\n",
      "Training loss = 0.27097293105685993\n",
      "Validation accuracy = 0.625\n",
      "Validation loss = 0.281076405197382\n",
      "Epoch 0015 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.5367222222222222\n",
      "Training loss = 0.2697442854311731\n",
      "Validation accuracy = 0.46875\n",
      "Validation loss = 0.2991277948021889\n",
      "Epoch 0016 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.5384375\n",
      "Training loss = 0.26904765199714653\n",
      "Validation accuracy = 0.53125\n",
      "Validation loss = 0.2866519559174776\n",
      "Epoch 0017 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.5395588235294118\n",
      "Training loss = 0.26821150901855206\n",
      "Validation accuracy = 0.59375\n",
      "Validation loss = 0.2722250558435917\n",
      "Epoch 0018 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.5411574074074074\n",
      "Training loss = 0.26759011901639124\n",
      "Validation accuracy = 0.59375\n",
      "Validation loss = 0.2640213072299957\n",
      "Epoch 0019 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.5421052631578948\n",
      "Training loss = 0.2669392825074886\n",
      "Validation accuracy = 0.625\n",
      "Validation loss = 0.278874009847641\n",
      "Epoch 0020 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.5450833333333334\n",
      "Training loss = 0.26578978840261697\n",
      "Validation accuracy = 0.59375\n",
      "Validation loss = 0.2695183102041483\n",
      "Epoch 0021 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.546031746031746\n",
      "Training loss = 0.2651182096735353\n",
      "Validation accuracy = 0.625\n",
      "Validation loss = 0.26586202532052994\n",
      "Epoch 0022 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.5467045454545455\n",
      "Training loss = 0.26446106071160597\n",
      "Validation accuracy = 0.5\n",
      "Validation loss = 0.2782575152814388\n",
      "Epoch 0023 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.5489855072463768\n",
      "Training loss = 0.2636586957068547\n",
      "Validation accuracy = 0.5625\n",
      "Validation loss = 0.2627913150936365\n",
      "Epoch 0024 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.5513888888888889\n",
      "Training loss = 0.26244939045773613\n",
      "Validation accuracy = 0.625\n",
      "Validation loss = 0.25722301937639713\n",
      "Epoch 0025 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.5526333333333333\n",
      "Training loss = 0.26185813709000744\n",
      "Validation accuracy = 0.65625\n",
      "Validation loss = 0.25427570287138224\n",
      "Epoch 0026 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.5542307692307692\n",
      "Training loss = 0.26110390525788835\n",
      "Validation accuracy = 0.5\n",
      "Validation loss = 0.3061613142490387\n",
      "Epoch 0027 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.5564197530864198\n",
      "Training loss = 0.2601445728310464\n",
      "Validation accuracy = 0.59375\n",
      "Validation loss = 0.23926386423408985\n",
      "Epoch 0028 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.5577678571428571\n",
      "Training loss = 0.2596201517220054\n",
      "Validation accuracy = 0.625\n",
      "Validation loss = 0.25669196899980307\n",
      "Epoch 0029 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.5595402298850575\n",
      "Training loss = 0.2590686342479854\n",
      "Validation accuracy = 0.625\n",
      "Validation loss = 0.27087201084941626\n",
      "Epoch 0030 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.5600555555555555\n",
      "Training loss = 0.2585938477077418\n",
      "Validation accuracy = 0.59375\n",
      "Validation loss = 0.27809687703847885\n",
      "Epoch 0031 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.5616129032258065\n",
      "Training loss = 0.25805526593920364\n",
      "Validation accuracy = 0.625\n",
      "Validation loss = 0.26198025420308113\n",
      "Epoch 0032 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.5625260416666666\n",
      "Training loss = 0.2574981845682487\n",
      "Validation accuracy = 0.59375\n",
      "Validation loss = 0.2782044094055891\n",
      "Epoch 0033 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.5632575757575757\n",
      "Training loss = 0.25702799855533875\n",
      "Validation accuracy = 0.5625\n",
      "Validation loss = 0.2751478459686041\n",
      "Epoch 0034 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.563921568627451\n",
      "Training loss = 0.25683810403022694\n",
      "Validation accuracy = 0.625\n",
      "Validation loss = 0.28747232258319855\n",
      "Epoch 0035 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.5652142857142857\n",
      "Training loss = 0.2561885186419601\n",
      "Validation accuracy = 0.625\n",
      "Validation loss = 0.2558532292023301\n",
      "Epoch 0036 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.5663888888888889\n",
      "Training loss = 0.2558494064991397\n",
      "Validation accuracy = 0.46875\n",
      "Validation loss = 0.28328060545027256\n",
      "Epoch 0037 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.5673873873873874\n",
      "Training loss = 0.25535443129840196\n",
      "Validation accuracy = 0.5\n",
      "Validation loss = 0.2677172189578414\n",
      "Epoch 0038 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.5679605263157895\n",
      "Training loss = 0.25517077821780715\n",
      "Validation accuracy = 0.5625\n",
      "Validation loss = 0.27762762643396854\n",
      "Epoch 0039 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.5686111111111111\n",
      "Training loss = 0.2547518974625402\n",
      "Validation accuracy = 0.5625\n",
      "Validation loss = 0.27804833091795444\n",
      "Epoch 0040 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.5694583333333333\n",
      "Training loss = 0.2544635098446161\n",
      "Validation accuracy = 0.5625\n",
      "Validation loss = 0.2686208812519908\n",
      "Epoch 0041 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.5703252032520325\n",
      "Training loss = 0.25405578882531904\n",
      "Validation accuracy = 0.59375\n",
      "Validation loss = 0.26730200462043285\n",
      "Epoch 0042 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.5711111111111111\n",
      "Training loss = 0.25369599074066157\n",
      "Validation accuracy = 0.625\n",
      "Validation loss = 0.26564678084105253\n",
      "Epoch 0043 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.5718798449612403\n",
      "Training loss = 0.25343536192363547\n",
      "Validation accuracy = 0.5625\n",
      "Validation loss = 0.2553187422454357\n",
      "Epoch 0044 / 0200\n",
      "=====================================\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training accuracy = 0.5725757575757576\n",
      "Training loss = 0.25314296072123177\n",
      "Validation accuracy = 0.5\n",
      "Validation loss = 0.2737253587692976\n",
      "Epoch 0045 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.5733703703703704\n",
      "Training loss = 0.25265141094227633\n",
      "Validation accuracy = 0.5625\n",
      "Validation loss = 0.28078424744307995\n",
      "Epoch 0046 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.573822463768116\n",
      "Training loss = 0.2525304530625758\n",
      "Validation accuracy = 0.5625\n",
      "Validation loss = 0.2962067723274231\n",
      "Epoch 0047 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.5745035460992908\n",
      "Training loss = 0.25206821686568415\n",
      "Validation accuracy = 0.5625\n",
      "Validation loss = 0.29191708099097013\n",
      "Epoch 0048 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.5751041666666666\n",
      "Training loss = 0.2517084446440761\n",
      "Validation accuracy = 0.5625\n",
      "Validation loss = 0.2776684118434787\n",
      "Epoch 0049 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.575952380952381\n",
      "Training loss = 0.25139305458942646\n",
      "Validation accuracy = 0.53125\n",
      "Validation loss = 0.2828899919986725\n",
      "Epoch 0050 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.5769166666666666\n",
      "Training loss = 0.2510070423235496\n",
      "Validation accuracy = 0.59375\n",
      "Validation loss = 0.2668806407600641\n",
      "Epoch 0051 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.5778921568627451\n",
      "Training loss = 0.25061588501082915\n",
      "Validation accuracy = 0.65625\n",
      "Validation loss = 0.2527133319526911\n",
      "Epoch 0052 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.5791346153846154\n",
      "Training loss = 0.25019596722311316\n",
      "Validation accuracy = 0.59375\n",
      "Validation loss = 0.25631033908575773\n",
      "Epoch 0053 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.5800943396226416\n",
      "Training loss = 0.24976824793941194\n",
      "Validation accuracy = 0.5\n",
      "Validation loss = 0.27226725965738297\n",
      "Epoch 0054 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.5811574074074074\n",
      "Training loss = 0.24932821753538317\n",
      "Validation accuracy = 0.5\n",
      "Validation loss = 0.26141555048525333\n",
      "Epoch 0055 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.5816818181818182\n",
      "Training loss = 0.24903804581544617\n",
      "Validation accuracy = 0.53125\n",
      "Validation loss = 0.28361025638878345\n",
      "Epoch 0056 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.5824255952380952\n",
      "Training loss = 0.24872908452570083\n",
      "Validation accuracy = 0.625\n",
      "Validation loss = 0.2608903646469116\n",
      "Epoch 0057 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.5827923976608187\n",
      "Training loss = 0.24847103751063\n",
      "Validation accuracy = 0.6875\n",
      "Validation loss = 0.26014420855790377\n",
      "Epoch 0058 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.5836063218390805\n",
      "Training loss = 0.24814681648694237\n",
      "Validation accuracy = 0.625\n",
      "Validation loss = 0.2732766093686223\n",
      "Epoch 0059 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.5838700564971752\n",
      "Training loss = 0.24795712356429317\n",
      "Validation accuracy = 0.59375\n",
      "Validation loss = 0.2893145205453038\n",
      "Epoch 0060 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.5839861111111111\n",
      "Training loss = 0.2478162373755541\n",
      "Validation accuracy = 0.625\n",
      "Validation loss = 0.26153563894331455\n",
      "Epoch 0061 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.5850409836065574\n",
      "Training loss = 0.2474545429683611\n",
      "Validation accuracy = 0.46875\n",
      "Validation loss = 0.29308680072426796\n",
      "Epoch 0062 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.5853763440860215\n",
      "Training loss = 0.24717529549874284\n",
      "Validation accuracy = 0.5625\n",
      "Validation loss = 0.29411371424794197\n",
      "Epoch 0063 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.5861904761904762\n",
      "Training loss = 0.24683923778434594\n",
      "Validation accuracy = 0.65625\n",
      "Validation loss = 0.23971666302531958\n",
      "Epoch 0064 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.5865104166666667\n",
      "Training loss = 0.24671670294754827\n",
      "Validation accuracy = 0.6875\n",
      "Validation loss = 0.23977162223309278\n",
      "Epoch 0065 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.5868717948717949\n",
      "Training loss = 0.24657425976372682\n",
      "Validation accuracy = 0.5625\n",
      "Validation loss = 0.2727564861997962\n",
      "Epoch 0066 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.5874242424242424\n",
      "Training loss = 0.24632489161246052\n",
      "Validation accuracy = 0.53125\n",
      "Validation loss = 0.27853792533278465\n",
      "Epoch 0067 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.5880348258706468\n",
      "Training loss = 0.24601969497306134\n",
      "Validation accuracy = 0.5625\n",
      "Validation loss = 0.27284857258200645\n",
      "Epoch 0068 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.5883088235294117\n",
      "Training loss = 0.24577714118887398\n",
      "Validation accuracy = 0.5625\n",
      "Validation loss = 0.2762573501095176\n",
      "Epoch 0069 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.5887922705314009\n",
      "Training loss = 0.24547777818956812\n",
      "Validation accuracy = 0.625\n",
      "Validation loss = 0.2569098547101021\n",
      "Epoch 0070 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.5888333333333333\n",
      "Training loss = 0.24527942672620218\n",
      "Validation accuracy = 0.53125\n",
      "Validation loss = 0.3006670447066426\n",
      "Epoch 0071 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.5892136150234741\n",
      "Training loss = 0.24501614064083133\n",
      "Validation accuracy = 0.53125\n",
      "Validation loss = 0.27094648219645023\n",
      "Epoch 0072 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.5898148148148148\n",
      "Training loss = 0.24476844311415874\n",
      "Validation accuracy = 0.53125\n",
      "Validation loss = 0.3052252158522606\n",
      "Epoch 0073 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.5900228310502283\n",
      "Training loss = 0.24457035039317662\n",
      "Validation accuracy = 0.5\n",
      "Validation loss = 0.2791856089606881\n",
      "Epoch 0074 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.5904954954954955\n",
      "Training loss = 0.2443925520505857\n",
      "Validation accuracy = 0.53125\n",
      "Validation loss = 0.2892430294305086\n",
      "Epoch 0075 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.5908333333333333\n",
      "Training loss = 0.24416312346458435\n",
      "Validation accuracy = 0.40625\n",
      "Validation loss = 0.3454072829335928\n",
      "Epoch 0076 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.5912719298245614\n",
      "Training loss = 0.24402057835734203\n",
      "Validation accuracy = 0.65625\n",
      "Validation loss = 0.2550513995811343\n",
      "Epoch 0077 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.5915909090909091\n",
      "Training loss = 0.2438373108043686\n",
      "Validation accuracy = 0.625\n",
      "Validation loss = 0.25492506846785545\n",
      "Epoch 0078 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.5921688034188034\n",
      "Training loss = 0.2436156570366942\n",
      "Validation accuracy = 0.46875\n",
      "Validation loss = 0.28204889688640833\n",
      "Epoch 0079 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.5927848101265822\n",
      "Training loss = 0.24328935245861483\n",
      "Validation accuracy = 0.53125\n",
      "Validation loss = 0.2627982208505273\n",
      "Epoch 0080 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.5930416666666667\n",
      "Training loss = 0.2430972477712979\n",
      "Validation accuracy = 0.5625\n",
      "Validation loss = 0.2793079009279609\n",
      "Epoch 0081 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.5938683127572016\n",
      "Training loss = 0.24277035322178292\n",
      "Validation accuracy = 0.5625\n",
      "Validation loss = 0.273909205570817\n",
      "Epoch 0082 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.5942479674796748\n",
      "Training loss = 0.24252745945248905\n",
      "Validation accuracy = 0.5\n",
      "Validation loss = 0.2793078627437353\n",
      "Epoch 0083 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.5946285140562249\n",
      "Training loss = 0.2423611897987175\n",
      "Validation accuracy = 0.59375\n",
      "Validation loss = 0.26189609710127115\n",
      "Epoch 0084 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.594920634920635\n",
      "Training loss = 0.2422344982615184\n",
      "Validation accuracy = 0.53125\n",
      "Validation loss = 0.2804284328594804\n",
      "Epoch 0085 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.5953039215686274\n",
      "Training loss = 0.24203620346913152\n",
      "Validation accuracy = 0.65625\n",
      "Validation loss = 0.2578886142000556\n",
      "Epoch 0086 / 0200\n",
      "=====================================\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training accuracy = 0.5957461240310078\n",
      "Training loss = 0.24187437364239564\n",
      "Validation accuracy = 0.5\n",
      "Validation loss = 0.29682335909456015\n",
      "Epoch 0087 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.596139846743295\n",
      "Training loss = 0.24173634005888897\n",
      "Validation accuracy = 0.6875\n",
      "Validation loss = 0.26700913719832897\n",
      "Epoch 0088 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.5965530303030303\n",
      "Training loss = 0.2415055549133456\n",
      "Validation accuracy = 0.65625\n",
      "Validation loss = 0.23018512222915888\n",
      "Epoch 0089 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.5968352059925094\n",
      "Training loss = 0.24129098401394453\n",
      "Validation accuracy = 0.65625\n",
      "Validation loss = 0.2667145598679781\n",
      "Epoch 0090 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.5971296296296297\n",
      "Training loss = 0.24112877998418278\n",
      "Validation accuracy = 0.6875\n",
      "Validation loss = 0.2496682396158576\n",
      "Epoch 0091 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.5974725274725274\n",
      "Training loss = 0.24090474210379326\n",
      "Validation accuracy = 0.59375\n",
      "Validation loss = 0.2603976298123598\n",
      "Epoch 0092 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.5979347826086957\n",
      "Training loss = 0.2406799602276389\n",
      "Validation accuracy = 0.59375\n",
      "Validation loss = 0.26970224827528\n",
      "Epoch 0093 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.598494623655914\n",
      "Training loss = 0.24048330746430863\n",
      "Validation accuracy = 0.53125\n",
      "Validation loss = 0.2947552539408207\n",
      "Epoch 0094 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.5985815602836879\n",
      "Training loss = 0.24039706776539485\n",
      "Validation accuracy = 0.59375\n",
      "Validation loss = 0.2733331751078367\n",
      "Epoch 0095 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.5992368421052632\n",
      "Training loss = 0.24007989720032927\n",
      "Validation accuracy = 0.5625\n",
      "Validation loss = 0.29712659772485495\n",
      "Epoch 0096 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.5994357638888889\n",
      "Training loss = 0.2399638069850496\n",
      "Validation accuracy = 0.34375\n",
      "Validation loss = 0.3269055522978306\n",
      "Epoch 0097 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.5996821305841924\n",
      "Training loss = 0.23975822172956573\n",
      "Validation accuracy = 0.53125\n",
      "Validation loss = 0.2949837502092123\n",
      "Epoch 0098 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.5998809523809524\n",
      "Training loss = 0.23960902093244452\n",
      "Validation accuracy = 0.625\n",
      "Validation loss = 0.24351707473397255\n",
      "Epoch 0099 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.6001010101010101\n",
      "Training loss = 0.23942310229922184\n",
      "Validation accuracy = 0.53125\n",
      "Validation loss = 0.28886317927390337\n",
      "Epoch 0100 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.600625\n",
      "Training loss = 0.2391974132652084\n",
      "Validation accuracy = 0.5625\n",
      "Validation loss = 0.27842634730041027\n",
      "Epoch 0101 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.6011881188118812\n",
      "Training loss = 0.23894472592341232\n",
      "Validation accuracy = 0.53125\n",
      "Validation loss = 0.27898372057825327\n",
      "Epoch 0102 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.6014705882352941\n",
      "Training loss = 0.23874706475660692\n",
      "Validation accuracy = 0.5\n",
      "Validation loss = 0.28841167595237494\n",
      "Epoch 0103 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.6017961165048543\n",
      "Training loss = 0.23851876419411316\n",
      "Validation accuracy = 0.5\n",
      "Validation loss = 0.3044437076896429\n",
      "Epoch 0104 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.6022516025641026\n",
      "Training loss = 0.23832389494642997\n",
      "Validation accuracy = 0.53125\n",
      "Validation loss = 0.28582650423049927\n",
      "Epoch 0105 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.602563492063492\n",
      "Training loss = 0.23816879252521764\n",
      "Validation accuracy = 0.4375\n",
      "Validation loss = 0.3335147611796856\n",
      "Epoch 0106 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.602940251572327\n",
      "Training loss = 0.23796809585425277\n",
      "Validation accuracy = 0.59375\n",
      "Validation loss = 0.25851158425211906\n",
      "Epoch 0107 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.6031464174454829\n",
      "Training loss = 0.23785446354626125\n",
      "Validation accuracy = 0.65625\n",
      "Validation loss = 0.2769874222576618\n",
      "Epoch 0108 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.6036111111111111\n",
      "Training loss = 0.23762351086225222\n",
      "Validation accuracy = 0.53125\n",
      "Validation loss = 0.2658070931211114\n",
      "Epoch 0109 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.6040290519877676\n",
      "Training loss = 0.23745306813411574\n",
      "Validation accuracy = 0.625\n",
      "Validation loss = 0.2478534672409296\n",
      "Epoch 0110 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.6043636363636363\n",
      "Training loss = 0.23732872539352287\n",
      "Validation accuracy = 0.5625\n",
      "Validation loss = 0.2762694852426648\n",
      "Epoch 0111 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.6045345345345345\n",
      "Training loss = 0.23721829550178558\n",
      "Validation accuracy = 0.5625\n",
      "Validation loss = 0.269714392721653\n",
      "Epoch 0112 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.6048586309523809\n",
      "Training loss = 0.23705876142052668\n",
      "Validation accuracy = 0.46875\n",
      "Validation loss = 0.3064659247174859\n",
      "Epoch 0113 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.6050147492625368\n",
      "Training loss = 0.23690114993525113\n",
      "Validation accuracy = 0.625\n",
      "Validation loss = 0.26993614062666893\n",
      "Epoch 0114 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.6054312865497076\n",
      "Training loss = 0.23671649423520466\n",
      "Validation accuracy = 0.6875\n",
      "Validation loss = 0.25146247260272503\n",
      "Epoch 0115 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.6056739130434783\n",
      "Training loss = 0.2366293748744588\n",
      "Validation accuracy = 0.625\n",
      "Validation loss = 0.2727004634216428\n",
      "Epoch 0116 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.6059985632183909\n",
      "Training loss = 0.23648351094888886\n",
      "Validation accuracy = 0.5625\n",
      "Validation loss = 0.27671286650002\n",
      "Epoch 0117 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.6064173789173789\n",
      "Training loss = 0.23630578319528844\n",
      "Validation accuracy = 0.59375\n",
      "Validation loss = 0.2758330060169101\n",
      "Epoch 0118 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.6065819209039548\n",
      "Training loss = 0.23618285369527878\n",
      "Validation accuracy = 0.59375\n",
      "Validation loss = 0.29803173523396254\n",
      "Epoch 0119 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.6070448179271709\n",
      "Training loss = 0.2359826867921012\n",
      "Validation accuracy = 0.5625\n",
      "Validation loss = 0.2758024847134948\n",
      "Epoch 0120 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.6074166666666667\n",
      "Training loss = 0.2357861054641091\n",
      "Validation accuracy = 0.5\n",
      "Validation loss = 0.3036228893324733\n",
      "Epoch 0121 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.6076928374655647\n",
      "Training loss = 0.23571310780306165\n",
      "Validation accuracy = 0.5625\n",
      "Validation loss = 0.2696871282532811\n",
      "Epoch 0122 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.6081284153005464\n",
      "Training loss = 0.23555418975020204\n",
      "Validation accuracy = 0.625\n",
      "Validation loss = 0.25574815832078457\n",
      "Epoch 0123 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.6085569105691057\n",
      "Training loss = 0.23535742389356218\n",
      "Validation accuracy = 0.65625\n",
      "Validation loss = 0.2625916674733162\n",
      "Epoch 0124 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.6087970430107527\n",
      "Training loss = 0.23528993858985844\n",
      "Validation accuracy = 0.5\n",
      "Validation loss = 0.3199942819774151\n",
      "Epoch 0125 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.6090933333333334\n",
      "Training loss = 0.2351250987915198\n",
      "Validation accuracy = 0.5625\n",
      "Validation loss = 0.2818420296534896\n",
      "Epoch 0126 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.6093584656084656\n",
      "Training loss = 0.23497598459264116\n",
      "Validation accuracy = 0.59375\n",
      "Validation loss = 0.28513857908546925\n",
      "Epoch 0127 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.6097703412073491\n",
      "Training loss = 0.23477319132135765\n",
      "Validation accuracy = 0.5625\n",
      "Validation loss = 0.2899635015055537\n",
      "Epoch 0128 / 0200\n",
      "=====================================\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training accuracy = 0.6100716145833334\n",
      "Training loss = 0.2346057667612331\n",
      "Validation accuracy = 0.5\n",
      "Validation loss = 0.2725086696445942\n",
      "Epoch 0129 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.6102842377260982\n",
      "Training loss = 0.23445039874091936\n",
      "Validation accuracy = 0.625\n",
      "Validation loss = 0.2714982870966196\n",
      "Epoch 0130 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.6108782051282051\n",
      "Training loss = 0.23421311573684214\n",
      "Validation accuracy = 0.5\n",
      "Validation loss = 0.29339057859033346\n",
      "Epoch 0131 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.611145038167939\n",
      "Training loss = 0.2341185577820427\n",
      "Validation accuracy = 0.46875\n",
      "Validation loss = 0.2743751686066389\n",
      "Epoch 0132 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.6114583333333333\n",
      "Training loss = 0.2339629734727093\n",
      "Validation accuracy = 0.625\n",
      "Validation loss = 0.25345373153686523\n",
      "Epoch 0133 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.6115664160401002\n",
      "Training loss = 0.23384150510779897\n",
      "Validation accuracy = 0.625\n",
      "Validation loss = 0.2588830469176173\n",
      "Epoch 0134 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.611679104477612\n",
      "Training loss = 0.2337823090049906\n",
      "Validation accuracy = 0.53125\n",
      "Validation loss = 0.2838034927845001\n",
      "Epoch 0135 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.612\n",
      "Training loss = 0.2336376243016602\n",
      "Validation accuracy = 0.65625\n",
      "Validation loss = 0.25249326787889004\n",
      "Epoch 0136 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.6124203431372549\n",
      "Training loss = 0.23349617196027847\n",
      "Validation accuracy = 0.59375\n",
      "Validation loss = 0.2756073661148548\n",
      "Epoch 0137 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.6127372262773723\n",
      "Training loss = 0.23335704433385038\n",
      "Validation accuracy = 0.5\n",
      "Validation loss = 0.2785883126780391\n",
      "Epoch 0138 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.6130434782608696\n",
      "Training loss = 0.23322102419042212\n",
      "Validation accuracy = 0.5\n",
      "Validation loss = 0.3069661743938923\n",
      "Epoch 0139 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.6132194244604317\n",
      "Training loss = 0.23310087552906084\n",
      "Validation accuracy = 0.5625\n",
      "Validation loss = 0.273596259765327\n",
      "Epoch 0140 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.6133988095238095\n",
      "Training loss = 0.23297117916317214\n",
      "Validation accuracy = 0.5625\n",
      "Validation loss = 0.29249920696020126\n",
      "Epoch 0141 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.6135815602836879\n",
      "Training loss = 0.23291239452946835\n",
      "Validation accuracy = 0.5625\n",
      "Validation loss = 0.27578813396394253\n",
      "Epoch 0142 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.6140023474178403\n",
      "Training loss = 0.23279437813558068\n",
      "Validation accuracy = 0.59375\n",
      "Validation loss = 0.27538877725601196\n",
      "Epoch 0143 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.6142132867132867\n",
      "Training loss = 0.2326952328883754\n",
      "Validation accuracy = 0.59375\n",
      "Validation loss = 0.27272268384695053\n",
      "Epoch 0144 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.6146759259259259\n",
      "Training loss = 0.23250405751237715\n",
      "Validation accuracy = 0.53125\n",
      "Validation loss = 0.27515197545289993\n",
      "Epoch 0145 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.6149942528735632\n",
      "Training loss = 0.23233942542781774\n",
      "Validation accuracy = 0.53125\n",
      "Validation loss = 0.27860510256141424\n",
      "Epoch 0146 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.6153367579908676\n",
      "Training loss = 0.23222265430713354\n",
      "Validation accuracy = 0.5\n",
      "Validation loss = 0.34366164449602365\n",
      "Epoch 0147 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.6155839002267574\n",
      "Training loss = 0.23209930692940883\n",
      "Validation accuracy = 0.5\n",
      "Validation loss = 0.2961234115064144\n",
      "Epoch 0148 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.6159121621621622\n",
      "Training loss = 0.23192300516407233\n",
      "Validation accuracy = 0.53125\n",
      "Validation loss = 0.3098192159086466\n",
      "Epoch 0149 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.6163031319910515\n",
      "Training loss = 0.23174221945855708\n",
      "Validation accuracy = 0.5625\n",
      "Validation loss = 0.26965526305139065\n",
      "Epoch 0150 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.6167277777777778\n",
      "Training loss = 0.2315206595444017\n",
      "Validation accuracy = 0.59375\n",
      "Validation loss = 0.25940958224236965\n",
      "Epoch 0151 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.6169260485651215\n",
      "Training loss = 0.23140620536246967\n",
      "Validation accuracy = 0.53125\n",
      "Validation loss = 0.27310087252408266\n",
      "Epoch 0152 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.6173135964912281\n",
      "Training loss = 0.23126599621583233\n",
      "Validation accuracy = 0.6875\n",
      "Validation loss = 0.2515080841258168\n",
      "Epoch 0153 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.6177124183006536\n",
      "Training loss = 0.23105752330589918\n",
      "Validation accuracy = 0.625\n",
      "Validation loss = 0.2643162216991186\n",
      "Epoch 0154 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.6180519480519481\n",
      "Training loss = 0.2309016258090541\n",
      "Validation accuracy = 0.59375\n",
      "Validation loss = 0.26707233022898436\n",
      "Epoch 0155 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.6183172043010753\n",
      "Training loss = 0.23078749294787324\n",
      "Validation accuracy = 0.4375\n",
      "Validation loss = 0.2727822884917259\n",
      "Epoch 0156 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.6185416666666667\n",
      "Training loss = 0.23065298527797573\n",
      "Validation accuracy = 0.5\n",
      "Validation loss = 0.27459029387682676\n",
      "Epoch 0157 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.6188057324840764\n",
      "Training loss = 0.23054278232236325\n",
      "Validation accuracy = 0.53125\n",
      "Validation loss = 0.2714890781790018\n",
      "Epoch 0158 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.6192457805907173\n",
      "Training loss = 0.23038824083432868\n",
      "Validation accuracy = 0.59375\n",
      "Validation loss = 0.28678962122648954\n",
      "Epoch 0159 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.6193763102725367\n",
      "Training loss = 0.23028400934201743\n",
      "Validation accuracy = 0.53125\n",
      "Validation loss = 0.27148600202053785\n",
      "Epoch 0160 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.6197083333333333\n",
      "Training loss = 0.23010307770734653\n",
      "Validation accuracy = 0.5625\n",
      "Validation loss = 0.28935240395367146\n",
      "Epoch 0161 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.6200621118012423\n",
      "Training loss = 0.2299223644841717\n",
      "Validation accuracy = 0.5\n",
      "Validation loss = 0.27285653725266457\n",
      "Epoch 0162 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.6203703703703703\n",
      "Training loss = 0.2297824518594109\n",
      "Validation accuracy = 0.5625\n",
      "Validation loss = 0.25899079255759716\n",
      "Epoch 0163 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.6207106339468302\n",
      "Training loss = 0.22960931334895957\n",
      "Validation accuracy = 0.5\n",
      "Validation loss = 0.28560619708150625\n",
      "Epoch 0164 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.6211483739837398\n",
      "Training loss = 0.22941173602910184\n",
      "Validation accuracy = 0.5625\n",
      "Validation loss = 0.2759972419589758\n",
      "Epoch 0165 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.6214191919191919\n",
      "Training loss = 0.22930535659931525\n",
      "Validation accuracy = 0.5\n",
      "Validation loss = 0.2794485595077276\n",
      "Epoch 0166 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.6216967871485943\n",
      "Training loss = 0.2291542165856584\n",
      "Validation accuracy = 0.5625\n",
      "Validation loss = 0.2663058442994952\n",
      "Epoch 0167 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.6219461077844312\n",
      "Training loss = 0.22902202397599786\n",
      "Validation accuracy = 0.5\n",
      "Validation loss = 0.27087605092674494\n",
      "Epoch 0168 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.6222172619047619\n",
      "Training loss = 0.22889171764683275\n",
      "Validation accuracy = 0.65625\n",
      "Validation loss = 0.23212506249547005\n",
      "Epoch 0169 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.6223915187376726\n",
      "Training loss = 0.22884297487474758\n",
      "Validation accuracy = 0.5625\n",
      "Validation loss = 0.260327803902328\n",
      "Epoch 0170 / 0200\n",
      "=====================================\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training accuracy = 0.6226372549019608\n",
      "Training loss = 0.228738490351421\n",
      "Validation accuracy = 0.5\n",
      "Validation loss = 0.2805750910192728\n",
      "Epoch 0171 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.6228606237816764\n",
      "Training loss = 0.22860491780945433\n",
      "Validation accuracy = 0.625\n",
      "Validation loss = 0.2505014343187213\n",
      "Epoch 0172 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.6230038759689922\n",
      "Training loss = 0.22856641502083502\n",
      "Validation accuracy = 0.53125\n",
      "Validation loss = 0.27583397552371025\n",
      "Epoch 0173 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.6232321772639692\n",
      "Training loss = 0.22847306630371395\n",
      "Validation accuracy = 0.5625\n",
      "Validation loss = 0.2697715684771538\n",
      "Epoch 0174 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.6234003831417625\n",
      "Training loss = 0.22835797711007896\n",
      "Validation accuracy = 0.625\n",
      "Validation loss = 0.2532040560618043\n",
      "Epoch 0175 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.6236\n",
      "Training loss = 0.2282658910545565\n",
      "Validation accuracy = 0.59375\n",
      "Validation loss = 0.2542311269789934\n",
      "Epoch 0176 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.6239251893939394\n",
      "Training loss = 0.22813683333806695\n",
      "Validation accuracy = 0.59375\n",
      "Validation loss = 0.24716724827885628\n",
      "Epoch 0177 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.6240913370998117\n",
      "Training loss = 0.22809039499252867\n",
      "Validation accuracy = 0.53125\n",
      "Validation loss = 0.2797422958537936\n",
      "Epoch 0178 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.6242977528089888\n",
      "Training loss = 0.22800954379908714\n",
      "Validation accuracy = 0.46875\n",
      "Validation loss = 0.25872205942869186\n",
      "Epoch 0179 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.6245949720670391\n",
      "Training loss = 0.22791361821236114\n",
      "Validation accuracy = 0.59375\n",
      "Validation loss = 0.2449533762410283\n",
      "Epoch 0180 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.6248194444444445\n",
      "Training loss = 0.22777074975175438\n",
      "Validation accuracy = 0.59375\n",
      "Validation loss = 0.2759510073810816\n",
      "Epoch 0181 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.6250644567219152\n",
      "Training loss = 0.22770442564102167\n",
      "Validation accuracy = 0.625\n",
      "Validation loss = 0.273836525157094\n",
      "Epoch 0182 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.6252838827838828\n",
      "Training loss = 0.22761920904392724\n",
      "Validation accuracy = 0.65625\n",
      "Validation loss = 0.25412571243941784\n",
      "Epoch 0183 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.6254280510018215\n",
      "Training loss = 0.22752571991503998\n",
      "Validation accuracy = 0.6875\n",
      "Validation loss = 0.2667642617598176\n",
      "Epoch 0184 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.6257155797101449\n",
      "Training loss = 0.22740534615041552\n",
      "Validation accuracy = 0.71875\n",
      "Validation loss = 0.23385826777666807\n",
      "Epoch 0185 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.6259594594594594\n",
      "Training loss = 0.22726350316499266\n",
      "Validation accuracy = 0.53125\n",
      "Validation loss = 0.28101002518087626\n",
      "Epoch 0186 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.6260707885304659\n",
      "Training loss = 0.22721931389022257\n",
      "Validation accuracy = 0.5625\n",
      "Validation loss = 0.26203866861760616\n",
      "Epoch 0187 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.6263101604278075\n",
      "Training loss = 0.22709179460378148\n",
      "Validation accuracy = 0.65625\n",
      "Validation loss = 0.25178121495991945\n",
      "Epoch 0188 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.6264760638297873\n",
      "Training loss = 0.22697922023515224\n",
      "Validation accuracy = 0.625\n",
      "Validation loss = 0.25485931150615215\n",
      "Epoch 0189 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.6266754850088183\n",
      "Training loss = 0.22689597334785017\n",
      "Validation accuracy = 0.625\n",
      "Validation loss = 0.2424293039366603\n",
      "Epoch 0190 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.6268377192982456\n",
      "Training loss = 0.22683631911102617\n",
      "Validation accuracy = 0.40625\n",
      "Validation loss = 0.32465336192399263\n",
      "Epoch 0191 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.6270244328097732\n",
      "Training loss = 0.22677473463261108\n",
      "Validation accuracy = 0.5625\n",
      "Validation loss = 0.26859720423817635\n",
      "Epoch 0192 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.6273003472222223\n",
      "Training loss = 0.22669121262475123\n",
      "Validation accuracy = 0.53125\n",
      "Validation loss = 0.2757993480190635\n",
      "Epoch 0193 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.6275993091537133\n",
      "Training loss = 0.2265744388777769\n",
      "Validation accuracy = 0.59375\n",
      "Validation loss = 0.25483854953199625\n",
      "Epoch 0194 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.627856529209622\n",
      "Training loss = 0.226466267046317\n",
      "Validation accuracy = 0.5625\n",
      "Validation loss = 0.2609663540497422\n",
      "Epoch 0195 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.6280470085470086\n",
      "Training loss = 0.22636016121939717\n",
      "Validation accuracy = 0.5625\n",
      "Validation loss = 0.2844852637499571\n",
      "Epoch 0196 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.6282780612244898\n",
      "Training loss = 0.2262804060673886\n",
      "Validation accuracy = 0.71875\n",
      "Validation loss = 0.23572184704244137\n",
      "Epoch 0197 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.628502538071066\n",
      "Training loss = 0.22616713482590295\n",
      "Validation accuracy = 0.375\n",
      "Validation loss = 0.31722230091691017\n",
      "Epoch 0198 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.6287710437710438\n",
      "Training loss = 0.22609766327108097\n",
      "Validation accuracy = 0.53125\n",
      "Validation loss = 0.2845789333805442\n",
      "Epoch 0199 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.6289907872696817\n",
      "Training loss = 0.22601360109570737\n",
      "Validation accuracy = 0.5625\n",
      "Validation loss = 0.2695937491953373\n",
      "Epoch 0200 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.6289916666666666\n",
      "Training loss = 0.22600111551644902\n",
      "Validation accuracy = 0.625\n",
      "Validation loss = 0.26281174551695585\n",
      "Making model for session group 20210310_15:29:25.107-20210319_16:15:18.712\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/imblearn/utils/_validation.py:326: UserWarning: After over-sampling, the number of samples (300) in class car will be larger than the number of samples in the majority class (class #signpost -> 160)\n",
      "  n_samples_majority,\n",
      "/usr/local/lib/python3.6/dist-packages/imblearn/utils/_validation.py:326: UserWarning: After over-sampling, the number of samples (300) in class signpost will be larger than the number of samples in the majority class (class #signpost -> 160)\n",
      "  n_samples_majority,\n",
      "/usr/local/lib/python3.6/dist-packages/imblearn/utils/_validation.py:326: UserWarning: After over-sampling, the number of samples (300) in class tree will be larger than the number of samples in the majority class (class #signpost -> 160)\n",
      "  n_samples_majority,\n",
      "/usr/local/lib/python3.6/dist-packages/imblearn/utils/_validation.py:326: UserWarning: After over-sampling, the number of samples (300) in class wall will be larger than the number of samples in the majority class (class #signpost -> 160)\n",
      "  n_samples_majority,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0001 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.43916666666666665\n",
      "Training loss = 0.3098136359949907\n",
      "Validation accuracy = 0.4375\n",
      "Validation loss = 0.28352541476488113\n",
      "Epoch 0002 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.47541666666666665\n",
      "Training loss = 0.3000177574902773\n",
      "Validation accuracy = 0.53125\n",
      "Validation loss = 0.2750350385904312\n",
      "Epoch 0003 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.49333333333333335\n",
      "Training loss = 0.2933666647473971\n",
      "Validation accuracy = 0.5\n",
      "Validation loss = 0.2744146045297384\n",
      "Epoch 0004 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.504375\n",
      "Training loss = 0.2890201628332337\n",
      "Validation accuracy = 0.71875\n",
      "Validation loss = 0.2406732589006424\n",
      "Epoch 0005 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.5168333333333334\n",
      "Training loss = 0.28413729564348855\n",
      "Validation accuracy = 0.65625\n",
      "Validation loss = 0.24653192795813084\n",
      "Epoch 0006 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.5240277777777778\n",
      "Training loss = 0.2804928751372629\n",
      "Validation accuracy = 0.625\n",
      "Validation loss = 0.24248793721199036\n",
      "Epoch 0007 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.5277380952380952\n",
      "Training loss = 0.27812990226206324\n",
      "Validation accuracy = 0.59375\n",
      "Validation loss = 0.23565805703401566\n",
      "Epoch 0008 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.534375\n",
      "Training loss = 0.2747876290821781\n",
      "Validation accuracy = 0.71875\n",
      "Validation loss = 0.2211656467989087\n",
      "Epoch 0009 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.5385185185185185\n",
      "Training loss = 0.2731875083705893\n",
      "Validation accuracy = 0.6875\n",
      "Validation loss = 0.2166236899793148\n",
      "Epoch 0010 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.54275\n",
      "Training loss = 0.2714421789993842\n",
      "Validation accuracy = 0.78125\n",
      "Validation loss = 0.22209664806723595\n",
      "Epoch 0011 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.5461363636363636\n",
      "Training loss = 0.2695762856417533\n",
      "Validation accuracy = 0.78125\n",
      "Validation loss = 0.2173963561654091\n",
      "Epoch 0012 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.5491666666666667\n",
      "Training loss = 0.26863993061706426\n",
      "Validation accuracy = 0.65625\n",
      "Validation loss = 0.24297989159822464\n",
      "Epoch 0013 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.5511538461538461\n",
      "Training loss = 0.2676239250695858\n",
      "Validation accuracy = 0.625\n",
      "Validation loss = 0.23251358978450298\n",
      "Epoch 0014 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.5535714285714286\n",
      "Training loss = 0.26650624132404727\n",
      "Validation accuracy = 0.75\n",
      "Validation loss = 0.2153610261157155\n",
      "Epoch 0015 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.5568888888888889\n",
      "Training loss = 0.265026823418008\n",
      "Validation accuracy = 0.78125\n",
      "Validation loss = 0.20791488513350487\n",
      "Epoch 0016 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.5581770833333334\n",
      "Training loss = 0.2643607884862771\n",
      "Validation accuracy = 0.625\n",
      "Validation loss = 0.22240658197551966\n",
      "Epoch 0017 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.5598039215686275\n",
      "Training loss = 0.2634672393196938\n",
      "Validation accuracy = 0.8125\n",
      "Validation loss = 0.21470732986927032\n",
      "Epoch 0018 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.5608333333333333\n",
      "Training loss = 0.26252783029719634\n",
      "Validation accuracy = 0.71875\n",
      "Validation loss = 0.20533722452819347\n",
      "Epoch 0019 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.5615789473684211\n",
      "Training loss = 0.26219435201402297\n",
      "Validation accuracy = 0.78125\n",
      "Validation loss = 0.21006616670638323\n",
      "Epoch 0020 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.5629166666666666\n",
      "Training loss = 0.2614178450430433\n",
      "Validation accuracy = 0.65625\n",
      "Validation loss = 0.2191038839519024\n",
      "Epoch 0021 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.5640873015873016\n",
      "Training loss = 0.2607244649245625\n",
      "Validation accuracy = 0.65625\n",
      "Validation loss = 0.23835625778883696\n",
      "Epoch 0022 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.5655681818181818\n",
      "Training loss = 0.2601315702227029\n",
      "Validation accuracy = 0.65625\n",
      "Validation loss = 0.23792111314833164\n",
      "Epoch 0023 / 0200\n",
      "=====================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/_classification.py:1221: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training accuracy = 0.5667391304347826\n",
      "Training loss = 0.25971875396975574\n",
      "Validation accuracy = 0.71875\n",
      "Validation loss = 0.2183009022846818\n",
      "Epoch 0024 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.5690625\n",
      "Training loss = 0.2587444078953316\n",
      "Validation accuracy = 0.6875\n",
      "Validation loss = 0.21478275582194328\n",
      "Epoch 0025 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.5700333333333333\n",
      "Training loss = 0.25808938186566033\n",
      "Validation accuracy = 0.8125\n",
      "Validation loss = 0.1934112273156643\n",
      "Epoch 0026 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.5707692307692308\n",
      "Training loss = 0.2575959433042086\n",
      "Validation accuracy = 0.59375\n",
      "Validation loss = 0.2074678037315607\n",
      "Epoch 0027 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.5717901234567901\n",
      "Training loss = 0.257104854122908\n",
      "Validation accuracy = 0.8125\n",
      "Validation loss = 0.20955860428512096\n",
      "Epoch 0028 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.5731845238095238\n",
      "Training loss = 0.25643857112509155\n",
      "Validation accuracy = 0.71875\n",
      "Validation loss = 0.22820205800235271\n",
      "Epoch 0029 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.5739080459770115\n",
      "Training loss = 0.2560648125949605\n",
      "Validation accuracy = 0.78125\n",
      "Validation loss = 0.1887628212571144\n",
      "Epoch 0030 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.5746111111111111\n",
      "Training loss = 0.2558157567712996\n",
      "Validation accuracy = 0.78125\n",
      "Validation loss = 0.19981728494167328\n",
      "Epoch 0031 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.5755913978494623\n",
      "Training loss = 0.25519256951187247\n",
      "Validation accuracy = 0.8125\n",
      "Validation loss = 0.19082760531455278\n",
      "Epoch 0032 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.576796875\n",
      "Training loss = 0.25477483397582545\n",
      "Validation accuracy = 0.71875\n",
      "Validation loss = 0.20381580013781786\n",
      "Epoch 0033 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.5777777777777777\n",
      "Training loss = 0.2540589653836055\n",
      "Validation accuracy = 0.40625\n",
      "Validation loss = 0.28960441052913666\n",
      "Epoch 0034 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.5788970588235294\n",
      "Training loss = 0.25362575516104696\n",
      "Validation accuracy = 0.75\n",
      "Validation loss = 0.20458966493606567\n",
      "Epoch 0035 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.5799285714285715\n",
      "Training loss = 0.253068027233084\n",
      "Validation accuracy = 0.71875\n",
      "Validation loss = 0.22373767755925655\n",
      "Epoch 0036 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.5802777777777778\n",
      "Training loss = 0.25283127101483166\n",
      "Validation accuracy = 0.6875\n",
      "Validation loss = 0.23495614528656006\n",
      "Epoch 0037 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.5811486486486487\n",
      "Training loss = 0.2523430454140311\n",
      "Validation accuracy = 0.75\n",
      "Validation loss = 0.21586098708212376\n",
      "Epoch 0038 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.5823903508771929\n",
      "Training loss = 0.2518282999908715\n",
      "Validation accuracy = 0.71875\n",
      "Validation loss = 0.19621768780052662\n",
      "Epoch 0039 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.583076923076923\n",
      "Training loss = 0.25130039031561624\n",
      "Validation accuracy = 0.78125\n",
      "Validation loss = 0.1985479975119233\n",
      "Epoch 0040 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.5836666666666667\n",
      "Training loss = 0.25102750783599914\n",
      "Validation accuracy = 0.65625\n",
      "Validation loss = 0.2482260363176465\n",
      "Epoch 0041 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.5844308943089431\n",
      "Training loss = 0.25068412315554733\n",
      "Validation accuracy = 0.6875\n",
      "Validation loss = 0.2293671853840351\n",
      "Epoch 0042 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.5856746031746032\n",
      "Training loss = 0.25010706316384057\n",
      "Validation accuracy = 0.65625\n",
      "Validation loss = 0.22713018022477627\n",
      "Epoch 0043 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.5864341085271317\n",
      "Training loss = 0.24966939977030883\n",
      "Validation accuracy = 0.75\n",
      "Validation loss = 0.2155899303033948\n",
      "Epoch 0044 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.5871780303030303\n",
      "Training loss = 0.24935459358222556\n",
      "Validation accuracy = 0.625\n",
      "Validation loss = 0.23197531048208475\n",
      "Epoch 0045 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.5879444444444445\n",
      "Training loss = 0.24906395356688235\n",
      "Validation accuracy = 0.78125\n",
      "Validation loss = 0.18606760818511248\n",
      "Epoch 0046 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.5892028985507246\n",
      "Training loss = 0.2485716975717873\n",
      "Validation accuracy = 0.75\n",
      "Validation loss = 0.21674115769565105\n",
      "Epoch 0047 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.5896808510638298\n",
      "Training loss = 0.24826353839261736\n",
      "Validation accuracy = 0.78125\n",
      "Validation loss = 0.18849918618798256\n",
      "Epoch 0048 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.5903125\n",
      "Training loss = 0.24799405303887195\n",
      "Validation accuracy = 0.71875\n",
      "Validation loss = 0.2107123089954257\n",
      "Epoch 0049 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.5910884353741497\n",
      "Training loss = 0.24762705683910927\n",
      "Validation accuracy = 0.65625\n",
      "Validation loss = 0.22144066262990236\n",
      "Epoch 0050 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.5916833333333333\n",
      "Training loss = 0.24739496049086254\n",
      "Validation accuracy = 0.625\n",
      "Validation loss = 0.2422431167215109\n",
      "Epoch 0051 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.5921895424836602\n",
      "Training loss = 0.24704951025204722\n",
      "Validation accuracy = 0.75\n",
      "Validation loss = 0.19908538274466991\n",
      "Epoch 0052 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.5925801282051282\n",
      "Training loss = 0.2468640614649615\n",
      "Validation accuracy = 0.6875\n",
      "Validation loss = 0.2064090445637703\n",
      "Epoch 0053 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.5931918238993711\n",
      "Training loss = 0.24652811036451058\n",
      "Validation accuracy = 0.625\n",
      "Validation loss = 0.21232858300209045\n",
      "Epoch 0054 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.5937037037037037\n",
      "Training loss = 0.24629339283033286\n",
      "Validation accuracy = 0.8125\n",
      "Validation loss = 0.16539413575083017\n",
      "Epoch 0055 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.5947727272727272\n",
      "Training loss = 0.2458598145707087\n",
      "Validation accuracy = 0.6875\n",
      "Validation loss = 0.22269983310252428\n",
      "Epoch 0056 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.5954017857142857\n",
      "Training loss = 0.24546664685188305\n",
      "Validation accuracy = 0.5625\n",
      "Validation loss = 0.23332585394382477\n",
      "Epoch 0057 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.5962280701754386\n",
      "Training loss = 0.2451087012063516\n",
      "Validation accuracy = 0.71875\n",
      "Validation loss = 0.21172386407852173\n",
      "Epoch 0058 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.596566091954023\n",
      "Training loss = 0.2448156049984625\n",
      "Validation accuracy = 0.5\n",
      "Validation loss = 0.2547172475606203\n",
      "Epoch 0059 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.597090395480226\n",
      "Training loss = 0.24443530025413143\n",
      "Validation accuracy = 0.5625\n",
      "Validation loss = 0.23888944927603006\n",
      "Epoch 0060 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.5974722222222222\n",
      "Training loss = 0.24421808037906886\n",
      "Validation accuracy = 0.75\n",
      "Validation loss = 0.20588676631450653\n",
      "Epoch 0061 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.5981284153005465\n",
      "Training loss = 0.2438562247560161\n",
      "Validation accuracy = 0.6875\n",
      "Validation loss = 0.2208450948819518\n",
      "Epoch 0062 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.5990860215053764\n",
      "Training loss = 0.24342637939719103\n",
      "Validation accuracy = 0.6875\n",
      "Validation loss = 0.239543741568923\n",
      "Epoch 0063 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.5994444444444444\n",
      "Training loss = 0.24322757324331967\n",
      "Validation accuracy = 0.59375\n",
      "Validation loss = 0.2603162042796612\n",
      "Epoch 0064 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.6000130208333333\n",
      "Training loss = 0.24302793568039002\n",
      "Validation accuracy = 0.6875\n",
      "Validation loss = 0.20585463475435972\n",
      "Epoch 0065 / 0200\n",
      "=====================================\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training accuracy = 0.6003974358974359\n",
      "Training loss = 0.2428652570209442\n",
      "Validation accuracy = 0.625\n",
      "Validation loss = 0.22943271324038506\n",
      "Epoch 0066 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.6011489898989899\n",
      "Training loss = 0.24254058078458213\n",
      "Validation accuracy = 0.75\n",
      "Validation loss = 0.19430801179260015\n",
      "Epoch 0067 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.6015671641791045\n",
      "Training loss = 0.24232118284116633\n",
      "Validation accuracy = 0.625\n",
      "Validation loss = 0.25053598172962666\n",
      "Epoch 0068 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.6018504901960784\n",
      "Training loss = 0.24220050083217667\n",
      "Validation accuracy = 0.65625\n",
      "Validation loss = 0.23201082926243544\n",
      "Epoch 0069 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.6021618357487922\n",
      "Training loss = 0.2419854357820634\n",
      "Validation accuracy = 0.59375\n",
      "Validation loss = 0.24559542909264565\n",
      "Epoch 0070 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.6027619047619047\n",
      "Training loss = 0.24172953707795766\n",
      "Validation accuracy = 0.75\n",
      "Validation loss = 0.2024843879044056\n",
      "Epoch 0071 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.6033450704225352\n",
      "Training loss = 0.2414359630429199\n",
      "Validation accuracy = 0.6875\n",
      "Validation loss = 0.2117926888167858\n",
      "Epoch 0072 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.6039467592592592\n",
      "Training loss = 0.24120762371509855\n",
      "Validation accuracy = 0.6875\n",
      "Validation loss = 0.2097185179591179\n",
      "Epoch 0073 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.6044178082191781\n",
      "Training loss = 0.2410221948340263\n",
      "Validation accuracy = 0.65625\n",
      "Validation loss = 0.23076758068054914\n",
      "Epoch 0074 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.605213963963964\n",
      "Training loss = 0.24078471431273732\n",
      "Validation accuracy = 0.78125\n",
      "Validation loss = 0.2001251857727766\n",
      "Epoch 0075 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.6056\n",
      "Training loss = 0.24062620279772415\n",
      "Validation accuracy = 0.71875\n",
      "Validation loss = 0.20006120204925537\n",
      "Epoch 0076 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.6058991228070175\n",
      "Training loss = 0.24044224078897714\n",
      "Validation accuracy = 0.625\n",
      "Validation loss = 0.2549276342615485\n",
      "Epoch 0077 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.6066125541125541\n",
      "Training loss = 0.24014857949938995\n",
      "Validation accuracy = 0.5625\n",
      "Validation loss = 0.2181425243616104\n",
      "Epoch 0078 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.6071260683760684\n",
      "Training loss = 0.2399148547125614\n",
      "Validation accuracy = 0.8125\n",
      "Validation loss = 0.17026224080473185\n",
      "Epoch 0079 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.6072995780590718\n",
      "Training loss = 0.23982870583402835\n",
      "Validation accuracy = 0.75\n",
      "Validation loss = 0.19826678186655045\n",
      "Epoch 0080 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.6075104166666667\n",
      "Training loss = 0.23966348800621926\n",
      "Validation accuracy = 0.4375\n",
      "Validation loss = 0.2833367995917797\n",
      "Epoch 0081 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.6081790123456791\n",
      "Training loss = 0.2393698289693015\n",
      "Validation accuracy = 0.78125\n",
      "Validation loss = 0.2117413878440857\n",
      "Epoch 0082 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.6085162601626016\n",
      "Training loss = 0.2391745680464598\n",
      "Validation accuracy = 0.6875\n",
      "Validation loss = 0.23787963204085827\n",
      "Epoch 0083 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.6089156626506024\n",
      "Training loss = 0.23904420053324546\n",
      "Validation accuracy = 0.6875\n",
      "Validation loss = 0.20821194257587194\n",
      "Epoch 0084 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.6093948412698412\n",
      "Training loss = 0.23885051982122518\n",
      "Validation accuracy = 0.75\n",
      "Validation loss = 0.19504963234066963\n",
      "Epoch 0085 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.6094313725490196\n",
      "Training loss = 0.23872203336188605\n",
      "Validation accuracy = 0.75\n",
      "Validation loss = 0.19117446430027485\n",
      "Epoch 0086 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.6097965116279069\n",
      "Training loss = 0.23858738705198201\n",
      "Validation accuracy = 0.6875\n",
      "Validation loss = 0.21238653268665075\n",
      "Epoch 0087 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.6103065134099617\n",
      "Training loss = 0.23835903958371088\n",
      "Validation accuracy = 0.65625\n",
      "Validation loss = 0.20603743474930525\n",
      "Epoch 0088 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.6105587121212122\n",
      "Training loss = 0.23824687356552618\n",
      "Validation accuracy = 0.53125\n",
      "Validation loss = 0.24665836058557034\n",
      "Epoch 0089 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.610749063670412\n",
      "Training loss = 0.23811505312525602\n",
      "Validation accuracy = 0.71875\n",
      "Validation loss = 0.20980140566825867\n",
      "Epoch 0090 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.6108981481481481\n",
      "Training loss = 0.23799307384341956\n",
      "Validation accuracy = 0.71875\n",
      "Validation loss = 0.18527162447571754\n",
      "Epoch 0091 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.6113553113553114\n",
      "Training loss = 0.23775885482492684\n",
      "Validation accuracy = 0.75\n",
      "Validation loss = 0.1917974790558219\n",
      "Epoch 0092 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.611875\n",
      "Training loss = 0.2375204468137868\n",
      "Validation accuracy = 0.6875\n",
      "Validation loss = 0.21423029154539108\n",
      "Epoch 0093 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.6123118279569892\n",
      "Training loss = 0.23737324468444326\n",
      "Validation accuracy = 0.5\n",
      "Validation loss = 0.22834458854049444\n",
      "Epoch 0094 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.612659574468085\n",
      "Training loss = 0.2372245988048983\n",
      "Validation accuracy = 0.75\n",
      "Validation loss = 0.19961651135236025\n",
      "Epoch 0095 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.6130175438596491\n",
      "Training loss = 0.23704096975138314\n",
      "Validation accuracy = 0.65625\n",
      "Validation loss = 0.22486868500709534\n",
      "Epoch 0096 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.6133854166666667\n",
      "Training loss = 0.2368270089596303\n",
      "Validation accuracy = 0.625\n",
      "Validation loss = 0.244009661488235\n",
      "Epoch 0097 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.6136340206185567\n",
      "Training loss = 0.2367612581991965\n",
      "Validation accuracy = 0.6875\n",
      "Validation loss = 0.2003790456801653\n",
      "Epoch 0098 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.6140816326530613\n",
      "Training loss = 0.23655963314253659\n",
      "Validation accuracy = 0.65625\n",
      "Validation loss = 0.20119111146777868\n",
      "Epoch 0099 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.614503367003367\n",
      "Training loss = 0.23642334514921562\n",
      "Validation accuracy = 0.71875\n",
      "Validation loss = 0.19495851173996925\n",
      "Epoch 0100 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.6145833333333334\n",
      "Training loss = 0.23633433775256077\n",
      "Validation accuracy = 0.6875\n",
      "Validation loss = 0.25018429197371006\n",
      "Epoch 0101 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.6149752475247525\n",
      "Training loss = 0.23618482109343653\n",
      "Validation accuracy = 0.71875\n",
      "Validation loss = 0.2035997100174427\n",
      "Epoch 0102 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.6153839869281046\n",
      "Training loss = 0.23598579800718167\n",
      "Validation accuracy = 0.625\n",
      "Validation loss = 0.22772367112338543\n",
      "Epoch 0103 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.615752427184466\n",
      "Training loss = 0.23579790572132495\n",
      "Validation accuracy = 0.71875\n",
      "Validation loss = 0.2144150175154209\n",
      "Epoch 0104 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.6160176282051282\n",
      "Training loss = 0.2356613269324104\n",
      "Validation accuracy = 0.625\n",
      "Validation loss = 0.23924081679433584\n",
      "Epoch 0105 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.616436507936508\n",
      "Training loss = 0.23546496641257453\n",
      "Validation accuracy = 0.71875\n",
      "Validation loss = 0.24355506151914597\n",
      "Epoch 0106 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.6168946540880503\n",
      "Training loss = 0.23529754443363574\n",
      "Validation accuracy = 0.71875\n",
      "Validation loss = 0.2071184879168868\n",
      "Epoch 0107 / 0200\n",
      "=====================================\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training accuracy = 0.6174454828660436\n",
      "Training loss = 0.2350649002387052\n",
      "Validation accuracy = 0.65625\n",
      "Validation loss = 0.23970327246934175\n",
      "Epoch 0108 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.6177700617283951\n",
      "Training loss = 0.23491608959979113\n",
      "Validation accuracy = 0.65625\n",
      "Validation loss = 0.21925323456525803\n",
      "Epoch 0109 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.6182798165137615\n",
      "Training loss = 0.23467299545007198\n",
      "Validation accuracy = 0.71875\n",
      "Validation loss = 0.22067006677389145\n",
      "Epoch 0110 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.6185378787878788\n",
      "Training loss = 0.23457711753610408\n",
      "Validation accuracy = 0.65625\n",
      "Validation loss = 0.22701749205589294\n",
      "Epoch 0111 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.6188438438438438\n",
      "Training loss = 0.23438264533855\n",
      "Validation accuracy = 0.6875\n",
      "Validation loss = 0.20150285586714745\n",
      "Epoch 0112 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.6190327380952381\n",
      "Training loss = 0.2342582108131388\n",
      "Validation accuracy = 0.71875\n",
      "Validation loss = 0.19362326245754957\n",
      "Epoch 0113 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.6193952802359882\n",
      "Training loss = 0.2340678193393798\n",
      "Validation accuracy = 0.625\n",
      "Validation loss = 0.2197276707738638\n",
      "Epoch 0114 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.6198611111111111\n",
      "Training loss = 0.2338694257435133\n",
      "Validation accuracy = 0.65625\n",
      "Validation loss = 0.2159035438671708\n",
      "Epoch 0115 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.6201014492753624\n",
      "Training loss = 0.23375561677642923\n",
      "Validation accuracy = 0.625\n",
      "Validation loss = 0.19795057084411383\n",
      "Epoch 0116 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.620632183908046\n",
      "Training loss = 0.23352048337748596\n",
      "Validation accuracy = 0.625\n",
      "Validation loss = 0.22917450685054064\n",
      "Epoch 0117 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.6210327635327635\n",
      "Training loss = 0.23333439992395816\n",
      "Validation accuracy = 0.75\n",
      "Validation loss = 0.18415740691125393\n",
      "Epoch 0118 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.6213771186440677\n",
      "Training loss = 0.2331646069815898\n",
      "Validation accuracy = 0.625\n",
      "Validation loss = 0.20601168274879456\n",
      "Epoch 0119 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.6217156862745098\n",
      "Training loss = 0.23297482925146318\n",
      "Validation accuracy = 0.65625\n",
      "Validation loss = 0.204056060872972\n",
      "Epoch 0120 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.6223055555555556\n",
      "Training loss = 0.23273966179653588\n",
      "Validation accuracy = 0.71875\n",
      "Validation loss = 0.194434461183846\n",
      "Epoch 0121 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.622568870523416\n",
      "Training loss = 0.23256599779802659\n",
      "Validation accuracy = 0.625\n",
      "Validation loss = 0.2391394730657339\n",
      "Epoch 0122 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.622834699453552\n",
      "Training loss = 0.23241548495346812\n",
      "Validation accuracy = 0.53125\n",
      "Validation loss = 0.25627022981643677\n",
      "Epoch 0123 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.622940379403794\n",
      "Training loss = 0.2323525512187179\n",
      "Validation accuracy = 0.6875\n",
      "Validation loss = 0.2209574282169342\n",
      "Epoch 0124 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.6233400537634408\n",
      "Training loss = 0.2321627169115449\n",
      "Validation accuracy = 0.625\n",
      "Validation loss = 0.21504239831119776\n",
      "Epoch 0125 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.6235733333333333\n",
      "Training loss = 0.23209681423674028\n",
      "Validation accuracy = 0.5625\n",
      "Validation loss = 0.23104929272085428\n",
      "Epoch 0126 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.6239021164021163\n",
      "Training loss = 0.23191232077452162\n",
      "Validation accuracy = 0.625\n",
      "Validation loss = 0.2076448891311884\n",
      "Epoch 0127 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.6243503937007874\n",
      "Training loss = 0.2317031792303904\n",
      "Validation accuracy = 0.75\n",
      "Validation loss = 0.17611151468008757\n",
      "Epoch 0128 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.6246484375\n",
      "Training loss = 0.23156268935951327\n",
      "Validation accuracy = 0.65625\n",
      "Validation loss = 0.21066186483949423\n",
      "Epoch 0129 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.6249289405684755\n",
      "Training loss = 0.23141993271961847\n",
      "Validation accuracy = 0.65625\n",
      "Validation loss = 0.2126943152397871\n",
      "Epoch 0130 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.6252307692307693\n",
      "Training loss = 0.23127507894849167\n",
      "Validation accuracy = 0.65625\n",
      "Validation loss = 0.23457090463489294\n",
      "Epoch 0131 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.6257506361323155\n",
      "Training loss = 0.23105446915419503\n",
      "Validation accuracy = 0.71875\n",
      "Validation loss = 0.20422443561255932\n",
      "Epoch 0132 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.6261616161616161\n",
      "Training loss = 0.23092218814643495\n",
      "Validation accuracy = 0.71875\n",
      "Validation loss = 0.19019312039017677\n",
      "Epoch 0133 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.6264598997493734\n",
      "Training loss = 0.23077547123604325\n",
      "Validation accuracy = 0.59375\n",
      "Validation loss = 0.23170038033276796\n",
      "Epoch 0134 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.6268967661691542\n",
      "Training loss = 0.23057350969071783\n",
      "Validation accuracy = 0.75\n",
      "Validation loss = 0.19662521872669458\n",
      "Epoch 0135 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.6271543209876543\n",
      "Training loss = 0.23046251363527995\n",
      "Validation accuracy = 0.75\n",
      "Validation loss = 0.18148995749652386\n",
      "Epoch 0136 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.6273835784313726\n",
      "Training loss = 0.23037604376153253\n",
      "Validation accuracy = 0.6875\n",
      "Validation loss = 0.2247436698526144\n",
      "Epoch 0137 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.6276155717761557\n",
      "Training loss = 0.2301469768845723\n",
      "Validation accuracy = 0.625\n",
      "Validation loss = 0.21479097660630941\n",
      "Epoch 0138 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.6280736714975845\n",
      "Training loss = 0.2299696871702186\n",
      "Validation accuracy = 0.8125\n",
      "Validation loss = 0.16148464754223824\n",
      "Epoch 0139 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.6283393285371702\n",
      "Training loss = 0.22987007174104881\n",
      "Validation accuracy = 0.5625\n",
      "Validation loss = 0.22597604058682919\n",
      "Epoch 0140 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.6286488095238095\n",
      "Training loss = 0.22970050362524178\n",
      "Validation accuracy = 0.625\n",
      "Validation loss = 0.25598713010549545\n",
      "Epoch 0141 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.6289479905437352\n",
      "Training loss = 0.2295492087354791\n",
      "Validation accuracy = 0.71875\n",
      "Validation loss = 0.1977740116417408\n",
      "Epoch 0142 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.6291960093896714\n",
      "Training loss = 0.22942786881997482\n",
      "Validation accuracy = 0.71875\n",
      "Validation loss = 0.16805019602179527\n",
      "Epoch 0143 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.6293356643356643\n",
      "Training loss = 0.22936448036573637\n",
      "Validation accuracy = 0.78125\n",
      "Validation loss = 0.169031267054379\n",
      "Epoch 0144 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.6296354166666667\n",
      "Training loss = 0.22918828574569758\n",
      "Validation accuracy = 0.65625\n",
      "Validation loss = 0.21553856134414673\n",
      "Epoch 0145 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.6299597701149425\n",
      "Training loss = 0.229024826644224\n",
      "Validation accuracy = 0.75\n",
      "Validation loss = 0.1912117898464203\n",
      "Epoch 0146 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.6303481735159817\n",
      "Training loss = 0.22883833954144764\n",
      "Validation accuracy = 0.5625\n",
      "Validation loss = 0.2761923037469387\n",
      "Epoch 0147 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.6305839002267574\n",
      "Training loss = 0.2287237343598419\n",
      "Validation accuracy = 0.5\n",
      "Validation loss = 0.2706508543342352\n",
      "Epoch 0148 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.6307826576576576\n",
      "Training loss = 0.22865026206810127\n",
      "Validation accuracy = 0.65625\n",
      "Validation loss = 0.2093154340982437\n",
      "Epoch 0149 / 0200\n",
      "=====================================\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training accuracy = 0.6312360178970917\n",
      "Training loss = 0.22848197932836392\n",
      "Validation accuracy = 0.59375\n",
      "Validation loss = 0.27684590965509415\n",
      "Epoch 0150 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.6314777777777778\n",
      "Training loss = 0.2283729760678278\n",
      "Validation accuracy = 0.65625\n",
      "Validation loss = 0.20373430289328098\n",
      "Epoch 0151 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.6317604856512141\n",
      "Training loss = 0.22825380888156938\n",
      "Validation accuracy = 0.6875\n",
      "Validation loss = 0.20147561561316252\n",
      "Epoch 0152 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.6320449561403508\n",
      "Training loss = 0.2281175786970804\n",
      "Validation accuracy = 0.6875\n",
      "Validation loss = 0.19561708346009254\n",
      "Epoch 0153 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.6323420479302833\n",
      "Training loss = 0.2279787205900664\n",
      "Validation accuracy = 0.59375\n",
      "Validation loss = 0.2769642509520054\n",
      "Epoch 0154 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.6326406926406927\n",
      "Training loss = 0.22782263297773092\n",
      "Validation accuracy = 0.4375\n",
      "Validation loss = 0.3175060208886862\n",
      "Epoch 0155 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.6328602150537634\n",
      "Training loss = 0.2277002872569106\n",
      "Validation accuracy = 0.65625\n",
      "Validation loss = 0.19858809560537338\n",
      "Epoch 0156 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.6332051282051282\n",
      "Training loss = 0.22753750399367995\n",
      "Validation accuracy = 0.65625\n",
      "Validation loss = 0.23254879005253315\n",
      "Epoch 0157 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.6333280254777071\n",
      "Training loss = 0.2274701332097632\n",
      "Validation accuracy = 0.65625\n",
      "Validation loss = 0.21755130775272846\n",
      "Epoch 0158 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.6335337552742616\n",
      "Training loss = 0.22734466513870324\n",
      "Validation accuracy = 0.65625\n",
      "Validation loss = 0.21205173898488283\n",
      "Epoch 0159 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.6337893081761006\n",
      "Training loss = 0.22720429862031336\n",
      "Validation accuracy = 0.625\n",
      "Validation loss = 0.22032432444393635\n",
      "Epoch 0160 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.63403125\n",
      "Training loss = 0.22708666612324305\n",
      "Validation accuracy = 0.78125\n",
      "Validation loss = 0.1840599337592721\n",
      "Epoch 0161 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.6342184265010352\n",
      "Training loss = 0.22698758552063017\n",
      "Validation accuracy = 0.6875\n",
      "Validation loss = 0.21950050629675388\n",
      "Epoch 0162 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.6344187242798354\n",
      "Training loss = 0.2269070752919364\n",
      "Validation accuracy = 0.71875\n",
      "Validation loss = 0.19038902688771486\n",
      "Epoch 0163 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.6346728016359918\n",
      "Training loss = 0.22679758236307368\n",
      "Validation accuracy = 0.6875\n",
      "Validation loss = 0.20300995837897062\n",
      "Epoch 0164 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.6348272357723578\n",
      "Training loss = 0.22671638969294122\n",
      "Validation accuracy = 0.6875\n",
      "Validation loss = 0.235894869081676\n",
      "Epoch 0165 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.6351060606060606\n",
      "Training loss = 0.22659044685274965\n",
      "Validation accuracy = 0.625\n",
      "Validation loss = 0.21779044158756733\n",
      "Epoch 0166 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.635421686746988\n",
      "Training loss = 0.22642623116116387\n",
      "Validation accuracy = 0.65625\n",
      "Validation loss = 0.22174732014536858\n",
      "Epoch 0167 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.6356037924151696\n",
      "Training loss = 0.2263209125209979\n",
      "Validation accuracy = 0.59375\n",
      "Validation loss = 0.22670450899749994\n",
      "Epoch 0168 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.6357043650793651\n",
      "Training loss = 0.22628321265084816\n",
      "Validation accuracy = 0.78125\n",
      "Validation loss = 0.16775787435472012\n",
      "Epoch 0169 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.635922090729783\n",
      "Training loss = 0.22618289776690143\n",
      "Validation accuracy = 0.625\n",
      "Validation loss = 0.23190092388540506\n",
      "Epoch 0170 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.6361862745098039\n",
      "Training loss = 0.2260919369964623\n",
      "Validation accuracy = 0.6875\n",
      "Validation loss = 0.20128033868968487\n",
      "Epoch 0171 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.636349902534113\n",
      "Training loss = 0.2259975983912659\n",
      "Validation accuracy = 0.65625\n",
      "Validation loss = 0.1985923359170556\n",
      "Epoch 0172 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.6365503875968992\n",
      "Training loss = 0.22590530038717413\n",
      "Validation accuracy = 0.8125\n",
      "Validation loss = 0.17698727268725634\n",
      "Epoch 0173 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.6367678227360308\n",
      "Training loss = 0.22579510662984642\n",
      "Validation accuracy = 0.5625\n",
      "Validation loss = 0.24665306322276592\n",
      "Epoch 0174 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.6370833333333333\n",
      "Training loss = 0.22569012657393098\n",
      "Validation accuracy = 0.59375\n",
      "Validation loss = 0.23950050864368677\n",
      "Epoch 0175 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.6373142857142857\n",
      "Training loss = 0.22560077610867363\n",
      "Validation accuracy = 0.625\n",
      "Validation loss = 0.21001942548900843\n",
      "Epoch 0176 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.6375047348484848\n",
      "Training loss = 0.2254772068300482\n",
      "Validation accuracy = 0.5625\n",
      "Validation loss = 0.24509768560528755\n",
      "Epoch 0177 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.63765065913371\n",
      "Training loss = 0.22541375152065143\n",
      "Validation accuracy = 0.65625\n",
      "Validation loss = 0.22619267646223307\n",
      "Epoch 0178 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.6378651685393258\n",
      "Training loss = 0.22531470440914123\n",
      "Validation accuracy = 0.6875\n",
      "Validation loss = 0.21010362915694714\n",
      "Epoch 0179 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.6380446927374301\n",
      "Training loss = 0.2252086701273252\n",
      "Validation accuracy = 0.6875\n",
      "Validation loss = 0.2036340031772852\n",
      "Epoch 0180 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.638287037037037\n",
      "Training loss = 0.2251071966131804\n",
      "Validation accuracy = 0.65625\n",
      "Validation loss = 0.21775846648961306\n",
      "Epoch 0181 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.6383609576427256\n",
      "Training loss = 0.22504677402503911\n",
      "Validation accuracy = 0.625\n",
      "Validation loss = 0.22075974009931087\n",
      "Epoch 0182 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.6386126373626374\n",
      "Training loss = 0.2249390791461636\n",
      "Validation accuracy = 0.65625\n",
      "Validation loss = 0.2012044358998537\n",
      "Epoch 0183 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.6387340619307832\n",
      "Training loss = 0.22487675751880057\n",
      "Validation accuracy = 0.625\n",
      "Validation loss = 0.24929506983608007\n",
      "Epoch 0184 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.6389673913043479\n",
      "Training loss = 0.22475823329930342\n",
      "Validation accuracy = 0.59375\n",
      "Validation loss = 0.23427945096045732\n",
      "Epoch 0185 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.6391981981981982\n",
      "Training loss = 0.22466306860872487\n",
      "Validation accuracy = 0.625\n",
      "Validation loss = 0.20726671442389488\n",
      "Epoch 0186 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.6393413978494623\n",
      "Training loss = 0.22460577212093819\n",
      "Validation accuracy = 0.6875\n",
      "Validation loss = 0.2063973294571042\n",
      "Epoch 0187 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.6396078431372549\n",
      "Training loss = 0.22449944273826006\n",
      "Validation accuracy = 0.625\n",
      "Validation loss = 0.18076829239726067\n",
      "Epoch 0188 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.639738475177305\n",
      "Training loss = 0.22439603894704568\n",
      "Validation accuracy = 0.65625\n",
      "Validation loss = 0.2223040945827961\n",
      "Epoch 0189 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.6397663139329806\n",
      "Training loss = 0.2243788103470858\n",
      "Validation accuracy = 0.625\n",
      "Validation loss = 0.21253050211817026\n",
      "Epoch 0190 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.6397763157894737\n",
      "Training loss = 0.2243164940423479\n",
      "Validation accuracy = 0.65625\n",
      "Validation loss = 0.21993313170969486\n",
      "Epoch 0191 / 0200\n",
      "=====================================\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training accuracy = 0.6399432809773123\n",
      "Training loss = 0.22423143517720084\n",
      "Validation accuracy = 0.625\n",
      "Validation loss = 0.20635160896927118\n",
      "Epoch 0192 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.6401432291666667\n",
      "Training loss = 0.2241317444521701\n",
      "Validation accuracy = 0.71875\n",
      "Validation loss = 0.2134783249348402\n",
      "Epoch 0193 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.640332469775475\n",
      "Training loss = 0.22402291151686912\n",
      "Validation accuracy = 0.78125\n",
      "Validation loss = 0.18270087521523237\n",
      "Epoch 0194 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.6403865979381443\n",
      "Training loss = 0.2239531399582311\n",
      "Validation accuracy = 0.8125\n",
      "Validation loss = 0.17794830352067947\n",
      "Epoch 0195 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.6405042735042735\n",
      "Training loss = 0.223863497268313\n",
      "Validation accuracy = 0.78125\n",
      "Validation loss = 0.17813103273510933\n",
      "Epoch 0196 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.6406675170068027\n",
      "Training loss = 0.22379220600449004\n",
      "Validation accuracy = 0.8125\n",
      "Validation loss = 0.1673043593764305\n",
      "Epoch 0197 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.6407656514382403\n",
      "Training loss = 0.22375292793433174\n",
      "Validation accuracy = 0.75\n",
      "Validation loss = 0.18470671866089106\n",
      "Epoch 0198 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.6409090909090909\n",
      "Training loss = 0.22367930060296448\n",
      "Validation accuracy = 0.75\n",
      "Validation loss = 0.18702766578644514\n",
      "Epoch 0199 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.64107202680067\n",
      "Training loss = 0.223601574634063\n",
      "Validation accuracy = 0.75\n",
      "Validation loss = 0.1866591265425086\n",
      "Epoch 0200 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.641275\n",
      "Training loss = 0.2235161112781614\n",
      "Validation accuracy = 0.59375\n",
      "Validation loss = 0.27166791167110205\n",
      "Making model for session group 20210310_15:29:41.711-20210319_16:15:55.217\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/imblearn/utils/_validation.py:326: UserWarning: After over-sampling, the number of samples (300) in class car will be larger than the number of samples in the majority class (class #signpost -> 160)\n",
      "  n_samples_majority,\n",
      "/usr/local/lib/python3.6/dist-packages/imblearn/utils/_validation.py:326: UserWarning: After over-sampling, the number of samples (300) in class signpost will be larger than the number of samples in the majority class (class #signpost -> 160)\n",
      "  n_samples_majority,\n",
      "/usr/local/lib/python3.6/dist-packages/imblearn/utils/_validation.py:326: UserWarning: After over-sampling, the number of samples (300) in class tree will be larger than the number of samples in the majority class (class #signpost -> 160)\n",
      "  n_samples_majority,\n",
      "/usr/local/lib/python3.6/dist-packages/imblearn/utils/_validation.py:326: UserWarning: After over-sampling, the number of samples (300) in class wall will be larger than the number of samples in the majority class (class #signpost -> 160)\n",
      "  n_samples_majority,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0001 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.44916666666666666\n",
      "Training loss = 0.30475096811850866\n",
      "Validation accuracy = 0.53125\n",
      "Validation loss = 0.31788886338472366\n",
      "Epoch 0002 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.47875\n",
      "Training loss = 0.2974663010487954\n",
      "Validation accuracy = 0.4375\n",
      "Validation loss = 0.3262736573815346\n",
      "Epoch 0003 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.49416666666666664\n",
      "Training loss = 0.28999370930923357\n",
      "Validation accuracy = 0.40625\n",
      "Validation loss = 0.32176445983350277\n",
      "Epoch 0004 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.5120833333333333\n",
      "Training loss = 0.28419531520456076\n",
      "Validation accuracy = 0.4375\n",
      "Validation loss = 0.3190681841224432\n",
      "Epoch 0005 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.5245\n",
      "Training loss = 0.28065387610594433\n",
      "Validation accuracy = 0.40625\n",
      "Validation loss = 0.31736747175455093\n",
      "Epoch 0006 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.5347222222222222\n",
      "Training loss = 0.276630078976353\n",
      "Validation accuracy = 0.375\n",
      "Validation loss = 0.3246142100542784\n",
      "Epoch 0007 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.5414285714285715\n",
      "Training loss = 0.2738378262661752\n",
      "Validation accuracy = 0.375\n",
      "Validation loss = 0.33231242559850216\n",
      "Epoch 0008 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.5470833333333334\n",
      "Training loss = 0.2709644939626257\n",
      "Validation accuracy = 0.53125\n",
      "Validation loss = 0.31857313960790634\n",
      "Epoch 0009 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.5496296296296296\n",
      "Training loss = 0.26925863020673946\n",
      "Validation accuracy = 0.375\n",
      "Validation loss = 0.36431561037898064\n",
      "Epoch 0010 / 0200\n",
      "=====================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/_classification.py:1221: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training accuracy = 0.5529166666666666\n",
      "Training loss = 0.2672119271482031\n",
      "Validation accuracy = 0.40625\n",
      "Validation loss = 0.33132570050656796\n",
      "Epoch 0011 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.5562121212121212\n",
      "Training loss = 0.26553550795849523\n",
      "Validation accuracy = 0.46875\n",
      "Validation loss = 0.31189753487706184\n",
      "Epoch 0012 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.5570138888888889\n",
      "Training loss = 0.26481412866670223\n",
      "Validation accuracy = 0.53125\n",
      "Validation loss = 0.3366143945604563\n",
      "Epoch 0013 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.5589102564102564\n",
      "Training loss = 0.2640218411061244\n",
      "Validation accuracy = 0.59375\n",
      "Validation loss = 0.33501181192696095\n",
      "Epoch 0014 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.562202380952381\n",
      "Training loss = 0.26271268221416644\n",
      "Validation accuracy = 0.53125\n",
      "Validation loss = 0.32747264206409454\n",
      "Epoch 0015 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.5647222222222222\n",
      "Training loss = 0.26173189036879274\n",
      "Validation accuracy = 0.46875\n",
      "Validation loss = 0.3126673027873039\n",
      "Epoch 0016 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.56640625\n",
      "Training loss = 0.2605827610877653\n",
      "Validation accuracy = 0.40625\n",
      "Validation loss = 0.3168336171656847\n",
      "Epoch 0017 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.5676960784313726\n",
      "Training loss = 0.2593936383344379\n",
      "Validation accuracy = 0.5625\n",
      "Validation loss = 0.31491386517882347\n",
      "Epoch 0018 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.5697222222222222\n",
      "Training loss = 0.25836274976945584\n",
      "Validation accuracy = 0.5625\n",
      "Validation loss = 0.3242900352925062\n",
      "Epoch 0019 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.5715350877192983\n",
      "Training loss = 0.2574452499796947\n",
      "Validation accuracy = 0.4375\n",
      "Validation loss = 0.32870555482804775\n",
      "Epoch 0020 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.5735\n",
      "Training loss = 0.25660615823417904\n",
      "Validation accuracy = 0.21875\n",
      "Validation loss = 0.32102464511990547\n",
      "Epoch 0021 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.5750396825396825\n",
      "Training loss = 0.2558347142842554\n",
      "Validation accuracy = 0.3125\n",
      "Validation loss = 0.3319459352642298\n",
      "Epoch 0022 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.5759090909090909\n",
      "Training loss = 0.25507477925695254\n",
      "Validation accuracy = 0.375\n",
      "Validation loss = 0.3386388495564461\n",
      "Epoch 0023 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.5782971014492754\n",
      "Training loss = 0.2542764642899451\n",
      "Validation accuracy = 0.28125\n",
      "Validation loss = 0.3141451831907034\n",
      "Epoch 0024 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.5800347222222222\n",
      "Training loss = 0.25339679149393407\n",
      "Validation accuracy = 0.53125\n",
      "Validation loss = 0.3273437526077032\n",
      "Epoch 0025 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.5812\n",
      "Training loss = 0.2528158810724815\n",
      "Validation accuracy = 0.59375\n",
      "Validation loss = 0.3119157738983631\n",
      "Epoch 0026 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.5820192307692308\n",
      "Training loss = 0.2525146644037121\n",
      "Validation accuracy = 0.5\n",
      "Validation loss = 0.3158750906586647\n",
      "Epoch 0027 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.5825617283950617\n",
      "Training loss = 0.2523907433900936\n",
      "Validation accuracy = 0.40625\n",
      "Validation loss = 0.3299146853387356\n",
      "Epoch 0028 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.5832738095238095\n",
      "Training loss = 0.2520671421706322\n",
      "Validation accuracy = 0.53125\n",
      "Validation loss = 0.3162200041115284\n",
      "Epoch 0029 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.5836206896551724\n",
      "Training loss = 0.2516588419598752\n",
      "Validation accuracy = 0.3125\n",
      "Validation loss = 0.3365862499922514\n",
      "Epoch 0030 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.5844166666666667\n",
      "Training loss = 0.2515002398979333\n",
      "Validation accuracy = 0.40625\n",
      "Validation loss = 0.32484953105449677\n",
      "Epoch 0031 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.5855107526881721\n",
      "Training loss = 0.2509357378607796\n",
      "Validation accuracy = 0.3125\n",
      "Validation loss = 0.3423354309052229\n",
      "Epoch 0032 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.5871614583333333\n",
      "Training loss = 0.2503443614183925\n",
      "Validation accuracy = 0.46875\n",
      "Validation loss = 0.3301303628832102\n",
      "Epoch 0033 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.5873737373737373\n",
      "Training loss = 0.25000816181151553\n",
      "Validation accuracy = 0.4375\n",
      "Validation loss = 0.31658521853387356\n",
      "Epoch 0034 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.587843137254902\n",
      "Training loss = 0.24960639668811185\n",
      "Validation accuracy = 0.375\n",
      "Validation loss = 0.3262985274195671\n",
      "Epoch 0035 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.5881428571428572\n",
      "Training loss = 0.2495115247191418\n",
      "Validation accuracy = 0.53125\n",
      "Validation loss = 0.31395973451435566\n",
      "Epoch 0036 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.5884722222222222\n",
      "Training loss = 0.24922749645594094\n",
      "Validation accuracy = 0.5\n",
      "Validation loss = 0.3223865795880556\n",
      "Epoch 0037 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.5893243243243244\n",
      "Training loss = 0.24881164648444265\n",
      "Validation accuracy = 0.3125\n",
      "Validation loss = 0.3761896574869752\n",
      "Epoch 0038 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.5901096491228071\n",
      "Training loss = 0.2483925635707483\n",
      "Validation accuracy = 0.34375\n",
      "Validation loss = 0.31866579689085484\n",
      "Epoch 0039 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.591068376068376\n",
      "Training loss = 0.24786067681371146\n",
      "Validation accuracy = 0.53125\n",
      "Validation loss = 0.2959908898919821\n",
      "Epoch 0040 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.5916041666666667\n",
      "Training loss = 0.24758958325659236\n",
      "Validation accuracy = 0.46875\n",
      "Validation loss = 0.316036781296134\n",
      "Epoch 0041 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.5919308943089431\n",
      "Training loss = 0.24733542459282448\n",
      "Validation accuracy = 0.53125\n",
      "Validation loss = 0.32582426257431507\n",
      "Epoch 0042 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.5926785714285714\n",
      "Training loss = 0.24688942231947467\n",
      "Validation accuracy = 0.3125\n",
      "Validation loss = 0.3396267928183079\n",
      "Epoch 0043 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.592984496124031\n",
      "Training loss = 0.24666187663295472\n",
      "Validation accuracy = 0.28125\n",
      "Validation loss = 0.3539698701351881\n",
      "Epoch 0044 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.5933522727272728\n",
      "Training loss = 0.24655843279183362\n",
      "Validation accuracy = 0.3125\n",
      "Validation loss = 0.33863797038793564\n",
      "Epoch 0045 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.5942592592592593\n",
      "Training loss = 0.24632320089472665\n",
      "Validation accuracy = 0.40625\n",
      "Validation loss = 0.33457198552787304\n",
      "Epoch 0046 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.5947826086956521\n",
      "Training loss = 0.24603620179753372\n",
      "Validation accuracy = 0.28125\n",
      "Validation loss = 0.3545903591439128\n",
      "Epoch 0047 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.5957624113475177\n",
      "Training loss = 0.24556403891256093\n",
      "Validation accuracy = 0.5\n",
      "Validation loss = 0.32730927877128124\n",
      "Epoch 0048 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.5962152777777778\n",
      "Training loss = 0.24525975834216096\n",
      "Validation accuracy = 0.5625\n",
      "Validation loss = 0.30855004489421844\n",
      "Epoch 0049 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.5966156462585034\n",
      "Training loss = 0.2448798998845678\n",
      "Validation accuracy = 0.4375\n",
      "Validation loss = 0.3072842247784138\n",
      "Epoch 0050 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.5974\n",
      "Training loss = 0.24445289539595444\n",
      "Validation accuracy = 0.3125\n",
      "Validation loss = 0.3356170542538166\n",
      "Epoch 0051 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.5982352941176471\n",
      "Training loss = 0.24406045256340816\n",
      "Validation accuracy = 0.3125\n",
      "Validation loss = 0.3440413735806942\n",
      "Epoch 0052 / 0200\n",
      "=====================================\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training accuracy = 0.598173076923077\n",
      "Training loss = 0.24386907951237682\n",
      "Validation accuracy = 0.3125\n",
      "Validation loss = 0.35144615545868874\n",
      "Epoch 0053 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.5985691823899371\n",
      "Training loss = 0.24356780995644114\n",
      "Validation accuracy = 0.40625\n",
      "Validation loss = 0.3239396996796131\n",
      "Epoch 0054 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.5992438271604938\n",
      "Training loss = 0.24317050434373044\n",
      "Validation accuracy = 0.5625\n",
      "Validation loss = 0.32235290855169296\n",
      "Epoch 0055 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.5999696969696969\n",
      "Training loss = 0.24281555524829662\n",
      "Validation accuracy = 0.53125\n",
      "Validation loss = 0.311253072693944\n",
      "Epoch 0056 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.6008779761904762\n",
      "Training loss = 0.2423853705322281\n",
      "Validation accuracy = 0.46875\n",
      "Validation loss = 0.30755344964563847\n",
      "Epoch 0057 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.6016959064327485\n",
      "Training loss = 0.2419328610529328\n",
      "Validation accuracy = 0.5\n",
      "Validation loss = 0.2994522899389267\n",
      "Epoch 0058 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.6019971264367816\n",
      "Training loss = 0.2416746751531616\n",
      "Validation accuracy = 0.3125\n",
      "Validation loss = 0.34106961265206337\n",
      "Epoch 0059 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.6021610169491526\n",
      "Training loss = 0.2414386557825541\n",
      "Validation accuracy = 0.5625\n",
      "Validation loss = 0.31103046610951424\n",
      "Epoch 0060 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.6024166666666667\n",
      "Training loss = 0.24129102765975727\n",
      "Validation accuracy = 0.34375\n",
      "Validation loss = 0.32992691174149513\n",
      "Epoch 0061 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.6028005464480874\n",
      "Training loss = 0.241035826866174\n",
      "Validation accuracy = 0.46875\n",
      "Validation loss = 0.31717985682189465\n",
      "Epoch 0062 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.6032661290322581\n",
      "Training loss = 0.2408773354897576\n",
      "Validation accuracy = 0.40625\n",
      "Validation loss = 0.3358616288751364\n",
      "Epoch 0063 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.6034920634920635\n",
      "Training loss = 0.24070561934637014\n",
      "Validation accuracy = 0.40625\n",
      "Validation loss = 0.3465911876410246\n",
      "Epoch 0064 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.6039713541666667\n",
      "Training loss = 0.24047706376373146\n",
      "Validation accuracy = 0.5\n",
      "Validation loss = 0.332037840038538\n",
      "Epoch 0065 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.6040641025641026\n",
      "Training loss = 0.24035157067194962\n",
      "Validation accuracy = 0.375\n",
      "Validation loss = 0.3549158591777086\n",
      "Epoch 0066 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.6042045454545455\n",
      "Training loss = 0.24027451003779365\n",
      "Validation accuracy = 0.5\n",
      "Validation loss = 0.312081890180707\n",
      "Epoch 0067 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.6042288557213931\n",
      "Training loss = 0.2401653100457506\n",
      "Validation accuracy = 0.40625\n",
      "Validation loss = 0.362115103751421\n",
      "Epoch 0068 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.6043627450980392\n",
      "Training loss = 0.24008249793786043\n",
      "Validation accuracy = 0.5625\n",
      "Validation loss = 0.30398040264844894\n",
      "Epoch 0069 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.6047101449275363\n",
      "Training loss = 0.23995909380200117\n",
      "Validation accuracy = 0.40625\n",
      "Validation loss = 0.33416682854294777\n",
      "Epoch 0070 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.6050714285714286\n",
      "Training loss = 0.2396839461734607\n",
      "Validation accuracy = 0.46875\n",
      "Validation loss = 0.33204831555485725\n",
      "Epoch 0071 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.605093896713615\n",
      "Training loss = 0.23960142167451237\n",
      "Validation accuracy = 0.46875\n",
      "Validation loss = 0.3337141554802656\n",
      "Epoch 0072 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.6052199074074074\n",
      "Training loss = 0.23944794995503293\n",
      "Validation accuracy = 0.375\n",
      "Validation loss = 0.3325427733361721\n",
      "Epoch 0073 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.6058105022831051\n",
      "Training loss = 0.23921472844603944\n",
      "Validation accuracy = 0.5\n",
      "Validation loss = 0.3218125235289335\n",
      "Epoch 0074 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.6063738738738739\n",
      "Training loss = 0.23905957837261863\n",
      "Validation accuracy = 0.53125\n",
      "Validation loss = 0.3168888371437788\n",
      "Epoch 0075 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.6068555555555556\n",
      "Training loss = 0.23879637868901094\n",
      "Validation accuracy = 0.34375\n",
      "Validation loss = 0.3276319392025471\n",
      "Epoch 0076 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.6072258771929825\n",
      "Training loss = 0.23856321660115531\n",
      "Validation accuracy = 0.3125\n",
      "Validation loss = 0.37821992114186287\n",
      "Epoch 0077 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.6075108225108226\n",
      "Training loss = 0.2384374219401703\n",
      "Validation accuracy = 0.28125\n",
      "Validation loss = 0.3366988003253937\n",
      "Epoch 0078 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.6076388888888888\n",
      "Training loss = 0.2382836467311041\n",
      "Validation accuracy = 0.3125\n",
      "Validation loss = 0.337817857041955\n",
      "Epoch 0079 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.6080379746835443\n",
      "Training loss = 0.23813930196098135\n",
      "Validation accuracy = 0.53125\n",
      "Validation loss = 0.31081120669841766\n",
      "Epoch 0080 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.6082291666666667\n",
      "Training loss = 0.23798138365056365\n",
      "Validation accuracy = 0.375\n",
      "Validation loss = 0.3084747977554798\n",
      "Epoch 0081 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.6085493827160494\n",
      "Training loss = 0.2377743504552071\n",
      "Validation accuracy = 0.3125\n",
      "Validation loss = 0.40159517899155617\n",
      "Epoch 0082 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.6088821138211382\n",
      "Training loss = 0.23761889155651253\n",
      "Validation accuracy = 0.46875\n",
      "Validation loss = 0.3242619000375271\n",
      "Epoch 0083 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.6092068273092369\n",
      "Training loss = 0.23748207793836612\n",
      "Validation accuracy = 0.40625\n",
      "Validation loss = 0.34115096367895603\n",
      "Epoch 0084 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.6095238095238096\n",
      "Training loss = 0.23729590246719973\n",
      "Validation accuracy = 0.40625\n",
      "Validation loss = 0.34947853349149227\n",
      "Epoch 0085 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.6100588235294118\n",
      "Training loss = 0.23706814882831245\n",
      "Validation accuracy = 0.46875\n",
      "Validation loss = 0.3042068723589182\n",
      "Epoch 0086 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.6102616279069767\n",
      "Training loss = 0.23702177589109472\n",
      "Validation accuracy = 0.3125\n",
      "Validation loss = 0.33936254121363163\n",
      "Epoch 0087 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.6106609195402298\n",
      "Training loss = 0.23680124297024419\n",
      "Validation accuracy = 0.4375\n",
      "Validation loss = 0.32704664021730423\n",
      "Epoch 0088 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.6109469696969697\n",
      "Training loss = 0.23668760113192328\n",
      "Validation accuracy = 0.53125\n",
      "Validation loss = 0.29931467212736607\n",
      "Epoch 0089 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.6111048689138576\n",
      "Training loss = 0.23663471798660157\n",
      "Validation accuracy = 0.53125\n",
      "Validation loss = 0.30746801011264324\n",
      "Epoch 0090 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.6114722222222222\n",
      "Training loss = 0.23644297582352602\n",
      "Validation accuracy = 0.59375\n",
      "Validation loss = 0.3141695652157068\n",
      "Epoch 0091 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.6116849816849816\n",
      "Training loss = 0.2363576349152095\n",
      "Validation accuracy = 0.4375\n",
      "Validation loss = 0.315503666177392\n",
      "Epoch 0092 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.6121105072463768\n",
      "Training loss = 0.2361877270191368\n",
      "Validation accuracy = 0.3125\n",
      "Validation loss = 0.3350231219083071\n",
      "Epoch 0093 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.6124014336917563\n",
      "Training loss = 0.23602325776651983\n",
      "Validation accuracy = 0.28125\n",
      "Validation loss = 0.3370685465633869\n",
      "Epoch 0094 / 0200\n",
      "=====================================\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training accuracy = 0.6128191489361702\n",
      "Training loss = 0.23586069266978943\n",
      "Validation accuracy = 0.34375\n",
      "Validation loss = 0.34447994641959667\n",
      "Epoch 0095 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.6130175438596491\n",
      "Training loss = 0.2357585050939468\n",
      "Validation accuracy = 0.4375\n",
      "Validation loss = 0.30983137153089046\n",
      "Epoch 0096 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.6133680555555555\n",
      "Training loss = 0.2356130766475366\n",
      "Validation accuracy = 0.3125\n",
      "Validation loss = 0.3319494314491749\n",
      "Epoch 0097 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.613754295532646\n",
      "Training loss = 0.23545993218998523\n",
      "Validation accuracy = 0.46875\n",
      "Validation loss = 0.31763308495283127\n",
      "Epoch 0098 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.6140901360544218\n",
      "Training loss = 0.23526889655536332\n",
      "Validation accuracy = 0.46875\n",
      "Validation loss = 0.33281307481229305\n",
      "Epoch 0099 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.6143265993265993\n",
      "Training loss = 0.23511928097442145\n",
      "Validation accuracy = 0.40625\n",
      "Validation loss = 0.33075702749192715\n",
      "Epoch 0100 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.6148166666666667\n",
      "Training loss = 0.23491614942848682\n",
      "Validation accuracy = 0.3125\n",
      "Validation loss = 0.3849561233073473\n",
      "Epoch 0101 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.614983498349835\n",
      "Training loss = 0.23481053125100954\n",
      "Validation accuracy = 0.46875\n",
      "Validation loss = 0.3139344844967127\n",
      "Epoch 0102 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.6155882352941177\n",
      "Training loss = 0.23455765895228955\n",
      "Validation accuracy = 0.3125\n",
      "Validation loss = 0.36373175866901875\n",
      "Epoch 0103 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.6157928802588997\n",
      "Training loss = 0.2344104110165032\n",
      "Validation accuracy = 0.5\n",
      "Validation loss = 0.3061804324388504\n",
      "Epoch 0104 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.6160496794871795\n",
      "Training loss = 0.23425088674761355\n",
      "Validation accuracy = 0.3125\n",
      "Validation loss = 0.34555006958544254\n",
      "Epoch 0105 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.6163650793650793\n",
      "Training loss = 0.23410593145115982\n",
      "Validation accuracy = 0.34375\n",
      "Validation loss = 0.35243402794003487\n",
      "Epoch 0106 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.6164858490566038\n",
      "Training loss = 0.23403597566949308\n",
      "Validation accuracy = 0.40625\n",
      "Validation loss = 0.31382024846971035\n",
      "Epoch 0107 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.616721183800623\n",
      "Training loss = 0.23390202124518955\n",
      "Validation accuracy = 0.375\n",
      "Validation loss = 0.3394255302846432\n",
      "Epoch 0108 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.6169907407407408\n",
      "Training loss = 0.23375421195325477\n",
      "Validation accuracy = 0.5\n",
      "Validation loss = 0.29457286559045315\n",
      "Epoch 0109 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.6172706422018348\n",
      "Training loss = 0.2336680678626813\n",
      "Validation accuracy = 0.5\n",
      "Validation loss = 0.33049213513731956\n",
      "Epoch 0110 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.6176818181818182\n",
      "Training loss = 0.2334881125997865\n",
      "Validation accuracy = 0.3125\n",
      "Validation loss = 0.3332342002540827\n",
      "Epoch 0111 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.618018018018018\n",
      "Training loss = 0.23330205480280045\n",
      "Validation accuracy = 0.46875\n",
      "Validation loss = 0.30273607559502125\n",
      "Epoch 0112 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.6184226190476191\n",
      "Training loss = 0.23315724136396532\n",
      "Validation accuracy = 0.46875\n",
      "Validation loss = 0.3128088228404522\n",
      "Epoch 0113 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.6185324483775811\n",
      "Training loss = 0.23306513477545396\n",
      "Validation accuracy = 0.40625\n",
      "Validation loss = 0.30386870354413986\n",
      "Epoch 0114 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.6187865497076024\n",
      "Training loss = 0.23293953130206865\n",
      "Validation accuracy = 0.46875\n",
      "Validation loss = 0.30933588929474354\n",
      "Epoch 0115 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.6191884057971014\n",
      "Training loss = 0.23278206646161667\n",
      "Validation accuracy = 0.375\n",
      "Validation loss = 0.3355929870158434\n",
      "Epoch 0116 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.6195114942528736\n",
      "Training loss = 0.23262556473499743\n",
      "Validation accuracy = 0.53125\n",
      "Validation loss = 0.31281297840178013\n",
      "Epoch 0117 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.6198433048433049\n",
      "Training loss = 0.23249559138553944\n",
      "Validation accuracy = 0.28125\n",
      "Validation loss = 0.3215370364487171\n",
      "Epoch 0118 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.6198587570621469\n",
      "Training loss = 0.23245729516560243\n",
      "Validation accuracy = 0.28125\n",
      "Validation loss = 0.3880513524636626\n",
      "Epoch 0119 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.620189075630252\n",
      "Training loss = 0.23230091599585798\n",
      "Validation accuracy = 0.4375\n",
      "Validation loss = 0.3095661662518978\n",
      "Epoch 0120 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.6206458333333333\n",
      "Training loss = 0.23214151060436336\n",
      "Validation accuracy = 0.34375\n",
      "Validation loss = 0.37813823390752077\n",
      "Epoch 0121 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.6207438016528926\n",
      "Training loss = 0.23206549789171574\n",
      "Validation accuracy = 0.46875\n",
      "Validation loss = 0.308579633012414\n",
      "Epoch 0122 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.6210860655737704\n",
      "Training loss = 0.23188575088468893\n",
      "Validation accuracy = 0.375\n",
      "Validation loss = 0.32501672953367233\n",
      "Epoch 0123 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.6213346883468834\n",
      "Training loss = 0.23173100394002466\n",
      "Validation accuracy = 0.5\n",
      "Validation loss = 0.30721672624349594\n",
      "Epoch 0124 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.6217204301075269\n",
      "Training loss = 0.23161461437781972\n",
      "Validation accuracy = 0.5\n",
      "Validation loss = 0.3025312162935734\n",
      "Epoch 0125 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.6220133333333333\n",
      "Training loss = 0.23153958468894165\n",
      "Validation accuracy = 0.375\n",
      "Validation loss = 0.3280099667608738\n",
      "Epoch 0126 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.6223875661375662\n",
      "Training loss = 0.23137575738762736\n",
      "Validation accuracy = 0.40625\n",
      "Validation loss = 0.34183075092732906\n",
      "Epoch 0127 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.6226706036745406\n",
      "Training loss = 0.23118995217141985\n",
      "Validation accuracy = 0.3125\n",
      "Validation loss = 0.38170343916863203\n",
      "Epoch 0128 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.62294921875\n",
      "Training loss = 0.23109428201549842\n",
      "Validation accuracy = 0.46875\n",
      "Validation loss = 0.31922355107963085\n",
      "Epoch 0129 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.6232881136950904\n",
      "Training loss = 0.23101247472741498\n",
      "Validation accuracy = 0.25\n",
      "Validation loss = 0.3764976402744651\n",
      "Epoch 0130 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.6235897435897436\n",
      "Training loss = 0.23083010846128066\n",
      "Validation accuracy = 0.46875\n",
      "Validation loss = 0.32541864179074764\n",
      "Epoch 0131 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.6238040712468194\n",
      "Training loss = 0.2307476278902541\n",
      "Validation accuracy = 0.34375\n",
      "Validation loss = 0.3155520223081112\n",
      "Epoch 0132 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.6241161616161616\n",
      "Training loss = 0.23059065844299215\n",
      "Validation accuracy = 0.46875\n",
      "Validation loss = 0.3228165991604328\n",
      "Epoch 0133 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.6244172932330827\n",
      "Training loss = 0.23046095326337449\n",
      "Validation accuracy = 0.34375\n",
      "Validation loss = 0.33379522152245045\n",
      "Epoch 0134 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.6245273631840796\n",
      "Training loss = 0.230363028778032\n",
      "Validation accuracy = 0.5\n",
      "Validation loss = 0.3024750743061304\n",
      "Epoch 0135 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.6248333333333334\n",
      "Training loss = 0.23026858634593678\n",
      "Validation accuracy = 0.5\n",
      "Validation loss = 0.31676591001451015\n",
      "Epoch 0136 / 0200\n",
      "=====================================\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training accuracy = 0.6250122549019608\n",
      "Training loss = 0.23014117491623276\n",
      "Validation accuracy = 0.375\n",
      "Validation loss = 0.3343074284493923\n",
      "Epoch 0137 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.6253102189781022\n",
      "Training loss = 0.23003577191292007\n",
      "Validation accuracy = 0.375\n",
      "Validation loss = 0.3406093455851078\n",
      "Epoch 0138 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.6254227053140097\n",
      "Training loss = 0.22994693302994837\n",
      "Validation accuracy = 0.5\n",
      "Validation loss = 0.313046233728528\n",
      "Epoch 0139 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.6258573141486811\n",
      "Training loss = 0.2298107946137909\n",
      "Validation accuracy = 0.28125\n",
      "Validation loss = 0.3328236658126116\n",
      "Epoch 0140 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.6260178571428572\n",
      "Training loss = 0.22970827357000892\n",
      "Validation accuracy = 0.46875\n",
      "Validation loss = 0.313980869948864\n",
      "Epoch 0141 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.6261820330969267\n",
      "Training loss = 0.22966414502898921\n",
      "Validation accuracy = 0.40625\n",
      "Validation loss = 0.3100648242980242\n",
      "Epoch 0142 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.6264964788732394\n",
      "Training loss = 0.2295622830259933\n",
      "Validation accuracy = 0.46875\n",
      "Validation loss = 0.3318888247013092\n",
      "Epoch 0143 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.6266666666666667\n",
      "Training loss = 0.2294716849109475\n",
      "Validation accuracy = 0.46875\n",
      "Validation loss = 0.3046035710722208\n",
      "Epoch 0144 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.6267708333333334\n",
      "Training loss = 0.22942364865905363\n",
      "Validation accuracy = 0.53125\n",
      "Validation loss = 0.2866991702467203\n",
      "Epoch 0145 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.6270574712643678\n",
      "Training loss = 0.22926892748021188\n",
      "Validation accuracy = 0.3125\n",
      "Validation loss = 0.35035104863345623\n",
      "Epoch 0146 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.627283105022831\n",
      "Training loss = 0.22914071164574457\n",
      "Validation accuracy = 0.46875\n",
      "Validation loss = 0.30262251384556293\n",
      "Epoch 0147 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.6273809523809524\n",
      "Training loss = 0.22908679468299595\n",
      "Validation accuracy = 0.34375\n",
      "Validation loss = 0.3636138569563627\n",
      "Epoch 0148 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.6277027027027027\n",
      "Training loss = 0.22894204501406634\n",
      "Validation accuracy = 0.375\n",
      "Validation loss = 0.3322402071207762\n",
      "Epoch 0149 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.6278579418344519\n",
      "Training loss = 0.22882869472898026\n",
      "Validation accuracy = 0.5\n",
      "Validation loss = 0.29560459591448307\n",
      "Epoch 0150 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.6279888888888889\n",
      "Training loss = 0.22874570495792562\n",
      "Validation accuracy = 0.53125\n",
      "Validation loss = 0.2927437610924244\n",
      "Epoch 0151 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.6280960264900662\n",
      "Training loss = 0.22864425543925948\n",
      "Validation accuracy = 0.3125\n",
      "Validation loss = 0.3711610557511449\n",
      "Epoch 0152 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.6282730263157895\n",
      "Training loss = 0.22857375588161838\n",
      "Validation accuracy = 0.375\n",
      "Validation loss = 0.3496146537363529\n",
      "Epoch 0153 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.6285021786492375\n",
      "Training loss = 0.22846810149154698\n",
      "Validation accuracy = 0.3125\n",
      "Validation loss = 0.3821321055293083\n",
      "Epoch 0154 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.6288419913419914\n",
      "Training loss = 0.2282832657607893\n",
      "Validation accuracy = 0.40625\n",
      "Validation loss = 0.3167579025030136\n",
      "Epoch 0155 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.6290322580645161\n",
      "Training loss = 0.2281551736241547\n",
      "Validation accuracy = 0.375\n",
      "Validation loss = 0.353209150955081\n",
      "Epoch 0156 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.629241452991453\n",
      "Training loss = 0.22807677211645896\n",
      "Validation accuracy = 0.375\n",
      "Validation loss = 0.32300217263400555\n",
      "Epoch 0157 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.6294851380042463\n",
      "Training loss = 0.22796704451519909\n",
      "Validation accuracy = 0.4375\n",
      "Validation loss = 0.3181401900947094\n",
      "Epoch 0158 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.6297099156118143\n",
      "Training loss = 0.22784135532097788\n",
      "Validation accuracy = 0.53125\n",
      "Validation loss = 0.30946253426373005\n",
      "Epoch 0159 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.6298218029350104\n",
      "Training loss = 0.22773214960380983\n",
      "Validation accuracy = 0.375\n",
      "Validation loss = 0.3284640293568373\n",
      "Epoch 0160 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.630203125\n",
      "Training loss = 0.2275428626483772\n",
      "Validation accuracy = 0.25\n",
      "Validation loss = 0.3981349002569914\n",
      "Epoch 0161 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.6303778467908903\n",
      "Training loss = 0.22739554665435113\n",
      "Validation accuracy = 0.375\n",
      "Validation loss = 0.32529981806874275\n",
      "Epoch 0162 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.630679012345679\n",
      "Training loss = 0.2272403712205037\n",
      "Validation accuracy = 0.34375\n",
      "Validation loss = 0.3761337958276272\n",
      "Epoch 0163 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.630920245398773\n",
      "Training loss = 0.22711393463914806\n",
      "Validation accuracy = 0.28125\n",
      "Validation loss = 0.3238123059272766\n",
      "Epoch 0164 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.6310569105691057\n",
      "Training loss = 0.22705553530881983\n",
      "Validation accuracy = 0.53125\n",
      "Validation loss = 0.28673515282571316\n",
      "Epoch 0165 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.6312474747474748\n",
      "Training loss = 0.227016210968371\n",
      "Validation accuracy = 0.375\n",
      "Validation loss = 0.31269422359764576\n",
      "Epoch 0166 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.631460843373494\n",
      "Training loss = 0.22691620597002438\n",
      "Validation accuracy = 0.40625\n",
      "Validation loss = 0.34087228029966354\n",
      "Epoch 0167 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.6316167664670659\n",
      "Training loss = 0.22681573426005192\n",
      "Validation accuracy = 0.40625\n",
      "Validation loss = 0.32328294031322\n",
      "Epoch 0168 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.6319196428571429\n",
      "Training loss = 0.2266860841107481\n",
      "Validation accuracy = 0.4375\n",
      "Validation loss = 0.30437382869422436\n",
      "Epoch 0169 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.6321153846153846\n",
      "Training loss = 0.22655270787642964\n",
      "Validation accuracy = 0.4375\n",
      "Validation loss = 0.3202409092336893\n",
      "Epoch 0170 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.6324019607843138\n",
      "Training loss = 0.22639907492792197\n",
      "Validation accuracy = 0.375\n",
      "Validation loss = 0.32829218730330467\n",
      "Epoch 0171 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.6324610136452242\n",
      "Training loss = 0.22634157026872823\n",
      "Validation accuracy = 0.5\n",
      "Validation loss = 0.3060470689088106\n",
      "Epoch 0172 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.6326259689922481\n",
      "Training loss = 0.22625060326318697\n",
      "Validation accuracy = 0.28125\n",
      "Validation loss = 0.3408204736188054\n",
      "Epoch 0173 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.6328323699421965\n",
      "Training loss = 0.22611134263756819\n",
      "Validation accuracy = 0.40625\n",
      "Validation loss = 0.32264200784265995\n",
      "Epoch 0174 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.6329214559386973\n",
      "Training loss = 0.22606559200383639\n",
      "Validation accuracy = 0.375\n",
      "Validation loss = 0.3096650280058384\n",
      "Epoch 0175 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.6330142857142858\n",
      "Training loss = 0.22599046472105241\n",
      "Validation accuracy = 0.40625\n",
      "Validation loss = 0.3184562921524048\n",
      "Epoch 0176 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.6332623106060606\n",
      "Training loss = 0.2258595744531009\n",
      "Validation accuracy = 0.375\n",
      "Validation loss = 0.3371037719771266\n",
      "Epoch 0177 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.6334086629001883\n",
      "Training loss = 0.22576455228949727\n",
      "Validation accuracy = 0.5\n",
      "Validation loss = 0.28300916962325573\n",
      "Epoch 0178 / 0200\n",
      "=====================================\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training accuracy = 0.6335908239700374\n",
      "Training loss = 0.22564537967349427\n",
      "Validation accuracy = 0.46875\n",
      "Validation loss = 0.27881337609142065\n",
      "Epoch 0179 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.6336964618249534\n",
      "Training loss = 0.22561243662940167\n",
      "Validation accuracy = 0.4375\n",
      "Validation loss = 0.301037834957242\n",
      "Epoch 0180 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.6338472222222222\n",
      "Training loss = 0.22554187824107982\n",
      "Validation accuracy = 0.46875\n",
      "Validation loss = 0.29533649515360594\n",
      "Epoch 0181 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.6339871086556169\n",
      "Training loss = 0.22547196837845318\n",
      "Validation accuracy = 0.53125\n",
      "Validation loss = 0.3082483680918813\n",
      "Epoch 0182 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.6340888278388278\n",
      "Training loss = 0.22536295332437578\n",
      "Validation accuracy = 0.5\n",
      "Validation loss = 0.3088559899479151\n",
      "Epoch 0183 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.6342577413479052\n",
      "Training loss = 0.22527537718442403\n",
      "Validation accuracy = 0.5\n",
      "Validation loss = 0.3228369150310755\n",
      "Epoch 0184 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.6344248188405797\n",
      "Training loss = 0.2252230990148973\n",
      "Validation accuracy = 0.40625\n",
      "Validation loss = 0.3550995383411646\n",
      "Epoch 0185 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.6347342342342343\n",
      "Training loss = 0.22508968634057688\n",
      "Validation accuracy = 0.53125\n",
      "Validation loss = 0.3038231935352087\n",
      "Epoch 0186 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.6349417562724015\n",
      "Training loss = 0.22496401156882978\n",
      "Validation accuracy = 0.3125\n",
      "Validation loss = 0.3832652419805527\n",
      "Epoch 0187 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.6351426024955437\n",
      "Training loss = 0.22489362005775201\n",
      "Validation accuracy = 0.375\n",
      "Validation loss = 0.33052722178399563\n",
      "Epoch 0188 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.6352836879432624\n",
      "Training loss = 0.22481865910443324\n",
      "Validation accuracy = 0.46875\n",
      "Validation loss = 0.3023555427789688\n",
      "Epoch 0189 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.6355114638447972\n",
      "Training loss = 0.22470008613479306\n",
      "Validation accuracy = 0.34375\n",
      "Validation loss = 0.3256320394575596\n",
      "Epoch 0190 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.6357412280701754\n",
      "Training loss = 0.22462512862695413\n",
      "Validation accuracy = 0.40625\n",
      "Validation loss = 0.31735833920538425\n",
      "Epoch 0191 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.6359729493891798\n",
      "Training loss = 0.2245143949659135\n",
      "Validation accuracy = 0.28125\n",
      "Validation loss = 0.3535839542746544\n",
      "Epoch 0192 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.636171875\n",
      "Training loss = 0.22441427457573201\n",
      "Validation accuracy = 0.3125\n",
      "Validation loss = 0.317164221778512\n",
      "Epoch 0193 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.6363385146804836\n",
      "Training loss = 0.2243247324700543\n",
      "Validation accuracy = 0.5\n",
      "Validation loss = 0.3220118395984173\n",
      "Epoch 0194 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.6365077319587629\n",
      "Training loss = 0.22423991698298054\n",
      "Validation accuracy = 0.5\n",
      "Validation loss = 0.29130837693810463\n",
      "Epoch 0195 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.6367735042735043\n",
      "Training loss = 0.2241074891809979\n",
      "Validation accuracy = 0.40625\n",
      "Validation loss = 0.31091335974633694\n",
      "Epoch 0196 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.6371003401360544\n",
      "Training loss = 0.22395209316417677\n",
      "Validation accuracy = 0.375\n",
      "Validation loss = 0.30430110916495323\n",
      "Epoch 0197 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.6373181049069374\n",
      "Training loss = 0.2238481434007284\n",
      "Validation accuracy = 0.5\n",
      "Validation loss = 0.31049996614456177\n",
      "Epoch 0198 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.637449494949495\n",
      "Training loss = 0.2237766332043843\n",
      "Validation accuracy = 0.46875\n",
      "Validation loss = 0.3047717437148094\n",
      "Epoch 0199 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.6375544388609715\n",
      "Training loss = 0.22371251727643124\n",
      "Validation accuracy = 0.3125\n",
      "Validation loss = 0.36405167542397976\n",
      "Epoch 0200 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.6378291666666667\n",
      "Training loss = 0.22357585492432117\n",
      "Validation accuracy = 0.40625\n",
      "Validation loss = 0.314427699893713\n",
      "Making model for session group 20210310_15:30:04.369-20210319_16:16:17.283\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/imblearn/utils/_validation.py:326: UserWarning: After over-sampling, the number of samples (300) in class car will be larger than the number of samples in the majority class (class #signpost -> 160)\n",
      "  n_samples_majority,\n",
      "/usr/local/lib/python3.6/dist-packages/imblearn/utils/_validation.py:326: UserWarning: After over-sampling, the number of samples (300) in class signpost will be larger than the number of samples in the majority class (class #signpost -> 160)\n",
      "  n_samples_majority,\n",
      "/usr/local/lib/python3.6/dist-packages/imblearn/utils/_validation.py:326: UserWarning: After over-sampling, the number of samples (300) in class tree will be larger than the number of samples in the majority class (class #signpost -> 160)\n",
      "  n_samples_majority,\n",
      "/usr/local/lib/python3.6/dist-packages/imblearn/utils/_validation.py:326: UserWarning: After over-sampling, the number of samples (300) in class wall will be larger than the number of samples in the majority class (class #signpost -> 160)\n",
      "  n_samples_majority,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0001 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.4266666666666667\n",
      "Training loss = 0.31186098739504814\n",
      "Validation accuracy = 0.625\n",
      "Validation loss = 0.2534905429929495\n",
      "Epoch 0002 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.45416666666666666\n",
      "Training loss = 0.29874487554033596\n",
      "Validation accuracy = 0.78125\n",
      "Validation loss = 0.2364222090691328\n",
      "Epoch 0003 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.48583333333333334\n",
      "Training loss = 0.2896827095250289\n",
      "Validation accuracy = 0.71875\n",
      "Validation loss = 0.24573992006480694\n",
      "Epoch 0004 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.4970833333333333\n",
      "Training loss = 0.2854298763722181\n",
      "Validation accuracy = 0.65625\n",
      "Validation loss = 0.24083393067121506\n",
      "Epoch 0005 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.503\n",
      "Training loss = 0.2827909557521343\n",
      "Validation accuracy = 0.875\n",
      "Validation loss = 0.22732898779213428\n",
      "Epoch 0006 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.5116666666666667\n",
      "Training loss = 0.2806026632669899\n",
      "Validation accuracy = 0.6875\n",
      "Validation loss = 0.21727287024259567\n",
      "Epoch 0007 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.5179761904761905\n",
      "Training loss = 0.27836125404352235\n",
      "Validation accuracy = 0.78125\n",
      "Validation loss = 0.22175166569650173\n",
      "Epoch 0008 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.524375\n",
      "Training loss = 0.2762199422872315\n",
      "Validation accuracy = 0.8125\n",
      "Validation loss = 0.225512208417058\n",
      "Epoch 0009 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.5287962962962963\n",
      "Training loss = 0.2741624893910355\n",
      "Validation accuracy = 0.875\n",
      "Validation loss = 0.2223353274166584\n",
      "Epoch 0010 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.53375\n",
      "Training loss = 0.27225215718398493\n",
      "Validation accuracy = 0.8125\n",
      "Validation loss = 0.21806985512375832\n",
      "Epoch 0011 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.5371969696969697\n",
      "Training loss = 0.2709179976695415\n",
      "Validation accuracy = 0.78125\n",
      "Validation loss = 0.23028367944061756\n",
      "Epoch 0012 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.539375\n",
      "Training loss = 0.26941646952595977\n",
      "Validation accuracy = 0.84375\n",
      "Validation loss = 0.23462205193936825\n",
      "Epoch 0013 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.5403205128205129\n",
      "Training loss = 0.26864566413255836\n",
      "Validation accuracy = 0.875\n",
      "Validation loss = 0.1954200267791748\n",
      "Epoch 0014 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.5436309523809524\n",
      "Training loss = 0.2672388181427405\n",
      "Validation accuracy = 0.6875\n",
      "Validation loss = 0.21747764199972153\n",
      "Epoch 0015 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.5451111111111111\n",
      "Training loss = 0.2665217049635119\n",
      "Validation accuracy = 0.90625\n",
      "Validation loss = 0.19500370882451534\n",
      "Epoch 0016 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.54625\n",
      "Training loss = 0.26586797734256834\n",
      "Validation accuracy = 0.625\n",
      "Validation loss = 0.2201898293569684\n",
      "Epoch 0017 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.5482843137254902\n",
      "Training loss = 0.26510031805318945\n",
      "Validation accuracy = 0.6875\n",
      "Validation loss = 0.21645056456327438\n",
      "Epoch 0018 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.55\n",
      "Training loss = 0.2644977357059165\n",
      "Validation accuracy = 0.8125\n",
      "Validation loss = 0.21855341084301472\n",
      "Epoch 0019 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.5514035087719298\n",
      "Training loss = 0.26387406161741206\n",
      "Validation accuracy = 0.84375\n",
      "Validation loss = 0.19840996991842985\n",
      "Epoch 0020 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.5516666666666666\n",
      "Training loss = 0.26376809758196273\n",
      "Validation accuracy = 0.90625\n",
      "Validation loss = 0.20330269634723663\n",
      "Epoch 0021 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.5534126984126985\n",
      "Training loss = 0.2632403428746121\n",
      "Validation accuracy = 0.84375\n",
      "Validation loss = 0.19862103648483753\n",
      "Epoch 0022 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.5540530303030303\n",
      "Training loss = 0.2628886837263902\n",
      "Validation accuracy = 0.875\n",
      "Validation loss = 0.20784342754632235\n",
      "Epoch 0023 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.5552898550724638\n",
      "Training loss = 0.26230406302040904\n",
      "Validation accuracy = 0.875\n",
      "Validation loss = 0.2014728458598256\n",
      "Epoch 0024 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.5571180555555556\n",
      "Training loss = 0.2614297675175799\n",
      "Validation accuracy = 0.84375\n",
      "Validation loss = 0.2016266230493784\n",
      "Epoch 0025 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.5590333333333334\n",
      "Training loss = 0.26086456015110016\n",
      "Validation accuracy = 0.8125\n",
      "Validation loss = 0.20154567994177341\n",
      "Epoch 0026 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.5598397435897436\n",
      "Training loss = 0.26033801274708446\n",
      "Validation accuracy = 0.875\n",
      "Validation loss = 0.2082901755347848\n",
      "Epoch 0027 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.5608641975308643\n",
      "Training loss = 0.2597307847164295\n",
      "Validation accuracy = 0.875\n",
      "Validation loss = 0.20667346380650997\n",
      "Epoch 0028 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.5617857142857143\n",
      "Training loss = 0.2592963567110045\n",
      "Validation accuracy = 0.90625\n",
      "Validation loss = 0.20444690436124802\n",
      "Epoch 0029 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.5627873563218391\n",
      "Training loss = 0.25884069018408484\n",
      "Validation accuracy = 0.84375\n",
      "Validation loss = 0.18614548072218895\n",
      "Epoch 0030 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.5640555555555555\n",
      "Training loss = 0.2584900116440323\n",
      "Validation accuracy = 0.90625\n",
      "Validation loss = 0.20536071434617043\n",
      "Epoch 0031 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.5654301075268817\n",
      "Training loss = 0.25804798103308163\n",
      "Validation accuracy = 0.5\n",
      "Validation loss = 0.22827942296862602\n",
      "Epoch 0032 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.5659375\n",
      "Training loss = 0.25764583292184395\n",
      "Validation accuracy = 0.8125\n",
      "Validation loss = 0.2060499731451273\n",
      "Epoch 0033 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.5668181818181818\n",
      "Training loss = 0.25719465156170457\n",
      "Validation accuracy = 0.84375\n",
      "Validation loss = 0.21389114018529654\n",
      "Epoch 0034 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.5673774509803922\n",
      "Training loss = 0.2569268667186592\n",
      "Validation accuracy = 0.8125\n",
      "Validation loss = 0.2105438895523548\n",
      "Epoch 0035 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.5687857142857143\n",
      "Training loss = 0.2562536944888887\n",
      "Validation accuracy = 0.84375\n",
      "Validation loss = 0.19521990977227688\n",
      "Epoch 0036 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.5702314814814815\n",
      "Training loss = 0.2556048701807029\n",
      "Validation accuracy = 0.875\n",
      "Validation loss = 0.19189751613885164\n",
      "Epoch 0037 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.5703828828828829\n",
      "Training loss = 0.25533186003498665\n",
      "Validation accuracy = 0.8125\n",
      "Validation loss = 0.17387249134480953\n",
      "Epoch 0038 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.5710526315789474\n",
      "Training loss = 0.254948728295664\n",
      "Validation accuracy = 0.90625\n",
      "Validation loss = 0.17897252179682255\n",
      "Epoch 0039 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.5717735042735043\n",
      "Training loss = 0.25455420879217294\n",
      "Validation accuracy = 0.90625\n",
      "Validation loss = 0.1961501594632864\n",
      "Epoch 0040 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.5720208333333333\n",
      "Training loss = 0.25444792342806855\n",
      "Validation accuracy = 0.78125\n",
      "Validation loss = 0.20238884165883064\n",
      "Epoch 0041 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.5726829268292682\n",
      "Training loss = 0.2541798859852843\n",
      "Validation accuracy = 0.8125\n",
      "Validation loss = 0.1883897939696908\n",
      "Epoch 0042 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.5737896825396825\n",
      "Training loss = 0.25362550861069133\n",
      "Validation accuracy = 0.84375\n",
      "Validation loss = 0.2029357384890318\n",
      "Epoch 0043 / 0200\n",
      "=====================================\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training accuracy = 0.5742054263565891\n",
      "Training loss = 0.25330078699503294\n",
      "Validation accuracy = 0.65625\n",
      "Validation loss = 0.22567568812519312\n",
      "Epoch 0044 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.5742045454545455\n",
      "Training loss = 0.25317214637035224\n",
      "Validation accuracy = 0.75\n",
      "Validation loss = 0.19812973495572805\n",
      "Epoch 0045 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.5747037037037037\n",
      "Training loss = 0.2529491751326455\n",
      "Validation accuracy = 0.875\n",
      "Validation loss = 0.18343786150217056\n",
      "Epoch 0046 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.5753442028985507\n",
      "Training loss = 0.2526030679306258\n",
      "Validation accuracy = 0.90625\n",
      "Validation loss = 0.1866843532770872\n",
      "Epoch 0047 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.5760283687943263\n",
      "Training loss = 0.2522529040102629\n",
      "Validation accuracy = 0.84375\n",
      "Validation loss = 0.20510680880397558\n",
      "Epoch 0048 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.5767881944444444\n",
      "Training loss = 0.25207409860152336\n",
      "Validation accuracy = 0.90625\n",
      "Validation loss = 0.2068066978827119\n",
      "Epoch 0049 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.5776360544217687\n",
      "Training loss = 0.25176187606591754\n",
      "Validation accuracy = 0.9375\n",
      "Validation loss = 0.18625544011592865\n",
      "Epoch 0050 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.5781\n",
      "Training loss = 0.2515659260774652\n",
      "Validation accuracy = 0.71875\n",
      "Validation loss = 0.20555459521710873\n",
      "Epoch 0051 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.5784967320261438\n",
      "Training loss = 0.2512588021524397\n",
      "Validation accuracy = 0.875\n",
      "Validation loss = 0.19432691112160683\n",
      "Epoch 0052 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.5791506410256411\n",
      "Training loss = 0.2510029337177865\n",
      "Validation accuracy = 0.90625\n",
      "Validation loss = 0.21406523324549198\n",
      "Epoch 0053 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.5799685534591195\n",
      "Training loss = 0.2506363328771209\n",
      "Validation accuracy = 0.71875\n",
      "Validation loss = 0.20313909836113453\n",
      "Epoch 0054 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.5806327160493827\n",
      "Training loss = 0.25024000085568354\n",
      "Validation accuracy = 0.875\n",
      "Validation loss = 0.2083635050803423\n",
      "Epoch 0055 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.5808939393939394\n",
      "Training loss = 0.2499911581670696\n",
      "Validation accuracy = 0.8125\n",
      "Validation loss = 0.1958400122821331\n",
      "Epoch 0056 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.5816666666666667\n",
      "Training loss = 0.2496126471783611\n",
      "Validation accuracy = 0.46875\n",
      "Validation loss = 0.23007552977651358\n",
      "Epoch 0057 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.5819736842105263\n",
      "Training loss = 0.2494398084431015\n",
      "Validation accuracy = 0.75\n",
      "Validation loss = 0.20444210804998875\n",
      "Epoch 0058 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.5824281609195402\n",
      "Training loss = 0.24916976301620403\n",
      "Validation accuracy = 0.9375\n",
      "Validation loss = 0.17865218222141266\n",
      "Epoch 0059 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.5830508474576271\n",
      "Training loss = 0.24889270355009427\n",
      "Validation accuracy = 0.65625\n",
      "Validation loss = 0.2090199626982212\n",
      "Epoch 0060 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.5838333333333333\n",
      "Training loss = 0.24851595800659723\n",
      "Validation accuracy = 0.8125\n",
      "Validation loss = 0.19113396760076284\n",
      "Epoch 0061 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.5842896174863388\n",
      "Training loss = 0.24834619958055476\n",
      "Validation accuracy = 0.90625\n",
      "Validation loss = 0.17944462597370148\n",
      "Epoch 0062 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.5851478494623656\n",
      "Training loss = 0.24798843252682878\n",
      "Validation accuracy = 0.90625\n",
      "Validation loss = 0.17930019181221724\n",
      "Epoch 0063 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.5856878306878307\n",
      "Training loss = 0.24769705168824033\n",
      "Validation accuracy = 0.8125\n",
      "Validation loss = 0.18075568322092295\n",
      "Epoch 0064 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.5862630208333334\n",
      "Training loss = 0.2474939727767681\n",
      "Validation accuracy = 0.9375\n",
      "Validation loss = 0.1612236611545086\n",
      "Epoch 0065 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.5869102564102564\n",
      "Training loss = 0.2472030755185928\n",
      "Validation accuracy = 0.84375\n",
      "Validation loss = 0.18605273589491844\n",
      "Epoch 0066 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.5875883838383839\n",
      "Training loss = 0.2468817535787821\n",
      "Validation accuracy = 0.875\n",
      "Validation loss = 0.1789441965520382\n",
      "Epoch 0067 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.5882089552238806\n",
      "Training loss = 0.24668361232722577\n",
      "Validation accuracy = 0.875\n",
      "Validation loss = 0.1778452154248953\n",
      "Epoch 0068 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.5887254901960784\n",
      "Training loss = 0.24639611996345076\n",
      "Validation accuracy = 0.84375\n",
      "Validation loss = 0.18746193498373032\n",
      "Epoch 0069 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.5892874396135266\n",
      "Training loss = 0.24612497402706007\n",
      "Validation accuracy = 0.875\n",
      "Validation loss = 0.17655980959534645\n",
      "Epoch 0070 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.5895238095238096\n",
      "Training loss = 0.24601336260388296\n",
      "Validation accuracy = 0.84375\n",
      "Validation loss = 0.18330088909715414\n",
      "Epoch 0071 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.5901525821596244\n",
      "Training loss = 0.24581713991195944\n",
      "Validation accuracy = 0.90625\n",
      "Validation loss = 0.18669052608311176\n",
      "Epoch 0072 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.5907291666666666\n",
      "Training loss = 0.2455695890493829\n",
      "Validation accuracy = 0.875\n",
      "Validation loss = 0.16234647668898106\n",
      "Epoch 0073 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.5911301369863013\n",
      "Training loss = 0.24542555889208295\n",
      "Validation accuracy = 0.75\n",
      "Validation loss = 0.20149467699229717\n",
      "Epoch 0074 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.5916103603603604\n",
      "Training loss = 0.24518361522639925\n",
      "Validation accuracy = 0.875\n",
      "Validation loss = 0.19484941102564335\n",
      "Epoch 0075 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.5921666666666666\n",
      "Training loss = 0.24487821318341627\n",
      "Validation accuracy = 0.8125\n",
      "Validation loss = 0.19931552931666374\n",
      "Epoch 0076 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.5927192982456141\n",
      "Training loss = 0.24461306308510533\n",
      "Validation accuracy = 0.84375\n",
      "Validation loss = 0.18585820402950048\n",
      "Epoch 0077 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.5932575757575758\n",
      "Training loss = 0.24422180857460996\n",
      "Validation accuracy = 0.875\n",
      "Validation loss = 0.17750066332519054\n",
      "Epoch 0078 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.5934722222222222\n",
      "Training loss = 0.243997037378896\n",
      "Validation accuracy = 0.875\n",
      "Validation loss = 0.17811552435159683\n",
      "Epoch 0079 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.5937869198312237\n",
      "Training loss = 0.24381858497134995\n",
      "Validation accuracy = 0.875\n",
      "Validation loss = 0.1880001649260521\n",
      "Epoch 0080 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.5944583333333333\n",
      "Training loss = 0.24347747329870859\n",
      "Validation accuracy = 0.84375\n",
      "Validation loss = 0.20170747581869364\n",
      "Epoch 0081 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.5947530864197531\n",
      "Training loss = 0.2433233455234349\n",
      "Validation accuracy = 0.75\n",
      "Validation loss = 0.18447423167526722\n",
      "Epoch 0082 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.5948983739837398\n",
      "Training loss = 0.24321141455110495\n",
      "Validation accuracy = 0.90625\n",
      "Validation loss = 0.17245075665414333\n",
      "Epoch 0083 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.5952208835341365\n",
      "Training loss = 0.24305008077058926\n",
      "Validation accuracy = 0.875\n",
      "Validation loss = 0.17275826819241047\n",
      "Epoch 0084 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.5956349206349206\n",
      "Training loss = 0.242899321535277\n",
      "Validation accuracy = 0.96875\n",
      "Validation loss = 0.1624945057556033\n",
      "Epoch 0085 / 0200\n",
      "=====================================\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training accuracy = 0.5960490196078432\n",
      "Training loss = 0.24268088359429557\n",
      "Validation accuracy = 0.875\n",
      "Validation loss = 0.17503701709210873\n",
      "Epoch 0086 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.5966763565891473\n",
      "Training loss = 0.24243547062743312\n",
      "Validation accuracy = 0.59375\n",
      "Validation loss = 0.2037087446078658\n",
      "Epoch 0087 / 0200\n",
      "=====================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/_classification.py:1221: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training accuracy = 0.596963601532567\n",
      "Training loss = 0.2422416258683264\n",
      "Validation accuracy = 0.6875\n",
      "Validation loss = 0.1955974269658327\n",
      "Epoch 0088 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.5970265151515152\n",
      "Training loss = 0.24219718563624404\n",
      "Validation accuracy = 0.78125\n",
      "Validation loss = 0.18721751123666763\n",
      "Epoch 0089 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.5976685393258427\n",
      "Training loss = 0.24193479842572624\n",
      "Validation accuracy = 0.8125\n",
      "Validation loss = 0.16100401617586613\n",
      "Epoch 0090 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.5978981481481481\n",
      "Training loss = 0.2417744278267578\n",
      "Validation accuracy = 0.90625\n",
      "Validation loss = 0.16320637799799442\n",
      "Epoch 0091 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.5982875457875458\n",
      "Training loss = 0.24157541571355565\n",
      "Validation accuracy = 0.90625\n",
      "Validation loss = 0.1709392685443163\n",
      "Epoch 0092 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.5984873188405797\n",
      "Training loss = 0.24143666762507696\n",
      "Validation accuracy = 0.84375\n",
      "Validation loss = 0.1684387121349573\n",
      "Epoch 0093 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.5987186379928315\n",
      "Training loss = 0.241274769458399\n",
      "Validation accuracy = 0.375\n",
      "Validation loss = 0.26753696613013744\n",
      "Epoch 0094 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.599095744680851\n",
      "Training loss = 0.24110022296825198\n",
      "Validation accuracy = 0.8125\n",
      "Validation loss = 0.17449038568884134\n",
      "Epoch 0095 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.5994473684210526\n",
      "Training loss = 0.240948679426783\n",
      "Validation accuracy = 0.875\n",
      "Validation loss = 0.16713170800358057\n",
      "Epoch 0096 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.5998090277777778\n",
      "Training loss = 0.2407072174991481\n",
      "Validation accuracy = 0.90625\n",
      "Validation loss = 0.17108474671840668\n",
      "Epoch 0097 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.6000171821305842\n",
      "Training loss = 0.24061354973369448\n",
      "Validation accuracy = 0.875\n",
      "Validation loss = 0.1916968272998929\n",
      "Epoch 0098 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.6001955782312925\n",
      "Training loss = 0.24051798401387775\n",
      "Validation accuracy = 0.6875\n",
      "Validation loss = 0.17653199844062328\n",
      "Epoch 0099 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.6004040404040404\n",
      "Training loss = 0.24036499444307502\n",
      "Validation accuracy = 0.84375\n",
      "Validation loss = 0.1858778689056635\n",
      "Epoch 0100 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.6006583333333333\n",
      "Training loss = 0.24023722276886303\n",
      "Validation accuracy = 0.875\n",
      "Validation loss = 0.1842642603442073\n",
      "Epoch 0101 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.6010148514851485\n",
      "Training loss = 0.24007298268525318\n",
      "Validation accuracy = 0.875\n",
      "Validation loss = 0.18209187127649784\n",
      "Epoch 0102 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.6013888888888889\n",
      "Training loss = 0.23986832962438367\n",
      "Validation accuracy = 0.90625\n",
      "Validation loss = 0.158933044411242\n",
      "Epoch 0103 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.6018851132686084\n",
      "Training loss = 0.23965435170891022\n",
      "Validation accuracy = 0.84375\n",
      "Validation loss = 0.1798440245911479\n",
      "Epoch 0104 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.6022035256410256\n",
      "Training loss = 0.2394524741729196\n",
      "Validation accuracy = 0.78125\n",
      "Validation loss = 0.1835886724293232\n",
      "Epoch 0105 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.6025873015873016\n",
      "Training loss = 0.239286376984583\n",
      "Validation accuracy = 0.78125\n",
      "Validation loss = 0.17439720779657364\n",
      "Epoch 0106 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.6030817610062893\n",
      "Training loss = 0.2390976886036542\n",
      "Validation accuracy = 0.8125\n",
      "Validation loss = 0.1831469740718603\n",
      "Epoch 0107 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.6035591900311527\n",
      "Training loss = 0.23888122632147923\n",
      "Validation accuracy = 0.875\n",
      "Validation loss = 0.16932676173746586\n",
      "Epoch 0108 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.6039583333333334\n",
      "Training loss = 0.2387389926692862\n",
      "Validation accuracy = 0.9375\n",
      "Validation loss = 0.16971573140472174\n",
      "Epoch 0109 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.6043960244648318\n",
      "Training loss = 0.23847198602119718\n",
      "Validation accuracy = 0.90625\n",
      "Validation loss = 0.1621127212420106\n",
      "Epoch 0110 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.6046590909090909\n",
      "Training loss = 0.23828313253187772\n",
      "Validation accuracy = 0.96875\n",
      "Validation loss = 0.14912838116288185\n",
      "Epoch 0111 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.6047447447447447\n",
      "Training loss = 0.2381680553487024\n",
      "Validation accuracy = 0.90625\n",
      "Validation loss = 0.17915275413542986\n",
      "Epoch 0112 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.6048065476190476\n",
      "Training loss = 0.23811057295384153\n",
      "Validation accuracy = 0.625\n",
      "Validation loss = 0.20606439746916294\n",
      "Epoch 0113 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.6047861356932154\n",
      "Training loss = 0.23806502173981658\n",
      "Validation accuracy = 0.6875\n",
      "Validation loss = 0.19733066763728857\n",
      "Epoch 0114 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.6051900584795321\n",
      "Training loss = 0.23785302128926006\n",
      "Validation accuracy = 0.875\n",
      "Validation loss = 0.18709245137870312\n",
      "Epoch 0115 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.6055652173913043\n",
      "Training loss = 0.23765728894912677\n",
      "Validation accuracy = 0.875\n",
      "Validation loss = 0.19295490253716707\n",
      "Epoch 0116 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.6058333333333333\n",
      "Training loss = 0.23747488215587093\n",
      "Validation accuracy = 0.875\n",
      "Validation loss = 0.1585623025894165\n",
      "Epoch 0117 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.606039886039886\n",
      "Training loss = 0.23733282896846616\n",
      "Validation accuracy = 0.71875\n",
      "Validation loss = 0.18461631424725056\n",
      "Epoch 0118 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.606475988700565\n",
      "Training loss = 0.2371426712776308\n",
      "Validation accuracy = 0.46875\n",
      "Validation loss = 0.2492654277011752\n",
      "Epoch 0119 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.6066596638655463\n",
      "Training loss = 0.23704182845621216\n",
      "Validation accuracy = 0.96875\n",
      "Validation loss = 0.153721546754241\n",
      "Epoch 0120 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.6068888888888889\n",
      "Training loss = 0.23689926312884524\n",
      "Validation accuracy = 0.9375\n",
      "Validation loss = 0.18342016264796257\n",
      "Epoch 0121 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.6071831955922865\n",
      "Training loss = 0.23681230250202098\n",
      "Validation accuracy = 0.84375\n",
      "Validation loss = 0.16462108306586742\n",
      "Epoch 0122 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.6075683060109289\n",
      "Training loss = 0.23662783397270032\n",
      "Validation accuracy = 0.71875\n",
      "Validation loss = 0.1682396149262786\n",
      "Epoch 0123 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.6078387533875339\n",
      "Training loss = 0.23648970127489347\n",
      "Validation accuracy = 0.875\n",
      "Validation loss = 0.19261248596012592\n",
      "Epoch 0124 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.6081518817204301\n",
      "Training loss = 0.23635773954832906\n",
      "Validation accuracy = 0.84375\n",
      "Validation loss = 0.1684027398005128\n",
      "Epoch 0125 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.60828\n",
      "Training loss = 0.23631002623359362\n",
      "Validation accuracy = 0.875\n",
      "Validation loss = 0.19872212130576372\n",
      "Epoch 0126 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.6083201058201059\n",
      "Training loss = 0.23621232264788536\n",
      "Validation accuracy = 0.78125\n",
      "Validation loss = 0.18176220916211605\n",
      "Epoch 0127 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.6087270341207349\n",
      "Training loss = 0.2360392091914112\n",
      "Validation accuracy = 0.75\n",
      "Validation loss = 0.19171471148729324\n",
      "Epoch 0128 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.6088932291666667\n",
      "Training loss = 0.23589343880400218\n",
      "Validation accuracy = 0.78125\n",
      "Validation loss = 0.1906666187569499\n",
      "Epoch 0129 / 0200\n",
      "=====================================\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training accuracy = 0.6089857881136951\n",
      "Training loss = 0.23581066468754633\n",
      "Validation accuracy = 0.8125\n",
      "Validation loss = 0.15603384748101234\n",
      "Epoch 0130 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.6092628205128205\n",
      "Training loss = 0.23565367395736467\n",
      "Validation accuracy = 0.90625\n",
      "Validation loss = 0.1714371433481574\n",
      "Epoch 0131 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.6094338422391857\n",
      "Training loss = 0.23553630853635815\n",
      "Validation accuracy = 0.9375\n",
      "Validation loss = 0.137839843519032\n",
      "Epoch 0132 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.6097979797979798\n",
      "Training loss = 0.2353835956927276\n",
      "Validation accuracy = 0.8125\n",
      "Validation loss = 0.1691042734310031\n",
      "Epoch 0133 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.6099248120300752\n",
      "Training loss = 0.23527543826565558\n",
      "Validation accuracy = 0.84375\n",
      "Validation loss = 0.18949794676154852\n",
      "Epoch 0134 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.6100870646766169\n",
      "Training loss = 0.2351287469390168\n",
      "Validation accuracy = 0.9375\n",
      "Validation loss = 0.1637525726109743\n",
      "Epoch 0135 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.6103703703703703\n",
      "Training loss = 0.23499478728112616\n",
      "Validation accuracy = 0.90625\n",
      "Validation loss = 0.1698447000235319\n",
      "Epoch 0136 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.6106985294117647\n",
      "Training loss = 0.2348735661877721\n",
      "Validation accuracy = 0.65625\n",
      "Validation loss = 0.1806036727502942\n",
      "Epoch 0137 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.6107664233576642\n",
      "Training loss = 0.23480373048688083\n",
      "Validation accuracy = 0.875\n",
      "Validation loss = 0.17648658994585276\n",
      "Epoch 0138 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.6109782608695652\n",
      "Training loss = 0.23472928626615788\n",
      "Validation accuracy = 0.84375\n",
      "Validation loss = 0.17712992802262306\n",
      "Epoch 0139 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.6110671462829736\n",
      "Training loss = 0.23465623175015124\n",
      "Validation accuracy = 0.875\n",
      "Validation loss = 0.16626672353595495\n",
      "Epoch 0140 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.6114107142857143\n",
      "Training loss = 0.2344713070351808\n",
      "Validation accuracy = 0.84375\n",
      "Validation loss = 0.19645191729068756\n",
      "Epoch 0141 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.6115721040189125\n",
      "Training loss = 0.23434793706992135\n",
      "Validation accuracy = 0.78125\n",
      "Validation loss = 0.1704076835885644\n",
      "Epoch 0142 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.6119131455399061\n",
      "Training loss = 0.23420840375807503\n",
      "Validation accuracy = 0.71875\n",
      "Validation loss = 0.2019841130822897\n",
      "Epoch 0143 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.6122261072261073\n",
      "Training loss = 0.2340815827844443\n",
      "Validation accuracy = 0.84375\n",
      "Validation loss = 0.16685969289392233\n",
      "Epoch 0144 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.6123321759259259\n",
      "Training loss = 0.23401611876122103\n",
      "Validation accuracy = 0.84375\n",
      "Validation loss = 0.1625563520938158\n",
      "Epoch 0145 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.6127011494252873\n",
      "Training loss = 0.23384255981513824\n",
      "Validation accuracy = 0.90625\n",
      "Validation loss = 0.15534513629972935\n",
      "Epoch 0146 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.6129908675799087\n",
      "Training loss = 0.23372560481757743\n",
      "Validation accuracy = 0.8125\n",
      "Validation loss = 0.17562078963965178\n",
      "Epoch 0147 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.6133163265306123\n",
      "Training loss = 0.2335563111509663\n",
      "Validation accuracy = 0.625\n",
      "Validation loss = 0.2019924195483327\n",
      "Epoch 0148 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.6136261261261261\n",
      "Training loss = 0.2334222584878942\n",
      "Validation accuracy = 0.75\n",
      "Validation loss = 0.18206423055380583\n",
      "Epoch 0149 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.613847874720358\n",
      "Training loss = 0.2333116375309909\n",
      "Validation accuracy = 0.6875\n",
      "Validation loss = 0.19881104957312346\n",
      "Epoch 0150 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.6140055555555556\n",
      "Training loss = 0.23323621243420575\n",
      "Validation accuracy = 0.9375\n",
      "Validation loss = 0.16128689143806696\n",
      "Epoch 0151 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.6144757174392936\n",
      "Training loss = 0.23307103925571668\n",
      "Validation accuracy = 0.90625\n",
      "Validation loss = 0.14970924984663725\n",
      "Epoch 0152 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.6147094298245614\n",
      "Training loss = 0.23293881057418492\n",
      "Validation accuracy = 0.875\n",
      "Validation loss = 0.17728286609053612\n",
      "Epoch 0153 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.615\n",
      "Training loss = 0.2328482272485697\n",
      "Validation accuracy = 0.90625\n",
      "Validation loss = 0.15814668405801058\n",
      "Epoch 0154 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.6150919913419913\n",
      "Training loss = 0.2327866801034127\n",
      "Validation accuracy = 1.0\n",
      "Validation loss = 0.14173439797013998\n",
      "Epoch 0155 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.6153225806451613\n",
      "Training loss = 0.23266829534483854\n",
      "Validation accuracy = 0.90625\n",
      "Validation loss = 0.15040103625506163\n",
      "Epoch 0156 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.6156303418803419\n",
      "Training loss = 0.23252496420716245\n",
      "Validation accuracy = 0.875\n",
      "Validation loss = 0.14975878037512302\n",
      "Epoch 0157 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.6159023354564755\n",
      "Training loss = 0.23243700179546248\n",
      "Validation accuracy = 0.9375\n",
      "Validation loss = 0.1520366994664073\n",
      "Epoch 0158 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.6160706751054852\n",
      "Training loss = 0.2323206636520252\n",
      "Validation accuracy = 0.9375\n",
      "Validation loss = 0.15027075819671154\n",
      "Epoch 0159 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.6163574423480084\n",
      "Training loss = 0.23220343925043221\n",
      "Validation accuracy = 0.65625\n",
      "Validation loss = 0.17433533538132906\n",
      "Epoch 0160 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.6165416666666667\n",
      "Training loss = 0.23207347704423592\n",
      "Validation accuracy = 0.875\n",
      "Validation loss = 0.14293364621698856\n",
      "Epoch 0161 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.6168581780538303\n",
      "Training loss = 0.23193224425502815\n",
      "Validation accuracy = 0.90625\n",
      "Validation loss = 0.1425102036446333\n",
      "Epoch 0162 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.6170164609053498\n",
      "Training loss = 0.23184073421644208\n",
      "Validation accuracy = 0.90625\n",
      "Validation loss = 0.15322696790099144\n",
      "Epoch 0163 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.6172443762781186\n",
      "Training loss = 0.231730385730024\n",
      "Validation accuracy = 0.84375\n",
      "Validation loss = 0.16928792279213667\n",
      "Epoch 0164 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.6174745934959349\n",
      "Training loss = 0.23162379675537226\n",
      "Validation accuracy = 0.90625\n",
      "Validation loss = 0.14190419763326645\n",
      "Epoch 0165 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.6176969696969697\n",
      "Training loss = 0.23155242044591542\n",
      "Validation accuracy = 0.875\n",
      "Validation loss = 0.14041848108172417\n",
      "Epoch 0166 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.6180672690763053\n",
      "Training loss = 0.231402125570579\n",
      "Validation accuracy = 0.90625\n",
      "Validation loss = 0.1296465490013361\n",
      "Epoch 0167 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.6184031936127744\n",
      "Training loss = 0.23125615086056991\n",
      "Validation accuracy = 0.90625\n",
      "Validation loss = 0.16442985460162163\n",
      "Epoch 0168 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.6185565476190477\n",
      "Training loss = 0.23120983724689317\n",
      "Validation accuracy = 0.90625\n",
      "Validation loss = 0.1368538225069642\n",
      "Epoch 0169 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.6188412228796845\n",
      "Training loss = 0.23109549731897885\n",
      "Validation accuracy = 0.46875\n",
      "Validation loss = 0.2693954221904278\n",
      "Epoch 0170 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.6189019607843137\n",
      "Training loss = 0.23104417665741023\n",
      "Validation accuracy = 0.9375\n",
      "Validation loss = 0.15095021203160286\n",
      "Epoch 0171 / 0200\n",
      "=====================================\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training accuracy = 0.6191715399610136\n",
      "Training loss = 0.230947142974646\n",
      "Validation accuracy = 0.8125\n",
      "Validation loss = 0.17167283967137337\n",
      "Epoch 0172 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.6194622093023255\n",
      "Training loss = 0.23081322877487356\n",
      "Validation accuracy = 0.84375\n",
      "Validation loss = 0.17388711124658585\n",
      "Epoch 0173 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.6196387283236994\n",
      "Training loss = 0.2307221118416745\n",
      "Validation accuracy = 0.84375\n",
      "Validation loss = 0.19560457952320576\n",
      "Epoch 0174 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.619808429118774\n",
      "Training loss = 0.2306406990007651\n",
      "Validation accuracy = 0.65625\n",
      "Validation loss = 0.17849442083388567\n",
      "Epoch 0175 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.6199571428571429\n",
      "Training loss = 0.23054530355249134\n",
      "Validation accuracy = 0.8125\n",
      "Validation loss = 0.17493003699928522\n",
      "Epoch 0176 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.6201041666666667\n",
      "Training loss = 0.23046868296904546\n",
      "Validation accuracy = 0.96875\n",
      "Validation loss = 0.147303675301373\n",
      "Epoch 0177 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.6204331450094162\n",
      "Training loss = 0.23032488911951104\n",
      "Validation accuracy = 0.78125\n",
      "Validation loss = 0.17521957494318485\n",
      "Epoch 0178 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.6205898876404494\n",
      "Training loss = 0.23017786350645375\n",
      "Validation accuracy = 0.8125\n",
      "Validation loss = 0.17945700325071812\n",
      "Epoch 0179 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.6209031657355679\n",
      "Training loss = 0.23001859080372464\n",
      "Validation accuracy = 0.90625\n",
      "Validation loss = 0.16131689678877592\n",
      "Epoch 0180 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.6210185185185185\n",
      "Training loss = 0.2299374036550246\n",
      "Validation accuracy = 0.6875\n",
      "Validation loss = 0.20382820535451174\n",
      "Epoch 0181 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.6212799263351749\n",
      "Training loss = 0.22987178997838145\n",
      "Validation accuracy = 0.875\n",
      "Validation loss = 0.1676025865599513\n",
      "Epoch 0182 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.6213736263736264\n",
      "Training loss = 0.22981280583206004\n",
      "Validation accuracy = 0.875\n",
      "Validation loss = 0.16352544073015451\n",
      "Epoch 0183 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.6215528233151184\n",
      "Training loss = 0.22968908257198897\n",
      "Validation accuracy = 0.84375\n",
      "Validation loss = 0.14934978354722261\n",
      "Epoch 0184 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.6217934782608696\n",
      "Training loss = 0.22958027168662976\n",
      "Validation accuracy = 0.90625\n",
      "Validation loss = 0.14536261092871428\n",
      "Epoch 0185 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.622\n",
      "Training loss = 0.22947259608018505\n",
      "Validation accuracy = 0.75\n",
      "Validation loss = 0.1872393349185586\n",
      "Epoch 0186 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.622168458781362\n",
      "Training loss = 0.22937346668212966\n",
      "Validation accuracy = 0.875\n",
      "Validation loss = 0.14171363320201635\n",
      "Epoch 0187 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.6224376114081996\n",
      "Training loss = 0.22924717317728754\n",
      "Validation accuracy = 0.84375\n",
      "Validation loss = 0.1647972445935011\n",
      "Epoch 0188 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.6225797872340425\n",
      "Training loss = 0.22919613659897067\n",
      "Validation accuracy = 0.9375\n",
      "Validation loss = 0.16939425189048052\n",
      "Epoch 0189 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.6228439153439154\n",
      "Training loss = 0.2290750542982125\n",
      "Validation accuracy = 0.9375\n",
      "Validation loss = 0.16707113292068243\n",
      "Epoch 0190 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.6230350877192983\n",
      "Training loss = 0.228957228234724\n",
      "Validation accuracy = 0.5625\n",
      "Validation loss = 0.22343744151294231\n",
      "Epoch 0191 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.623302792321117\n",
      "Training loss = 0.22883243693822236\n",
      "Validation accuracy = 0.90625\n",
      "Validation loss = 0.16854260861873627\n",
      "Epoch 0192 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.6235460069444444\n",
      "Training loss = 0.22872029351587925\n",
      "Validation accuracy = 0.90625\n",
      "Validation loss = 0.15686547197401524\n",
      "Epoch 0193 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.6236485319516407\n",
      "Training loss = 0.2286133462191915\n",
      "Validation accuracy = 0.84375\n",
      "Validation loss = 0.1790188755840063\n",
      "Epoch 0194 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.6236984536082474\n",
      "Training loss = 0.22857553086598817\n",
      "Validation accuracy = 0.84375\n",
      "Validation loss = 0.1677424293011427\n",
      "Epoch 0195 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.623991452991453\n",
      "Training loss = 0.22846304817383106\n",
      "Validation accuracy = 0.9375\n",
      "Validation loss = 0.16087814327329397\n",
      "Epoch 0196 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.6241411564625851\n",
      "Training loss = 0.22838492339730365\n",
      "Validation accuracy = 0.96875\n",
      "Validation loss = 0.14267519395798445\n",
      "Epoch 0197 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.6242808798646362\n",
      "Training loss = 0.2283127882419857\n",
      "Validation accuracy = 0.90625\n",
      "Validation loss = 0.16897317115217447\n",
      "Epoch 0198 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.6245244107744108\n",
      "Training loss = 0.2282159475089123\n",
      "Validation accuracy = 0.65625\n",
      "Validation loss = 0.18499110452830791\n",
      "Epoch 0199 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.6247068676716918\n",
      "Training loss = 0.22815949932913884\n",
      "Validation accuracy = 0.65625\n",
      "Validation loss = 0.2143163038417697\n",
      "Epoch 0200 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.6249333333333333\n",
      "Training loss = 0.22805229433476926\n",
      "Validation accuracy = 0.84375\n",
      "Validation loss = 0.1693726684898138\n",
      "Making model for session group 20210310_15:30:21.964-20210319_16:16:47.785\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/imblearn/utils/_validation.py:326: UserWarning: After over-sampling, the number of samples (300) in class car will be larger than the number of samples in the majority class (class #signpost -> 160)\n",
      "  n_samples_majority,\n",
      "/usr/local/lib/python3.6/dist-packages/imblearn/utils/_validation.py:326: UserWarning: After over-sampling, the number of samples (300) in class signpost will be larger than the number of samples in the majority class (class #signpost -> 160)\n",
      "  n_samples_majority,\n",
      "/usr/local/lib/python3.6/dist-packages/imblearn/utils/_validation.py:326: UserWarning: After over-sampling, the number of samples (300) in class tree will be larger than the number of samples in the majority class (class #signpost -> 160)\n",
      "  n_samples_majority,\n",
      "/usr/local/lib/python3.6/dist-packages/imblearn/utils/_validation.py:326: UserWarning: After over-sampling, the number of samples (300) in class wall will be larger than the number of samples in the majority class (class #signpost -> 160)\n",
      "  n_samples_majority,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0001 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.38916666666666666\n",
      "Training loss = 0.320827090293169\n",
      "Validation accuracy = 0.46875\n",
      "Validation loss = 0.3274104930460453\n",
      "Epoch 0002 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.4216666666666667\n",
      "Training loss = 0.3125278125206629\n",
      "Validation accuracy = 0.40625\n",
      "Validation loss = 0.32861896976828575\n",
      "Epoch 0003 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.4436111111111111\n",
      "Training loss = 0.30550726246502663\n",
      "Validation accuracy = 0.4375\n",
      "Validation loss = 0.3111685439944267\n",
      "Epoch 0004 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.465625\n",
      "Training loss = 0.300125806927681\n",
      "Validation accuracy = 0.625\n",
      "Validation loss = 0.3020687885582447\n",
      "Epoch 0005 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.48183333333333334\n",
      "Training loss = 0.29503803662459055\n",
      "Validation accuracy = 0.59375\n",
      "Validation loss = 0.3047700449824333\n",
      "Epoch 0006 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.4905555555555556\n",
      "Training loss = 0.29138972838719684\n",
      "Validation accuracy = 0.59375\n",
      "Validation loss = 0.30070757679641247\n",
      "Epoch 0007 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.4975\n",
      "Training loss = 0.28791981103874387\n",
      "Validation accuracy = 0.5625\n",
      "Validation loss = 0.3042220175266266\n",
      "Epoch 0008 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.5057291666666667\n",
      "Training loss = 0.28493729073554275\n",
      "Validation accuracy = 0.6875\n",
      "Validation loss = 0.29659227281808853\n",
      "Epoch 0009 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.5112962962962962\n",
      "Training loss = 0.2824364797108703\n",
      "Validation accuracy = 0.53125\n",
      "Validation loss = 0.28969219140708447\n",
      "Epoch 0010 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.51725\n",
      "Training loss = 0.2800440560926994\n",
      "Validation accuracy = 0.5625\n",
      "Validation loss = 0.28914064168930054\n",
      "Epoch 0011 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.5236363636363637\n",
      "Training loss = 0.2777406068213961\n",
      "Validation accuracy = 0.65625\n",
      "Validation loss = 0.28745527006685734\n",
      "Epoch 0012 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.5288888888888889\n",
      "Training loss = 0.27561902625279294\n",
      "Validation accuracy = 0.5\n",
      "Validation loss = 0.29593855515122414\n",
      "Epoch 0013 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.5334615384615384\n",
      "Training loss = 0.274041546990092\n",
      "Validation accuracy = 0.5\n",
      "Validation loss = 0.2791848462074995\n",
      "Epoch 0014 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.5357738095238095\n",
      "Training loss = 0.2727880155383831\n",
      "Validation accuracy = 0.59375\n",
      "Validation loss = 0.2811618000268936\n",
      "Epoch 0015 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.5388888888888889\n",
      "Training loss = 0.2714506796962685\n",
      "Validation accuracy = 0.65625\n",
      "Validation loss = 0.28558151610195637\n",
      "Epoch 0016 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.5422916666666666\n",
      "Training loss = 0.2701316638089096\n",
      "Validation accuracy = 0.71875\n",
      "Validation loss = 0.2616670597344637\n",
      "Epoch 0017 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.5446568627450981\n",
      "Training loss = 0.26900640995040825\n",
      "Validation accuracy = 0.5\n",
      "Validation loss = 0.2876238841563463\n",
      "Epoch 0018 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.5465740740740741\n",
      "Training loss = 0.2679259270264043\n",
      "Validation accuracy = 0.65625\n",
      "Validation loss = 0.26527328975498676\n",
      "Epoch 0019 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.5495614035087719\n",
      "Training loss = 0.2669626528822016\n",
      "Validation accuracy = 0.5625\n",
      "Validation loss = 0.28948727808892727\n",
      "Epoch 0020 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.5515\n",
      "Training loss = 0.2658578355796635\n",
      "Validation accuracy = 0.53125\n",
      "Validation loss = 0.28365066181868315\n",
      "Epoch 0021 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.5534920634920635\n",
      "Training loss = 0.2648795190962061\n",
      "Validation accuracy = 0.625\n",
      "Validation loss = 0.2744191214442253\n",
      "Epoch 0022 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.5553030303030303\n",
      "Training loss = 0.26409235421568156\n",
      "Validation accuracy = 0.59375\n",
      "Validation loss = 0.2681318260729313\n",
      "Epoch 0023 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.5571376811594203\n",
      "Training loss = 0.2629887774932212\n",
      "Validation accuracy = 0.625\n",
      "Validation loss = 0.2673924872651696\n",
      "Epoch 0024 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.5595833333333333\n",
      "Training loss = 0.2620375334823297\n",
      "Validation accuracy = 0.5\n",
      "Validation loss = 0.28793866373598576\n",
      "Epoch 0025 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.5616666666666666\n",
      "Training loss = 0.2613104349146287\n",
      "Validation accuracy = 0.375\n",
      "Validation loss = 0.3128057047724724\n",
      "Epoch 0026 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.5633333333333334\n",
      "Training loss = 0.26063995316624644\n",
      "Validation accuracy = 0.65625\n",
      "Validation loss = 0.265915522351861\n",
      "Epoch 0027 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.5638271604938272\n",
      "Training loss = 0.2602057626217972\n",
      "Validation accuracy = 0.5625\n",
      "Validation loss = 0.2892417497932911\n",
      "Epoch 0028 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.565029761904762\n",
      "Training loss = 0.2595547595868508\n",
      "Validation accuracy = 0.53125\n",
      "Validation loss = 0.27651190757751465\n",
      "Epoch 0029 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.5659770114942528\n",
      "Training loss = 0.2590206573278397\n",
      "Validation accuracy = 0.5625\n",
      "Validation loss = 0.29143117368221283\n",
      "Epoch 0030 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.5667777777777778\n",
      "Training loss = 0.2585903531461954\n",
      "Validation accuracy = 0.59375\n",
      "Validation loss = 0.2687956504523754\n",
      "Epoch 0031 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.5681451612903226\n",
      "Training loss = 0.2580227822081376\n",
      "Validation accuracy = 0.625\n",
      "Validation loss = 0.27022313326597214\n",
      "Epoch 0032 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.569296875\n",
      "Training loss = 0.2576532972037482\n",
      "Validation accuracy = 0.5625\n",
      "Validation loss = 0.2941687386482954\n",
      "Epoch 0033 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.5698989898989899\n",
      "Training loss = 0.2573094643381509\n",
      "Validation accuracy = 0.53125\n",
      "Validation loss = 0.29716285318136215\n",
      "Epoch 0034 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.5708823529411765\n",
      "Training loss = 0.2567991553604895\n",
      "Validation accuracy = 0.59375\n",
      "Validation loss = 0.2776497695595026\n",
      "Epoch 0035 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.5713333333333334\n",
      "Training loss = 0.2567027510340725\n",
      "Validation accuracy = 0.5625\n",
      "Validation loss = 0.30273918621242046\n",
      "Epoch 0036 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.5725462962962963\n",
      "Training loss = 0.2561599694771899\n",
      "Validation accuracy = 0.59375\n",
      "Validation loss = 0.2894176635891199\n",
      "Epoch 0037 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.5738738738738739\n",
      "Training loss = 0.2555672895384801\n",
      "Validation accuracy = 0.5625\n",
      "Validation loss = 0.275753203779459\n",
      "Epoch 0038 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.5744736842105264\n",
      "Training loss = 0.25522463205482876\n",
      "Validation accuracy = 0.4375\n",
      "Validation loss = 0.2863614186644554\n",
      "Epoch 0039 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.5754273504273504\n",
      "Training loss = 0.25469781339805353\n",
      "Validation accuracy = 0.625\n",
      "Validation loss = 0.2608512379229069\n",
      "Epoch 0040 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.5760625\n",
      "Training loss = 0.25421035732515157\n",
      "Validation accuracy = 0.4375\n",
      "Validation loss = 0.28017515502870083\n",
      "Epoch 0041 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.5759146341463415\n",
      "Training loss = 0.25401732362019336\n",
      "Validation accuracy = 0.59375\n",
      "Validation loss = 0.271346615627408\n",
      "Epoch 0042 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.5771031746031746\n",
      "Training loss = 0.2533098714390681\n",
      "Validation accuracy = 0.59375\n",
      "Validation loss = 0.2755501288920641\n",
      "Epoch 0043 / 0200\n",
      "=====================================\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training accuracy = 0.5778100775193798\n",
      "Training loss = 0.2529394867080589\n",
      "Validation accuracy = 0.4375\n",
      "Validation loss = 0.3072832301259041\n",
      "Epoch 0044 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.5782765151515151\n",
      "Training loss = 0.25283653441365017\n",
      "Validation accuracy = 0.53125\n",
      "Validation loss = 0.2644448596984148\n",
      "Epoch 0045 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.5792592592592593\n",
      "Training loss = 0.25245537753403186\n",
      "Validation accuracy = 0.59375\n",
      "Validation loss = 0.2708946354687214\n",
      "Epoch 0046 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.5798913043478261\n",
      "Training loss = 0.2521726888013275\n",
      "Validation accuracy = 0.625\n",
      "Validation loss = 0.26449666917324066\n",
      "Epoch 0047 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.5806737588652482\n",
      "Training loss = 0.25184324060348756\n",
      "Validation accuracy = 0.625\n",
      "Validation loss = 0.27681598253548145\n",
      "Epoch 0048 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.5813194444444445\n",
      "Training loss = 0.25149330300692885\n",
      "Validation accuracy = 0.59375\n",
      "Validation loss = 0.278475034981966\n",
      "Epoch 0049 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.5818707482993197\n",
      "Training loss = 0.2510568580406458\n",
      "Validation accuracy = 0.625\n",
      "Validation loss = 0.26407748460769653\n",
      "Epoch 0050 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.5828\n",
      "Training loss = 0.2506602117791772\n",
      "Validation accuracy = 0.46875\n",
      "Validation loss = 0.3186945989727974\n",
      "Epoch 0051 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.5834477124183006\n",
      "Training loss = 0.2503105130884188\n",
      "Validation accuracy = 0.53125\n",
      "Validation loss = 0.2557234466075897\n",
      "Epoch 0052 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.5840544871794872\n",
      "Training loss = 0.2500216830951663\n",
      "Validation accuracy = 0.5625\n",
      "Validation loss = 0.27353547140955925\n",
      "Epoch 0053 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.5848427672955975\n",
      "Training loss = 0.24967840156558924\n",
      "Validation accuracy = 0.5625\n",
      "Validation loss = 0.29378318041563034\n",
      "Epoch 0054 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.5852623456790124\n",
      "Training loss = 0.2495299914649423\n",
      "Validation accuracy = 0.46875\n",
      "Validation loss = 0.29189308173954487\n",
      "Epoch 0055 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.5857424242424243\n",
      "Training loss = 0.24929962726208296\n",
      "Validation accuracy = 0.5625\n",
      "Validation loss = 0.2702483907341957\n",
      "Epoch 0056 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.5862648809523809\n",
      "Training loss = 0.24893602556770755\n",
      "Validation accuracy = 0.59375\n",
      "Validation loss = 0.29474415071308613\n",
      "Epoch 0057 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.5869444444444445\n",
      "Training loss = 0.24854776808828638\n",
      "Validation accuracy = 0.625\n",
      "Validation loss = 0.25271834433078766\n",
      "Epoch 0058 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.5874281609195402\n",
      "Training loss = 0.24829920116640714\n",
      "Validation accuracy = 0.46875\n",
      "Validation loss = 0.3142304662615061\n",
      "Epoch 0059 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.5882627118644068\n",
      "Training loss = 0.2479290115563883\n",
      "Validation accuracy = 0.53125\n",
      "Validation loss = 0.2768253721296787\n",
      "Epoch 0060 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.5888888888888889\n",
      "Training loss = 0.2476159266713593\n",
      "Validation accuracy = 0.5625\n",
      "Validation loss = 0.2806275114417076\n",
      "Epoch 0061 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.5895628415300547\n",
      "Training loss = 0.24722977351091924\n",
      "Validation accuracy = 0.53125\n",
      "Validation loss = 0.27126489765942097\n",
      "Epoch 0062 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.5899731182795699\n",
      "Training loss = 0.24697784269889517\n",
      "Validation accuracy = 0.65625\n",
      "Validation loss = 0.2552489871159196\n",
      "Epoch 0063 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.5902380952380952\n",
      "Training loss = 0.2467656344474939\n",
      "Validation accuracy = 0.625\n",
      "Validation loss = 0.26795276906341314\n",
      "Epoch 0064 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.5909895833333333\n",
      "Training loss = 0.24643203749204987\n",
      "Validation accuracy = 0.59375\n",
      "Validation loss = 0.26748630683869123\n",
      "Epoch 0065 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.591551282051282\n",
      "Training loss = 0.2461785649385972\n",
      "Validation accuracy = 0.5625\n",
      "Validation loss = 0.28771036490797997\n",
      "Epoch 0066 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.5919318181818182\n",
      "Training loss = 0.24601282116025686\n",
      "Validation accuracy = 0.5625\n",
      "Validation loss = 0.29774780105799437\n",
      "Epoch 0067 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.5928109452736319\n",
      "Training loss = 0.24568866399464323\n",
      "Validation accuracy = 0.53125\n",
      "Validation loss = 0.2938649859279394\n",
      "Epoch 0068 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.5932475490196079\n",
      "Training loss = 0.24548585541400256\n",
      "Validation accuracy = 0.5\n",
      "Validation loss = 0.2947908714413643\n",
      "Epoch 0069 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.5938285024154589\n",
      "Training loss = 0.24520948800451803\n",
      "Validation accuracy = 0.4375\n",
      "Validation loss = 0.3028312027454376\n",
      "Epoch 0070 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.5944880952380952\n",
      "Training loss = 0.2448863275721669\n",
      "Validation accuracy = 0.375\n",
      "Validation loss = 0.3091088756918907\n",
      "Epoch 0071 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.5951408450704225\n",
      "Training loss = 0.24476682877771452\n",
      "Validation accuracy = 0.5\n",
      "Validation loss = 0.29239841271191835\n",
      "Epoch 0072 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.5954861111111112\n",
      "Training loss = 0.24448311407498463\n",
      "Validation accuracy = 0.46875\n",
      "Validation loss = 0.276731813326478\n",
      "Epoch 0073 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.5960958904109589\n",
      "Training loss = 0.24427585707815816\n",
      "Validation accuracy = 0.4375\n",
      "Validation loss = 0.31436054967343807\n",
      "Epoch 0074 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.5969031531531531\n",
      "Training loss = 0.24396524679385595\n",
      "Validation accuracy = 0.625\n",
      "Validation loss = 0.25770287215709686\n",
      "Epoch 0075 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.5974111111111111\n",
      "Training loss = 0.2438238564464781\n",
      "Validation accuracy = 0.59375\n",
      "Validation loss = 0.293592962436378\n",
      "Epoch 0076 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.5977521929824562\n",
      "Training loss = 0.24366019239877923\n",
      "Validation accuracy = 0.53125\n",
      "Validation loss = 0.28917065635323524\n",
      "Epoch 0077 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.598008658008658\n",
      "Training loss = 0.24352050154562635\n",
      "Validation accuracy = 0.53125\n",
      "Validation loss = 0.30336424242705107\n",
      "Epoch 0078 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.5985576923076923\n",
      "Training loss = 0.24328654500058827\n",
      "Validation accuracy = 0.5625\n",
      "Validation loss = 0.28812985867261887\n",
      "Epoch 0079 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.5989135021097046\n",
      "Training loss = 0.24308995683264883\n",
      "Validation accuracy = 0.53125\n",
      "Validation loss = 0.30080827977508307\n",
      "Epoch 0080 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.5992291666666667\n",
      "Training loss = 0.24290491539705544\n",
      "Validation accuracy = 0.5\n",
      "Validation loss = 0.2849040422588587\n",
      "Epoch 0081 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.5996604938271605\n",
      "Training loss = 0.24275726395195404\n",
      "Validation accuracy = 0.53125\n",
      "Validation loss = 0.2880766950547695\n",
      "Epoch 0082 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.6003150406504065\n",
      "Training loss = 0.24246076922409418\n",
      "Validation accuracy = 0.4375\n",
      "Validation loss = 0.2901993431150913\n",
      "Epoch 0083 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.6008132530120482\n",
      "Training loss = 0.24224509935870947\n",
      "Validation accuracy = 0.53125\n",
      "Validation loss = 0.2903592400252819\n",
      "Epoch 0084 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.6009920634920635\n",
      "Training loss = 0.2422342162579298\n",
      "Validation accuracy = 0.53125\n",
      "Validation loss = 0.29910455271601677\n",
      "Epoch 0085 / 0200\n",
      "=====================================\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training accuracy = 0.6013823529411765\n",
      "Training loss = 0.24204669529930048\n",
      "Validation accuracy = 0.4375\n",
      "Validation loss = 0.2989547159522772\n",
      "Epoch 0086 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.6018701550387597\n",
      "Training loss = 0.24184334419003523\n",
      "Validation accuracy = 0.53125\n",
      "Validation loss = 0.2989856544882059\n",
      "Epoch 0087 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.6023084291187739\n",
      "Training loss = 0.24155457280861692\n",
      "Validation accuracy = 0.46875\n",
      "Validation loss = 0.2979149278253317\n",
      "Epoch 0088 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.6029166666666667\n",
      "Training loss = 0.24136890354848495\n",
      "Validation accuracy = 0.5625\n",
      "Validation loss = 0.28633631207048893\n",
      "Epoch 0089 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.6035580524344569\n",
      "Training loss = 0.2410847000758188\n",
      "Validation accuracy = 0.46875\n",
      "Validation loss = 0.2936891308054328\n",
      "Epoch 0090 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.6042685185185185\n",
      "Training loss = 0.24078032645583153\n",
      "Validation accuracy = 0.53125\n",
      "Validation loss = 0.2830791659653187\n",
      "Epoch 0091 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.6046062271062271\n",
      "Training loss = 0.24057454795682387\n",
      "Validation accuracy = 0.46875\n",
      "Validation loss = 0.3212177287787199\n",
      "Epoch 0092 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.6051539855072464\n",
      "Training loss = 0.24031776466501364\n",
      "Validation accuracy = 0.46875\n",
      "Validation loss = 0.28224118053913116\n",
      "Epoch 0093 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.6055376344086022\n",
      "Training loss = 0.24013381665485733\n",
      "Validation accuracy = 0.53125\n",
      "Validation loss = 0.2748837787657976\n",
      "Epoch 0094 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.605886524822695\n",
      "Training loss = 0.24002617805245074\n",
      "Validation accuracy = 0.5625\n",
      "Validation loss = 0.2664067968726158\n",
      "Epoch 0095 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.6063421052631579\n",
      "Training loss = 0.2397834185461203\n",
      "Validation accuracy = 0.46875\n",
      "Validation loss = 0.27175844740122557\n",
      "Epoch 0096 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.6067534722222222\n",
      "Training loss = 0.23954722069902346\n",
      "Validation accuracy = 0.53125\n",
      "Validation loss = 0.2650239299982786\n",
      "Epoch 0097 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.6071048109965635\n",
      "Training loss = 0.23935852710836122\n",
      "Validation accuracy = 0.53125\n",
      "Validation loss = 0.2964813560247421\n",
      "Epoch 0098 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.6076360544217687\n",
      "Training loss = 0.2390460165699019\n",
      "Validation accuracy = 0.5\n",
      "Validation loss = 0.2767011523246765\n",
      "Epoch 0099 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.6077441077441077\n",
      "Training loss = 0.2389898476992994\n",
      "Validation accuracy = 0.53125\n",
      "Validation loss = 0.26636793464422226\n",
      "Epoch 0100 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.608025\n",
      "Training loss = 0.23883234137346346\n",
      "Validation accuracy = 0.4375\n",
      "Validation loss = 0.2930757403373718\n",
      "Epoch 0101 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.6083250825082508\n",
      "Training loss = 0.238645810908807\n",
      "Validation accuracy = 0.46875\n",
      "Validation loss = 0.2817601077258587\n",
      "Epoch 0102 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.6086519607843137\n",
      "Training loss = 0.23847030633683103\n",
      "Validation accuracy = 0.53125\n",
      "Validation loss = 0.2589334202930331\n",
      "Epoch 0103 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.609004854368932\n",
      "Training loss = 0.23827557960133336\n",
      "Validation accuracy = 0.625\n",
      "Validation loss = 0.2580973068252206\n",
      "Epoch 0104 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.6094391025641026\n",
      "Training loss = 0.2381062806973186\n",
      "Validation accuracy = 0.5\n",
      "Validation loss = 0.28691710345447063\n",
      "Epoch 0105 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.609579365079365\n",
      "Training loss = 0.23798951127746748\n",
      "Validation accuracy = 0.40625\n",
      "Validation loss = 0.2866537868976593\n",
      "Epoch 0106 / 0200\n",
      "=====================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/_classification.py:1221: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training accuracy = 0.6099449685534591\n",
      "Training loss = 0.23780876876259188\n",
      "Validation accuracy = 0.5625\n",
      "Validation loss = 0.279959375038743\n",
      "Epoch 0107 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.6105373831775701\n",
      "Training loss = 0.2376148824598002\n",
      "Validation accuracy = 0.5\n",
      "Validation loss = 0.28682333044707775\n",
      "Epoch 0108 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.6109799382716049\n",
      "Training loss = 0.23740420002881207\n",
      "Validation accuracy = 0.46875\n",
      "Validation loss = 0.2922865357249975\n",
      "Epoch 0109 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.6114067278287462\n",
      "Training loss = 0.23715709997221418\n",
      "Validation accuracy = 0.5625\n",
      "Validation loss = 0.2851436994969845\n",
      "Epoch 0110 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.6118106060606061\n",
      "Training loss = 0.23702726454468387\n",
      "Validation accuracy = 0.4375\n",
      "Validation loss = 0.29906307999044657\n",
      "Epoch 0111 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.6122597597597598\n",
      "Training loss = 0.23682014328648557\n",
      "Validation accuracy = 0.5625\n",
      "Validation loss = 0.2670030929148197\n",
      "Epoch 0112 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.6125669642857143\n",
      "Training loss = 0.2366034305505898\n",
      "Validation accuracy = 0.5625\n",
      "Validation loss = 0.2691717743873596\n",
      "Epoch 0113 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.6128392330383481\n",
      "Training loss = 0.23644819532172168\n",
      "Validation accuracy = 0.5\n",
      "Validation loss = 0.2964187692850828\n",
      "Epoch 0114 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.6131359649122807\n",
      "Training loss = 0.23636790990742326\n",
      "Validation accuracy = 0.46875\n",
      "Validation loss = 0.299192126840353\n",
      "Epoch 0115 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.6135942028985507\n",
      "Training loss = 0.23614756284934887\n",
      "Validation accuracy = 0.5625\n",
      "Validation loss = 0.27328420151025057\n",
      "Epoch 0116 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.6139727011494253\n",
      "Training loss = 0.2359365115929181\n",
      "Validation accuracy = 0.53125\n",
      "Validation loss = 0.27193792909383774\n",
      "Epoch 0117 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.614002849002849\n",
      "Training loss = 0.23587601648075798\n",
      "Validation accuracy = 0.5625\n",
      "Validation loss = 0.2846671063452959\n",
      "Epoch 0118 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.6141454802259887\n",
      "Training loss = 0.2357356186057467\n",
      "Validation accuracy = 0.53125\n",
      "Validation loss = 0.28132893703877926\n",
      "Epoch 0119 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.6143557422969188\n",
      "Training loss = 0.2356048137005888\n",
      "Validation accuracy = 0.53125\n",
      "Validation loss = 0.28186119068413973\n",
      "Epoch 0120 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.614625\n",
      "Training loss = 0.23549135806866817\n",
      "Validation accuracy = 0.46875\n",
      "Validation loss = 0.30723453871905804\n",
      "Epoch 0121 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.6147933884297521\n",
      "Training loss = 0.23534593299544382\n",
      "Validation accuracy = 0.5625\n",
      "Validation loss = 0.2553514204919338\n",
      "Epoch 0122 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.6151092896174863\n",
      "Training loss = 0.2351848611158263\n",
      "Validation accuracy = 0.4375\n",
      "Validation loss = 0.29809617064893246\n",
      "Epoch 0123 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.6154674796747968\n",
      "Training loss = 0.23503076142310936\n",
      "Validation accuracy = 0.53125\n",
      "Validation loss = 0.29380199685692787\n",
      "Epoch 0124 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.6158534946236559\n",
      "Training loss = 0.23484313314760563\n",
      "Validation accuracy = 0.625\n",
      "Validation loss = 0.2687022481113672\n",
      "Epoch 0125 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.6162733333333333\n",
      "Training loss = 0.23463805841386318\n",
      "Validation accuracy = 0.4375\n",
      "Validation loss = 0.2920318581163883\n",
      "Epoch 0126 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.6165806878306879\n",
      "Training loss = 0.2344804343261889\n",
      "Validation accuracy = 0.53125\n",
      "Validation loss = 0.28644493222236633\n",
      "Epoch 0127 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.6169422572178478\n",
      "Training loss = 0.234295410818941\n",
      "Validation accuracy = 0.53125\n",
      "Validation loss = 0.2886944664642215\n",
      "Epoch 0128 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.6172786458333334\n",
      "Training loss = 0.23415688883823654\n",
      "Validation accuracy = 0.5625\n",
      "Validation loss = 0.2790456423535943\n",
      "Epoch 0129 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.6176421188630491\n",
      "Training loss = 0.23397323513138818\n",
      "Validation accuracy = 0.53125\n",
      "Validation loss = 0.2855698522180319\n",
      "Epoch 0130 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.6179230769230769\n",
      "Training loss = 0.2338382610604167\n",
      "Validation accuracy = 0.59375\n",
      "Validation loss = 0.2750303242355585\n",
      "Epoch 0131 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.618174300254453\n",
      "Training loss = 0.23371198438904212\n",
      "Validation accuracy = 0.53125\n",
      "Validation loss = 0.28058251179754734\n",
      "Epoch 0132 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.6184974747474747\n",
      "Training loss = 0.23356086643055232\n",
      "Validation accuracy = 0.4375\n",
      "Validation loss = 0.3099564742296934\n",
      "Epoch 0133 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.6187844611528822\n",
      "Training loss = 0.23337450309075358\n",
      "Validation accuracy = 0.53125\n",
      "Validation loss = 0.28334908932447433\n",
      "Epoch 0134 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.6191044776119403\n",
      "Training loss = 0.23323050304839563\n",
      "Validation accuracy = 0.5625\n",
      "Validation loss = 0.2860719598829746\n",
      "Epoch 0135 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.6194753086419753\n",
      "Training loss = 0.2330177480503917\n",
      "Validation accuracy = 0.59375\n",
      "Validation loss = 0.2588968053460121\n",
      "Epoch 0136 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.6198284313725491\n",
      "Training loss = 0.232869123529515\n",
      "Validation accuracy = 0.59375\n",
      "Validation loss = 0.26047537475824356\n",
      "Epoch 0137 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.620279805352798\n",
      "Training loss = 0.23269539431236014\n",
      "Validation accuracy = 0.53125\n",
      "Validation loss = 0.2710564099252224\n",
      "Epoch 0138 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.6206763285024155\n",
      "Training loss = 0.23252949955949676\n",
      "Validation accuracy = 0.59375\n",
      "Validation loss = 0.2687001097947359\n",
      "Epoch 0139 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.6209712230215827\n",
      "Training loss = 0.23240042958712334\n",
      "Validation accuracy = 0.59375\n",
      "Validation loss = 0.262592900544405\n",
      "Epoch 0140 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.6213214285714286\n",
      "Training loss = 0.23225249387119853\n",
      "Validation accuracy = 0.59375\n",
      "Validation loss = 0.25861711613833904\n",
      "Epoch 0141 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.6217434988179669\n",
      "Training loss = 0.23206003066258016\n",
      "Validation accuracy = 0.5\n",
      "Validation loss = 0.28992144018411636\n",
      "Epoch 0142 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.6221009389671361\n",
      "Training loss = 0.231903939840292\n",
      "Validation accuracy = 0.34375\n",
      "Validation loss = 0.30869787000119686\n",
      "Epoch 0143 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.6222727272727273\n",
      "Training loss = 0.2317816374007187\n",
      "Validation accuracy = 0.53125\n",
      "Validation loss = 0.2877752175554633\n",
      "Epoch 0144 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.6225347222222222\n",
      "Training loss = 0.2316266448332721\n",
      "Validation accuracy = 0.46875\n",
      "Validation loss = 0.2955142641440034\n",
      "Epoch 0145 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.6227241379310345\n",
      "Training loss = 0.23154394669462552\n",
      "Validation accuracy = 0.46875\n",
      "Validation loss = 0.32329334039241076\n",
      "Epoch 0146 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.6229737442922374\n",
      "Training loss = 0.23142374747530578\n",
      "Validation accuracy = 0.59375\n",
      "Validation loss = 0.28672175854444504\n",
      "Epoch 0147 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.6232823129251701\n",
      "Training loss = 0.23128749258098216\n",
      "Validation accuracy = 0.46875\n",
      "Validation loss = 0.31810646317899227\n",
      "Epoch 0148 / 0200\n",
      "=====================================\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training accuracy = 0.623688063063063\n",
      "Training loss = 0.23113862496985307\n",
      "Validation accuracy = 0.59375\n",
      "Validation loss = 0.2739618979394436\n",
      "Epoch 0149 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.6240995525727069\n",
      "Training loss = 0.23093435866279025\n",
      "Validation accuracy = 0.5625\n",
      "Validation loss = 0.2948798779398203\n",
      "Epoch 0150 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.6244944444444445\n",
      "Training loss = 0.2307298347753783\n",
      "Validation accuracy = 0.4375\n",
      "Validation loss = 0.29623493552207947\n",
      "Epoch 0151 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.6248289183222958\n",
      "Training loss = 0.23057740139275396\n",
      "Validation accuracy = 0.5\n",
      "Validation loss = 0.28187788976356387\n",
      "Epoch 0152 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.6252138157894737\n",
      "Training loss = 0.2304645812741007\n",
      "Validation accuracy = 0.53125\n",
      "Validation loss = 0.2971585765480995\n",
      "Epoch 0153 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.6254901960784314\n",
      "Training loss = 0.23026462054825622\n",
      "Validation accuracy = 0.4375\n",
      "Validation loss = 0.3008396318182349\n",
      "Epoch 0154 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.625806277056277\n",
      "Training loss = 0.23011356569318608\n",
      "Validation accuracy = 0.53125\n",
      "Validation loss = 0.3025042209774256\n",
      "Epoch 0155 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.6262311827956989\n",
      "Training loss = 0.22994182137287753\n",
      "Validation accuracy = 0.5\n",
      "Validation loss = 0.30866965278983116\n",
      "Epoch 0156 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.6265010683760683\n",
      "Training loss = 0.2297742225563265\n",
      "Validation accuracy = 0.53125\n",
      "Validation loss = 0.2893738830462098\n",
      "Epoch 0157 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.6266029723991507\n",
      "Training loss = 0.22972154200306427\n",
      "Validation accuracy = 0.5\n",
      "Validation loss = 0.3021328765898943\n",
      "Epoch 0158 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.6268512658227848\n",
      "Training loss = 0.22961735157563276\n",
      "Validation accuracy = 0.5625\n",
      "Validation loss = 0.29795030131936073\n",
      "Epoch 0159 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.6270964360587002\n",
      "Training loss = 0.22955468694931305\n",
      "Validation accuracy = 0.59375\n",
      "Validation loss = 0.27440715208649635\n",
      "Epoch 0160 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.6273333333333333\n",
      "Training loss = 0.2294181643128395\n",
      "Validation accuracy = 0.5\n",
      "Validation loss = 0.2944934405386448\n",
      "Epoch 0161 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.6275672877846791\n",
      "Training loss = 0.22931769481032901\n",
      "Validation accuracy = 0.625\n",
      "Validation loss = 0.27693912480026484\n",
      "Epoch 0162 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.6277109053497942\n",
      "Training loss = 0.229212443447622\n",
      "Validation accuracy = 0.5625\n",
      "Validation loss = 0.26834837161004543\n",
      "Epoch 0163 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.6279601226993865\n",
      "Training loss = 0.22910223654930334\n",
      "Validation accuracy = 0.53125\n",
      "Validation loss = 0.2787184603512287\n",
      "Epoch 0164 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.6279827235772357\n",
      "Training loss = 0.22906505957533552\n",
      "Validation accuracy = 0.5625\n",
      "Validation loss = 0.2787916148081422\n",
      "Epoch 0165 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.6281313131313131\n",
      "Training loss = 0.22899858873074103\n",
      "Validation accuracy = 0.5\n",
      "Validation loss = 0.2939152028411627\n",
      "Epoch 0166 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.62839859437751\n",
      "Training loss = 0.228885354002616\n",
      "Validation accuracy = 0.5\n",
      "Validation loss = 0.2933859843760729\n",
      "Epoch 0167 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.6286976047904191\n",
      "Training loss = 0.22875930874870565\n",
      "Validation accuracy = 0.59375\n",
      "Validation loss = 0.2848633136600256\n",
      "Epoch 0168 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.6290128968253968\n",
      "Training loss = 0.22860300255688054\n",
      "Validation accuracy = 0.5\n",
      "Validation loss = 0.3002536091953516\n",
      "Epoch 0169 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.6291765285996055\n",
      "Training loss = 0.22848416550918915\n",
      "Validation accuracy = 0.5625\n",
      "Validation loss = 0.25955121871083975\n",
      "Epoch 0170 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.6293578431372548\n",
      "Training loss = 0.22843930527012724\n",
      "Validation accuracy = 0.5625\n",
      "Validation loss = 0.27153895422816277\n",
      "Epoch 0171 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.6296442495126706\n",
      "Training loss = 0.22829292135396664\n",
      "Validation accuracy = 0.53125\n",
      "Validation loss = 0.2929628435522318\n",
      "Epoch 0172 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.6299418604651162\n",
      "Training loss = 0.2281431009702731\n",
      "Validation accuracy = 0.4375\n",
      "Validation loss = 0.28080745600163937\n",
      "Epoch 0173 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.6302408477842004\n",
      "Training loss = 0.22800229669844657\n",
      "Validation accuracy = 0.59375\n",
      "Validation loss = 0.2727223355323076\n",
      "Epoch 0174 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.6305363984674329\n",
      "Training loss = 0.22786942926239065\n",
      "Validation accuracy = 0.5\n",
      "Validation loss = 0.28666989132761955\n",
      "Epoch 0175 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.6308523809523809\n",
      "Training loss = 0.22772732058202935\n",
      "Validation accuracy = 0.59375\n",
      "Validation loss = 0.295460625551641\n",
      "Epoch 0176 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.6310558712121213\n",
      "Training loss = 0.22762265683271724\n",
      "Validation accuracy = 0.53125\n",
      "Validation loss = 0.2906432691961527\n",
      "Epoch 0177 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.6311299435028248\n",
      "Training loss = 0.22755349017742832\n",
      "Validation accuracy = 0.4375\n",
      "Validation loss = 0.30001164227724075\n",
      "Epoch 0178 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.6313061797752809\n",
      "Training loss = 0.22745206342828686\n",
      "Validation accuracy = 0.4375\n",
      "Validation loss = 0.2846479080617428\n",
      "Epoch 0179 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.6315735567970204\n",
      "Training loss = 0.22731922517379735\n",
      "Validation accuracy = 0.5\n",
      "Validation loss = 0.28814978525042534\n",
      "Epoch 0180 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.631800925925926\n",
      "Training loss = 0.227213958673938\n",
      "Validation accuracy = 0.5625\n",
      "Validation loss = 0.2723440993577242\n",
      "Epoch 0181 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.6321408839779006\n",
      "Training loss = 0.22706765245358093\n",
      "Validation accuracy = 0.5625\n",
      "Validation loss = 0.26311158388853073\n",
      "Epoch 0182 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.6323076923076923\n",
      "Training loss = 0.22697622133296105\n",
      "Validation accuracy = 0.5\n",
      "Validation loss = 0.29979537054896355\n",
      "Epoch 0183 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.6325455373406194\n",
      "Training loss = 0.22687387139534743\n",
      "Validation accuracy = 0.5625\n",
      "Validation loss = 0.2779403608292341\n",
      "Epoch 0184 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.6327490942028986\n",
      "Training loss = 0.2267502883988419\n",
      "Validation accuracy = 0.59375\n",
      "Validation loss = 0.27138432674109936\n",
      "Epoch 0185 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.6331666666666667\n",
      "Training loss = 0.22657765556610113\n",
      "Validation accuracy = 0.4375\n",
      "Validation loss = 0.2914292300119996\n",
      "Epoch 0186 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.6333422939068101\n",
      "Training loss = 0.2264908652778675\n",
      "Validation accuracy = 0.59375\n",
      "Validation loss = 0.2760614659637213\n",
      "Epoch 0187 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.6335160427807487\n",
      "Training loss = 0.2263894262741886\n",
      "Validation accuracy = 0.59375\n",
      "Validation loss = 0.2774451859295368\n",
      "Epoch 0188 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.633758865248227\n",
      "Training loss = 0.22627570079566897\n",
      "Validation accuracy = 0.53125\n",
      "Validation loss = 0.29125217348337173\n",
      "Epoch 0189 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.6339285714285714\n",
      "Training loss = 0.2261804053241903\n",
      "Validation accuracy = 0.59375\n",
      "Validation loss = 0.2823301497846842\n",
      "Epoch 0190 / 0200\n",
      "=====================================\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training accuracy = 0.634109649122807\n",
      "Training loss = 0.22609025485310377\n",
      "Validation accuracy = 0.5625\n",
      "Validation loss = 0.263543589040637\n",
      "Epoch 0191 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.6342277486910994\n",
      "Training loss = 0.22597653184281125\n",
      "Validation accuracy = 0.5625\n",
      "Validation loss = 0.28875882737338543\n",
      "Epoch 0192 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.6344097222222222\n",
      "Training loss = 0.22585775672432243\n",
      "Validation accuracy = 0.625\n",
      "Validation loss = 0.2758203577250242\n",
      "Epoch 0193 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.6346113989637305\n",
      "Training loss = 0.2257570537065183\n",
      "Validation accuracy = 0.53125\n",
      "Validation loss = 0.2757320757955313\n",
      "Epoch 0194 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.6347551546391753\n",
      "Training loss = 0.22568693972304718\n",
      "Validation accuracy = 0.5\n",
      "Validation loss = 0.28572014532983303\n",
      "Epoch 0195 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.6350854700854701\n",
      "Training loss = 0.22554272950408805\n",
      "Validation accuracy = 0.4375\n",
      "Validation loss = 0.3222861476242542\n",
      "Epoch 0196 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.6353231292517006\n",
      "Training loss = 0.2254242736730902\n",
      "Validation accuracy = 0.53125\n",
      "Validation loss = 0.3008474539965391\n",
      "Epoch 0197 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.6356598984771573\n",
      "Training loss = 0.22527277931772716\n",
      "Validation accuracy = 0.4375\n",
      "Validation loss = 0.29213789850473404\n",
      "Epoch 0198 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.6359175084175084\n",
      "Training loss = 0.22516776520846668\n",
      "Validation accuracy = 0.5625\n",
      "Validation loss = 0.2676483178511262\n",
      "Epoch 0199 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.6361809045226131\n",
      "Training loss = 0.2250241159524151\n",
      "Validation accuracy = 0.5625\n",
      "Validation loss = 0.28725866228342056\n",
      "Epoch 0200 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.6363041666666667\n",
      "Training loss = 0.22493450950719415\n",
      "Validation accuracy = 0.53125\n",
      "Validation loss = 0.26841662265360355\n",
      "Making model for session group 20210310_15:30:50.167-20210319_16:17:22.477\n",
      "Epoch 0001 / 0200\n",
      "=====================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/imblearn/utils/_validation.py:326: UserWarning: After over-sampling, the number of samples (300) in class car will be larger than the number of samples in the majority class (class #signpost -> 160)\n",
      "  n_samples_majority,\n",
      "/usr/local/lib/python3.6/dist-packages/imblearn/utils/_validation.py:326: UserWarning: After over-sampling, the number of samples (300) in class signpost will be larger than the number of samples in the majority class (class #signpost -> 160)\n",
      "  n_samples_majority,\n",
      "/usr/local/lib/python3.6/dist-packages/imblearn/utils/_validation.py:326: UserWarning: After over-sampling, the number of samples (300) in class tree will be larger than the number of samples in the majority class (class #signpost -> 160)\n",
      "  n_samples_majority,\n",
      "/usr/local/lib/python3.6/dist-packages/imblearn/utils/_validation.py:326: UserWarning: After over-sampling, the number of samples (300) in class wall will be larger than the number of samples in the majority class (class #signpost -> 160)\n",
      "  n_samples_majority,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training accuracy = 0.43\n",
      "Training loss = 0.3138992238541444\n",
      "Validation accuracy = 0.625\n",
      "Validation loss = 0.2783141937106848\n",
      "Epoch 0002 / 0200\n",
      "=====================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/_classification.py:1221: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training accuracy = 0.4583333333333333\n",
      "Training loss = 0.3031561896453301\n",
      "Validation accuracy = 0.53125\n",
      "Validation loss = 0.26309051364660263\n",
      "Epoch 0003 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.4727777777777778\n",
      "Training loss = 0.29609364908602503\n",
      "Validation accuracy = 0.875\n",
      "Validation loss = 0.2405892238020897\n",
      "Epoch 0004 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.49083333333333334\n",
      "Training loss = 0.2897832726066311\n",
      "Validation accuracy = 0.84375\n",
      "Validation loss = 0.23626815527677536\n",
      "Epoch 0005 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.4995\n",
      "Training loss = 0.28562053546806176\n",
      "Validation accuracy = 0.71875\n",
      "Validation loss = 0.2129172496497631\n",
      "Epoch 0006 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.5086111111111111\n",
      "Training loss = 0.28184482410136197\n",
      "Validation accuracy = 0.75\n",
      "Validation loss = 0.21762819960713387\n",
      "Epoch 0007 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.5175\n",
      "Training loss = 0.27844148977171806\n",
      "Validation accuracy = 0.8125\n",
      "Validation loss = 0.22012073453515768\n",
      "Epoch 0008 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.5234375\n",
      "Training loss = 0.27650112584233283\n",
      "Validation accuracy = 0.5625\n",
      "Validation loss = 0.21696955151855946\n",
      "Epoch 0009 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.5287962962962963\n",
      "Training loss = 0.2743024353351858\n",
      "Validation accuracy = 0.78125\n",
      "Validation loss = 0.20564084686338902\n",
      "Epoch 0010 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.5330833333333334\n",
      "Training loss = 0.2725974959010879\n",
      "Validation accuracy = 0.8125\n",
      "Validation loss = 0.21002343017607927\n",
      "Epoch 0011 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.5331818181818182\n",
      "Training loss = 0.2722135215117173\n",
      "Validation accuracy = 0.75\n",
      "Validation loss = 0.19624239392578602\n",
      "Epoch 0012 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.5365972222222222\n",
      "Training loss = 0.2711360829261442\n",
      "Validation accuracy = 0.65625\n",
      "Validation loss = 0.205170345492661\n",
      "Epoch 0013 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.538974358974359\n",
      "Training loss = 0.2699760133161759\n",
      "Validation accuracy = 0.71875\n",
      "Validation loss = 0.20433699898421764\n",
      "Epoch 0014 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.5424404761904762\n",
      "Training loss = 0.2685062494962698\n",
      "Validation accuracy = 0.78125\n",
      "Validation loss = 0.20470750890672207\n",
      "Epoch 0015 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.5440555555555555\n",
      "Training loss = 0.26744423508312964\n",
      "Validation accuracy = 0.71875\n",
      "Validation loss = 0.20019976422190666\n",
      "Epoch 0016 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.5468229166666667\n",
      "Training loss = 0.26611625985552867\n",
      "Validation accuracy = 0.8125\n",
      "Validation loss = 0.20639482885599136\n",
      "Epoch 0017 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.5472549019607843\n",
      "Training loss = 0.26548380478193945\n",
      "Validation accuracy = 0.875\n",
      "Validation loss = 0.17567791789770126\n",
      "Epoch 0018 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.5494907407407408\n",
      "Training loss = 0.2647617126352809\n",
      "Validation accuracy = 0.6875\n",
      "Validation loss = 0.2141767106950283\n",
      "Epoch 0019 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.5500877192982456\n",
      "Training loss = 0.26413012289425786\n",
      "Validation accuracy = 0.65625\n",
      "Validation loss = 0.22582711651921272\n",
      "Epoch 0020 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.552125\n",
      "Training loss = 0.263245273626099\n",
      "Validation accuracy = 0.8125\n",
      "Validation loss = 0.19876380637288094\n",
      "Epoch 0021 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.5536507936507936\n",
      "Training loss = 0.26250533540925336\n",
      "Validation accuracy = 0.75\n",
      "Validation loss = 0.19883479457348585\n",
      "Epoch 0022 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.5556818181818182\n",
      "Training loss = 0.2616180301773729\n",
      "Validation accuracy = 0.625\n",
      "Validation loss = 0.21526462025940418\n",
      "Epoch 0023 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.558804347826087\n",
      "Training loss = 0.26046717314076595\n",
      "Validation accuracy = 0.71875\n",
      "Validation loss = 0.1978013589978218\n",
      "Epoch 0024 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.5603125\n",
      "Training loss = 0.26001131660408444\n",
      "Validation accuracy = 0.8125\n",
      "Validation loss = 0.1880631586536765\n",
      "Epoch 0025 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.5619333333333333\n",
      "Training loss = 0.2592487581501404\n",
      "Validation accuracy = 0.75\n",
      "Validation loss = 0.18843695055693388\n",
      "Epoch 0026 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.561923076923077\n",
      "Training loss = 0.2593504297265258\n",
      "Validation accuracy = 0.78125\n",
      "Validation loss = 0.19617504440248013\n",
      "Epoch 0027 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.563179012345679\n",
      "Training loss = 0.2587802281663006\n",
      "Validation accuracy = 0.84375\n",
      "Validation loss = 0.19600302912294865\n",
      "Epoch 0028 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.5641964285714286\n",
      "Training loss = 0.258241016172937\n",
      "Validation accuracy = 0.75\n",
      "Validation loss = 0.18326561897993088\n",
      "Epoch 0029 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.565\n",
      "Training loss = 0.25774145561902\n",
      "Validation accuracy = 0.75\n",
      "Validation loss = 0.17837155796587467\n",
      "Epoch 0030 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.566\n",
      "Training loss = 0.2573507216854228\n",
      "Validation accuracy = 0.6875\n",
      "Validation loss = 0.20220758207142353\n",
      "Epoch 0031 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.567258064516129\n",
      "Training loss = 0.2565927329547303\n",
      "Validation accuracy = 0.84375\n",
      "Validation loss = 0.1715218098834157\n",
      "Epoch 0032 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.5680989583333333\n",
      "Training loss = 0.2559892808110453\n",
      "Validation accuracy = 0.75\n",
      "Validation loss = 0.20088688749819994\n",
      "Epoch 0033 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.5692929292929293\n",
      "Training loss = 0.25558654399306485\n",
      "Validation accuracy = 0.84375\n",
      "Validation loss = 0.1713536949828267\n",
      "Epoch 0034 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.5707107843137255\n",
      "Training loss = 0.2549722911147218\n",
      "Validation accuracy = 0.84375\n",
      "Validation loss = 0.1903324956074357\n",
      "Epoch 0035 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.5721190476190476\n",
      "Training loss = 0.2546018178782293\n",
      "Validation accuracy = 0.75\n",
      "Validation loss = 0.18655914720147848\n",
      "Epoch 0036 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.573125\n",
      "Training loss = 0.2541346886374608\n",
      "Validation accuracy = 0.84375\n",
      "Validation loss = 0.17378076910972595\n",
      "Epoch 0037 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.5738063063063064\n",
      "Training loss = 0.2537298220872611\n",
      "Validation accuracy = 0.6875\n",
      "Validation loss = 0.19514038786292076\n",
      "Epoch 0038 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.5746271929824561\n",
      "Training loss = 0.25333175902173183\n",
      "Validation accuracy = 0.78125\n",
      "Validation loss = 0.19469312019646168\n",
      "Epoch 0039 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.576068376068376\n",
      "Training loss = 0.2527677709227189\n",
      "Validation accuracy = 0.625\n",
      "Validation loss = 0.2082243673503399\n",
      "Epoch 0040 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.5770208333333333\n",
      "Training loss = 0.25227668045523266\n",
      "Validation accuracy = 0.78125\n",
      "Validation loss = 0.20944813452661037\n",
      "Epoch 0041 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.578089430894309\n",
      "Training loss = 0.25170007508641823\n",
      "Validation accuracy = 0.78125\n",
      "Validation loss = 0.17813748121261597\n",
      "Epoch 0042 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.5787301587301588\n",
      "Training loss = 0.2514239981226505\n",
      "Validation accuracy = 0.84375\n",
      "Validation loss = 0.16958833765238523\n",
      "Epoch 0043 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.579437984496124\n",
      "Training loss = 0.2509555573536213\n",
      "Validation accuracy = 0.6875\n",
      "Validation loss = 0.19269685726612806\n",
      "Epoch 0044 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.5801515151515152\n",
      "Training loss = 0.2507299844914991\n",
      "Validation accuracy = 0.8125\n",
      "Validation loss = 0.2021185178309679\n",
      "Epoch 0045 / 0200\n",
      "=====================================\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training accuracy = 0.5805555555555556\n",
      "Training loss = 0.2505406666469795\n",
      "Validation accuracy = 0.8125\n",
      "Validation loss = 0.19327092356979847\n",
      "Epoch 0046 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.5808333333333333\n",
      "Training loss = 0.25024164745341176\n",
      "Validation accuracy = 0.84375\n",
      "Validation loss = 0.16631543077528477\n",
      "Epoch 0047 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.5813297872340426\n",
      "Training loss = 0.2498656564374976\n",
      "Validation accuracy = 0.78125\n",
      "Validation loss = 0.16774648241698742\n",
      "Epoch 0048 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.5821875\n",
      "Training loss = 0.24939877681227193\n",
      "Validation accuracy = 0.875\n",
      "Validation loss = 0.1797372130677104\n",
      "Epoch 0049 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.5828571428571429\n",
      "Training loss = 0.2490189662398327\n",
      "Validation accuracy = 0.78125\n",
      "Validation loss = 0.17797076608985662\n",
      "Epoch 0050 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.5835166666666667\n",
      "Training loss = 0.24868375822057326\n",
      "Validation accuracy = 0.59375\n",
      "Validation loss = 0.2315489910542965\n",
      "Epoch 0051 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.5843137254901961\n",
      "Training loss = 0.24816914790449968\n",
      "Validation accuracy = 0.8125\n",
      "Validation loss = 0.16448288690298796\n",
      "Epoch 0052 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.5848878205128205\n",
      "Training loss = 0.24794149530526155\n",
      "Validation accuracy = 0.78125\n",
      "Validation loss = 0.1642167791724205\n",
      "Epoch 0053 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.5857232704402515\n",
      "Training loss = 0.24744084867525776\n",
      "Validation accuracy = 0.75\n",
      "Validation loss = 0.17785415053367615\n",
      "Epoch 0054 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.5861728395061728\n",
      "Training loss = 0.2472340814617497\n",
      "Validation accuracy = 0.75\n",
      "Validation loss = 0.17986243031919003\n",
      "Epoch 0055 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.5867878787878787\n",
      "Training loss = 0.24693831365578103\n",
      "Validation accuracy = 0.59375\n",
      "Validation loss = 0.20980654284358025\n",
      "Epoch 0056 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.5873809523809523\n",
      "Training loss = 0.2466019844059788\n",
      "Validation accuracy = 0.6875\n",
      "Validation loss = 0.19211578462272882\n",
      "Epoch 0057 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.5874415204678363\n",
      "Training loss = 0.24653757885708447\n",
      "Validation accuracy = 0.625\n",
      "Validation loss = 0.19461148604750633\n",
      "Epoch 0058 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.5883908045977011\n",
      "Training loss = 0.2461723861115417\n",
      "Validation accuracy = 0.6875\n",
      "Validation loss = 0.21549035515636206\n",
      "Epoch 0059 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.5890112994350283\n",
      "Training loss = 0.24590447266770285\n",
      "Validation accuracy = 0.84375\n",
      "Validation loss = 0.17808339186012745\n",
      "Epoch 0060 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.5896111111111111\n",
      "Training loss = 0.24562513307316436\n",
      "Validation accuracy = 0.84375\n",
      "Validation loss = 0.17056390270590782\n",
      "Epoch 0061 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.5898087431693989\n",
      "Training loss = 0.24541303210896873\n",
      "Validation accuracy = 0.78125\n",
      "Validation loss = 0.18550339713692665\n",
      "Epoch 0062 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.5903763440860215\n",
      "Training loss = 0.24520592185598547\n",
      "Validation accuracy = 0.40625\n",
      "Validation loss = 0.27447478100657463\n",
      "Epoch 0063 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.5907010582010582\n",
      "Training loss = 0.24491676803500878\n",
      "Validation accuracy = 0.78125\n",
      "Validation loss = 0.1790851429104805\n",
      "Epoch 0064 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.5908984375\n",
      "Training loss = 0.24474901841953398\n",
      "Validation accuracy = 0.65625\n",
      "Validation loss = 0.2031408865004778\n",
      "Epoch 0065 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.5915128205128205\n",
      "Training loss = 0.24440982066973663\n",
      "Validation accuracy = 0.84375\n",
      "Validation loss = 0.1708591990172863\n",
      "Epoch 0066 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.591729797979798\n",
      "Training loss = 0.24422393747464274\n",
      "Validation accuracy = 0.65625\n",
      "Validation loss = 0.2057016035541892\n",
      "Epoch 0067 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.5921268656716417\n",
      "Training loss = 0.2439319550186692\n",
      "Validation accuracy = 0.65625\n",
      "Validation loss = 0.18290952499955893\n",
      "Epoch 0068 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.5927083333333333\n",
      "Training loss = 0.24366161394060826\n",
      "Validation accuracy = 0.75\n",
      "Validation loss = 0.1591726979240775\n",
      "Epoch 0069 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.5931400966183575\n",
      "Training loss = 0.24350868096674122\n",
      "Validation accuracy = 0.84375\n",
      "Validation loss = 0.17101443465799093\n",
      "Epoch 0070 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.5935\n",
      "Training loss = 0.24326231135427953\n",
      "Validation accuracy = 0.84375\n",
      "Validation loss = 0.16906359046697617\n",
      "Epoch 0071 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.5937910798122066\n",
      "Training loss = 0.2431792589563859\n",
      "Validation accuracy = 0.65625\n",
      "Validation loss = 0.17508972436189651\n",
      "Epoch 0072 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.5945486111111111\n",
      "Training loss = 0.24283028632367926\n",
      "Validation accuracy = 0.71875\n",
      "Validation loss = 0.18901599012315273\n",
      "Epoch 0073 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.5952397260273973\n",
      "Training loss = 0.24254003238086014\n",
      "Validation accuracy = 0.78125\n",
      "Validation loss = 0.1940504051744938\n",
      "Epoch 0074 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.5954391891891891\n",
      "Training loss = 0.24236381057079312\n",
      "Validation accuracy = 0.6875\n",
      "Validation loss = 0.19908616784960032\n",
      "Epoch 0075 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.5958333333333333\n",
      "Training loss = 0.24217202157179515\n",
      "Validation accuracy = 0.78125\n",
      "Validation loss = 0.1961391344666481\n",
      "Epoch 0076 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.5962280701754386\n",
      "Training loss = 0.24202538118158515\n",
      "Validation accuracy = 0.84375\n",
      "Validation loss = 0.1733165131881833\n",
      "Epoch 0077 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.5966341991341991\n",
      "Training loss = 0.24185079658734593\n",
      "Validation accuracy = 0.65625\n",
      "Validation loss = 0.18207714054733515\n",
      "Epoch 0078 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.5973290598290598\n",
      "Training loss = 0.24157841586117815\n",
      "Validation accuracy = 0.84375\n",
      "Validation loss = 0.17058854456990957\n",
      "Epoch 0079 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.5977426160337552\n",
      "Training loss = 0.2413595833978321\n",
      "Validation accuracy = 0.875\n",
      "Validation loss = 0.1761382333934307\n",
      "Epoch 0080 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.5982291666666667\n",
      "Training loss = 0.24121377139817923\n",
      "Validation accuracy = 0.78125\n",
      "Validation loss = 0.16563559882342815\n",
      "Epoch 0081 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.5986419753086419\n",
      "Training loss = 0.24110714295518743\n",
      "Validation accuracy = 0.78125\n",
      "Validation loss = 0.18941087927669287\n",
      "Epoch 0082 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.5988617886178862\n",
      "Training loss = 0.24101813133593983\n",
      "Validation accuracy = 0.6875\n",
      "Validation loss = 0.20598023384809494\n",
      "Epoch 0083 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.5995180722891567\n",
      "Training loss = 0.24077506284218236\n",
      "Validation accuracy = 0.65625\n",
      "Validation loss = 0.18868804164230824\n",
      "Epoch 0084 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.6001289682539682\n",
      "Training loss = 0.2404919920826242\n",
      "Validation accuracy = 0.59375\n",
      "Validation loss = 0.2264178805053234\n",
      "Epoch 0085 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.6005882352941176\n",
      "Training loss = 0.24019308045886312\n",
      "Validation accuracy = 0.84375\n",
      "Validation loss = 0.14510096237063408\n",
      "Epoch 0086 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.6011143410852713\n",
      "Training loss = 0.23998999209049368\n",
      "Validation accuracy = 0.6875\n",
      "Validation loss = 0.19567483756691217\n",
      "Epoch 0087 / 0200\n",
      "=====================================\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training accuracy = 0.601772030651341\n",
      "Training loss = 0.23971071476908937\n",
      "Validation accuracy = 0.65625\n",
      "Validation loss = 0.17116353567689657\n",
      "Epoch 0088 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.6020643939393939\n",
      "Training loss = 0.23956303798198475\n",
      "Validation accuracy = 0.78125\n",
      "Validation loss = 0.17546247318387032\n",
      "Epoch 0089 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.6024906367041198\n",
      "Training loss = 0.2393840382292811\n",
      "Validation accuracy = 0.75\n",
      "Validation loss = 0.1696261242032051\n",
      "Epoch 0090 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.6027037037037037\n",
      "Training loss = 0.23931535103310037\n",
      "Validation accuracy = 0.84375\n",
      "Validation loss = 0.14910661708563566\n",
      "Epoch 0091 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.6028296703296703\n",
      "Training loss = 0.23920109733256883\n",
      "Validation accuracy = 0.71875\n",
      "Validation loss = 0.15798604022711515\n",
      "Epoch 0092 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.6030072463768116\n",
      "Training loss = 0.23908540707081558\n",
      "Validation accuracy = 0.65625\n",
      "Validation loss = 0.19297881983220577\n",
      "Epoch 0093 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.6032706093189965\n",
      "Training loss = 0.2389186315983534\n",
      "Validation accuracy = 0.78125\n",
      "Validation loss = 0.15096957609057426\n",
      "Epoch 0094 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.6035904255319149\n",
      "Training loss = 0.2387774705313516\n",
      "Validation accuracy = 0.53125\n",
      "Validation loss = 0.23568908870220184\n",
      "Epoch 0095 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.6037894736842105\n",
      "Training loss = 0.23868423827698357\n",
      "Validation accuracy = 0.78125\n",
      "Validation loss = 0.16871237196028233\n",
      "Epoch 0096 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.6041145833333333\n",
      "Training loss = 0.23841673548540307\n",
      "Validation accuracy = 0.875\n",
      "Validation loss = 0.17263820953667164\n",
      "Epoch 0097 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.6046649484536083\n",
      "Training loss = 0.23814165069219173\n",
      "Validation accuracy = 0.84375\n",
      "Validation loss = 0.1672770380973816\n",
      "Epoch 0098 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.6048044217687075\n",
      "Training loss = 0.2380078126307653\n",
      "Validation accuracy = 0.84375\n",
      "Validation loss = 0.1538117816671729\n",
      "Epoch 0099 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.6051178451178452\n",
      "Training loss = 0.23785443557758726\n",
      "Validation accuracy = 0.65625\n",
      "Validation loss = 0.18945952877402306\n",
      "Epoch 0100 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.605475\n",
      "Training loss = 0.2376706127755344\n",
      "Validation accuracy = 0.71875\n",
      "Validation loss = 0.18084644433110952\n",
      "Epoch 0101 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.6058910891089109\n",
      "Training loss = 0.2374691839044047\n",
      "Validation accuracy = 0.84375\n",
      "Validation loss = 0.15484129823744297\n",
      "Epoch 0102 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.6061192810457516\n",
      "Training loss = 0.23731285214278044\n",
      "Validation accuracy = 0.875\n",
      "Validation loss = 0.16861664596945047\n",
      "Epoch 0103 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.6065533980582525\n",
      "Training loss = 0.23708532647407557\n",
      "Validation accuracy = 0.875\n",
      "Validation loss = 0.15550652332603931\n",
      "Epoch 0104 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.6069711538461539\n",
      "Training loss = 0.23689470478381294\n",
      "Validation accuracy = 0.6875\n",
      "Validation loss = 0.19465898908674717\n",
      "Epoch 0105 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.6071111111111112\n",
      "Training loss = 0.2367911343654943\n",
      "Validation accuracy = 0.78125\n",
      "Validation loss = 0.15905439294874668\n",
      "Epoch 0106 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.6074449685534591\n",
      "Training loss = 0.2366839688325172\n",
      "Validation accuracy = 0.65625\n",
      "Validation loss = 0.1743664750829339\n",
      "Epoch 0107 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.6077102803738318\n",
      "Training loss = 0.23651744040512593\n",
      "Validation accuracy = 0.8125\n",
      "Validation loss = 0.1621085051447153\n",
      "Epoch 0108 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.608125\n",
      "Training loss = 0.23631907277867015\n",
      "Validation accuracy = 0.65625\n",
      "Validation loss = 0.17626983486115932\n",
      "Epoch 0109 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.6083792048929664\n",
      "Training loss = 0.2361735484632877\n",
      "Validation accuracy = 0.84375\n",
      "Validation loss = 0.1623979266732931\n",
      "Epoch 0110 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.6084545454545455\n",
      "Training loss = 0.23607503036251573\n",
      "Validation accuracy = 0.71875\n",
      "Validation loss = 0.18324713502079248\n",
      "Epoch 0111 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.6087687687687687\n",
      "Training loss = 0.23596221520199073\n",
      "Validation accuracy = 0.8125\n",
      "Validation loss = 0.18981597758829594\n",
      "Epoch 0112 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.6091964285714285\n",
      "Training loss = 0.23579082361511178\n",
      "Validation accuracy = 0.84375\n",
      "Validation loss = 0.17295538447797298\n",
      "Epoch 0113 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.6096165191740412\n",
      "Training loss = 0.2356365069735982\n",
      "Validation accuracy = 0.84375\n",
      "Validation loss = 0.18120951857417822\n",
      "Epoch 0114 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.6098172514619883\n",
      "Training loss = 0.23551588133173554\n",
      "Validation accuracy = 0.71875\n",
      "Validation loss = 0.16154679469764233\n",
      "Epoch 0115 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.6100869565217392\n",
      "Training loss = 0.23537010840488518\n",
      "Validation accuracy = 0.625\n",
      "Validation loss = 0.2025593938305974\n",
      "Epoch 0116 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.6104741379310344\n",
      "Training loss = 0.23517679791362292\n",
      "Validation accuracy = 0.84375\n",
      "Validation loss = 0.18609843589365482\n",
      "Epoch 0117 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.6108903133903134\n",
      "Training loss = 0.23499852401345034\n",
      "Validation accuracy = 0.71875\n",
      "Validation loss = 0.1691348310559988\n",
      "Epoch 0118 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.6110381355932203\n",
      "Training loss = 0.23493386791040333\n",
      "Validation accuracy = 0.84375\n",
      "Validation loss = 0.16390797309577465\n",
      "Epoch 0119 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.6112044817927171\n",
      "Training loss = 0.23484163721381615\n",
      "Validation accuracy = 0.78125\n",
      "Validation loss = 0.16060934122651815\n",
      "Epoch 0120 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.6114097222222222\n",
      "Training loss = 0.2347162009343091\n",
      "Validation accuracy = 0.8125\n",
      "Validation loss = 0.16378882806748152\n",
      "Epoch 0121 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.6116666666666667\n",
      "Training loss = 0.23458924561184794\n",
      "Validation accuracy = 0.84375\n",
      "Validation loss = 0.1715935692191124\n",
      "Epoch 0122 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.6120560109289618\n",
      "Training loss = 0.23437244841879834\n",
      "Validation accuracy = 0.6875\n",
      "Validation loss = 0.1889308551326394\n",
      "Epoch 0123 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.6125\n",
      "Training loss = 0.23417118329181258\n",
      "Validation accuracy = 0.6875\n",
      "Validation loss = 0.1780104599893093\n",
      "Epoch 0124 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.6126881720430107\n",
      "Training loss = 0.23405927288135694\n",
      "Validation accuracy = 0.75\n",
      "Validation loss = 0.16760412696748972\n",
      "Epoch 0125 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.6129733333333334\n",
      "Training loss = 0.2339060300117731\n",
      "Validation accuracy = 0.78125\n",
      "Validation loss = 0.1786439809948206\n",
      "Epoch 0126 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.613287037037037\n",
      "Training loss = 0.23375858432835056\n",
      "Validation accuracy = 0.8125\n",
      "Validation loss = 0.18020244967192411\n",
      "Epoch 0127 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.6134645669291339\n",
      "Training loss = 0.23368078365706865\n",
      "Validation accuracy = 0.71875\n",
      "Validation loss = 0.195533717982471\n",
      "Epoch 0128 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.6135872395833334\n",
      "Training loss = 0.23363883464810595\n",
      "Validation accuracy = 0.84375\n",
      "Validation loss = 0.17885721568018198\n",
      "Epoch 0129 / 0200\n",
      "=====================================\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training accuracy = 0.6139276485788113\n",
      "Training loss = 0.23349027211313408\n",
      "Validation accuracy = 0.65625\n",
      "Validation loss = 0.19251393899321556\n",
      "Epoch 0130 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.6140897435897436\n",
      "Training loss = 0.23336430009779258\n",
      "Validation accuracy = 0.59375\n",
      "Validation loss = 0.19407940562814474\n",
      "Epoch 0131 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.6144020356234097\n",
      "Training loss = 0.23323597426841428\n",
      "Validation accuracy = 0.84375\n",
      "Validation loss = 0.16885375697165728\n",
      "Epoch 0132 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.6146338383838383\n",
      "Training loss = 0.23310467895346157\n",
      "Validation accuracy = 0.6875\n",
      "Validation loss = 0.21090861689299345\n",
      "Epoch 0133 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.614906015037594\n",
      "Training loss = 0.2329661976456418\n",
      "Validation accuracy = 0.6875\n",
      "Validation loss = 0.1858426947146654\n",
      "Epoch 0134 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.615136815920398\n",
      "Training loss = 0.23290965036169362\n",
      "Validation accuracy = 0.78125\n",
      "Validation loss = 0.17417146544903517\n",
      "Epoch 0135 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.6154444444444445\n",
      "Training loss = 0.23278145799463915\n",
      "Validation accuracy = 0.75\n",
      "Validation loss = 0.1754388902336359\n",
      "Epoch 0136 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.6157843137254903\n",
      "Training loss = 0.23261469551471664\n",
      "Validation accuracy = 0.78125\n",
      "Validation loss = 0.1738209156319499\n",
      "Epoch 0137 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.6160097323600974\n",
      "Training loss = 0.23247079579281982\n",
      "Validation accuracy = 0.84375\n",
      "Validation loss = 0.13077997416257858\n",
      "Epoch 0138 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.616207729468599\n",
      "Training loss = 0.23241291448941842\n",
      "Validation accuracy = 0.625\n",
      "Validation loss = 0.18904597777873278\n",
      "Epoch 0139 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.6164448441247002\n",
      "Training loss = 0.23229974578610427\n",
      "Validation accuracy = 0.8125\n",
      "Validation loss = 0.1487748334184289\n",
      "Epoch 0140 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.6167857142857143\n",
      "Training loss = 0.23218242676928638\n",
      "Validation accuracy = 0.8125\n",
      "Validation loss = 0.17558413837105036\n",
      "Epoch 0141 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.6169917257683215\n",
      "Training loss = 0.23202185137386722\n",
      "Validation accuracy = 0.71875\n",
      "Validation loss = 0.17848196160048246\n",
      "Epoch 0142 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.6171830985915493\n",
      "Training loss = 0.23187299177820134\n",
      "Validation accuracy = 0.71875\n",
      "Validation loss = 0.17922650650143623\n",
      "Epoch 0143 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.6174417249417249\n",
      "Training loss = 0.23180253780318863\n",
      "Validation accuracy = 0.75\n",
      "Validation loss = 0.1608328027650714\n",
      "Epoch 0144 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.6176967592592593\n",
      "Training loss = 0.23169942685592643\n",
      "Validation accuracy = 0.75\n",
      "Validation loss = 0.1500586336478591\n",
      "Epoch 0145 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.6181264367816092\n",
      "Training loss = 0.23154080396085636\n",
      "Validation accuracy = 0.71875\n",
      "Validation loss = 0.17647775821387768\n",
      "Epoch 0146 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.6182420091324201\n",
      "Training loss = 0.23147779432980164\n",
      "Validation accuracy = 0.75\n",
      "Validation loss = 0.1551949568092823\n",
      "Epoch 0147 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.6184863945578232\n",
      "Training loss = 0.23135722655777624\n",
      "Validation accuracy = 0.78125\n",
      "Validation loss = 0.17466618306934834\n",
      "Epoch 0148 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.6187331081081081\n",
      "Training loss = 0.23123389852912846\n",
      "Validation accuracy = 0.65625\n",
      "Validation loss = 0.19815214164555073\n",
      "Epoch 0149 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.6189261744966443\n",
      "Training loss = 0.23109963985547524\n",
      "Validation accuracy = 0.75\n",
      "Validation loss = 0.1777220256626606\n",
      "Epoch 0150 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.6193555555555555\n",
      "Training loss = 0.23091101541452938\n",
      "Validation accuracy = 0.8125\n",
      "Validation loss = 0.1600667256861925\n",
      "Epoch 0151 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.619569536423841\n",
      "Training loss = 0.2308358193233313\n",
      "Validation accuracy = 0.65625\n",
      "Validation loss = 0.1972259385511279\n",
      "Epoch 0152 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.6197532894736842\n",
      "Training loss = 0.2307205249748209\n",
      "Validation accuracy = 0.84375\n",
      "Validation loss = 0.15837194584310055\n",
      "Epoch 0153 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.6198583877995643\n",
      "Training loss = 0.23060670044362416\n",
      "Validation accuracy = 0.90625\n",
      "Validation loss = 0.15581928193569183\n",
      "Epoch 0154 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.6201298701298701\n",
      "Training loss = 0.23047671241161627\n",
      "Validation accuracy = 0.8125\n",
      "Validation loss = 0.16579672414809465\n",
      "Epoch 0155 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.6203978494623655\n",
      "Training loss = 0.23038179151056914\n",
      "Validation accuracy = 0.8125\n",
      "Validation loss = 0.15532686281949282\n",
      "Epoch 0156 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.6206089743589743\n",
      "Training loss = 0.23025764752832106\n",
      "Validation accuracy = 0.78125\n",
      "Validation loss = 0.1649042246863246\n",
      "Epoch 0157 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.620764331210191\n",
      "Training loss = 0.2301673393155549\n",
      "Validation accuracy = 0.84375\n",
      "Validation loss = 0.1263099815696478\n",
      "Epoch 0158 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.6208649789029536\n",
      "Training loss = 0.23010088568152506\n",
      "Validation accuracy = 0.8125\n",
      "Validation loss = 0.17475340142846107\n",
      "Epoch 0159 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.6209276729559748\n",
      "Training loss = 0.2300573960426156\n",
      "Validation accuracy = 0.78125\n",
      "Validation loss = 0.15520473942160606\n",
      "Epoch 0160 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.620984375\n",
      "Training loss = 0.23000780831230805\n",
      "Validation accuracy = 0.6875\n",
      "Validation loss = 0.1524384031072259\n",
      "Epoch 0161 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.6211180124223602\n",
      "Training loss = 0.22993023502160304\n",
      "Validation accuracy = 0.78125\n",
      "Validation loss = 0.14925233833491802\n",
      "Epoch 0162 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.6213477366255145\n",
      "Training loss = 0.22979501392109772\n",
      "Validation accuracy = 0.8125\n",
      "Validation loss = 0.127246817573905\n",
      "Epoch 0163 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.6215644171779141\n",
      "Training loss = 0.22969344438386963\n",
      "Validation accuracy = 0.5625\n",
      "Validation loss = 0.22807557974010706\n",
      "Epoch 0164 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.621875\n",
      "Training loss = 0.22955922909626147\n",
      "Validation accuracy = 0.84375\n",
      "Validation loss = 0.15593745280057192\n",
      "Epoch 0165 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.6221111111111111\n",
      "Training loss = 0.22949040372413818\n",
      "Validation accuracy = 0.75\n",
      "Validation loss = 0.16876400727778673\n",
      "Epoch 0166 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.6223845381526104\n",
      "Training loss = 0.2293832229017972\n",
      "Validation accuracy = 0.84375\n",
      "Validation loss = 0.15893268398940563\n",
      "Epoch 0167 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.6225399201596806\n",
      "Training loss = 0.22929583516901364\n",
      "Validation accuracy = 0.84375\n",
      "Validation loss = 0.1448172079399228\n",
      "Epoch 0168 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.6228025793650793\n",
      "Training loss = 0.22915827262377927\n",
      "Validation accuracy = 0.75\n",
      "Validation loss = 0.17329390347003937\n",
      "Epoch 0169 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.62301775147929\n",
      "Training loss = 0.22905820220076945\n",
      "Validation accuracy = 0.71875\n",
      "Validation loss = 0.1638427972793579\n",
      "Epoch 0170 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.6232941176470588\n",
      "Training loss = 0.22894284061371695\n",
      "Validation accuracy = 0.6875\n",
      "Validation loss = 0.15408898331224918\n",
      "Epoch 0171 / 0200\n",
      "=====================================\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training accuracy = 0.623620857699805\n",
      "Training loss = 0.22879702532892687\n",
      "Validation accuracy = 0.78125\n",
      "Validation loss = 0.1514277644455433\n",
      "Epoch 0172 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.6237403100775194\n",
      "Training loss = 0.22870385092026158\n",
      "Validation accuracy = 0.75\n",
      "Validation loss = 0.1688569411635399\n",
      "Epoch 0173 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.6238631984585742\n",
      "Training loss = 0.228619775274528\n",
      "Validation accuracy = 0.84375\n",
      "Validation loss = 0.16319110989570618\n",
      "Epoch 0174 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.6242193486590039\n",
      "Training loss = 0.2284869817327494\n",
      "Validation accuracy = 0.65625\n",
      "Validation loss = 0.16847181878983974\n",
      "Epoch 0175 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.624452380952381\n",
      "Training loss = 0.22834947403300376\n",
      "Validation accuracy = 0.78125\n",
      "Validation loss = 0.17252971604466438\n",
      "Epoch 0176 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.6247537878787879\n",
      "Training loss = 0.22823026274980018\n",
      "Validation accuracy = 0.90625\n",
      "Validation loss = 0.13878229167312384\n",
      "Epoch 0177 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.6249105461393597\n",
      "Training loss = 0.22816513754146808\n",
      "Validation accuracy = 0.84375\n",
      "Validation loss = 0.15764157380908728\n",
      "Epoch 0178 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.6251264044943821\n",
      "Training loss = 0.22804276120517583\n",
      "Validation accuracy = 0.875\n",
      "Validation loss = 0.1425453694537282\n",
      "Epoch 0179 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.6252839851024209\n",
      "Training loss = 0.22798857452358282\n",
      "Validation accuracy = 0.8125\n",
      "Validation loss = 0.14871754497289658\n",
      "Epoch 0180 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.6254074074074074\n",
      "Training loss = 0.22786895926600254\n",
      "Validation accuracy = 0.84375\n",
      "Validation loss = 0.17348739318549633\n",
      "Epoch 0181 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.625621546961326\n",
      "Training loss = 0.22771759603920344\n",
      "Validation accuracy = 0.8125\n",
      "Validation loss = 0.16295292135328054\n",
      "Epoch 0182 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.6256822344322345\n",
      "Training loss = 0.22766646274648633\n",
      "Validation accuracy = 0.65625\n",
      "Validation loss = 0.17739243805408478\n",
      "Epoch 0183 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.6260018214936248\n",
      "Training loss = 0.2275536583353153\n",
      "Validation accuracy = 0.75\n",
      "Validation loss = 0.15406147204339504\n",
      "Epoch 0184 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.626195652173913\n",
      "Training loss = 0.22747393277122815\n",
      "Validation accuracy = 0.8125\n",
      "Validation loss = 0.14896466210484505\n",
      "Epoch 0185 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.6263468468468468\n",
      "Training loss = 0.22736848121881484\n",
      "Validation accuracy = 0.8125\n",
      "Validation loss = 0.1555263064801693\n",
      "Epoch 0186 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.6265412186379928\n",
      "Training loss = 0.22726557357937738\n",
      "Validation accuracy = 0.8125\n",
      "Validation loss = 0.16616803593933582\n",
      "Epoch 0187 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.6267424242424242\n",
      "Training loss = 0.22718147575244335\n",
      "Validation accuracy = 0.59375\n",
      "Validation loss = 0.21517545264214277\n",
      "Epoch 0188 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.6271232269503546\n",
      "Training loss = 0.227006529259185\n",
      "Validation accuracy = 0.90625\n",
      "Validation loss = 0.15599680319428444\n",
      "Epoch 0189 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.6272927689594356\n",
      "Training loss = 0.22692362414071798\n",
      "Validation accuracy = 0.78125\n",
      "Validation loss = 0.16803286783397198\n",
      "Epoch 0190 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.6275394736842105\n",
      "Training loss = 0.22681283280828543\n",
      "Validation accuracy = 0.53125\n",
      "Validation loss = 0.20800070464611053\n",
      "Epoch 0191 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.6277225130890053\n",
      "Training loss = 0.2267161314797963\n",
      "Validation accuracy = 0.6875\n",
      "Validation loss = 0.1839108895510435\n",
      "Epoch 0192 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.6278819444444445\n",
      "Training loss = 0.2266367133310996\n",
      "Validation accuracy = 0.78125\n",
      "Validation loss = 0.1675966428592801\n",
      "Epoch 0193 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.6279620034542315\n",
      "Training loss = 0.22656061440423156\n",
      "Validation accuracy = 0.75\n",
      "Validation loss = 0.17528820969164371\n",
      "Epoch 0194 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.6282345360824743\n",
      "Training loss = 0.22643905134673176\n",
      "Validation accuracy = 0.6875\n",
      "Validation loss = 0.19059227779507637\n",
      "Epoch 0195 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.6284700854700854\n",
      "Training loss = 0.2263442399589679\n",
      "Validation accuracy = 0.78125\n",
      "Validation loss = 0.159772714599967\n",
      "Epoch 0196 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.6286522108843537\n",
      "Training loss = 0.22626197428841677\n",
      "Validation accuracy = 0.8125\n",
      "Validation loss = 0.1656158585101366\n",
      "Epoch 0197 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.6289043993231811\n",
      "Training loss = 0.22617098686646184\n",
      "Validation accuracy = 0.84375\n",
      "Validation loss = 0.1449987031519413\n",
      "Epoch 0198 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.6290993265993265\n",
      "Training loss = 0.22605706523401467\n",
      "Validation accuracy = 0.84375\n",
      "Validation loss = 0.1599441571161151\n",
      "Epoch 0199 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.6292211055276382\n",
      "Training loss = 0.2259618200130848\n",
      "Validation accuracy = 0.78125\n",
      "Validation loss = 0.18110515736043453\n",
      "Epoch 0200 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.6295\n",
      "Training loss = 0.22583102980442346\n",
      "Validation accuracy = 0.78125\n",
      "Validation loss = 0.1547063523903489\n",
      "Making model for session group 20210310_15:31:09.318-20210319_16:17:45.271\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/imblearn/utils/_validation.py:326: UserWarning: After over-sampling, the number of samples (300) in class car will be larger than the number of samples in the majority class (class #signpost -> 160)\n",
      "  n_samples_majority,\n",
      "/usr/local/lib/python3.6/dist-packages/imblearn/utils/_validation.py:326: UserWarning: After over-sampling, the number of samples (300) in class signpost will be larger than the number of samples in the majority class (class #signpost -> 160)\n",
      "  n_samples_majority,\n",
      "/usr/local/lib/python3.6/dist-packages/imblearn/utils/_validation.py:326: UserWarning: After over-sampling, the number of samples (300) in class tree will be larger than the number of samples in the majority class (class #signpost -> 160)\n",
      "  n_samples_majority,\n",
      "/usr/local/lib/python3.6/dist-packages/imblearn/utils/_validation.py:326: UserWarning: After over-sampling, the number of samples (300) in class wall will be larger than the number of samples in the majority class (class #signpost -> 160)\n",
      "  n_samples_majority,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0001 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.3275\n",
      "Training loss = 0.3337379808227221\n",
      "Validation accuracy = 0.5\n",
      "Validation loss = 0.31311042606830597\n",
      "Epoch 0002 / 0200\n",
      "=====================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/_classification.py:1221: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training accuracy = 0.4075\n",
      "Training loss = 0.32164346421758333\n",
      "Validation accuracy = 0.4375\n",
      "Validation loss = 0.29345205426216125\n",
      "Epoch 0003 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.44166666666666665\n",
      "Training loss = 0.31265358765920004\n",
      "Validation accuracy = 0.71875\n",
      "Validation loss = 0.2870268113911152\n",
      "Epoch 0004 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.46125\n",
      "Training loss = 0.3063804133608937\n",
      "Validation accuracy = 0.75\n",
      "Validation loss = 0.27782517299056053\n",
      "Epoch 0005 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.48\n",
      "Training loss = 0.30109224847952526\n",
      "Validation accuracy = 0.625\n",
      "Validation loss = 0.2798611279577017\n",
      "Epoch 0006 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.49444444444444446\n",
      "Training loss = 0.2964273943586482\n",
      "Validation accuracy = 0.71875\n",
      "Validation loss = 0.27377746999263763\n",
      "Epoch 0007 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.5022619047619048\n",
      "Training loss = 0.2933177894211951\n",
      "Validation accuracy = 0.46875\n",
      "Validation loss = 0.27706387639045715\n",
      "Epoch 0008 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.5080208333333334\n",
      "Training loss = 0.2898139872960746\n",
      "Validation accuracy = 0.6875\n",
      "Validation loss = 0.26690930128097534\n",
      "Epoch 0009 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.5141666666666667\n",
      "Training loss = 0.28717226409249835\n",
      "Validation accuracy = 0.65625\n",
      "Validation loss = 0.2580138463526964\n",
      "Epoch 0010 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.5186666666666667\n",
      "Training loss = 0.28446498621503513\n",
      "Validation accuracy = 0.6875\n",
      "Validation loss = 0.2720364909619093\n",
      "Epoch 0011 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.5222727272727272\n",
      "Training loss = 0.2823800983799226\n",
      "Validation accuracy = 0.65625\n",
      "Validation loss = 0.25565648637712\n",
      "Epoch 0012 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.5258333333333334\n",
      "Training loss = 0.2804625300318003\n",
      "Validation accuracy = 0.71875\n",
      "Validation loss = 0.2590146977454424\n",
      "Epoch 0013 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.5296153846153846\n",
      "Training loss = 0.2787319505902437\n",
      "Validation accuracy = 0.59375\n",
      "Validation loss = 0.25644025579094887\n",
      "Epoch 0014 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.5347619047619048\n",
      "Training loss = 0.27703873700329235\n",
      "Validation accuracy = 0.3125\n",
      "Validation loss = 0.273956798017025\n",
      "Epoch 0015 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.538\n",
      "Training loss = 0.2756486866441038\n",
      "Validation accuracy = 0.59375\n",
      "Validation loss = 0.26992570236325264\n",
      "Epoch 0016 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.5391145833333333\n",
      "Training loss = 0.2746158631006256\n",
      "Validation accuracy = 0.4375\n",
      "Validation loss = 0.2723452001810074\n",
      "Epoch 0017 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.5403921568627451\n",
      "Training loss = 0.27386559959574075\n",
      "Validation accuracy = 0.6875\n",
      "Validation loss = 0.25861113518476486\n",
      "Epoch 0018 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.5418981481481482\n",
      "Training loss = 0.27295036369313797\n",
      "Validation accuracy = 0.53125\n",
      "Validation loss = 0.2683740686625242\n",
      "Epoch 0019 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.5430263157894737\n",
      "Training loss = 0.2718903409532811\n",
      "Validation accuracy = 0.59375\n",
      "Validation loss = 0.26621573977172375\n",
      "Epoch 0020 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.5469166666666667\n",
      "Training loss = 0.27059957187871136\n",
      "Validation accuracy = 0.71875\n",
      "Validation loss = 0.2571629974991083\n",
      "Epoch 0021 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.5480158730158731\n",
      "Training loss = 0.2695650492904205\n",
      "Validation accuracy = 0.59375\n",
      "Validation loss = 0.24751758016645908\n",
      "Epoch 0022 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.5503030303030303\n",
      "Training loss = 0.2685779216117931\n",
      "Validation accuracy = 0.65625\n",
      "Validation loss = 0.2662748172879219\n",
      "Epoch 0023 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.5517391304347826\n",
      "Training loss = 0.2680438655398894\n",
      "Validation accuracy = 0.625\n",
      "Validation loss = 0.2567974366247654\n",
      "Epoch 0024 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.5538888888888889\n",
      "Training loss = 0.26731181382719016\n",
      "Validation accuracy = 0.65625\n",
      "Validation loss = 0.273432832211256\n",
      "Epoch 0025 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.556\n",
      "Training loss = 0.2663478656987349\n",
      "Validation accuracy = 0.46875\n",
      "Validation loss = 0.27107018791139126\n",
      "Epoch 0026 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.5580128205128205\n",
      "Training loss = 0.2654709302070431\n",
      "Validation accuracy = 0.5625\n",
      "Validation loss = 0.23369386047124863\n",
      "Epoch 0027 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.5593518518518519\n",
      "Training loss = 0.26495659436432667\n",
      "Validation accuracy = 0.59375\n",
      "Validation loss = 0.2558670062571764\n",
      "Epoch 0028 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.5598511904761905\n",
      "Training loss = 0.2647259801067412\n",
      "Validation accuracy = 0.4375\n",
      "Validation loss = 0.2683049291372299\n",
      "Epoch 0029 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.5604885057471264\n",
      "Training loss = 0.26420699444567336\n",
      "Validation accuracy = 0.59375\n",
      "Validation loss = 0.259240192361176\n",
      "Epoch 0030 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.5616388888888889\n",
      "Training loss = 0.26371144247882894\n",
      "Validation accuracy = 0.5\n",
      "Validation loss = 0.2636138554662466\n",
      "Epoch 0031 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.5629569892473119\n",
      "Training loss = 0.26295726445493517\n",
      "Validation accuracy = 0.71875\n",
      "Validation loss = 0.25110082887113094\n",
      "Epoch 0032 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.5636197916666666\n",
      "Training loss = 0.26244238037616013\n",
      "Validation accuracy = 0.59375\n",
      "Validation loss = 0.23970993980765343\n",
      "Epoch 0033 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.5646969696969697\n",
      "Training loss = 0.2617812078092435\n",
      "Validation accuracy = 0.53125\n",
      "Validation loss = 0.27387977577745914\n",
      "Epoch 0034 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.5652450980392156\n",
      "Training loss = 0.2612447185880121\n",
      "Validation accuracy = 0.40625\n",
      "Validation loss = 0.26262457482516766\n",
      "Epoch 0035 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.5664047619047619\n",
      "Training loss = 0.26060178630834535\n",
      "Validation accuracy = 0.625\n",
      "Validation loss = 0.2519272053614259\n",
      "Epoch 0036 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.5672453703703704\n",
      "Training loss = 0.26022477723865045\n",
      "Validation accuracy = 0.59375\n",
      "Validation loss = 0.24566163681447506\n",
      "Epoch 0037 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.5685135135135135\n",
      "Training loss = 0.2596569549030549\n",
      "Validation accuracy = 0.5\n",
      "Validation loss = 0.24637287762016058\n",
      "Epoch 0038 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.5692543859649123\n",
      "Training loss = 0.2592778432937829\n",
      "Validation accuracy = 0.5\n",
      "Validation loss = 0.24911048263311386\n",
      "Epoch 0039 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.5699786324786325\n",
      "Training loss = 0.25881704095400804\n",
      "Validation accuracy = 0.65625\n",
      "Validation loss = 0.23237926047295332\n",
      "Epoch 0040 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.5704583333333333\n",
      "Training loss = 0.2584464387781918\n",
      "Validation accuracy = 0.5\n",
      "Validation loss = 0.25220953673124313\n",
      "Epoch 0041 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.5710365853658537\n",
      "Training loss = 0.2580124252707493\n",
      "Validation accuracy = 0.5625\n",
      "Validation loss = 0.25171386264264584\n",
      "Epoch 0042 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.5721825396825397\n",
      "Training loss = 0.25754210876626155\n",
      "Validation accuracy = 0.59375\n",
      "Validation loss = 0.25005797296762466\n",
      "Epoch 0043 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.5736627906976745\n",
      "Training loss = 0.2567953307245129\n",
      "Validation accuracy = 0.59375\n",
      "Validation loss = 0.26716361474245787\n",
      "Epoch 0044 / 0200\n",
      "=====================================\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training accuracy = 0.5746969696969697\n",
      "Training loss = 0.25639372233357843\n",
      "Validation accuracy = 0.59375\n",
      "Validation loss = 0.25223279371857643\n",
      "Epoch 0045 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.5752407407407407\n",
      "Training loss = 0.2560805467896991\n",
      "Validation accuracy = 0.5\n",
      "Validation loss = 0.2849977910518646\n",
      "Epoch 0046 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.576268115942029\n",
      "Training loss = 0.2555505972053262\n",
      "Validation accuracy = 0.46875\n",
      "Validation loss = 0.2588329780846834\n",
      "Epoch 0047 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.5771631205673758\n",
      "Training loss = 0.2549507543983612\n",
      "Validation accuracy = 0.40625\n",
      "Validation loss = 0.2710170280188322\n",
      "Epoch 0048 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.5780729166666667\n",
      "Training loss = 0.25442194831247134\n",
      "Validation accuracy = 0.59375\n",
      "Validation loss = 0.2518863771110773\n",
      "Epoch 0049 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.5787755102040816\n",
      "Training loss = 0.2538974887857429\n",
      "Validation accuracy = 0.5625\n",
      "Validation loss = 0.25604994036257267\n",
      "Epoch 0050 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.5795833333333333\n",
      "Training loss = 0.25346707407782476\n",
      "Validation accuracy = 0.59375\n",
      "Validation loss = 0.25792630575597286\n",
      "Epoch 0051 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.5800980392156863\n",
      "Training loss = 0.2531340186229718\n",
      "Validation accuracy = 0.40625\n",
      "Validation loss = 0.25986576452851295\n",
      "Epoch 0052 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.5807852564102564\n",
      "Training loss = 0.2526938558026002\n",
      "Validation accuracy = 0.5625\n",
      "Validation loss = 0.25641871616244316\n",
      "Epoch 0053 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.5815723270440252\n",
      "Training loss = 0.2523814853655655\n",
      "Validation accuracy = 0.59375\n",
      "Validation loss = 0.2612978145480156\n",
      "Epoch 0054 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.5822222222222222\n",
      "Training loss = 0.25207182981763726\n",
      "Validation accuracy = 0.59375\n",
      "Validation loss = 0.23920074105262756\n",
      "Epoch 0055 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.5829848484848484\n",
      "Training loss = 0.2516934420046481\n",
      "Validation accuracy = 0.5625\n",
      "Validation loss = 0.2516239173710346\n",
      "Epoch 0056 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.5836755952380952\n",
      "Training loss = 0.251351594661939\n",
      "Validation accuracy = 0.53125\n",
      "Validation loss = 0.24235790874809027\n",
      "Epoch 0057 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.5843859649122807\n",
      "Training loss = 0.2510080405559979\n",
      "Validation accuracy = 0.5625\n",
      "Validation loss = 0.2453878428786993\n",
      "Epoch 0058 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.5850862068965518\n",
      "Training loss = 0.2506118049416905\n",
      "Validation accuracy = 0.59375\n",
      "Validation loss = 0.24272686801850796\n",
      "Epoch 0059 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.585225988700565\n",
      "Training loss = 0.2504287682881968\n",
      "Validation accuracy = 0.625\n",
      "Validation loss = 0.2562885656952858\n",
      "Epoch 0060 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.5859861111111111\n",
      "Training loss = 0.25004175393076405\n",
      "Validation accuracy = 0.59375\n",
      "Validation loss = 0.2552902614697814\n",
      "Epoch 0061 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.5863387978142076\n",
      "Training loss = 0.24984095102573028\n",
      "Validation accuracy = 0.65625\n",
      "Validation loss = 0.26112523302435875\n",
      "Epoch 0062 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.5871102150537635\n",
      "Training loss = 0.24942323998097451\n",
      "Validation accuracy = 0.40625\n",
      "Validation loss = 0.277041370049119\n",
      "Epoch 0063 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.5875264550264551\n",
      "Training loss = 0.2491715159819082\n",
      "Validation accuracy = 0.5625\n",
      "Validation loss = 0.24364930763840675\n",
      "Epoch 0064 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.5880078125\n",
      "Training loss = 0.2489301092014648\n",
      "Validation accuracy = 0.5\n",
      "Validation loss = 0.2566415313631296\n",
      "Epoch 0065 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.5885641025641025\n",
      "Training loss = 0.24873564290006955\n",
      "Validation accuracy = 0.5625\n",
      "Validation loss = 0.2638078276067972\n",
      "Epoch 0066 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.5891287878787879\n",
      "Training loss = 0.24845629473865935\n",
      "Validation accuracy = 0.59375\n",
      "Validation loss = 0.24222327768802643\n",
      "Epoch 0067 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.5898009950248756\n",
      "Training loss = 0.24813239973612983\n",
      "Validation accuracy = 0.4375\n",
      "Validation loss = 0.2537346100434661\n",
      "Epoch 0068 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.5904166666666667\n",
      "Training loss = 0.24784476849524414\n",
      "Validation accuracy = 0.59375\n",
      "Validation loss = 0.24588779732584953\n",
      "Epoch 0069 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.5909782608695652\n",
      "Training loss = 0.24750673404278387\n",
      "Validation accuracy = 0.59375\n",
      "Validation loss = 0.25910704024136066\n",
      "Epoch 0070 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.591202380952381\n",
      "Training loss = 0.2472958131411246\n",
      "Validation accuracy = 0.53125\n",
      "Validation loss = 0.24145329743623734\n",
      "Epoch 0071 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.5916666666666667\n",
      "Training loss = 0.24701426355666678\n",
      "Validation accuracy = 0.53125\n",
      "Validation loss = 0.26705230958759785\n",
      "Epoch 0072 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.5920949074074074\n",
      "Training loss = 0.24670740263364105\n",
      "Validation accuracy = 0.53125\n",
      "Validation loss = 0.26143521070480347\n",
      "Epoch 0073 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.5928310502283105\n",
      "Training loss = 0.2463834034845437\n",
      "Validation accuracy = 0.53125\n",
      "Validation loss = 0.25613251235336065\n",
      "Epoch 0074 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.5929842342342342\n",
      "Training loss = 0.24628386971918312\n",
      "Validation accuracy = 0.5625\n",
      "Validation loss = 0.23065914399921894\n",
      "Epoch 0075 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.5933111111111111\n",
      "Training loss = 0.2460326851758692\n",
      "Validation accuracy = 0.65625\n",
      "Validation loss = 0.24142752774059772\n",
      "Epoch 0076 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.5934429824561404\n",
      "Training loss = 0.24597163747113787\n",
      "Validation accuracy = 0.5625\n",
      "Validation loss = 0.24907675106078386\n",
      "Epoch 0077 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.5941883116883117\n",
      "Training loss = 0.2456545341130975\n",
      "Validation accuracy = 0.53125\n",
      "Validation loss = 0.23023947421461344\n",
      "Epoch 0078 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.5946260683760684\n",
      "Training loss = 0.2453221983752317\n",
      "Validation accuracy = 0.40625\n",
      "Validation loss = 0.2686728164553642\n",
      "Epoch 0079 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.5950316455696203\n",
      "Training loss = 0.24505129711411675\n",
      "Validation accuracy = 0.46875\n",
      "Validation loss = 0.2680747117847204\n",
      "Epoch 0080 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.59559375\n",
      "Training loss = 0.2447165890308097\n",
      "Validation accuracy = 0.59375\n",
      "Validation loss = 0.25082806777209044\n",
      "Epoch 0081 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.5959156378600823\n",
      "Training loss = 0.24455217052757003\n",
      "Validation accuracy = 0.5625\n",
      "Validation loss = 0.25215652491897345\n",
      "Epoch 0082 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.5967886178861789\n",
      "Training loss = 0.24416282489138647\n",
      "Validation accuracy = 0.46875\n",
      "Validation loss = 0.24681337364017963\n",
      "Epoch 0083 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.5974196787148595\n",
      "Training loss = 0.24389890864670996\n",
      "Validation accuracy = 0.53125\n",
      "Validation loss = 0.23360607214272022\n",
      "Epoch 0084 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.5978968253968254\n",
      "Training loss = 0.2436731460714151\n",
      "Validation accuracy = 0.53125\n",
      "Validation loss = 0.2508923914283514\n",
      "Epoch 0085 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.5984411764705883\n",
      "Training loss = 0.24344658955201215\n",
      "Validation accuracy = 0.59375\n",
      "Validation loss = 0.2500637173652649\n",
      "Epoch 0086 / 0200\n",
      "=====================================\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training accuracy = 0.5989341085271318\n",
      "Training loss = 0.24320614138603672\n",
      "Validation accuracy = 0.5\n",
      "Validation loss = 0.22763269767165184\n",
      "Epoch 0087 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.5992145593869732\n",
      "Training loss = 0.24307430294253132\n",
      "Validation accuracy = 0.46875\n",
      "Validation loss = 0.2897350415587425\n",
      "Epoch 0088 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.5996117424242424\n",
      "Training loss = 0.2428163771294622\n",
      "Validation accuracy = 0.46875\n",
      "Validation loss = 0.26657139882445335\n",
      "Epoch 0089 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.6002153558052434\n",
      "Training loss = 0.2424887175556649\n",
      "Validation accuracy = 0.53125\n",
      "Validation loss = 0.2584178615361452\n",
      "Epoch 0090 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.6006296296296296\n",
      "Training loss = 0.24226168520610641\n",
      "Validation accuracy = 0.5\n",
      "Validation loss = 0.24775351956486702\n",
      "Epoch 0091 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.6009065934065934\n",
      "Training loss = 0.24207594592192452\n",
      "Validation accuracy = 0.4375\n",
      "Validation loss = 0.25339047238230705\n",
      "Epoch 0092 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.6013586956521739\n",
      "Training loss = 0.24189516444002157\n",
      "Validation accuracy = 0.5625\n",
      "Validation loss = 0.24504730943590403\n",
      "Epoch 0093 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.6018817204301076\n",
      "Training loss = 0.24168572356437057\n",
      "Validation accuracy = 0.46875\n",
      "Validation loss = 0.24519195221364498\n",
      "Epoch 0094 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.602322695035461\n",
      "Training loss = 0.2414287811866466\n",
      "Validation accuracy = 0.59375\n",
      "Validation loss = 0.23378886375576258\n",
      "Epoch 0095 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.6025350877192982\n",
      "Training loss = 0.24133592407954366\n",
      "Validation accuracy = 0.59375\n",
      "Validation loss = 0.24317757785320282\n",
      "Epoch 0096 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.6029166666666667\n",
      "Training loss = 0.24112844540504738\n",
      "Validation accuracy = 0.5625\n",
      "Validation loss = 0.23606041446328163\n",
      "Epoch 0097 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.6033333333333334\n",
      "Training loss = 0.24098361590781162\n",
      "Validation accuracy = 0.5625\n",
      "Validation loss = 0.23773940932005644\n",
      "Epoch 0098 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.6036139455782313\n",
      "Training loss = 0.24083973995834387\n",
      "Validation accuracy = 0.5\n",
      "Validation loss = 0.2463935762643814\n",
      "Epoch 0099 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.6036531986531987\n",
      "Training loss = 0.24076299464712642\n",
      "Validation accuracy = 0.4375\n",
      "Validation loss = 0.2491050623357296\n",
      "Epoch 0100 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.60415\n",
      "Training loss = 0.24055088341285785\n",
      "Validation accuracy = 0.34375\n",
      "Validation loss = 0.28500401694327593\n",
      "Epoch 0101 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.6044719471947194\n",
      "Training loss = 0.24039278931989527\n",
      "Validation accuracy = 0.40625\n",
      "Validation loss = 0.2747848741710186\n",
      "Epoch 0102 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.605\n",
      "Training loss = 0.24011949151364806\n",
      "Validation accuracy = 0.53125\n",
      "Validation loss = 0.2645961716771126\n",
      "Epoch 0103 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.6054773462783172\n",
      "Training loss = 0.23987048394978047\n",
      "Validation accuracy = 0.59375\n",
      "Validation loss = 0.2485667346045375\n",
      "Epoch 0104 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.6058253205128206\n",
      "Training loss = 0.23961852264638323\n",
      "Validation accuracy = 0.5625\n",
      "Validation loss = 0.2634817101061344\n",
      "Epoch 0105 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.6061428571428571\n",
      "Training loss = 0.23942793135392287\n",
      "Validation accuracy = 0.5\n",
      "Validation loss = 0.2704182993620634\n",
      "Epoch 0106 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.606501572327044\n",
      "Training loss = 0.23925064600394957\n",
      "Validation accuracy = 0.625\n",
      "Validation loss = 0.2305544726550579\n",
      "Epoch 0107 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.6065732087227415\n",
      "Training loss = 0.2392145591916232\n",
      "Validation accuracy = 0.5\n",
      "Validation loss = 0.27118675969541073\n",
      "Epoch 0108 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.6069984567901234\n",
      "Training loss = 0.2390431085539361\n",
      "Validation accuracy = 0.5\n",
      "Validation loss = 0.2644808618351817\n",
      "Epoch 0109 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.607125382262997\n",
      "Training loss = 0.23891763552317014\n",
      "Validation accuracy = 0.4375\n",
      "Validation loss = 0.2544511128216982\n",
      "Epoch 0110 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.6073257575757576\n",
      "Training loss = 0.2387777311894478\n",
      "Validation accuracy = 0.34375\n",
      "Validation loss = 0.2557005789130926\n",
      "Epoch 0111 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.6078378378378378\n",
      "Training loss = 0.23855150382999366\n",
      "Validation accuracy = 0.46875\n",
      "Validation loss = 0.25045900233089924\n",
      "Epoch 0112 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.6082366071428571\n",
      "Training loss = 0.2383842152135358\n",
      "Validation accuracy = 0.46875\n",
      "Validation loss = 0.25497956946492195\n",
      "Epoch 0113 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.6086946902654867\n",
      "Training loss = 0.23814099643456374\n",
      "Validation accuracy = 0.5\n",
      "Validation loss = 0.2499959748238325\n",
      "Epoch 0114 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.6091154970760234\n",
      "Training loss = 0.23790057918176666\n",
      "Validation accuracy = 0.53125\n",
      "Validation loss = 0.23129159770905972\n",
      "Epoch 0115 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.6092753623188406\n",
      "Training loss = 0.23773176743327706\n",
      "Validation accuracy = 0.53125\n",
      "Validation loss = 0.24290973134338856\n",
      "Epoch 0116 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.6095474137931034\n",
      "Training loss = 0.23757417113295404\n",
      "Validation accuracy = 0.4375\n",
      "Validation loss = 0.2554810680449009\n",
      "Epoch 0117 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.61002849002849\n",
      "Training loss = 0.23738429518973725\n",
      "Validation accuracy = 0.5\n",
      "Validation loss = 0.2447433453053236\n",
      "Epoch 0118 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.6102895480225988\n",
      "Training loss = 0.23727870007987414\n",
      "Validation accuracy = 0.53125\n",
      "Validation loss = 0.27628021594136953\n",
      "Epoch 0119 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.6105742296918768\n",
      "Training loss = 0.23712977847110492\n",
      "Validation accuracy = 0.53125\n",
      "Validation loss = 0.2821273561567068\n",
      "Epoch 0120 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.6109097222222222\n",
      "Training loss = 0.2369082849688\n",
      "Validation accuracy = 0.46875\n",
      "Validation loss = 0.278772234916687\n",
      "Epoch 0121 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.6112052341597796\n",
      "Training loss = 0.236745206126661\n",
      "Validation accuracy = 0.5625\n",
      "Validation loss = 0.25613308046013117\n",
      "Epoch 0122 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.6115846994535519\n",
      "Training loss = 0.23659984958424268\n",
      "Validation accuracy = 0.6875\n",
      "Validation loss = 0.23106077127158642\n",
      "Epoch 0123 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.6120663956639566\n",
      "Training loss = 0.2363627708347913\n",
      "Validation accuracy = 0.53125\n",
      "Validation loss = 0.2551414165645838\n",
      "Epoch 0124 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.6125\n",
      "Training loss = 0.2361660628887995\n",
      "Validation accuracy = 0.46875\n",
      "Validation loss = 0.2591585135087371\n",
      "Epoch 0125 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.613\n",
      "Training loss = 0.23592522230287394\n",
      "Validation accuracy = 0.5625\n",
      "Validation loss = 0.23754767328500748\n",
      "Epoch 0126 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.6133928571428572\n",
      "Training loss = 0.23576475934790714\n",
      "Validation accuracy = 0.4375\n",
      "Validation loss = 0.25326467491686344\n",
      "Epoch 0127 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.6136482939632546\n",
      "Training loss = 0.23559682803145388\n",
      "Validation accuracy = 0.53125\n",
      "Validation loss = 0.22894466295838356\n",
      "Epoch 0128 / 0200\n",
      "=====================================\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training accuracy = 0.6140625\n",
      "Training loss = 0.23536427859721396\n",
      "Validation accuracy = 0.53125\n",
      "Validation loss = 0.25475326739251614\n",
      "Epoch 0129 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.6142700258397933\n",
      "Training loss = 0.23521405490274114\n",
      "Validation accuracy = 0.4375\n",
      "Validation loss = 0.2533571198582649\n",
      "Epoch 0130 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.6144487179487179\n",
      "Training loss = 0.23513388780504466\n",
      "Validation accuracy = 0.53125\n",
      "Validation loss = 0.24261672049760818\n",
      "Epoch 0131 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.6149491094147582\n",
      "Training loss = 0.2349077354547859\n",
      "Validation accuracy = 0.53125\n",
      "Validation loss = 0.22183008026331663\n",
      "Epoch 0132 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.6152020202020202\n",
      "Training loss = 0.23474944197789135\n",
      "Validation accuracy = 0.53125\n",
      "Validation loss = 0.2613452114164829\n",
      "Epoch 0133 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.6154573934837093\n",
      "Training loss = 0.23464144408292043\n",
      "Validation accuracy = 0.53125\n",
      "Validation loss = 0.24872939381748438\n",
      "Epoch 0134 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.615907960199005\n",
      "Training loss = 0.23440175458770338\n",
      "Validation accuracy = 0.59375\n",
      "Validation loss = 0.24091747403144836\n",
      "Epoch 0135 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.6162407407407408\n",
      "Training loss = 0.23425990384375608\n",
      "Validation accuracy = 0.53125\n",
      "Validation loss = 0.24494982045143843\n",
      "Epoch 0136 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.6165257352941177\n",
      "Training loss = 0.23415917444535914\n",
      "Validation accuracy = 0.5625\n",
      "Validation loss = 0.24024924542754889\n",
      "Epoch 0137 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.616794403892944\n",
      "Training loss = 0.23408095023964154\n",
      "Validation accuracy = 0.65625\n",
      "Validation loss = 0.22546268068253994\n",
      "Epoch 0138 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.6170471014492753\n",
      "Training loss = 0.23393489837916434\n",
      "Validation accuracy = 0.5\n",
      "Validation loss = 0.24475729651749134\n",
      "Epoch 0139 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.6174280575539568\n",
      "Training loss = 0.2337446147693004\n",
      "Validation accuracy = 0.625\n",
      "Validation loss = 0.23618264868855476\n",
      "Epoch 0140 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.6176785714285714\n",
      "Training loss = 0.23365350186062\n",
      "Validation accuracy = 0.59375\n",
      "Validation loss = 0.22910130769014359\n",
      "Epoch 0141 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.6179018912529551\n",
      "Training loss = 0.2335118743296422\n",
      "Validation accuracy = 0.59375\n",
      "Validation loss = 0.21724986843764782\n",
      "Epoch 0142 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.6181690140845071\n",
      "Training loss = 0.2333575399338919\n",
      "Validation accuracy = 0.625\n",
      "Validation loss = 0.23532087914645672\n",
      "Epoch 0143 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.6185081585081585\n",
      "Training loss = 0.2331689758996516\n",
      "Validation accuracy = 0.625\n",
      "Validation loss = 0.2300680037587881\n",
      "Epoch 0144 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.6188252314814815\n",
      "Training loss = 0.23306477160624195\n",
      "Validation accuracy = 0.5625\n",
      "Validation loss = 0.23439817782491446\n",
      "Epoch 0145 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.6190632183908046\n",
      "Training loss = 0.23292705824543006\n",
      "Validation accuracy = 0.53125\n",
      "Validation loss = 0.2265856098383665\n",
      "Epoch 0146 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.6192066210045662\n",
      "Training loss = 0.2328293351754206\n",
      "Validation accuracy = 0.4375\n",
      "Validation loss = 0.27548054978251457\n",
      "Epoch 0147 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.6193990929705215\n",
      "Training loss = 0.23268313796781087\n",
      "Validation accuracy = 0.59375\n",
      "Validation loss = 0.231117345392704\n",
      "Epoch 0148 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.6195382882882883\n",
      "Training loss = 0.2326019145534919\n",
      "Validation accuracy = 0.4375\n",
      "Validation loss = 0.25649041682481766\n",
      "Epoch 0149 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.6197818791946309\n",
      "Training loss = 0.23251259839891453\n",
      "Validation accuracy = 0.4375\n",
      "Validation loss = 0.2513597719371319\n",
      "Epoch 0150 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.6200722222222222\n",
      "Training loss = 0.23235194393793743\n",
      "Validation accuracy = 0.65625\n",
      "Validation loss = 0.2447627391666174\n",
      "Epoch 0151 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.6204690949227373\n",
      "Training loss = 0.23218412206349914\n",
      "Validation accuracy = 0.625\n",
      "Validation loss = 0.2502367990091443\n",
      "Epoch 0152 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.6207401315789474\n",
      "Training loss = 0.2320398483923718\n",
      "Validation accuracy = 0.625\n",
      "Validation loss = 0.23229424841701984\n",
      "Epoch 0153 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.6208605664488017\n",
      "Training loss = 0.23195225591266078\n",
      "Validation accuracy = 0.46875\n",
      "Validation loss = 0.2736702589318156\n",
      "Epoch 0154 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.6211742424242425\n",
      "Training loss = 0.2317492952228431\n",
      "Validation accuracy = 0.53125\n",
      "Validation loss = 0.26804363541305065\n",
      "Epoch 0155 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.6215537634408602\n",
      "Training loss = 0.23158469642346263\n",
      "Validation accuracy = 0.5\n",
      "Validation loss = 0.2488919533789158\n",
      "Epoch 0156 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.621741452991453\n",
      "Training loss = 0.23145144858453265\n",
      "Validation accuracy = 0.5\n",
      "Validation loss = 0.24592077545821667\n",
      "Epoch 0157 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.6217569002123142\n",
      "Training loss = 0.23135020638426523\n",
      "Validation accuracy = 0.59375\n",
      "Validation loss = 0.22118190303444862\n",
      "Epoch 0158 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.6221571729957805\n",
      "Training loss = 0.23116722949886623\n",
      "Validation accuracy = 0.59375\n",
      "Validation loss = 0.2508260924369097\n",
      "Epoch 0159 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.622374213836478\n",
      "Training loss = 0.23103648503933813\n",
      "Validation accuracy = 0.625\n",
      "Validation loss = 0.21834035404026508\n",
      "Epoch 0160 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.6226666666666667\n",
      "Training loss = 0.23089090867945924\n",
      "Validation accuracy = 0.46875\n",
      "Validation loss = 0.26490967720746994\n",
      "Epoch 0161 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.622991718426501\n",
      "Training loss = 0.23072603303391495\n",
      "Validation accuracy = 0.65625\n",
      "Validation loss = 0.24980606883764267\n",
      "Epoch 0162 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.6233641975308643\n",
      "Training loss = 0.23057253032984065\n",
      "Validation accuracy = 0.65625\n",
      "Validation loss = 0.23853237088769674\n",
      "Epoch 0163 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.6236860940695297\n",
      "Training loss = 0.23040468876286274\n",
      "Validation accuracy = 0.4375\n",
      "Validation loss = 0.2671083714812994\n",
      "Epoch 0164 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.6240243902439024\n",
      "Training loss = 0.23019378396387144\n",
      "Validation accuracy = 0.53125\n",
      "Validation loss = 0.22654812783002853\n",
      "Epoch 0165 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.624439393939394\n",
      "Training loss = 0.23002013889376563\n",
      "Validation accuracy = 0.5625\n",
      "Validation loss = 0.25581818260252476\n",
      "Epoch 0166 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.6247690763052209\n",
      "Training loss = 0.22987084459633114\n",
      "Validation accuracy = 0.53125\n",
      "Validation loss = 0.2667483724653721\n",
      "Epoch 0167 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.6249800399201597\n",
      "Training loss = 0.2297438395778814\n",
      "Validation accuracy = 0.5\n",
      "Validation loss = 0.2811578121036291\n",
      "Epoch 0168 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.6252430555555556\n",
      "Training loss = 0.2296062969809605\n",
      "Validation accuracy = 0.5\n",
      "Validation loss = 0.2556708734482527\n",
      "Epoch 0169 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.6254635108481262\n",
      "Training loss = 0.22945751822206395\n",
      "Validation accuracy = 0.65625\n",
      "Validation loss = 0.2704570423811674\n",
      "Epoch 0170 / 0200\n",
      "=====================================\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training accuracy = 0.6257205882352941\n",
      "Training loss = 0.22935107743374858\n",
      "Validation accuracy = 0.65625\n",
      "Validation loss = 0.23963891249150038\n",
      "Epoch 0171 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.6257261208576999\n",
      "Training loss = 0.2293133527980155\n",
      "Validation accuracy = 0.65625\n",
      "Validation loss = 0.23890331014990807\n",
      "Epoch 0172 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.6260368217054264\n",
      "Training loss = 0.22920171237427944\n",
      "Validation accuracy = 0.5625\n",
      "Validation loss = 0.24691606685519218\n",
      "Epoch 0173 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.6261271676300578\n",
      "Training loss = 0.22912333402359186\n",
      "Validation accuracy = 0.65625\n",
      "Validation loss = 0.22108925133943558\n",
      "Epoch 0174 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.6263218390804598\n",
      "Training loss = 0.22900732416160033\n",
      "Validation accuracy = 0.65625\n",
      "Validation loss = 0.24444101937115192\n",
      "Epoch 0175 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.6265190476190476\n",
      "Training loss = 0.22891929240460906\n",
      "Validation accuracy = 0.625\n",
      "Validation loss = 0.23178773000836372\n",
      "Epoch 0176 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.6267092803030303\n",
      "Training loss = 0.2287733445471068\n",
      "Validation accuracy = 0.53125\n",
      "Validation loss = 0.2517918748781085\n",
      "Epoch 0177 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.6269444444444444\n",
      "Training loss = 0.22865892117257228\n",
      "Validation accuracy = 0.625\n",
      "Validation loss = 0.2376699298620224\n",
      "Epoch 0178 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.6271629213483146\n",
      "Training loss = 0.22850974212250627\n",
      "Validation accuracy = 0.5\n",
      "Validation loss = 0.23485887236893177\n",
      "Epoch 0179 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.6273649906890131\n",
      "Training loss = 0.22839990204127308\n",
      "Validation accuracy = 0.53125\n",
      "Validation loss = 0.2715658266097307\n",
      "Epoch 0180 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.6275277777777778\n",
      "Training loss = 0.22829989896983735\n",
      "Validation accuracy = 0.59375\n",
      "Validation loss = 0.22357885353267193\n",
      "Epoch 0181 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.627633517495396\n",
      "Training loss = 0.2282570377416895\n",
      "Validation accuracy = 0.5625\n",
      "Validation loss = 0.26017914712429047\n",
      "Epoch 0182 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.6277380952380952\n",
      "Training loss = 0.22819101058171837\n",
      "Validation accuracy = 0.53125\n",
      "Validation loss = 0.2874253150075674\n",
      "Epoch 0183 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.6279690346083788\n",
      "Training loss = 0.22808298155102194\n",
      "Validation accuracy = 0.625\n",
      "Validation loss = 0.23680760897696018\n",
      "Epoch 0184 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.6280389492753623\n",
      "Training loss = 0.22800134443995151\n",
      "Validation accuracy = 0.65625\n",
      "Validation loss = 0.22971604578197002\n",
      "Epoch 0185 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.6281801801801802\n",
      "Training loss = 0.22792624700680242\n",
      "Validation accuracy = 0.5\n",
      "Validation loss = 0.24706771969795227\n",
      "Epoch 0186 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.6283378136200717\n",
      "Training loss = 0.2278184383431296\n",
      "Validation accuracy = 0.5625\n",
      "Validation loss = 0.2341612819582224\n",
      "Epoch 0187 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.6282976827094474\n",
      "Training loss = 0.22776912870194344\n",
      "Validation accuracy = 0.53125\n",
      "Validation loss = 0.2447047084569931\n",
      "Epoch 0188 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.6284929078014184\n",
      "Training loss = 0.22767615440169495\n",
      "Validation accuracy = 0.5\n",
      "Validation loss = 0.26062302477657795\n",
      "Epoch 0189 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.6287213403880071\n",
      "Training loss = 0.22757137440466954\n",
      "Validation accuracy = 0.4375\n",
      "Validation loss = 0.2770416606217623\n",
      "Epoch 0190 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.6287368421052631\n",
      "Training loss = 0.22752855206444336\n",
      "Validation accuracy = 0.40625\n",
      "Validation loss = 0.27446955256164074\n",
      "Epoch 0191 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.6289790575916231\n",
      "Training loss = 0.22742603356125934\n",
      "Validation accuracy = 0.625\n",
      "Validation loss = 0.23498615622520447\n",
      "Epoch 0192 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.6291623263888889\n",
      "Training loss = 0.22734335959753177\n",
      "Validation accuracy = 0.53125\n",
      "Validation loss = 0.26635855808854103\n",
      "Epoch 0193 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.6293221070811744\n",
      "Training loss = 0.22725850026411148\n",
      "Validation accuracy = 0.4375\n",
      "Validation loss = 0.29743316024541855\n",
      "Epoch 0194 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.6293943298969072\n",
      "Training loss = 0.22717796233825105\n",
      "Validation accuracy = 0.65625\n",
      "Validation loss = 0.22246192395687103\n",
      "Epoch 0195 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.629525641025641\n",
      "Training loss = 0.22711774387821937\n",
      "Validation accuracy = 0.4375\n",
      "Validation loss = 0.26256969198584557\n",
      "Epoch 0196 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.629766156462585\n",
      "Training loss = 0.2270162564694096\n",
      "Validation accuracy = 0.5\n",
      "Validation loss = 0.2411425057798624\n",
      "Epoch 0197 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.6300465313028765\n",
      "Training loss = 0.22687467735386793\n",
      "Validation accuracy = 0.40625\n",
      "Validation loss = 0.259674159809947\n",
      "Epoch 0198 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.6301052188552189\n",
      "Training loss = 0.22680938932147843\n",
      "Validation accuracy = 0.46875\n",
      "Validation loss = 0.2835895922034979\n",
      "Epoch 0199 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.6303056951423786\n",
      "Training loss = 0.2267059041462976\n",
      "Validation accuracy = 0.59375\n",
      "Validation loss = 0.2358216792345047\n",
      "Epoch 0200 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.6305\n",
      "Training loss = 0.22662311980295927\n",
      "Validation accuracy = 0.5625\n",
      "Validation loss = 0.2549550998955965\n",
      "Making model for session group 20210310_15:31:57.174-20210319_16:18:28.688\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/imblearn/utils/_validation.py:326: UserWarning: After over-sampling, the number of samples (300) in class car will be larger than the number of samples in the majority class (class #signpost -> 160)\n",
      "  n_samples_majority,\n",
      "/usr/local/lib/python3.6/dist-packages/imblearn/utils/_validation.py:326: UserWarning: After over-sampling, the number of samples (300) in class signpost will be larger than the number of samples in the majority class (class #signpost -> 160)\n",
      "  n_samples_majority,\n",
      "/usr/local/lib/python3.6/dist-packages/imblearn/utils/_validation.py:326: UserWarning: After over-sampling, the number of samples (300) in class tree will be larger than the number of samples in the majority class (class #signpost -> 160)\n",
      "  n_samples_majority,\n",
      "/usr/local/lib/python3.6/dist-packages/imblearn/utils/_validation.py:326: UserWarning: After over-sampling, the number of samples (300) in class wall will be larger than the number of samples in the majority class (class #signpost -> 160)\n",
      "  n_samples_majority,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0001 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.37916666666666665\n",
      "Training loss = 0.3187013392150402\n",
      "Validation accuracy = 0.5\n",
      "Validation loss = 0.30901241675019264\n",
      "Epoch 0002 / 0200\n",
      "=====================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/_classification.py:1221: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training accuracy = 0.39791666666666664\n",
      "Training loss = 0.30908370050291223\n",
      "Validation accuracy = 0.5625\n",
      "Validation loss = 0.28240502811968327\n",
      "Epoch 0003 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.4255555555555556\n",
      "Training loss = 0.3015399755206373\n",
      "Validation accuracy = 0.6875\n",
      "Validation loss = 0.26783798448741436\n",
      "Epoch 0004 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.448125\n",
      "Training loss = 0.29666557220121226\n",
      "Validation accuracy = 0.6875\n",
      "Validation loss = 0.27626379765570164\n",
      "Epoch 0005 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.4605\n",
      "Training loss = 0.29221785990397137\n",
      "Validation accuracy = 0.6875\n",
      "Validation loss = 0.2800255659967661\n",
      "Epoch 0006 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.47444444444444445\n",
      "Training loss = 0.28807142989503015\n",
      "Validation accuracy = 0.65625\n",
      "Validation loss = 0.26204957719892263\n",
      "Epoch 0007 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.48523809523809525\n",
      "Training loss = 0.2843232834126268\n",
      "Validation accuracy = 0.75\n",
      "Validation loss = 0.23335277289152145\n",
      "Epoch 0008 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.4917708333333333\n",
      "Training loss = 0.2817045430776974\n",
      "Validation accuracy = 0.6875\n",
      "Validation loss = 0.2531417477875948\n",
      "Epoch 0009 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.4999074074074074\n",
      "Training loss = 0.27929679580032823\n",
      "Validation accuracy = 0.6875\n",
      "Validation loss = 0.22988677769899368\n",
      "Epoch 0010 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.5066666666666667\n",
      "Training loss = 0.27694383553167184\n",
      "Validation accuracy = 0.71875\n",
      "Validation loss = 0.2369423769414425\n",
      "Epoch 0011 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.5097727272727273\n",
      "Training loss = 0.2760525211285461\n",
      "Validation accuracy = 0.75\n",
      "Validation loss = 0.2231373693794012\n",
      "Epoch 0012 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.514375\n",
      "Training loss = 0.27481793052620357\n",
      "Validation accuracy = 0.65625\n",
      "Validation loss = 0.24042466841638088\n",
      "Epoch 0013 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.5177564102564103\n",
      "Training loss = 0.27346886341006327\n",
      "Validation accuracy = 0.71875\n",
      "Validation loss = 0.23144408222287893\n",
      "Epoch 0014 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.5207738095238095\n",
      "Training loss = 0.27241804810152165\n",
      "Validation accuracy = 0.75\n",
      "Validation loss = 0.23106703348457813\n",
      "Epoch 0015 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.5221111111111111\n",
      "Training loss = 0.2718537304484182\n",
      "Validation accuracy = 0.65625\n",
      "Validation loss = 0.24722669273614883\n",
      "Epoch 0016 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.52546875\n",
      "Training loss = 0.27056287390800815\n",
      "Validation accuracy = 0.6875\n",
      "Validation loss = 0.21018714923411608\n",
      "Epoch 0017 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.528921568627451\n",
      "Training loss = 0.2691100033080461\n",
      "Validation accuracy = 0.75\n",
      "Validation loss = 0.23254996351897717\n",
      "Epoch 0018 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.5313888888888889\n",
      "Training loss = 0.26809872472175844\n",
      "Validation accuracy = 0.5625\n",
      "Validation loss = 0.2390215713530779\n",
      "Epoch 0019 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.5344298245614035\n",
      "Training loss = 0.26705966541772347\n",
      "Validation accuracy = 0.75\n",
      "Validation loss = 0.2097280900925398\n",
      "Epoch 0020 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.5355833333333333\n",
      "Training loss = 0.26634942802662653\n",
      "Validation accuracy = 0.6875\n",
      "Validation loss = 0.21574419271200895\n",
      "Epoch 0021 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.5375\n",
      "Training loss = 0.26572721726482823\n",
      "Validation accuracy = 0.6875\n",
      "Validation loss = 0.2030192483216524\n",
      "Epoch 0022 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.5391287878787879\n",
      "Training loss = 0.2649048907106573\n",
      "Validation accuracy = 0.6875\n",
      "Validation loss = 0.22425812017172575\n",
      "Epoch 0023 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.5410869565217391\n",
      "Training loss = 0.26401684469394926\n",
      "Validation accuracy = 0.625\n",
      "Validation loss = 0.21684222854673862\n",
      "Epoch 0024 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.5434722222222222\n",
      "Training loss = 0.26291832729139264\n",
      "Validation accuracy = 0.625\n",
      "Validation loss = 0.25733577087521553\n",
      "Epoch 0025 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.5453333333333333\n",
      "Training loss = 0.26220781733691695\n",
      "Validation accuracy = 0.71875\n",
      "Validation loss = 0.2168360184878111\n",
      "Epoch 0026 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.5468910256410257\n",
      "Training loss = 0.261632701108853\n",
      "Validation accuracy = 0.8125\n",
      "Validation loss = 0.20950112864375114\n",
      "Epoch 0027 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.548179012345679\n",
      "Training loss = 0.26117064398839884\n",
      "Validation accuracy = 0.71875\n",
      "Validation loss = 0.2082969406619668\n",
      "Epoch 0028 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.5487202380952381\n",
      "Training loss = 0.26042067820472375\n",
      "Validation accuracy = 0.53125\n",
      "Validation loss = 0.22187852207571268\n",
      "Epoch 0029 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.5507183908045977\n",
      "Training loss = 0.25978802030627757\n",
      "Validation accuracy = 0.71875\n",
      "Validation loss = 0.215569905936718\n",
      "Epoch 0030 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.5525277777777777\n",
      "Training loss = 0.2589074648511079\n",
      "Validation accuracy = 0.78125\n",
      "Validation loss = 0.19743974599987268\n",
      "Epoch 0031 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.5537096774193548\n",
      "Training loss = 0.25840835640827814\n",
      "Validation accuracy = 0.75\n",
      "Validation loss = 0.19667756278067827\n",
      "Epoch 0032 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.5551302083333334\n",
      "Training loss = 0.2578190608578734\n",
      "Validation accuracy = 0.65625\n",
      "Validation loss = 0.22574186511337757\n",
      "Epoch 0033 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.5561616161616162\n",
      "Training loss = 0.2574190568796011\n",
      "Validation accuracy = 0.65625\n",
      "Validation loss = 0.2200733432546258\n",
      "Epoch 0034 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.5578186274509804\n",
      "Training loss = 0.25685047030668046\n",
      "Validation accuracy = 0.65625\n",
      "Validation loss = 0.21735653281211853\n",
      "Epoch 0035 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.5589047619047619\n",
      "Training loss = 0.2565669513578926\n",
      "Validation accuracy = 0.65625\n",
      "Validation loss = 0.2429992239922285\n",
      "Epoch 0036 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.5602546296296296\n",
      "Training loss = 0.25604882847793675\n",
      "Validation accuracy = 0.71875\n",
      "Validation loss = 0.21383682638406754\n",
      "Epoch 0037 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.5618243243243243\n",
      "Training loss = 0.2555932084739477\n",
      "Validation accuracy = 0.78125\n",
      "Validation loss = 0.2078605480492115\n",
      "Epoch 0038 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.5637061403508772\n",
      "Training loss = 0.2549625711306407\n",
      "Validation accuracy = 0.75\n",
      "Validation loss = 0.21632505860179663\n",
      "Epoch 0039 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.5648504273504273\n",
      "Training loss = 0.25457303263629094\n",
      "Validation accuracy = 0.5625\n",
      "Validation loss = 0.23204469960182905\n",
      "Epoch 0040 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.5654791666666666\n",
      "Training loss = 0.2542527615682532\n",
      "Validation accuracy = 0.6875\n",
      "Validation loss = 0.22951210662722588\n",
      "Epoch 0041 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.5663821138211382\n",
      "Training loss = 0.2538919953081181\n",
      "Validation accuracy = 0.75\n",
      "Validation loss = 0.22905563935637474\n",
      "Epoch 0042 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.5672420634920635\n",
      "Training loss = 0.25362202228712183\n",
      "Validation accuracy = 0.5625\n",
      "Validation loss = 0.23536008317023516\n",
      "Epoch 0043 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.5673449612403101\n",
      "Training loss = 0.2534011558125647\n",
      "Validation accuracy = 0.78125\n",
      "Validation loss = 0.20855665765702724\n",
      "Epoch 0044 / 0200\n",
      "=====================================\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training accuracy = 0.5677840909090909\n",
      "Training loss = 0.2532407401507777\n",
      "Validation accuracy = 0.75\n",
      "Validation loss = 0.21823957655578852\n",
      "Epoch 0045 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.5685\n",
      "Training loss = 0.25292318719515094\n",
      "Validation accuracy = 0.71875\n",
      "Validation loss = 0.21854051668196917\n",
      "Epoch 0046 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.5692934782608695\n",
      "Training loss = 0.2526653771167216\n",
      "Validation accuracy = 0.6875\n",
      "Validation loss = 0.21479538269340992\n",
      "Epoch 0047 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.5699113475177305\n",
      "Training loss = 0.2523198892160299\n",
      "Validation accuracy = 0.4375\n",
      "Validation loss = 0.23567268345505\n",
      "Epoch 0048 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.5702951388888889\n",
      "Training loss = 0.2521247287798259\n",
      "Validation accuracy = 0.5625\n",
      "Validation loss = 0.2354546757414937\n",
      "Epoch 0049 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.5710204081632653\n",
      "Training loss = 0.25185300756068457\n",
      "Validation accuracy = 0.5\n",
      "Validation loss = 0.2342333709821105\n",
      "Epoch 0050 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.57095\n",
      "Training loss = 0.2517877393633127\n",
      "Validation accuracy = 0.8125\n",
      "Validation loss = 0.2036225739866495\n",
      "Epoch 0051 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.5714542483660131\n",
      "Training loss = 0.2514815211685654\n",
      "Validation accuracy = 0.53125\n",
      "Validation loss = 0.24117744155228138\n",
      "Epoch 0052 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.5725961538461538\n",
      "Training loss = 0.2509186388662037\n",
      "Validation accuracy = 0.5\n",
      "Validation loss = 0.22886779252439737\n",
      "Epoch 0053 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.5732075471698114\n",
      "Training loss = 0.2506656153312644\n",
      "Validation accuracy = 0.6875\n",
      "Validation loss = 0.22346788737922907\n",
      "Epoch 0054 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.5739197530864197\n",
      "Training loss = 0.2503646944127517\n",
      "Validation accuracy = 0.625\n",
      "Validation loss = 0.24431774485856295\n",
      "Epoch 0055 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.5746212121212121\n",
      "Training loss = 0.2500489891212095\n",
      "Validation accuracy = 0.75\n",
      "Validation loss = 0.21858412493020296\n",
      "Epoch 0056 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.5751785714285714\n",
      "Training loss = 0.24977513611937563\n",
      "Validation accuracy = 0.65625\n",
      "Validation loss = 0.238189653493464\n",
      "Epoch 0057 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.575921052631579\n",
      "Training loss = 0.24947225941421344\n",
      "Validation accuracy = 0.6875\n",
      "Validation loss = 0.20956157334148884\n",
      "Epoch 0058 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.5769396551724137\n",
      "Training loss = 0.24903082059032616\n",
      "Validation accuracy = 0.78125\n",
      "Validation loss = 0.19773161690682173\n",
      "Epoch 0059 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.5775706214689266\n",
      "Training loss = 0.24886332992064414\n",
      "Validation accuracy = 0.59375\n",
      "Validation loss = 0.2425468247383833\n",
      "Epoch 0060 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.5778611111111112\n",
      "Training loss = 0.24873746502978933\n",
      "Validation accuracy = 0.625\n",
      "Validation loss = 0.23518990725278854\n",
      "Epoch 0061 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.5784836065573771\n",
      "Training loss = 0.24849644982749647\n",
      "Validation accuracy = 0.75\n",
      "Validation loss = 0.22680397145450115\n",
      "Epoch 0062 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.5793010752688172\n",
      "Training loss = 0.248161987098715\n",
      "Validation accuracy = 0.71875\n",
      "Validation loss = 0.2069930788129568\n",
      "Epoch 0063 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.5796693121693122\n",
      "Training loss = 0.2480158376145773\n",
      "Validation accuracy = 0.8125\n",
      "Validation loss = 0.20774073712527752\n",
      "Epoch 0064 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.5808463541666666\n",
      "Training loss = 0.24758774538640865\n",
      "Validation accuracy = 0.8125\n",
      "Validation loss = 0.18799866642802954\n",
      "Epoch 0065 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.5816025641025641\n",
      "Training loss = 0.24734994434316954\n",
      "Validation accuracy = 0.625\n",
      "Validation loss = 0.2232823744416237\n",
      "Epoch 0066 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.5821212121212122\n",
      "Training loss = 0.24711269532302113\n",
      "Validation accuracy = 0.6875\n",
      "Validation loss = 0.2023926293477416\n",
      "Epoch 0067 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.5827611940298507\n",
      "Training loss = 0.24693782580432608\n",
      "Validation accuracy = 0.78125\n",
      "Validation loss = 0.19444454461336136\n",
      "Epoch 0068 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.5834926470588235\n",
      "Training loss = 0.2466849881202421\n",
      "Validation accuracy = 0.6875\n",
      "Validation loss = 0.22590381372720003\n",
      "Epoch 0069 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.5841787439613526\n",
      "Training loss = 0.24645985644688642\n",
      "Validation accuracy = 0.75\n",
      "Validation loss = 0.20773678738623857\n",
      "Epoch 0070 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.5845476190476191\n",
      "Training loss = 0.2463426837222207\n",
      "Validation accuracy = 0.53125\n",
      "Validation loss = 0.24031331297010183\n",
      "Epoch 0071 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.5851173708920188\n",
      "Training loss = 0.24610904000314748\n",
      "Validation accuracy = 0.4375\n",
      "Validation loss = 0.23121084179729223\n",
      "Epoch 0072 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.5856828703703704\n",
      "Training loss = 0.2457769163152962\n",
      "Validation accuracy = 0.78125\n",
      "Validation loss = 0.21985796373337507\n",
      "Epoch 0073 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.5859703196347033\n",
      "Training loss = 0.24565278612349403\n",
      "Validation accuracy = 0.8125\n",
      "Validation loss = 0.1866971869021654\n",
      "Epoch 0074 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.5864864864864865\n",
      "Training loss = 0.2454178714460215\n",
      "Validation accuracy = 0.75\n",
      "Validation loss = 0.20763635262846947\n",
      "Epoch 0075 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.5870777777777778\n",
      "Training loss = 0.24511214052306282\n",
      "Validation accuracy = 0.84375\n",
      "Validation loss = 0.1716454653069377\n",
      "Epoch 0076 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.5877302631578948\n",
      "Training loss = 0.2448330435934558\n",
      "Validation accuracy = 0.59375\n",
      "Validation loss = 0.25164757296442986\n",
      "Epoch 0077 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.5881926406926407\n",
      "Training loss = 0.2446070112591182\n",
      "Validation accuracy = 0.84375\n",
      "Validation loss = 0.20091059617698193\n",
      "Epoch 0078 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.5887820512820513\n",
      "Training loss = 0.24434770501481418\n",
      "Validation accuracy = 0.75\n",
      "Validation loss = 0.19536574184894562\n",
      "Epoch 0079 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.5894725738396625\n",
      "Training loss = 0.24401667985923683\n",
      "Validation accuracy = 0.5625\n",
      "Validation loss = 0.2385052554309368\n",
      "Epoch 0080 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.5900625\n",
      "Training loss = 0.2437220020070672\n",
      "Validation accuracy = 0.53125\n",
      "Validation loss = 0.232874171808362\n",
      "Epoch 0081 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.5904423868312757\n",
      "Training loss = 0.2434976322924404\n",
      "Validation accuracy = 0.6875\n",
      "Validation loss = 0.2173646381124854\n",
      "Epoch 0082 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.5911077235772357\n",
      "Training loss = 0.24322012635387055\n",
      "Validation accuracy = 0.75\n",
      "Validation loss = 0.22235058154910803\n",
      "Epoch 0083 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.5916164658634538\n",
      "Training loss = 0.24300609729136807\n",
      "Validation accuracy = 0.65625\n",
      "Validation loss = 0.20692971907556057\n",
      "Epoch 0084 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.5918253968253968\n",
      "Training loss = 0.242884353763823\n",
      "Validation accuracy = 0.78125\n",
      "Validation loss = 0.21290023252367973\n",
      "Epoch 0085 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.592078431372549\n",
      "Training loss = 0.24274873653901557\n",
      "Validation accuracy = 0.5625\n",
      "Validation loss = 0.23371322453022003\n",
      "Epoch 0086 / 0200\n",
      "=====================================\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training accuracy = 0.5924709302325581\n",
      "Training loss = 0.2425573813993224\n",
      "Validation accuracy = 0.75\n",
      "Validation loss = 0.20846371911466122\n",
      "Epoch 0087 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.5928735632183908\n",
      "Training loss = 0.24234840797281815\n",
      "Validation accuracy = 0.65625\n",
      "Validation loss = 0.23410459607839584\n",
      "Epoch 0088 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.5931723484848485\n",
      "Training loss = 0.24223023978372415\n",
      "Validation accuracy = 0.78125\n",
      "Validation loss = 0.21578391827642918\n",
      "Epoch 0089 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.5936610486891386\n",
      "Training loss = 0.2419745357702957\n",
      "Validation accuracy = 0.5\n",
      "Validation loss = 0.23331107944250107\n",
      "Epoch 0090 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.5941481481481482\n",
      "Training loss = 0.24174364329819326\n",
      "Validation accuracy = 0.6875\n",
      "Validation loss = 0.226008883677423\n",
      "Epoch 0091 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.5946062271062271\n",
      "Training loss = 0.2415998943070898\n",
      "Validation accuracy = 0.71875\n",
      "Validation loss = 0.19542949553579092\n",
      "Epoch 0092 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.5949184782608695\n",
      "Training loss = 0.24145810570027948\n",
      "Validation accuracy = 0.65625\n",
      "Validation loss = 0.210665094666183\n",
      "Epoch 0093 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.5953763440860215\n",
      "Training loss = 0.24128081081214772\n",
      "Validation accuracy = 0.65625\n",
      "Validation loss = 0.22278488241136074\n",
      "Epoch 0094 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.5960106382978724\n",
      "Training loss = 0.2410133263503089\n",
      "Validation accuracy = 0.75\n",
      "Validation loss = 0.20453848131000996\n",
      "Epoch 0095 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.596359649122807\n",
      "Training loss = 0.240855396212193\n",
      "Validation accuracy = 0.75\n",
      "Validation loss = 0.20838862471282482\n",
      "Epoch 0096 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.5967447916666667\n",
      "Training loss = 0.24064250738127158\n",
      "Validation accuracy = 0.78125\n",
      "Validation loss = 0.20934834145009518\n",
      "Epoch 0097 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.5973711340206186\n",
      "Training loss = 0.24040383931441406\n",
      "Validation accuracy = 0.8125\n",
      "Validation loss = 0.20539217069745064\n",
      "Epoch 0098 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.5979251700680273\n",
      "Training loss = 0.24022102129601297\n",
      "Validation accuracy = 0.8125\n",
      "Validation loss = 0.19411013182252645\n",
      "Epoch 0099 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.5981313131313132\n",
      "Training loss = 0.24017473267435224\n",
      "Validation accuracy = 0.40625\n",
      "Validation loss = 0.2621525200083852\n",
      "Epoch 0100 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.5984166666666667\n",
      "Training loss = 0.24006962159549197\n",
      "Validation accuracy = 0.65625\n",
      "Validation loss = 0.22673889249563217\n",
      "Epoch 0101 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.5987211221122112\n",
      "Training loss = 0.2398718704927479\n",
      "Validation accuracy = 0.6875\n",
      "Validation loss = 0.2121711354702711\n",
      "Epoch 0102 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.5988970588235294\n",
      "Training loss = 0.23979614737839286\n",
      "Validation accuracy = 0.5\n",
      "Validation loss = 0.22317725885659456\n",
      "Epoch 0103 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.5994093851132686\n",
      "Training loss = 0.23956155255412787\n",
      "Validation accuracy = 0.65625\n",
      "Validation loss = 0.21967630740255117\n",
      "Epoch 0104 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.5998717948717949\n",
      "Training loss = 0.2393972826281037\n",
      "Validation accuracy = 0.71875\n",
      "Validation loss = 0.1939176805317402\n",
      "Epoch 0105 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.6004126984126984\n",
      "Training loss = 0.2391309696873502\n",
      "Validation accuracy = 0.6875\n",
      "Validation loss = 0.20955067314207554\n",
      "Epoch 0106 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.6009591194968553\n",
      "Training loss = 0.23891417190573125\n",
      "Validation accuracy = 0.75\n",
      "Validation loss = 0.16146438010036945\n",
      "Epoch 0107 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.6013940809968847\n",
      "Training loss = 0.23870218369668797\n",
      "Validation accuracy = 0.65625\n",
      "Validation loss = 0.20660650450736284\n",
      "Epoch 0108 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.6016666666666667\n",
      "Training loss = 0.23861810920403603\n",
      "Validation accuracy = 0.75\n",
      "Validation loss = 0.20512756519019604\n",
      "Epoch 0109 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.6019954128440367\n",
      "Training loss = 0.23848724553765963\n",
      "Validation accuracy = 0.84375\n",
      "Validation loss = 0.18916549813002348\n",
      "Epoch 0110 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.6024015151515152\n",
      "Training loss = 0.2383292451551692\n",
      "Validation accuracy = 0.78125\n",
      "Validation loss = 0.21228323876857758\n",
      "Epoch 0111 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.6027477477477478\n",
      "Training loss = 0.23817571444162824\n",
      "Validation accuracy = 0.84375\n",
      "Validation loss = 0.1774628423154354\n",
      "Epoch 0112 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.6032738095238095\n",
      "Training loss = 0.23797892121720082\n",
      "Validation accuracy = 0.75\n",
      "Validation loss = 0.19701269082725048\n",
      "Epoch 0113 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.6037315634218289\n",
      "Training loss = 0.23780670042509613\n",
      "Validation accuracy = 0.78125\n",
      "Validation loss = 0.1921297274529934\n",
      "Epoch 0114 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.6040350877192983\n",
      "Training loss = 0.23772517510422925\n",
      "Validation accuracy = 0.625\n",
      "Validation loss = 0.22992897406220436\n",
      "Epoch 0115 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.6041449275362318\n",
      "Training loss = 0.2377253657789982\n",
      "Validation accuracy = 0.71875\n",
      "Validation loss = 0.19830995425581932\n",
      "Epoch 0116 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.6044396551724138\n",
      "Training loss = 0.23757495028694728\n",
      "Validation accuracy = 0.46875\n",
      "Validation loss = 0.25624828319996595\n",
      "Epoch 0117 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.6048290598290599\n",
      "Training loss = 0.23737469209490764\n",
      "Validation accuracy = 0.625\n",
      "Validation loss = 0.21830778662115335\n",
      "Epoch 0118 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.6052824858757062\n",
      "Training loss = 0.23722973010202839\n",
      "Validation accuracy = 0.71875\n",
      "Validation loss = 0.1994917020201683\n",
      "Epoch 0119 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.6056512605042017\n",
      "Training loss = 0.2370940959654978\n",
      "Validation accuracy = 0.5625\n",
      "Validation loss = 0.23623147699981928\n",
      "Epoch 0120 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.6060416666666667\n",
      "Training loss = 0.23690247639485945\n",
      "Validation accuracy = 0.71875\n",
      "Validation loss = 0.21281355246901512\n",
      "Epoch 0121 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.6063774104683196\n",
      "Training loss = 0.236761229864473\n",
      "Validation accuracy = 0.75\n",
      "Validation loss = 0.21610415913164616\n",
      "Epoch 0122 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.6068374316939891\n",
      "Training loss = 0.2365946151663249\n",
      "Validation accuracy = 0.71875\n",
      "Validation loss = 0.17745967395603657\n",
      "Epoch 0123 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.607079945799458\n",
      "Training loss = 0.2364674708070511\n",
      "Validation accuracy = 0.78125\n",
      "Validation loss = 0.20138158649206161\n",
      "Epoch 0124 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.6074731182795698\n",
      "Training loss = 0.2363028403268426\n",
      "Validation accuracy = 0.53125\n",
      "Validation loss = 0.2534597860649228\n",
      "Epoch 0125 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.6079266666666666\n",
      "Training loss = 0.2361194177771608\n",
      "Validation accuracy = 0.46875\n",
      "Validation loss = 0.2864034604281187\n",
      "Epoch 0126 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.6082936507936508\n",
      "Training loss = 0.23600799627138902\n",
      "Validation accuracy = 0.59375\n",
      "Validation loss = 0.22768217790871859\n",
      "Epoch 0127 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.6085958005249343\n",
      "Training loss = 0.2358488111979184\n",
      "Validation accuracy = 0.5625\n",
      "Validation loss = 0.23223105818033218\n",
      "Epoch 0128 / 0200\n",
      "=====================================\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training accuracy = 0.6088541666666667\n",
      "Training loss = 0.2356755465751242\n",
      "Validation accuracy = 0.8125\n",
      "Validation loss = 0.17846465297043324\n",
      "Epoch 0129 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.6091214470284237\n",
      "Training loss = 0.2355365358203534\n",
      "Validation accuracy = 0.75\n",
      "Validation loss = 0.21598107740283012\n",
      "Epoch 0130 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.6093076923076923\n",
      "Training loss = 0.23540778592716044\n",
      "Validation accuracy = 0.75\n",
      "Validation loss = 0.2224573539569974\n",
      "Epoch 0131 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.6097900763358779\n",
      "Training loss = 0.23520278636441963\n",
      "Validation accuracy = 0.8125\n",
      "Validation loss = 0.20349776558578014\n",
      "Epoch 0132 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.6100757575757576\n",
      "Training loss = 0.23511155461845448\n",
      "Validation accuracy = 0.78125\n",
      "Validation loss = 0.18901783507317305\n",
      "Epoch 0133 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.6104260651629073\n",
      "Training loss = 0.23494945228183853\n",
      "Validation accuracy = 0.53125\n",
      "Validation loss = 0.21950939670205116\n",
      "Epoch 0134 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.6106529850746268\n",
      "Training loss = 0.23482718255435722\n",
      "Validation accuracy = 0.8125\n",
      "Validation loss = 0.1661821948364377\n",
      "Epoch 0135 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.6110555555555556\n",
      "Training loss = 0.23464710447109408\n",
      "Validation accuracy = 0.71875\n",
      "Validation loss = 0.20214937441051006\n",
      "Epoch 0136 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.6113725490196078\n",
      "Training loss = 0.23446235291851575\n",
      "Validation accuracy = 0.8125\n",
      "Validation loss = 0.20941461995244026\n",
      "Epoch 0137 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.611654501216545\n",
      "Training loss = 0.23438787517692994\n",
      "Validation accuracy = 0.65625\n",
      "Validation loss = 0.21491970214992762\n",
      "Epoch 0138 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.6120108695652174\n",
      "Training loss = 0.2342605973392329\n",
      "Validation accuracy = 0.75\n",
      "Validation loss = 0.20279764756560326\n",
      "Epoch 0139 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.612242206235012\n",
      "Training loss = 0.2341413265008399\n",
      "Validation accuracy = 0.65625\n",
      "Validation loss = 0.22118929028511047\n",
      "Epoch 0140 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.6127321428571428\n",
      "Training loss = 0.2339568415927213\n",
      "Validation accuracy = 0.46875\n",
      "Validation loss = 0.24863269459456205\n",
      "Epoch 0141 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.6130023640661939\n",
      "Training loss = 0.2338318437425063\n",
      "Validation accuracy = 0.75\n",
      "Validation loss = 0.2000901810824871\n",
      "Epoch 0142 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.6133039906103286\n",
      "Training loss = 0.2336648796739258\n",
      "Validation accuracy = 0.71875\n",
      "Validation loss = 0.21707668527960777\n",
      "Epoch 0143 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.6135431235431236\n",
      "Training loss = 0.233577738329855\n",
      "Validation accuracy = 0.75\n",
      "Validation loss = 0.21291873790323734\n",
      "Epoch 0144 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.6138136574074075\n",
      "Training loss = 0.23344991129676432\n",
      "Validation accuracy = 0.75\n",
      "Validation loss = 0.1866985373198986\n",
      "Epoch 0145 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.6140977011494253\n",
      "Training loss = 0.233317451644646\n",
      "Validation accuracy = 0.71875\n",
      "Validation loss = 0.19454395957291126\n",
      "Epoch 0146 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.6144977168949771\n",
      "Training loss = 0.23314461648302603\n",
      "Validation accuracy = 0.5625\n",
      "Validation loss = 0.23351694270968437\n",
      "Epoch 0147 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.6146882086167801\n",
      "Training loss = 0.23303159966532674\n",
      "Validation accuracy = 0.6875\n",
      "Validation loss = 0.23375010676681995\n",
      "Epoch 0148 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.6150112612612613\n",
      "Training loss = 0.23290701622286022\n",
      "Validation accuracy = 0.75\n",
      "Validation loss = 0.20666417479515076\n",
      "Epoch 0149 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.6152293064876958\n",
      "Training loss = 0.23281847822844515\n",
      "Validation accuracy = 0.625\n",
      "Validation loss = 0.2123114075511694\n",
      "Epoch 0150 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.6154611111111111\n",
      "Training loss = 0.23277919154788057\n",
      "Validation accuracy = 0.5625\n",
      "Validation loss = 0.22938373312354088\n",
      "Epoch 0151 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.615667770419426\n",
      "Training loss = 0.23266130765073545\n",
      "Validation accuracy = 0.5625\n",
      "Validation loss = 0.22525213658809662\n",
      "Epoch 0152 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.6159265350877193\n",
      "Training loss = 0.23250058880737542\n",
      "Validation accuracy = 0.78125\n",
      "Validation loss = 0.1824955828487873\n",
      "Epoch 0153 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.6161165577342048\n",
      "Training loss = 0.2323725329460434\n",
      "Validation accuracy = 0.59375\n",
      "Validation loss = 0.22384989634156227\n",
      "Epoch 0154 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.6162878787878788\n",
      "Training loss = 0.2322601949374365\n",
      "Validation accuracy = 0.75\n",
      "Validation loss = 0.21472368761897087\n",
      "Epoch 0155 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.6165\n",
      "Training loss = 0.23215369147711223\n",
      "Validation accuracy = 0.6875\n",
      "Validation loss = 0.21802120842039585\n",
      "Epoch 0156 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.6168482905982906\n",
      "Training loss = 0.23202992325990945\n",
      "Validation accuracy = 0.84375\n",
      "Validation loss = 0.19812863320112228\n",
      "Epoch 0157 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.6171549893842887\n",
      "Training loss = 0.23191631373018026\n",
      "Validation accuracy = 0.71875\n",
      "Validation loss = 0.21850487031042576\n",
      "Epoch 0158 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.6174261603375527\n",
      "Training loss = 0.23175160368558664\n",
      "Validation accuracy = 0.75\n",
      "Validation loss = 0.20060116238892078\n",
      "Epoch 0159 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.6177672955974842\n",
      "Training loss = 0.23164862176555695\n",
      "Validation accuracy = 0.75\n",
      "Validation loss = 0.18941787257790565\n",
      "Epoch 0160 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.618046875\n",
      "Training loss = 0.23151308579440227\n",
      "Validation accuracy = 0.8125\n",
      "Validation loss = 0.17815332114696503\n",
      "Epoch 0161 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.6184109730848861\n",
      "Training loss = 0.23137491780508687\n",
      "Validation accuracy = 0.78125\n",
      "Validation loss = 0.1852179579436779\n",
      "Epoch 0162 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.6184979423868313\n",
      "Training loss = 0.23131161337059158\n",
      "Validation accuracy = 0.625\n",
      "Validation loss = 0.23971889447420835\n",
      "Epoch 0163 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.6187934560327198\n",
      "Training loss = 0.2311973770563862\n",
      "Validation accuracy = 0.5\n",
      "Validation loss = 0.2373990435153246\n",
      "Epoch 0164 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.6190497967479675\n",
      "Training loss = 0.23107432175601825\n",
      "Validation accuracy = 0.625\n",
      "Validation loss = 0.2269915398210287\n",
      "Epoch 0165 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.6193232323232323\n",
      "Training loss = 0.23093523302621613\n",
      "Validation accuracy = 0.4375\n",
      "Validation loss = 0.24282937683165073\n",
      "Epoch 0166 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.6194929718875501\n",
      "Training loss = 0.23081834567905252\n",
      "Validation accuracy = 0.625\n",
      "Validation loss = 0.21989518962800503\n",
      "Epoch 0167 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.6198702594810379\n",
      "Training loss = 0.2306585612904258\n",
      "Validation accuracy = 0.78125\n",
      "Validation loss = 0.1818021209910512\n",
      "Epoch 0168 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.6201587301587301\n",
      "Training loss = 0.23050924826612962\n",
      "Validation accuracy = 0.71875\n",
      "Validation loss = 0.19756004959344864\n",
      "Epoch 0169 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.6203895463510848\n",
      "Training loss = 0.2304090946669556\n",
      "Validation accuracy = 0.75\n",
      "Validation loss = 0.18693844508379698\n",
      "Epoch 0170 / 0200\n",
      "=====================================\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training accuracy = 0.6206029411764706\n",
      "Training loss = 0.23027424205876157\n",
      "Validation accuracy = 0.78125\n",
      "Validation loss = 0.2077216198667884\n",
      "Epoch 0171 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.6207163742690058\n",
      "Training loss = 0.23021045194172662\n",
      "Validation accuracy = 0.8125\n",
      "Validation loss = 0.17624613549560308\n",
      "Epoch 0172 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.6209932170542636\n",
      "Training loss = 0.2300876971222316\n",
      "Validation accuracy = 0.6875\n",
      "Validation loss = 0.20952296070754528\n",
      "Epoch 0173 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.6212909441233141\n",
      "Training loss = 0.22997231959198425\n",
      "Validation accuracy = 0.75\n",
      "Validation loss = 0.19429029989987612\n",
      "Epoch 0174 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.6214894636015326\n",
      "Training loss = 0.22986596366390585\n",
      "Validation accuracy = 0.78125\n",
      "Validation loss = 0.20656472258269787\n",
      "Epoch 0175 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.6216142857142857\n",
      "Training loss = 0.229763414724455\n",
      "Validation accuracy = 0.65625\n",
      "Validation loss = 0.22585073672235012\n",
      "Epoch 0176 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.6218939393939394\n",
      "Training loss = 0.22962090507932853\n",
      "Validation accuracy = 0.78125\n",
      "Validation loss = 0.19033183064311743\n",
      "Epoch 0177 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.6222033898305085\n",
      "Training loss = 0.22950804982923687\n",
      "Validation accuracy = 0.84375\n",
      "Validation loss = 0.19005974009633064\n",
      "Epoch 0178 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.6224297752808988\n",
      "Training loss = 0.22939399937195668\n",
      "Validation accuracy = 0.75\n",
      "Validation loss = 0.19590150844305754\n",
      "Epoch 0179 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.6226070763500932\n",
      "Training loss = 0.22936877585642276\n",
      "Validation accuracy = 0.6875\n",
      "Validation loss = 0.19902478531002998\n",
      "Epoch 0180 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.6227685185185186\n",
      "Training loss = 0.2292843333133669\n",
      "Validation accuracy = 0.75\n",
      "Validation loss = 0.19196817465126514\n",
      "Epoch 0181 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.6229373848987109\n",
      "Training loss = 0.22918573835538786\n",
      "Validation accuracy = 0.75\n",
      "Validation loss = 0.18957842513918877\n",
      "Epoch 0182 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.6231135531135531\n",
      "Training loss = 0.22912400249596482\n",
      "Validation accuracy = 0.8125\n",
      "Validation loss = 0.1930272076278925\n",
      "Epoch 0183 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.6233606557377049\n",
      "Training loss = 0.22906906689288187\n",
      "Validation accuracy = 0.6875\n",
      "Validation loss = 0.22531618922948837\n",
      "Epoch 0184 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.6235190217391304\n",
      "Training loss = 0.22897114347113107\n",
      "Validation accuracy = 0.6875\n",
      "Validation loss = 0.2060501929372549\n",
      "Epoch 0185 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.6237252252252252\n",
      "Training loss = 0.2288540620776984\n",
      "Validation accuracy = 0.5625\n",
      "Validation loss = 0.22755114920437336\n",
      "Epoch 0186 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.6238978494623656\n",
      "Training loss = 0.2287829277513542\n",
      "Validation accuracy = 0.625\n",
      "Validation loss = 0.2055390253663063\n",
      "Epoch 0187 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.6240775401069518\n",
      "Training loss = 0.22865692097195647\n",
      "Validation accuracy = 0.75\n",
      "Validation loss = 0.2075716843828559\n",
      "Epoch 0188 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.6243129432624114\n",
      "Training loss = 0.22856046753994963\n",
      "Validation accuracy = 0.8125\n",
      "Validation loss = 0.1670007584616542\n",
      "Epoch 0189 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.6245017636684304\n",
      "Training loss = 0.22840569569333416\n",
      "Validation accuracy = 0.59375\n",
      "Validation loss = 0.25604130513966084\n",
      "Epoch 0190 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.6246271929824562\n",
      "Training loss = 0.22831715449102616\n",
      "Validation accuracy = 0.78125\n",
      "Validation loss = 0.17140643298625946\n",
      "Epoch 0191 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.6248516579406632\n",
      "Training loss = 0.22821957298832415\n",
      "Validation accuracy = 0.65625\n",
      "Validation loss = 0.1912300679832697\n",
      "Epoch 0192 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.6251649305555556\n",
      "Training loss = 0.22809051194525737\n",
      "Validation accuracy = 0.71875\n",
      "Validation loss = 0.1791219785809517\n",
      "Epoch 0193 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.6254058721934369\n",
      "Training loss = 0.22799842441444879\n",
      "Validation accuracy = 0.5625\n",
      "Validation loss = 0.2352519752457738\n",
      "Epoch 0194 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.625618556701031\n",
      "Training loss = 0.22787767432284417\n",
      "Validation accuracy = 0.8125\n",
      "Validation loss = 0.19492351915687323\n",
      "Epoch 0195 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.6257820512820513\n",
      "Training loss = 0.22775869173040758\n",
      "Validation accuracy = 0.5625\n",
      "Validation loss = 0.22005501575767994\n",
      "Epoch 0196 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.6260416666666667\n",
      "Training loss = 0.22767664721260975\n",
      "Validation accuracy = 0.71875\n",
      "Validation loss = 0.1884996648877859\n",
      "Epoch 0197 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.626324027072758\n",
      "Training loss = 0.22754315461137675\n",
      "Validation accuracy = 0.6875\n",
      "Validation loss = 0.19455705769360065\n",
      "Epoch 0198 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.626456228956229\n",
      "Training loss = 0.22747229927417004\n",
      "Validation accuracy = 0.6875\n",
      "Validation loss = 0.2084274347871542\n",
      "Epoch 0199 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.6266457286432161\n",
      "Training loss = 0.2273598927190805\n",
      "Validation accuracy = 0.5\n",
      "Validation loss = 0.26597022265195847\n",
      "Epoch 0200 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.6268791666666667\n",
      "Training loss = 0.22723844266533852\n",
      "Validation accuracy = 0.78125\n",
      "Validation loss = 0.1762549728155136\n",
      "Making model for session group 20210310_15:32:14.252-20210319_16:19:24.958\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/imblearn/utils/_validation.py:326: UserWarning: After over-sampling, the number of samples (300) in class car will be larger than the number of samples in the majority class (class #signpost -> 160)\n",
      "  n_samples_majority,\n",
      "/usr/local/lib/python3.6/dist-packages/imblearn/utils/_validation.py:326: UserWarning: After over-sampling, the number of samples (300) in class signpost will be larger than the number of samples in the majority class (class #signpost -> 160)\n",
      "  n_samples_majority,\n",
      "/usr/local/lib/python3.6/dist-packages/imblearn/utils/_validation.py:326: UserWarning: After over-sampling, the number of samples (300) in class tree will be larger than the number of samples in the majority class (class #signpost -> 160)\n",
      "  n_samples_majority,\n",
      "/usr/local/lib/python3.6/dist-packages/imblearn/utils/_validation.py:326: UserWarning: After over-sampling, the number of samples (300) in class wall will be larger than the number of samples in the majority class (class #signpost -> 160)\n",
      "  n_samples_majority,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0001 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.38166666666666665\n",
      "Training loss = 0.3201738113661607\n",
      "Validation accuracy = 0.40625\n",
      "Validation loss = 0.31576818600296974\n",
      "Epoch 0002 / 0200\n",
      "=====================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/_classification.py:1221: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training accuracy = 0.44125\n",
      "Training loss = 0.31135754885772865\n",
      "Validation accuracy = 0.40625\n",
      "Validation loss = 0.30333814583718777\n",
      "Epoch 0003 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.4652777777777778\n",
      "Training loss = 0.30393667893277276\n",
      "Validation accuracy = 0.6875\n",
      "Validation loss = 0.28357110545039177\n",
      "Epoch 0004 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.4839583333333333\n",
      "Training loss = 0.2986445883537332\n",
      "Validation accuracy = 0.65625\n",
      "Validation loss = 0.2823042143136263\n",
      "Epoch 0005 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.4935\n",
      "Training loss = 0.29463366767764093\n",
      "Validation accuracy = 0.6875\n",
      "Validation loss = 0.25555168092250824\n",
      "Epoch 0006 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.5027777777777778\n",
      "Training loss = 0.29155059484971896\n",
      "Validation accuracy = 0.71875\n",
      "Validation loss = 0.2534965444356203\n",
      "Epoch 0007 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.5094047619047619\n",
      "Training loss = 0.28832229434734297\n",
      "Validation accuracy = 0.625\n",
      "Validation loss = 0.25305975042283535\n",
      "Epoch 0008 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.5161458333333333\n",
      "Training loss = 0.28578009829856454\n",
      "Validation accuracy = 0.5\n",
      "Validation loss = 0.25604080595076084\n",
      "Epoch 0009 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.5201851851851852\n",
      "Training loss = 0.28389171274999775\n",
      "Validation accuracy = 0.65625\n",
      "Validation loss = 0.24883930385112762\n",
      "Epoch 0010 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.5231666666666667\n",
      "Training loss = 0.281889452594022\n",
      "Validation accuracy = 0.625\n",
      "Validation loss = 0.23584830202162266\n",
      "Epoch 0011 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.5268181818181819\n",
      "Training loss = 0.2794023240560835\n",
      "Validation accuracy = 0.71875\n",
      "Validation loss = 0.23869177512824535\n",
      "Epoch 0012 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.530625\n",
      "Training loss = 0.27760093958427506\n",
      "Validation accuracy = 0.625\n",
      "Validation loss = 0.23775165900588036\n",
      "Epoch 0013 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.5341025641025641\n",
      "Training loss = 0.27595732868481904\n",
      "Validation accuracy = 0.71875\n",
      "Validation loss = 0.2330168578773737\n",
      "Epoch 0014 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.5364880952380953\n",
      "Training loss = 0.27492827589135793\n",
      "Validation accuracy = 0.59375\n",
      "Validation loss = 0.2376860547810793\n",
      "Epoch 0015 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.5392777777777777\n",
      "Training loss = 0.27368550984727014\n",
      "Validation accuracy = 0.625\n",
      "Validation loss = 0.22884417325258255\n",
      "Epoch 0016 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.541875\n",
      "Training loss = 0.2725251537033667\n",
      "Validation accuracy = 0.59375\n",
      "Validation loss = 0.22838734928518534\n",
      "Epoch 0017 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.5436274509803921\n",
      "Training loss = 0.2714296337377791\n",
      "Validation accuracy = 0.53125\n",
      "Validation loss = 0.2488135788589716\n",
      "Epoch 0018 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.5460185185185186\n",
      "Training loss = 0.27002972712257395\n",
      "Validation accuracy = 0.65625\n",
      "Validation loss = 0.2150784470140934\n",
      "Epoch 0019 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.5481140350877193\n",
      "Training loss = 0.2690602525833406\n",
      "Validation accuracy = 0.59375\n",
      "Validation loss = 0.24429967533797026\n",
      "Epoch 0020 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.54875\n",
      "Training loss = 0.2685063978396356\n",
      "Validation accuracy = 0.59375\n",
      "Validation loss = 0.2413033489137888\n",
      "Epoch 0021 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.5501190476190476\n",
      "Training loss = 0.2677396570891142\n",
      "Validation accuracy = 0.53125\n",
      "Validation loss = 0.24674751237034798\n",
      "Epoch 0022 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.5518939393939394\n",
      "Training loss = 0.26667870909201374\n",
      "Validation accuracy = 0.6875\n",
      "Validation loss = 0.22668436355888844\n",
      "Epoch 0023 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.552572463768116\n",
      "Training loss = 0.26627633940050566\n",
      "Validation accuracy = 0.59375\n",
      "Validation loss = 0.23004490695893764\n",
      "Epoch 0024 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.5536458333333333\n",
      "Training loss = 0.2656273890576429\n",
      "Validation accuracy = 0.5\n",
      "Validation loss = 0.24605613015592098\n",
      "Epoch 0025 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.5551\n",
      "Training loss = 0.26461056556801\n",
      "Validation accuracy = 0.5\n",
      "Validation loss = 0.25780039839446545\n",
      "Epoch 0026 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.5560897435897436\n",
      "Training loss = 0.26432633475233347\n",
      "Validation accuracy = 0.6875\n",
      "Validation loss = 0.21482858806848526\n",
      "Epoch 0027 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.5572222222222222\n",
      "Training loss = 0.263761481611449\n",
      "Validation accuracy = 0.6875\n",
      "Validation loss = 0.21560553833842278\n",
      "Epoch 0028 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.5572321428571428\n",
      "Training loss = 0.2634830132845257\n",
      "Validation accuracy = 0.75\n",
      "Validation loss = 0.21589384600520134\n",
      "Epoch 0029 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.5589942528735632\n",
      "Training loss = 0.262682148467364\n",
      "Validation accuracy = 0.71875\n",
      "Validation loss = 0.2283970396965742\n",
      "Epoch 0030 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.5605\n",
      "Training loss = 0.2620905591199795\n",
      "Validation accuracy = 0.6875\n",
      "Validation loss = 0.23323685862123966\n",
      "Epoch 0031 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.5605913978494623\n",
      "Training loss = 0.261740864861396\n",
      "Validation accuracy = 0.65625\n",
      "Validation loss = 0.23211473785340786\n",
      "Epoch 0032 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.5626041666666667\n",
      "Training loss = 0.2610505823690134\n",
      "Validation accuracy = 0.6875\n",
      "Validation loss = 0.22597960382699966\n",
      "Epoch 0033 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.5634848484848485\n",
      "Training loss = 0.2604416591282746\n",
      "Validation accuracy = 0.5\n",
      "Validation loss = 0.2588924942538142\n",
      "Epoch 0034 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.5642156862745098\n",
      "Training loss = 0.2600488812023518\n",
      "Validation accuracy = 0.75\n",
      "Validation loss = 0.22908055875450373\n",
      "Epoch 0035 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.5653095238095238\n",
      "Training loss = 0.2594729805978991\n",
      "Validation accuracy = 0.75\n",
      "Validation loss = 0.21722442097961903\n",
      "Epoch 0036 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.5660416666666667\n",
      "Training loss = 0.25902638146860735\n",
      "Validation accuracy = 0.625\n",
      "Validation loss = 0.23624557070434093\n",
      "Epoch 0037 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.567027027027027\n",
      "Training loss = 0.2584107056877635\n",
      "Validation accuracy = 0.71875\n",
      "Validation loss = 0.20844833552837372\n",
      "Epoch 0038 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.5674780701754386\n",
      "Training loss = 0.2579537656962087\n",
      "Validation accuracy = 0.78125\n",
      "Validation loss = 0.1965885702520609\n",
      "Epoch 0039 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.5684615384615385\n",
      "Training loss = 0.25745904447813317\n",
      "Validation accuracy = 0.71875\n",
      "Validation loss = 0.2206124234944582\n",
      "Epoch 0040 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.5695208333333334\n",
      "Training loss = 0.2569910409518828\n",
      "Validation accuracy = 0.5625\n",
      "Validation loss = 0.2387950150296092\n",
      "Epoch 0041 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.5708739837398374\n",
      "Training loss = 0.25629366964162364\n",
      "Validation accuracy = 0.71875\n",
      "Validation loss = 0.22388028632849455\n",
      "Epoch 0042 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.5718253968253968\n",
      "Training loss = 0.2557642469969061\n",
      "Validation accuracy = 0.71875\n",
      "Validation loss = 0.21188722364604473\n",
      "Epoch 0043 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.5730620155038759\n",
      "Training loss = 0.25531183470473734\n",
      "Validation accuracy = 0.6875\n",
      "Validation loss = 0.2287327405065298\n",
      "Epoch 0044 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.5739962121212121\n",
      "Training loss = 0.2548797681227778\n",
      "Validation accuracy = 0.6875\n",
      "Validation loss = 0.19365427177399397\n",
      "Epoch 0045 / 0200\n",
      "=====================================\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training accuracy = 0.5746111111111111\n",
      "Training loss = 0.25444289171033435\n",
      "Validation accuracy = 0.53125\n",
      "Validation loss = 0.21354103740304708\n",
      "Epoch 0046 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.5754166666666667\n",
      "Training loss = 0.253968486196321\n",
      "Validation accuracy = 0.53125\n",
      "Validation loss = 0.23912928625941277\n",
      "Epoch 0047 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.5763652482269503\n",
      "Training loss = 0.2534879884747326\n",
      "Validation accuracy = 0.78125\n",
      "Validation loss = 0.20109687000513077\n",
      "Epoch 0048 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.5771354166666667\n",
      "Training loss = 0.2531354037594671\n",
      "Validation accuracy = 0.53125\n",
      "Validation loss = 0.23235110938549042\n",
      "Epoch 0049 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.5779761904761904\n",
      "Training loss = 0.25277913507555616\n",
      "Validation accuracy = 0.71875\n",
      "Validation loss = 0.21604997385293245\n",
      "Epoch 0050 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.5788666666666666\n",
      "Training loss = 0.2523524652282397\n",
      "Validation accuracy = 0.71875\n",
      "Validation loss = 0.22886601369827986\n",
      "Epoch 0051 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.5799346405228758\n",
      "Training loss = 0.25184806415847705\n",
      "Validation accuracy = 0.59375\n",
      "Validation loss = 0.22975261136889458\n",
      "Epoch 0052 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.5807371794871795\n",
      "Training loss = 0.2514210301403625\n",
      "Validation accuracy = 0.6875\n",
      "Validation loss = 0.20226176641881466\n",
      "Epoch 0053 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.5813993710691824\n",
      "Training loss = 0.25106857424262186\n",
      "Validation accuracy = 0.75\n",
      "Validation loss = 0.20298463385552168\n",
      "Epoch 0054 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.5821141975308642\n",
      "Training loss = 0.25071357603886246\n",
      "Validation accuracy = 0.71875\n",
      "Validation loss = 0.21014616824686527\n",
      "Epoch 0055 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.5824848484848485\n",
      "Training loss = 0.25040683904064426\n",
      "Validation accuracy = 0.6875\n",
      "Validation loss = 0.22739890404045582\n",
      "Epoch 0056 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.5832440476190476\n",
      "Training loss = 0.250063421345715\n",
      "Validation accuracy = 0.84375\n",
      "Validation loss = 0.19757476169615984\n",
      "Epoch 0057 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.5841374269005848\n",
      "Training loss = 0.24961199103827364\n",
      "Validation accuracy = 0.53125\n",
      "Validation loss = 0.21345697436481714\n",
      "Epoch 0058 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.5845977011494253\n",
      "Training loss = 0.24935634982226224\n",
      "Validation accuracy = 0.71875\n",
      "Validation loss = 0.1911364570260048\n",
      "Epoch 0059 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.5852401129943503\n",
      "Training loss = 0.24902428063716592\n",
      "Validation accuracy = 0.5625\n",
      "Validation loss = 0.24630179069936275\n",
      "Epoch 0060 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.5855\n",
      "Training loss = 0.24872776129055355\n",
      "Validation accuracy = 0.53125\n",
      "Validation loss = 0.23887960240244865\n",
      "Epoch 0061 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.5860928961748634\n",
      "Training loss = 0.24842852356370354\n",
      "Validation accuracy = 0.53125\n",
      "Validation loss = 0.22620917670428753\n",
      "Epoch 0062 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.5867204301075268\n",
      "Training loss = 0.24811297843292837\n",
      "Validation accuracy = 0.625\n",
      "Validation loss = 0.23412572033703327\n",
      "Epoch 0063 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.5875661375661375\n",
      "Training loss = 0.24774638420374936\n",
      "Validation accuracy = 0.71875\n",
      "Validation loss = 0.20571477711200714\n",
      "Epoch 0064 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.5879947916666667\n",
      "Training loss = 0.24758853216383916\n",
      "Validation accuracy = 0.75\n",
      "Validation loss = 0.20715943165123463\n",
      "Epoch 0065 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.5885128205128205\n",
      "Training loss = 0.2473343163705789\n",
      "Validation accuracy = 0.71875\n",
      "Validation loss = 0.19401909690350294\n",
      "Epoch 0066 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.5891792929292929\n",
      "Training loss = 0.24708358793397142\n",
      "Validation accuracy = 0.75\n",
      "Validation loss = 0.20340661238878965\n",
      "Epoch 0067 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.5898507462686567\n",
      "Training loss = 0.24691220934118205\n",
      "Validation accuracy = 0.71875\n",
      "Validation loss = 0.2184826135635376\n",
      "Epoch 0068 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.5904411764705882\n",
      "Training loss = 0.2466037803950409\n",
      "Validation accuracy = 0.75\n",
      "Validation loss = 0.21525314450263977\n",
      "Epoch 0069 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.5908574879227053\n",
      "Training loss = 0.246414425952567\n",
      "Validation accuracy = 0.71875\n",
      "Validation loss = 0.19282442517578602\n",
      "Epoch 0070 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.5913690476190476\n",
      "Training loss = 0.2462004994551341\n",
      "Validation accuracy = 0.5\n",
      "Validation loss = 0.23521902412176132\n",
      "Epoch 0071 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.5918896713615024\n",
      "Training loss = 0.24594719165927367\n",
      "Validation accuracy = 0.6875\n",
      "Validation loss = 0.23583021946251392\n",
      "Epoch 0072 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.5923032407407407\n",
      "Training loss = 0.2457575853831238\n",
      "Validation accuracy = 0.75\n",
      "Validation loss = 0.22600804455578327\n",
      "Epoch 0073 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.5926712328767123\n",
      "Training loss = 0.2455542537835363\n",
      "Validation accuracy = 0.78125\n",
      "Validation loss = 0.20041054114699364\n",
      "Epoch 0074 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.5936486486486486\n",
      "Training loss = 0.24516493129434885\n",
      "Validation accuracy = 0.71875\n",
      "Validation loss = 0.23018961865454912\n",
      "Epoch 0075 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.5939111111111111\n",
      "Training loss = 0.2449818779528141\n",
      "Validation accuracy = 0.59375\n",
      "Validation loss = 0.21496731229126453\n",
      "Epoch 0076 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.5941666666666666\n",
      "Training loss = 0.24485131136321447\n",
      "Validation accuracy = 0.78125\n",
      "Validation loss = 0.2014469988644123\n",
      "Epoch 0077 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.5944805194805195\n",
      "Training loss = 0.24472823351170078\n",
      "Validation accuracy = 0.71875\n",
      "Validation loss = 0.21675982605665922\n",
      "Epoch 0078 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.5952564102564103\n",
      "Training loss = 0.2444597825376142\n",
      "Validation accuracy = 0.6875\n",
      "Validation loss = 0.20629256963729858\n",
      "Epoch 0079 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.5958438818565401\n",
      "Training loss = 0.244217462800286\n",
      "Validation accuracy = 0.71875\n",
      "Validation loss = 0.20416336879134178\n",
      "Epoch 0080 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.5964166666666667\n",
      "Training loss = 0.2439583482205247\n",
      "Validation accuracy = 0.71875\n",
      "Validation loss = 0.21564076095819473\n",
      "Epoch 0081 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.5969135802469135\n",
      "Training loss = 0.2437754920704497\n",
      "Validation accuracy = 0.71875\n",
      "Validation loss = 0.21453741006553173\n",
      "Epoch 0082 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.5973373983739837\n",
      "Training loss = 0.24357523799851175\n",
      "Validation accuracy = 0.71875\n",
      "Validation loss = 0.22302168980240822\n",
      "Epoch 0083 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.5975803212851406\n",
      "Training loss = 0.24337731709920737\n",
      "Validation accuracy = 0.71875\n",
      "Validation loss = 0.19306597206741571\n",
      "Epoch 0084 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.5978670634920635\n",
      "Training loss = 0.24323502548512013\n",
      "Validation accuracy = 0.71875\n",
      "Validation loss = 0.21164209209382534\n",
      "Epoch 0085 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.5982058823529411\n",
      "Training loss = 0.24306772626936435\n",
      "Validation accuracy = 0.53125\n",
      "Validation loss = 0.24104308430105448\n",
      "Epoch 0086 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.5990503875968992\n",
      "Training loss = 0.24274147707131483\n",
      "Validation accuracy = 0.6875\n",
      "Validation loss = 0.21727747656404972\n",
      "Epoch 0087 / 0200\n",
      "=====================================\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training accuracy = 0.5995019157088123\n",
      "Training loss = 0.2425179948198156\n",
      "Validation accuracy = 0.71875\n",
      "Validation loss = 0.21405320335179567\n",
      "Epoch 0088 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.6000189393939394\n",
      "Training loss = 0.24227320918474685\n",
      "Validation accuracy = 0.71875\n",
      "Validation loss = 0.21943497005850077\n",
      "Epoch 0089 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.6002434456928839\n",
      "Training loss = 0.24213807518088193\n",
      "Validation accuracy = 0.6875\n",
      "Validation loss = 0.2281839195638895\n",
      "Epoch 0090 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.6006851851851852\n",
      "Training loss = 0.2419822609493578\n",
      "Validation accuracy = 0.59375\n",
      "Validation loss = 0.20955324545502663\n",
      "Epoch 0091 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.601007326007326\n",
      "Training loss = 0.24175027233203908\n",
      "Validation accuracy = 0.53125\n",
      "Validation loss = 0.2370626525953412\n",
      "Epoch 0092 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.6014311594202899\n",
      "Training loss = 0.24152802136254267\n",
      "Validation accuracy = 0.75\n",
      "Validation loss = 0.20747444126755\n",
      "Epoch 0093 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.6020071684587813\n",
      "Training loss = 0.24122313467965972\n",
      "Validation accuracy = 0.6875\n",
      "Validation loss = 0.20092864520847797\n",
      "Epoch 0094 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.6023581560283688\n",
      "Training loss = 0.24096106174910534\n",
      "Validation accuracy = 0.6875\n",
      "Validation loss = 0.221667118370533\n",
      "Epoch 0095 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.602719298245614\n",
      "Training loss = 0.24079924612819104\n",
      "Validation accuracy = 0.65625\n",
      "Validation loss = 0.22471864614635706\n",
      "Epoch 0096 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.6032118055555555\n",
      "Training loss = 0.24049100434950862\n",
      "Validation accuracy = 0.5625\n",
      "Validation loss = 0.21845939941704273\n",
      "Epoch 0097 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.6036168384879725\n",
      "Training loss = 0.2402931294864191\n",
      "Validation accuracy = 0.6875\n",
      "Validation loss = 0.20214036665856838\n",
      "Epoch 0098 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.6041071428571428\n",
      "Training loss = 0.24006107887392547\n",
      "Validation accuracy = 0.59375\n",
      "Validation loss = 0.1975776432082057\n",
      "Epoch 0099 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.604469696969697\n",
      "Training loss = 0.23982468348184618\n",
      "Validation accuracy = 0.75\n",
      "Validation loss = 0.18988709896802902\n",
      "Epoch 0100 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.6050833333333333\n",
      "Training loss = 0.23959289825161298\n",
      "Validation accuracy = 0.6875\n",
      "Validation loss = 0.20185430627316236\n",
      "Epoch 0101 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.605470297029703\n",
      "Training loss = 0.2394447105043497\n",
      "Validation accuracy = 0.6875\n",
      "Validation loss = 0.2102679256349802\n",
      "Epoch 0102 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.6056535947712418\n",
      "Training loss = 0.2393419466316213\n",
      "Validation accuracy = 0.625\n",
      "Validation loss = 0.2307221544906497\n",
      "Epoch 0103 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.6061650485436894\n",
      "Training loss = 0.23904325418270714\n",
      "Validation accuracy = 0.625\n",
      "Validation loss = 0.2275766283273697\n",
      "Epoch 0104 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.6065384615384616\n",
      "Training loss = 0.23884193958045963\n",
      "Validation accuracy = 0.6875\n",
      "Validation loss = 0.2171150455251336\n",
      "Epoch 0105 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.6069444444444444\n",
      "Training loss = 0.23864029569734657\n",
      "Validation accuracy = 0.625\n",
      "Validation loss = 0.23085503559559584\n",
      "Epoch 0106 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.6075\n",
      "Training loss = 0.23841504741178932\n",
      "Validation accuracy = 0.75\n",
      "Validation loss = 0.20130348205566406\n",
      "Epoch 0107 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.6080218068535825\n",
      "Training loss = 0.23822362723055288\n",
      "Validation accuracy = 0.6875\n",
      "Validation loss = 0.2090157549828291\n",
      "Epoch 0108 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.6081944444444445\n",
      "Training loss = 0.2380900227683194\n",
      "Validation accuracy = 0.71875\n",
      "Validation loss = 0.2075007213279605\n",
      "Epoch 0109 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.608631498470948\n",
      "Training loss = 0.237881273197107\n",
      "Validation accuracy = 0.5625\n",
      "Validation loss = 0.21532320324331522\n",
      "Epoch 0110 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.609030303030303\n",
      "Training loss = 0.2376827645326654\n",
      "Validation accuracy = 0.59375\n",
      "Validation loss = 0.24194895941764116\n",
      "Epoch 0111 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.6096021021021021\n",
      "Training loss = 0.23747639364420295\n",
      "Validation accuracy = 0.75\n",
      "Validation loss = 0.1988043673336506\n",
      "Epoch 0112 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.6100223214285714\n",
      "Training loss = 0.23732095867838887\n",
      "Validation accuracy = 0.625\n",
      "Validation loss = 0.22115606721490622\n",
      "Epoch 0113 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.6103023598820059\n",
      "Training loss = 0.2371368771395852\n",
      "Validation accuracy = 0.65625\n",
      "Validation loss = 0.19749888218939304\n",
      "Epoch 0114 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.6106067251461988\n",
      "Training loss = 0.2369850554779085\n",
      "Validation accuracy = 0.75\n",
      "Validation loss = 0.19616295211017132\n",
      "Epoch 0115 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.6107971014492753\n",
      "Training loss = 0.2368752596274666\n",
      "Validation accuracy = 0.75\n",
      "Validation loss = 0.19892829284071922\n",
      "Epoch 0116 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.6112715517241379\n",
      "Training loss = 0.23668726568634826\n",
      "Validation accuracy = 0.5625\n",
      "Validation loss = 0.2326697465032339\n",
      "Epoch 0117 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.6115954415954415\n",
      "Training loss = 0.2365063468700121\n",
      "Validation accuracy = 0.59375\n",
      "Validation loss = 0.2149859657511115\n",
      "Epoch 0118 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.6119209039548023\n",
      "Training loss = 0.236401661036715\n",
      "Validation accuracy = 0.75\n",
      "Validation loss = 0.22405491210520267\n",
      "Epoch 0119 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.612233893557423\n",
      "Training loss = 0.23623142794150265\n",
      "Validation accuracy = 0.75\n",
      "Validation loss = 0.20207681320607662\n",
      "Epoch 0120 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.6125347222222223\n",
      "Training loss = 0.2360408840694775\n",
      "Validation accuracy = 0.75\n",
      "Validation loss = 0.1995751028880477\n",
      "Epoch 0121 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.6128236914600551\n",
      "Training loss = 0.23591939931483966\n",
      "Validation accuracy = 0.71875\n",
      "Validation loss = 0.21115936804562807\n",
      "Epoch 0122 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.6131079234972677\n",
      "Training loss = 0.23573104318557053\n",
      "Validation accuracy = 0.65625\n",
      "Validation loss = 0.21145791839808226\n",
      "Epoch 0123 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.6133875338753387\n",
      "Training loss = 0.2355965306088934\n",
      "Validation accuracy = 0.59375\n",
      "Validation loss = 0.2278268365189433\n",
      "Epoch 0124 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.6135349462365591\n",
      "Training loss = 0.23549518935101968\n",
      "Validation accuracy = 0.53125\n",
      "Validation loss = 0.21911457553505898\n",
      "Epoch 0125 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.6139\n",
      "Training loss = 0.23534396883388362\n",
      "Validation accuracy = 0.6875\n",
      "Validation loss = 0.1867810320109129\n",
      "Epoch 0126 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.6141137566137567\n",
      "Training loss = 0.23523018006117097\n",
      "Validation accuracy = 0.625\n",
      "Validation loss = 0.2112571457400918\n",
      "Epoch 0127 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.6143307086614174\n",
      "Training loss = 0.23510919340326406\n",
      "Validation accuracy = 0.65625\n",
      "Validation loss = 0.21827862225472927\n",
      "Epoch 0128 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.61470703125\n",
      "Training loss = 0.23495346206162745\n",
      "Validation accuracy = 0.75\n",
      "Validation loss = 0.19528726302087307\n",
      "Epoch 0129 / 0200\n",
      "=====================================\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training accuracy = 0.6150968992248061\n",
      "Training loss = 0.2347655866410612\n",
      "Validation accuracy = 0.75\n",
      "Validation loss = 0.2012124378234148\n",
      "Epoch 0130 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.6153717948717948\n",
      "Training loss = 0.23467568274530082\n",
      "Validation accuracy = 0.75\n",
      "Validation loss = 0.19754651747643948\n",
      "Epoch 0131 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.615737913486005\n",
      "Training loss = 0.23452887688580967\n",
      "Validation accuracy = 0.59375\n",
      "Validation loss = 0.2060318998992443\n",
      "Epoch 0132 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.6161363636363636\n",
      "Training loss = 0.23434222421693532\n",
      "Validation accuracy = 0.71875\n",
      "Validation loss = 0.18446949496865273\n",
      "Epoch 0133 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.6164473684210526\n",
      "Training loss = 0.23417095425825818\n",
      "Validation accuracy = 0.8125\n",
      "Validation loss = 0.20509647205471992\n",
      "Epoch 0134 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.616797263681592\n",
      "Training loss = 0.23397592956765523\n",
      "Validation accuracy = 0.65625\n",
      "Validation loss = 0.1960559319704771\n",
      "Epoch 0135 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.6169074074074075\n",
      "Training loss = 0.23392804182734755\n",
      "Validation accuracy = 0.75\n",
      "Validation loss = 0.20561092905700207\n",
      "Epoch 0136 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.6172916666666667\n",
      "Training loss = 0.23381917638156344\n",
      "Validation accuracy = 0.5\n",
      "Validation loss = 0.24218403361737728\n",
      "Epoch 0137 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.61757299270073\n",
      "Training loss = 0.23368724463829305\n",
      "Validation accuracy = 0.625\n",
      "Validation loss = 0.22328184358775616\n",
      "Epoch 0138 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.6179347826086956\n",
      "Training loss = 0.23354196452378218\n",
      "Validation accuracy = 0.75\n",
      "Validation loss = 0.2083939230069518\n",
      "Epoch 0139 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.6181954436450839\n",
      "Training loss = 0.2334321735790379\n",
      "Validation accuracy = 0.75\n",
      "Validation loss = 0.17985991016030312\n",
      "Epoch 0140 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.6185595238095238\n",
      "Training loss = 0.23323777524044825\n",
      "Validation accuracy = 0.75\n",
      "Validation loss = 0.2107490934431553\n",
      "Epoch 0141 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.6188179669030733\n",
      "Training loss = 0.23311256088527804\n",
      "Validation accuracy = 0.78125\n",
      "Validation loss = 0.18874293100088835\n",
      "Epoch 0142 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.6192488262910798\n",
      "Training loss = 0.23292021248682004\n",
      "Validation accuracy = 0.75\n",
      "Validation loss = 0.20342579018324614\n",
      "Epoch 0143 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.6195571095571095\n",
      "Training loss = 0.23276202235049578\n",
      "Validation accuracy = 0.59375\n",
      "Validation loss = 0.22232909314334393\n",
      "Epoch 0144 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.6198611111111111\n",
      "Training loss = 0.232597319331641\n",
      "Validation accuracy = 0.625\n",
      "Validation loss = 0.21052183862775564\n",
      "Epoch 0145 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.6202011494252874\n",
      "Training loss = 0.23242931221853727\n",
      "Validation accuracy = 0.78125\n",
      "Validation loss = 0.20110248867422342\n",
      "Epoch 0146 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.6204223744292238\n",
      "Training loss = 0.2323201129000345\n",
      "Validation accuracy = 0.8125\n",
      "Validation loss = 0.17678691539913416\n",
      "Epoch 0147 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.6206859410430839\n",
      "Training loss = 0.23217503605566733\n",
      "Validation accuracy = 0.59375\n",
      "Validation loss = 0.22592996060848236\n",
      "Epoch 0148 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.6207939189189189\n",
      "Training loss = 0.2321068293124706\n",
      "Validation accuracy = 0.46875\n",
      "Validation loss = 0.25969017669558525\n",
      "Epoch 0149 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.6210234899328859\n",
      "Training loss = 0.23202129297858518\n",
      "Validation accuracy = 0.75\n",
      "Validation loss = 0.2010554661974311\n",
      "Epoch 0150 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.6212666666666666\n",
      "Training loss = 0.23187277709758944\n",
      "Validation accuracy = 0.75\n",
      "Validation loss = 0.191094059497118\n",
      "Epoch 0151 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.6214238410596027\n",
      "Training loss = 0.23177011720293406\n",
      "Validation accuracy = 0.75\n",
      "Validation loss = 0.21522176079452038\n",
      "Epoch 0152 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.6215131578947368\n",
      "Training loss = 0.23168055342510344\n",
      "Validation accuracy = 0.5625\n",
      "Validation loss = 0.22739029116928577\n",
      "Epoch 0153 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.6218028322440087\n",
      "Training loss = 0.23153017297062478\n",
      "Validation accuracy = 0.5\n",
      "Validation loss = 0.25779564026743174\n",
      "Epoch 0154 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.6219859307359308\n",
      "Training loss = 0.23142391931604256\n",
      "Validation accuracy = 0.5625\n",
      "Validation loss = 0.23495208472013474\n",
      "Epoch 0155 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.6222849462365592\n",
      "Training loss = 0.23124016650758122\n",
      "Validation accuracy = 0.71875\n",
      "Validation loss = 0.19802365731447935\n",
      "Epoch 0156 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.6223985042735043\n",
      "Training loss = 0.23113589574113233\n",
      "Validation accuracy = 0.625\n",
      "Validation loss = 0.21547962352633476\n",
      "Epoch 0157 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.6226539278131635\n",
      "Training loss = 0.23098854076821207\n",
      "Validation accuracy = 0.6875\n",
      "Validation loss = 0.20794316660612822\n",
      "Epoch 0158 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.6229430379746835\n",
      "Training loss = 0.23082902610254816\n",
      "Validation accuracy = 0.71875\n",
      "Validation loss = 0.1898469002917409\n",
      "Epoch 0159 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.6231761006289308\n",
      "Training loss = 0.23068255461752415\n",
      "Validation accuracy = 0.53125\n",
      "Validation loss = 0.2286812588572502\n",
      "Epoch 0160 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.623546875\n",
      "Training loss = 0.23051799455983565\n",
      "Validation accuracy = 0.53125\n",
      "Validation loss = 0.26045046653598547\n",
      "Epoch 0161 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.6238768115942029\n",
      "Training loss = 0.23039981895768494\n",
      "Validation accuracy = 0.34375\n",
      "Validation loss = 0.3013773765414953\n",
      "Epoch 0162 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.6242129629629629\n",
      "Training loss = 0.23019810807588414\n",
      "Validation accuracy = 0.65625\n",
      "Validation loss = 0.2197168618440628\n",
      "Epoch 0163 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.6244427402862985\n",
      "Training loss = 0.23004457359649774\n",
      "Validation accuracy = 0.53125\n",
      "Validation loss = 0.22985499631613493\n",
      "Epoch 0164 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.6247713414634146\n",
      "Training loss = 0.22994550168302244\n",
      "Validation accuracy = 0.75\n",
      "Validation loss = 0.18568688165396452\n",
      "Epoch 0165 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.6250606060606061\n",
      "Training loss = 0.229782593446097\n",
      "Validation accuracy = 0.59375\n",
      "Validation loss = 0.23942684475332499\n",
      "Epoch 0166 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.6254819277108433\n",
      "Training loss = 0.2296208260100649\n",
      "Validation accuracy = 0.71875\n",
      "Validation loss = 0.1964821359142661\n",
      "Epoch 0167 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.6258083832335329\n",
      "Training loss = 0.22946074020511614\n",
      "Validation accuracy = 0.71875\n",
      "Validation loss = 0.20428177900612354\n",
      "Epoch 0168 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.6261011904761905\n",
      "Training loss = 0.2293400401055872\n",
      "Validation accuracy = 0.53125\n",
      "Validation loss = 0.2265803162008524\n",
      "Epoch 0169 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.6262475345167653\n",
      "Training loss = 0.22925991189888362\n",
      "Validation accuracy = 0.5\n",
      "Validation loss = 0.25194060802459717\n",
      "Epoch 0170 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.6265196078431372\n",
      "Training loss = 0.22913235855599245\n",
      "Validation accuracy = 0.6875\n",
      "Validation loss = 0.2037842497229576\n",
      "Epoch 0171 / 0200\n",
      "=====================================\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training accuracy = 0.6267592592592592\n",
      "Training loss = 0.2289834415052834\n",
      "Validation accuracy = 0.53125\n",
      "Validation loss = 0.22185220010578632\n",
      "Epoch 0172 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.6270106589147287\n",
      "Training loss = 0.22884408193445482\n",
      "Validation accuracy = 0.71875\n",
      "Validation loss = 0.1918304432183504\n",
      "Epoch 0173 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.6272928709055877\n",
      "Training loss = 0.22866982265747007\n",
      "Validation accuracy = 0.71875\n",
      "Validation loss = 0.20354640297591686\n",
      "Epoch 0174 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.6275383141762452\n",
      "Training loss = 0.2285598841974676\n",
      "Validation accuracy = 0.6875\n",
      "Validation loss = 0.19323056563735008\n",
      "Epoch 0175 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.6277571428571429\n",
      "Training loss = 0.22843366949629215\n",
      "Validation accuracy = 0.5625\n",
      "Validation loss = 0.23364533111453056\n",
      "Epoch 0176 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.6280492424242424\n",
      "Training loss = 0.22832507447452483\n",
      "Validation accuracy = 0.65625\n",
      "Validation loss = 0.21271730493754148\n",
      "Epoch 0177 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.6283380414312618\n",
      "Training loss = 0.22820224437252276\n",
      "Validation accuracy = 0.5625\n",
      "Validation loss = 0.21358142606914043\n",
      "Epoch 0178 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.6285205992509363\n",
      "Training loss = 0.228058722196391\n",
      "Validation accuracy = 0.6875\n",
      "Validation loss = 0.2138513782992959\n",
      "Epoch 0179 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.6288314711359404\n",
      "Training loss = 0.22790155467568607\n",
      "Validation accuracy = 0.65625\n",
      "Validation loss = 0.21636047586798668\n",
      "Epoch 0180 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.6290046296296297\n",
      "Training loss = 0.2278007372951618\n",
      "Validation accuracy = 0.46875\n",
      "Validation loss = 0.22812281362712383\n",
      "Epoch 0181 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.629231123388582\n",
      "Training loss = 0.22767944999546855\n",
      "Validation accuracy = 0.78125\n",
      "Validation loss = 0.18970467150211334\n",
      "Epoch 0182 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.6295054945054945\n",
      "Training loss = 0.22753824635371292\n",
      "Validation accuracy = 0.78125\n",
      "Validation loss = 0.17944695800542831\n",
      "Epoch 0183 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.6297677595628415\n",
      "Training loss = 0.2274255625979605\n",
      "Validation accuracy = 0.59375\n",
      "Validation loss = 0.22508744895458221\n",
      "Epoch 0184 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.630036231884058\n",
      "Training loss = 0.2273194630468345\n",
      "Validation accuracy = 0.59375\n",
      "Validation loss = 0.20324455574154854\n",
      "Epoch 0185 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.6302612612612613\n",
      "Training loss = 0.22722492885267412\n",
      "Validation accuracy = 0.625\n",
      "Validation loss = 0.21393959410488605\n",
      "Epoch 0186 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.6304301075268817\n",
      "Training loss = 0.22710899294637757\n",
      "Validation accuracy = 0.78125\n",
      "Validation loss = 0.19212647806853056\n",
      "Epoch 0187 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.6304946524064171\n",
      "Training loss = 0.22705542087010416\n",
      "Validation accuracy = 0.75\n",
      "Validation loss = 0.18792684748768806\n",
      "Epoch 0188 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.6306427304964539\n",
      "Training loss = 0.22692684822880946\n",
      "Validation accuracy = 0.75\n",
      "Validation loss = 0.1872338205575943\n",
      "Epoch 0189 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.6308641975308642\n",
      "Training loss = 0.22681288885297599\n",
      "Validation accuracy = 0.6875\n",
      "Validation loss = 0.206794835627079\n",
      "Epoch 0190 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.6310921052631578\n",
      "Training loss = 0.22672711704436102\n",
      "Validation accuracy = 0.6875\n",
      "Validation loss = 0.20656918175518513\n",
      "Epoch 0191 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.6312914485165794\n",
      "Training loss = 0.22663194825186883\n",
      "Validation accuracy = 0.5625\n",
      "Validation loss = 0.2257144097238779\n",
      "Epoch 0192 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.6313237847222222\n",
      "Training loss = 0.2265869575292648\n",
      "Validation accuracy = 0.625\n",
      "Validation loss = 0.20834789890795946\n",
      "Epoch 0193 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.631472366148532\n",
      "Training loss = 0.22649965105948258\n",
      "Validation accuracy = 0.78125\n",
      "Validation loss = 0.18459222465753555\n",
      "Epoch 0194 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.631606529209622\n",
      "Training loss = 0.22644193508371044\n",
      "Validation accuracy = 0.71875\n",
      "Validation loss = 0.1826627142727375\n",
      "Epoch 0195 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.6318119658119659\n",
      "Training loss = 0.22634527785795877\n",
      "Validation accuracy = 0.59375\n",
      "Validation loss = 0.2061194758862257\n",
      "Epoch 0196 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.6320110544217687\n",
      "Training loss = 0.22626572924495048\n",
      "Validation accuracy = 0.625\n",
      "Validation loss = 0.20246143825352192\n",
      "Epoch 0197 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.6321235194585448\n",
      "Training loss = 0.2262063886431974\n",
      "Validation accuracy = 0.6875\n",
      "Validation loss = 0.19621344283223152\n",
      "Epoch 0198 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.6323905723905724\n",
      "Training loss = 0.2260823552454712\n",
      "Validation accuracy = 0.625\n",
      "Validation loss = 0.20828145742416382\n",
      "Epoch 0199 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.6325335008375209\n",
      "Training loss = 0.22600445749185094\n",
      "Validation accuracy = 0.75\n",
      "Validation loss = 0.20189526956528425\n",
      "Epoch 0200 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.63275\n",
      "Training loss = 0.22590408728979527\n",
      "Validation accuracy = 0.6875\n",
      "Validation loss = 0.20432414393872023\n",
      "Making model for session group 20210310_15:32:32.730-20210319_16:21:29.421\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/imblearn/utils/_validation.py:326: UserWarning: After over-sampling, the number of samples (300) in class car will be larger than the number of samples in the majority class (class #signpost -> 160)\n",
      "  n_samples_majority,\n",
      "/usr/local/lib/python3.6/dist-packages/imblearn/utils/_validation.py:326: UserWarning: After over-sampling, the number of samples (300) in class signpost will be larger than the number of samples in the majority class (class #signpost -> 160)\n",
      "  n_samples_majority,\n",
      "/usr/local/lib/python3.6/dist-packages/imblearn/utils/_validation.py:326: UserWarning: After over-sampling, the number of samples (300) in class tree will be larger than the number of samples in the majority class (class #signpost -> 160)\n",
      "  n_samples_majority,\n",
      "/usr/local/lib/python3.6/dist-packages/imblearn/utils/_validation.py:326: UserWarning: After over-sampling, the number of samples (300) in class wall will be larger than the number of samples in the majority class (class #signpost -> 160)\n",
      "  n_samples_majority,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0001 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.38416666666666666\n",
      "Training loss = 0.3128192855914434\n",
      "Validation accuracy = 0.40625\n",
      "Validation loss = 0.2896533887833357\n",
      "Epoch 0002 / 0200\n",
      "=====================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/_classification.py:1221: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training accuracy = 0.41833333333333333\n",
      "Training loss = 0.3014809117714564\n",
      "Validation accuracy = 0.53125\n",
      "Validation loss = 0.2783853318542242\n",
      "Epoch 0003 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.4525\n",
      "Training loss = 0.2951374419364664\n",
      "Validation accuracy = 0.65625\n",
      "Validation loss = 0.2688387930393219\n",
      "Epoch 0004 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.4739583333333333\n",
      "Training loss = 0.29010054845362904\n",
      "Validation accuracy = 0.6875\n",
      "Validation loss = 0.2506577856838703\n",
      "Epoch 0005 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.491\n",
      "Training loss = 0.28572964322566985\n",
      "Validation accuracy = 0.6875\n",
      "Validation loss = 0.27523273043334484\n",
      "Epoch 0006 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.5040277777777777\n",
      "Training loss = 0.28195286933746605\n",
      "Validation accuracy = 0.75\n",
      "Validation loss = 0.2554728854447603\n",
      "Epoch 0007 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.5138095238095238\n",
      "Training loss = 0.2788503376359031\n",
      "Validation accuracy = 0.71875\n",
      "Validation loss = 0.23264230042696\n",
      "Epoch 0008 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.5180208333333334\n",
      "Training loss = 0.27710049152374266\n",
      "Validation accuracy = 0.53125\n",
      "Validation loss = 0.2615507710725069\n",
      "Epoch 0009 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.5243518518518518\n",
      "Training loss = 0.2755770730227232\n",
      "Validation accuracy = 0.71875\n",
      "Validation loss = 0.24199814349412918\n",
      "Epoch 0010 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.5290833333333333\n",
      "Training loss = 0.27359991579006115\n",
      "Validation accuracy = 0.75\n",
      "Validation loss = 0.24584491178393364\n",
      "Epoch 0011 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.5323484848484848\n",
      "Training loss = 0.2722886905661135\n",
      "Validation accuracy = 0.75\n",
      "Validation loss = 0.25459459982812405\n",
      "Epoch 0012 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.5363888888888889\n",
      "Training loss = 0.27068583846713107\n",
      "Validation accuracy = 0.6875\n",
      "Validation loss = 0.23588775470852852\n",
      "Epoch 0013 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.538974358974359\n",
      "Training loss = 0.26962661978717034\n",
      "Validation accuracy = 0.78125\n",
      "Validation loss = 0.23757974058389664\n",
      "Epoch 0014 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.5410119047619047\n",
      "Training loss = 0.26883033683612234\n",
      "Validation accuracy = 0.75\n",
      "Validation loss = 0.23473167046904564\n",
      "Epoch 0015 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.543\n",
      "Training loss = 0.26782156882021163\n",
      "Validation accuracy = 0.75\n",
      "Validation loss = 0.22677228692919016\n",
      "Epoch 0016 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.5447916666666667\n",
      "Training loss = 0.26694439819082616\n",
      "Validation accuracy = 0.78125\n",
      "Validation loss = 0.23794426023960114\n",
      "Epoch 0017 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.5462745098039216\n",
      "Training loss = 0.2661949647130335\n",
      "Validation accuracy = 0.71875\n",
      "Validation loss = 0.23378957621753216\n",
      "Epoch 0018 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.5500462962962963\n",
      "Training loss = 0.26483920679462175\n",
      "Validation accuracy = 0.59375\n",
      "Validation loss = 0.25394989363849163\n",
      "Epoch 0019 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.5513157894736842\n",
      "Training loss = 0.2643568469623202\n",
      "Validation accuracy = 0.78125\n",
      "Validation loss = 0.23159611970186234\n",
      "Epoch 0020 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.5533333333333333\n",
      "Training loss = 0.2633775369686385\n",
      "Validation accuracy = 0.75\n",
      "Validation loss = 0.2360039297491312\n",
      "Epoch 0021 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.5557539682539683\n",
      "Training loss = 0.2622679218969175\n",
      "Validation accuracy = 0.71875\n",
      "Validation loss = 0.24304071813821793\n",
      "Epoch 0022 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.5572727272727273\n",
      "Training loss = 0.2616662586898063\n",
      "Validation accuracy = 0.78125\n",
      "Validation loss = 0.2225466798990965\n",
      "Epoch 0023 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.5581884057971015\n",
      "Training loss = 0.2610004339021617\n",
      "Validation accuracy = 0.75\n",
      "Validation loss = 0.22312313131988049\n",
      "Epoch 0024 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.5598611111111111\n",
      "Training loss = 0.26017807078754734\n",
      "Validation accuracy = 0.65625\n",
      "Validation loss = 0.2594099482521415\n",
      "Epoch 0025 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.5608\n",
      "Training loss = 0.2596418773730596\n",
      "Validation accuracy = 0.75\n",
      "Validation loss = 0.23138658329844475\n",
      "Epoch 0026 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.5622115384615385\n",
      "Training loss = 0.2588050939868658\n",
      "Validation accuracy = 0.71875\n",
      "Validation loss = 0.2306623589247465\n",
      "Epoch 0027 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.5634259259259259\n",
      "Training loss = 0.2582986804024305\n",
      "Validation accuracy = 0.78125\n",
      "Validation loss = 0.2072215937077999\n",
      "Epoch 0028 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.5647321428571429\n",
      "Training loss = 0.25768816659315713\n",
      "Validation accuracy = 0.5625\n",
      "Validation loss = 0.24218768253922462\n",
      "Epoch 0029 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.5650862068965518\n",
      "Training loss = 0.25756180736011475\n",
      "Validation accuracy = 0.78125\n",
      "Validation loss = 0.2345858858898282\n",
      "Epoch 0030 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.5653611111111111\n",
      "Training loss = 0.25737305830253493\n",
      "Validation accuracy = 0.59375\n",
      "Validation loss = 0.2405210379511118\n",
      "Epoch 0031 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.5666666666666667\n",
      "Training loss = 0.2567839407360041\n",
      "Validation accuracy = 0.625\n",
      "Validation loss = 0.2396680749952793\n",
      "Epoch 0032 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.5676302083333333\n",
      "Training loss = 0.25634083347472675\n",
      "Validation accuracy = 0.6875\n",
      "Validation loss = 0.2299527693539858\n",
      "Epoch 0033 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.568030303030303\n",
      "Training loss = 0.2562122725183615\n",
      "Validation accuracy = 0.75\n",
      "Validation loss = 0.23659471049904823\n",
      "Epoch 0034 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.568406862745098\n",
      "Training loss = 0.2557826478304524\n",
      "Validation accuracy = 0.625\n",
      "Validation loss = 0.2231213115155697\n",
      "Epoch 0035 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.569595238095238\n",
      "Training loss = 0.25539012022955077\n",
      "Validation accuracy = 0.75\n",
      "Validation loss = 0.22807889059185982\n",
      "Epoch 0036 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.5704861111111111\n",
      "Training loss = 0.2549866694825943\n",
      "Validation accuracy = 0.75\n",
      "Validation loss = 0.22788104228675365\n",
      "Epoch 0037 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.5719369369369369\n",
      "Training loss = 0.2545667685528059\n",
      "Validation accuracy = 0.65625\n",
      "Validation loss = 0.2319721933454275\n",
      "Epoch 0038 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.5720614035087719\n",
      "Training loss = 0.25437188572462716\n",
      "Validation accuracy = 0.71875\n",
      "Validation loss = 0.23158238269388676\n",
      "Epoch 0039 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.573034188034188\n",
      "Training loss = 0.25401504116116935\n",
      "Validation accuracy = 0.71875\n",
      "Validation loss = 0.21439809072762728\n",
      "Epoch 0040 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.5741458333333334\n",
      "Training loss = 0.2535547140923639\n",
      "Validation accuracy = 0.40625\n",
      "Validation loss = 0.2557701710611582\n",
      "Epoch 0041 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.5744308943089431\n",
      "Training loss = 0.25323884002137476\n",
      "Validation accuracy = 0.625\n",
      "Validation loss = 0.24459358491003513\n",
      "Epoch 0042 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.5750396825396825\n",
      "Training loss = 0.2528780082772885\n",
      "Validation accuracy = 0.78125\n",
      "Validation loss = 0.2223782017827034\n",
      "Epoch 0043 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.5756589147286821\n",
      "Training loss = 0.25256141788968745\n",
      "Validation accuracy = 0.75\n",
      "Validation loss = 0.21252827811986208\n",
      "Epoch 0044 / 0200\n",
      "=====================================\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training accuracy = 0.5765719696969697\n",
      "Training loss = 0.25213542966115654\n",
      "Validation accuracy = 0.78125\n",
      "Validation loss = 0.21493842266499996\n",
      "Epoch 0045 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.5771111111111111\n",
      "Training loss = 0.25179879042837355\n",
      "Validation accuracy = 0.59375\n",
      "Validation loss = 0.228749206289649\n",
      "Epoch 0046 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.5773550724637682\n",
      "Training loss = 0.2515417474502887\n",
      "Validation accuracy = 0.78125\n",
      "Validation loss = 0.22748048789799213\n",
      "Epoch 0047 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.5778900709219859\n",
      "Training loss = 0.2511525240514084\n",
      "Validation accuracy = 0.78125\n",
      "Validation loss = 0.21643843967467546\n",
      "Epoch 0048 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.5776388888888889\n",
      "Training loss = 0.2510387471044022\n",
      "Validation accuracy = 0.65625\n",
      "Validation loss = 0.2284093890339136\n",
      "Epoch 0049 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.5785034013605442\n",
      "Training loss = 0.2506998982265288\n",
      "Validation accuracy = 0.71875\n",
      "Validation loss = 0.22162223607301712\n",
      "Epoch 0050 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.5792333333333334\n",
      "Training loss = 0.2503996942554911\n",
      "Validation accuracy = 0.6875\n",
      "Validation loss = 0.22685881331562996\n",
      "Epoch 0051 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.5798856209150327\n",
      "Training loss = 0.2500855243736817\n",
      "Validation accuracy = 0.625\n",
      "Validation loss = 0.23425137624144554\n",
      "Epoch 0052 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.5803205128205128\n",
      "Training loss = 0.2498526585756395\n",
      "Validation accuracy = 0.625\n",
      "Validation loss = 0.21780264005064964\n",
      "Epoch 0053 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.5812421383647799\n",
      "Training loss = 0.24949170778663654\n",
      "Validation accuracy = 0.6875\n",
      "Validation loss = 0.22513363510370255\n",
      "Epoch 0054 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.5817746913580247\n",
      "Training loss = 0.24918388579868608\n",
      "Validation accuracy = 0.75\n",
      "Validation loss = 0.22141660191118717\n",
      "Epoch 0055 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.5825303030303031\n",
      "Training loss = 0.24890068152727501\n",
      "Validation accuracy = 0.65625\n",
      "Validation loss = 0.2161750365048647\n",
      "Epoch 0056 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.5825148809523809\n",
      "Training loss = 0.24882234134312187\n",
      "Validation accuracy = 0.75\n",
      "Validation loss = 0.2364696618169546\n",
      "Epoch 0057 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.5828070175438597\n",
      "Training loss = 0.24863243573938895\n",
      "Validation accuracy = 0.53125\n",
      "Validation loss = 0.23068758472800255\n",
      "Epoch 0058 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.5833477011494252\n",
      "Training loss = 0.24848213256090537\n",
      "Validation accuracy = 0.6875\n",
      "Validation loss = 0.22074309643357992\n",
      "Epoch 0059 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.5838418079096045\n",
      "Training loss = 0.24815045304975267\n",
      "Validation accuracy = 0.65625\n",
      "Validation loss = 0.22814316116273403\n",
      "Epoch 0060 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.5844166666666667\n",
      "Training loss = 0.24787917981834875\n",
      "Validation accuracy = 0.75\n",
      "Validation loss = 0.22876047529280186\n",
      "Epoch 0061 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.5846994535519126\n",
      "Training loss = 0.2477343911347819\n",
      "Validation accuracy = 0.8125\n",
      "Validation loss = 0.21705115027725697\n",
      "Epoch 0062 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.5857123655913978\n",
      "Training loss = 0.24732823350416716\n",
      "Validation accuracy = 0.75\n",
      "Validation loss = 0.2410505786538124\n",
      "Epoch 0063 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.5861243386243387\n",
      "Training loss = 0.24722851405343996\n",
      "Validation accuracy = 0.65625\n",
      "Validation loss = 0.22651574481278658\n",
      "Epoch 0064 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.5863932291666667\n",
      "Training loss = 0.24705487911822274\n",
      "Validation accuracy = 0.65625\n",
      "Validation loss = 0.22526728175580502\n",
      "Epoch 0065 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.5868333333333333\n",
      "Training loss = 0.2468822524001201\n",
      "Validation accuracy = 0.65625\n",
      "Validation loss = 0.2145068347454071\n",
      "Epoch 0066 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.5873611111111111\n",
      "Training loss = 0.24659010401767012\n",
      "Validation accuracy = 0.53125\n",
      "Validation loss = 0.25172630324959755\n",
      "Epoch 0067 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.5879726368159204\n",
      "Training loss = 0.246285769887528\n",
      "Validation accuracy = 0.59375\n",
      "Validation loss = 0.23866531625390053\n",
      "Epoch 0068 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.588063725490196\n",
      "Training loss = 0.24621885951097106\n",
      "Validation accuracy = 0.6875\n",
      "Validation loss = 0.22394919954240322\n",
      "Epoch 0069 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.5886956521739131\n",
      "Training loss = 0.2459881451913124\n",
      "Validation accuracy = 0.59375\n",
      "Validation loss = 0.23622493259608746\n",
      "Epoch 0070 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.5890238095238095\n",
      "Training loss = 0.24578187699509518\n",
      "Validation accuracy = 0.5625\n",
      "Validation loss = 0.23015163652598858\n",
      "Epoch 0071 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.5896596244131456\n",
      "Training loss = 0.24558228670746227\n",
      "Validation accuracy = 0.75\n",
      "Validation loss = 0.2336314357817173\n",
      "Epoch 0072 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.5901851851851851\n",
      "Training loss = 0.2454102809437447\n",
      "Validation accuracy = 0.71875\n",
      "Validation loss = 0.23742886632680893\n",
      "Epoch 0073 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.5908219178082191\n",
      "Training loss = 0.2452493258072361\n",
      "Validation accuracy = 0.71875\n",
      "Validation loss = 0.23432601243257523\n",
      "Epoch 0074 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.5914752252252252\n",
      "Training loss = 0.24501114677805622\n",
      "Validation accuracy = 0.75\n",
      "Validation loss = 0.21893947012722492\n",
      "Epoch 0075 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.5919444444444445\n",
      "Training loss = 0.24480612920953168\n",
      "Validation accuracy = 0.71875\n",
      "Validation loss = 0.22080391645431519\n",
      "Epoch 0076 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.5925328947368421\n",
      "Training loss = 0.2444588883420485\n",
      "Validation accuracy = 0.625\n",
      "Validation loss = 0.23192781582474709\n",
      "Epoch 0077 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.592943722943723\n",
      "Training loss = 0.2442751357785035\n",
      "Validation accuracy = 0.59375\n",
      "Validation loss = 0.23435888066887856\n",
      "Epoch 0078 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.5932478632478633\n",
      "Training loss = 0.2440635368304375\n",
      "Validation accuracy = 0.5625\n",
      "Validation loss = 0.22729952447116375\n",
      "Epoch 0079 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.5939556962025316\n",
      "Training loss = 0.24381573725758976\n",
      "Validation accuracy = 0.625\n",
      "Validation loss = 0.21854347176849842\n",
      "Epoch 0080 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.5946770833333334\n",
      "Training loss = 0.24357760385641208\n",
      "Validation accuracy = 0.625\n",
      "Validation loss = 0.2239690199494362\n",
      "Epoch 0081 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.5952777777777778\n",
      "Training loss = 0.24325416488228022\n",
      "Validation accuracy = 0.75\n",
      "Validation loss = 0.22277810331434011\n",
      "Epoch 0082 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.5956910569105691\n",
      "Training loss = 0.24306098857576527\n",
      "Validation accuracy = 0.625\n",
      "Validation loss = 0.22915556468069553\n",
      "Epoch 0083 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.5961244979919679\n",
      "Training loss = 0.24282010047610506\n",
      "Validation accuracy = 0.65625\n",
      "Validation loss = 0.2203987082466483\n",
      "Epoch 0084 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.59625\n",
      "Training loss = 0.24269029918644164\n",
      "Validation accuracy = 0.78125\n",
      "Validation loss = 0.22428144980221987\n",
      "Epoch 0085 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.5963823529411765\n",
      "Training loss = 0.24259765892110619\n",
      "Validation accuracy = 0.53125\n",
      "Validation loss = 0.23050110880285501\n",
      "Epoch 0086 / 0200\n",
      "=====================================\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training accuracy = 0.5966860465116279\n",
      "Training loss = 0.2424340986968704\n",
      "Validation accuracy = 0.65625\n",
      "Validation loss = 0.2242236714810133\n",
      "Epoch 0087 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.597183908045977\n",
      "Training loss = 0.24223153177206316\n",
      "Validation accuracy = 0.65625\n",
      "Validation loss = 0.2278355285525322\n",
      "Epoch 0088 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.5977367424242425\n",
      "Training loss = 0.24207983052104035\n",
      "Validation accuracy = 0.71875\n",
      "Validation loss = 0.2355765365064144\n",
      "Epoch 0089 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.598005617977528\n",
      "Training loss = 0.2419328160422125\n",
      "Validation accuracy = 0.75\n",
      "Validation loss = 0.23134900070726871\n",
      "Epoch 0090 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.5982314814814815\n",
      "Training loss = 0.24178785799057395\n",
      "Validation accuracy = 0.6875\n",
      "Validation loss = 0.2218119017779827\n",
      "Epoch 0091 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.5987454212454213\n",
      "Training loss = 0.24161841689830735\n",
      "Validation accuracy = 0.6875\n",
      "Validation loss = 0.22004682943224907\n",
      "Epoch 0092 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.599375\n",
      "Training loss = 0.2413826949837739\n",
      "Validation accuracy = 0.6875\n",
      "Validation loss = 0.23010974936187267\n",
      "Epoch 0093 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.5996057347670251\n",
      "Training loss = 0.24120556852963876\n",
      "Validation accuracy = 0.65625\n",
      "Validation loss = 0.22383607178926468\n",
      "Epoch 0094 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.6000177304964539\n",
      "Training loss = 0.24105773188543658\n",
      "Validation accuracy = 0.75\n",
      "Validation loss = 0.21458903327584267\n",
      "Epoch 0095 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.6005877192982456\n",
      "Training loss = 0.24079390825174357\n",
      "Validation accuracy = 0.53125\n",
      "Validation loss = 0.21201618760824203\n",
      "Epoch 0096 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.6012847222222222\n",
      "Training loss = 0.24048307206171254\n",
      "Validation accuracy = 0.65625\n",
      "Validation loss = 0.22653458081185818\n",
      "Epoch 0097 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.6013230240549828\n",
      "Training loss = 0.24035536785126757\n",
      "Validation accuracy = 0.75\n",
      "Validation loss = 0.2088487185537815\n",
      "Epoch 0098 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.6018962585034013\n",
      "Training loss = 0.24012991950828202\n",
      "Validation accuracy = 0.625\n",
      "Validation loss = 0.24284583516418934\n",
      "Epoch 0099 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.6023400673400673\n",
      "Training loss = 0.23990838464311878\n",
      "Validation accuracy = 0.71875\n",
      "Validation loss = 0.22832022234797478\n",
      "Epoch 0100 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.6027416666666666\n",
      "Training loss = 0.2398238183863461\n",
      "Validation accuracy = 0.75\n",
      "Validation loss = 0.19734950922429562\n",
      "Epoch 0101 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.6031023102310231\n",
      "Training loss = 0.23965152849040605\n",
      "Validation accuracy = 0.65625\n",
      "Validation loss = 0.22067512944340706\n",
      "Epoch 0102 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.6036437908496732\n",
      "Training loss = 0.23943044443389558\n",
      "Validation accuracy = 0.65625\n",
      "Validation loss = 0.2122016828507185\n",
      "Epoch 0103 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.6040938511326861\n",
      "Training loss = 0.23924931182348227\n",
      "Validation accuracy = 0.65625\n",
      "Validation loss = 0.23010569717735052\n",
      "Epoch 0104 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.6044471153846154\n",
      "Training loss = 0.23906405269359357\n",
      "Validation accuracy = 0.6875\n",
      "Validation loss = 0.21912508644163609\n",
      "Epoch 0105 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.6046349206349206\n",
      "Training loss = 0.23898379160676683\n",
      "Validation accuracy = 0.65625\n",
      "Validation loss = 0.2099147057160735\n",
      "Epoch 0106 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.6049685534591195\n",
      "Training loss = 0.23884413065845675\n",
      "Validation accuracy = 0.625\n",
      "Validation loss = 0.207373452372849\n",
      "Epoch 0107 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.6052959501557632\n",
      "Training loss = 0.2386767779070176\n",
      "Validation accuracy = 0.65625\n",
      "Validation loss = 0.2251384099945426\n",
      "Epoch 0108 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.6056018518518519\n",
      "Training loss = 0.23853606398090904\n",
      "Validation accuracy = 0.71875\n",
      "Validation loss = 0.2191190253943205\n",
      "Epoch 0109 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.6059938837920489\n",
      "Training loss = 0.23834398467446868\n",
      "Validation accuracy = 0.65625\n",
      "Validation loss = 0.22487475536763668\n",
      "Epoch 0110 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.6061742424242424\n",
      "Training loss = 0.23818686204968076\n",
      "Validation accuracy = 0.625\n",
      "Validation loss = 0.2277403101325035\n",
      "Epoch 0111 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.6066291291291291\n",
      "Training loss = 0.23796337533619133\n",
      "Validation accuracy = 0.8125\n",
      "Validation loss = 0.21627089381217957\n",
      "Epoch 0112 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.6070907738095238\n",
      "Training loss = 0.23775743272709882\n",
      "Validation accuracy = 0.65625\n",
      "Validation loss = 0.22759991325438023\n",
      "Epoch 0113 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.6073746312684366\n",
      "Training loss = 0.2375918536936551\n",
      "Validation accuracy = 0.5\n",
      "Validation loss = 0.24346922058612108\n",
      "Epoch 0114 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.607609649122807\n",
      "Training loss = 0.2374685196399863\n",
      "Validation accuracy = 0.8125\n",
      "Validation loss = 0.2345063267275691\n",
      "Epoch 0115 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.6079420289855072\n",
      "Training loss = 0.23730355279838694\n",
      "Validation accuracy = 0.75\n",
      "Validation loss = 0.19652598910033703\n",
      "Epoch 0116 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.6084195402298851\n",
      "Training loss = 0.23707691115487753\n",
      "Validation accuracy = 0.53125\n",
      "Validation loss = 0.21859485283493996\n",
      "Epoch 0117 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.6086396011396011\n",
      "Training loss = 0.23691081762356297\n",
      "Validation accuracy = 0.75\n",
      "Validation loss = 0.20635053515434265\n",
      "Epoch 0118 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.6091666666666666\n",
      "Training loss = 0.23669693454637028\n",
      "Validation accuracy = 0.6875\n",
      "Validation loss = 0.2384199434891343\n",
      "Epoch 0119 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.6095028011204482\n",
      "Training loss = 0.2365510892062461\n",
      "Validation accuracy = 0.71875\n",
      "Validation loss = 0.2418594118207693\n",
      "Epoch 0120 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.6097847222222222\n",
      "Training loss = 0.23642827413231135\n",
      "Validation accuracy = 0.75\n",
      "Validation loss = 0.22205892484635115\n",
      "Epoch 0121 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.6100964187327824\n",
      "Training loss = 0.236284539780423\n",
      "Validation accuracy = 0.65625\n",
      "Validation loss = 0.20831703674048185\n",
      "Epoch 0122 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.6103551912568306\n",
      "Training loss = 0.23617266586711985\n",
      "Validation accuracy = 0.46875\n",
      "Validation loss = 0.24685081467032433\n",
      "Epoch 0123 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.6107249322493224\n",
      "Training loss = 0.23599868417876524\n",
      "Validation accuracy = 0.65625\n",
      "Validation loss = 0.20445129089057446\n",
      "Epoch 0124 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.6109677419354839\n",
      "Training loss = 0.23585469219973812\n",
      "Validation accuracy = 0.8125\n",
      "Validation loss = 0.20284016150981188\n",
      "Epoch 0125 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.6112533333333333\n",
      "Training loss = 0.23570573692897956\n",
      "Validation accuracy = 0.65625\n",
      "Validation loss = 0.21264021284878254\n",
      "Epoch 0126 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.6116071428571429\n",
      "Training loss = 0.23548851411730523\n",
      "Validation accuracy = 0.78125\n",
      "Validation loss = 0.21774409152567387\n",
      "Epoch 0127 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.6118372703412074\n",
      "Training loss = 0.23534374079542367\n",
      "Validation accuracy = 0.59375\n",
      "Validation loss = 0.22621628362685442\n",
      "Epoch 0128 / 0200\n",
      "=====================================\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training accuracy = 0.6121549479166667\n",
      "Training loss = 0.23516164852151025\n",
      "Validation accuracy = 0.59375\n",
      "Validation loss = 0.2300217319279909\n",
      "Epoch 0129 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.6124095607235142\n",
      "Training loss = 0.2349999356231332\n",
      "Validation accuracy = 0.8125\n",
      "Validation loss = 0.2174927620217204\n",
      "Epoch 0130 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.6127564102564103\n",
      "Training loss = 0.23484357405702272\n",
      "Validation accuracy = 0.75\n",
      "Validation loss = 0.20795753691345453\n",
      "Epoch 0131 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.6130152671755725\n",
      "Training loss = 0.23467389023467025\n",
      "Validation accuracy = 0.75\n",
      "Validation loss = 0.2201579287648201\n",
      "Epoch 0132 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.6132070707070707\n",
      "Training loss = 0.2345556059739355\n",
      "Validation accuracy = 0.5625\n",
      "Validation loss = 0.23135810997337103\n",
      "Epoch 0133 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.6135087719298246\n",
      "Training loss = 0.2344155350674812\n",
      "Validation accuracy = 0.71875\n",
      "Validation loss = 0.20805352088063955\n",
      "Epoch 0134 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.6139987562189054\n",
      "Training loss = 0.2341875002952061\n",
      "Validation accuracy = 0.78125\n",
      "Validation loss = 0.20255752000957727\n",
      "Epoch 0135 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.6141172839506173\n",
      "Training loss = 0.2341215129341976\n",
      "Validation accuracy = 0.71875\n",
      "Validation loss = 0.1939001539722085\n",
      "Epoch 0136 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.614313725490196\n",
      "Training loss = 0.2340527964965897\n",
      "Validation accuracy = 0.75\n",
      "Validation loss = 0.20716157462447882\n",
      "Epoch 0137 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.6147323600973236\n",
      "Training loss = 0.2338657529324003\n",
      "Validation accuracy = 0.625\n",
      "Validation loss = 0.20555375050753355\n",
      "Epoch 0138 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.6151207729468599\n",
      "Training loss = 0.23370210740247355\n",
      "Validation accuracy = 0.6875\n",
      "Validation loss = 0.2069535180926323\n",
      "Epoch 0139 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.6154676258992806\n",
      "Training loss = 0.23353470653483122\n",
      "Validation accuracy = 0.46875\n",
      "Validation loss = 0.21748948469758034\n",
      "Epoch 0140 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.6157083333333333\n",
      "Training loss = 0.23339037920330608\n",
      "Validation accuracy = 0.78125\n",
      "Validation loss = 0.19932814687490463\n",
      "Epoch 0141 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.6160224586288416\n",
      "Training loss = 0.2332736321416272\n",
      "Validation accuracy = 0.6875\n",
      "Validation loss = 0.22033502627164125\n",
      "Epoch 0142 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.6162558685446009\n",
      "Training loss = 0.23318268578656962\n",
      "Validation accuracy = 0.6875\n",
      "Validation loss = 0.22107289917767048\n",
      "Epoch 0143 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.6165675990675991\n",
      "Training loss = 0.23305907305251886\n",
      "Validation accuracy = 0.59375\n",
      "Validation loss = 0.22074095904827118\n",
      "Epoch 0144 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.6168634259259259\n",
      "Training loss = 0.23292251070409462\n",
      "Validation accuracy = 0.75\n",
      "Validation loss = 0.21409715432673693\n",
      "Epoch 0145 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.6170804597701149\n",
      "Training loss = 0.2328128215199572\n",
      "Validation accuracy = 0.71875\n",
      "Validation loss = 0.21719051524996758\n",
      "Epoch 0146 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.617420091324201\n",
      "Training loss = 0.23264486506317644\n",
      "Validation accuracy = 0.8125\n",
      "Validation loss = 0.21502101328223944\n",
      "Epoch 0147 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.6177891156462585\n",
      "Training loss = 0.2324744853574166\n",
      "Validation accuracy = 0.78125\n",
      "Validation loss = 0.19805552065372467\n",
      "Epoch 0148 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.6179560810810811\n",
      "Training loss = 0.23237161067884987\n",
      "Validation accuracy = 0.625\n",
      "Validation loss = 0.2428996404632926\n",
      "Epoch 0149 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.618165548098434\n",
      "Training loss = 0.2322105725255422\n",
      "Validation accuracy = 0.65625\n",
      "Validation loss = 0.223787484690547\n",
      "Epoch 0150 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.6184\n",
      "Training loss = 0.23206643916393319\n",
      "Validation accuracy = 0.6875\n",
      "Validation loss = 0.21755822096019983\n",
      "Epoch 0151 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.6186258278145695\n",
      "Training loss = 0.2319674352583605\n",
      "Validation accuracy = 0.75\n",
      "Validation loss = 0.22052777372300625\n",
      "Epoch 0152 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.618859649122807\n",
      "Training loss = 0.23186412447205695\n",
      "Validation accuracy = 0.78125\n",
      "Validation loss = 0.22642555925995111\n",
      "Epoch 0153 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.619041394335512\n",
      "Training loss = 0.23176624500762857\n",
      "Validation accuracy = 0.6875\n",
      "Validation loss = 0.2115510068833828\n",
      "Epoch 0154 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.6192261904761904\n",
      "Training loss = 0.23165193899667688\n",
      "Validation accuracy = 0.5625\n",
      "Validation loss = 0.22997577767819166\n",
      "Epoch 0155 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.619494623655914\n",
      "Training loss = 0.23154507756978274\n",
      "Validation accuracy = 0.8125\n",
      "Validation loss = 0.205702917650342\n",
      "Epoch 0156 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.6196153846153846\n",
      "Training loss = 0.23148594272856274\n",
      "Validation accuracy = 0.65625\n",
      "Validation loss = 0.1915877377614379\n",
      "Epoch 0157 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.6198248407643312\n",
      "Training loss = 0.23140401934330884\n",
      "Validation accuracy = 0.75\n",
      "Validation loss = 0.21947637759149075\n",
      "Epoch 0158 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.6199261603375528\n",
      "Training loss = 0.23127632938734086\n",
      "Validation accuracy = 0.5625\n",
      "Validation loss = 0.21000351943075657\n",
      "Epoch 0159 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.6201310272536688\n",
      "Training loss = 0.2311413951921013\n",
      "Validation accuracy = 0.625\n",
      "Validation loss = 0.2559164194390178\n",
      "Epoch 0160 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.620453125\n",
      "Training loss = 0.231019830657014\n",
      "Validation accuracy = 0.6875\n",
      "Validation loss = 0.2151037845760584\n",
      "Epoch 0161 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.6206728778467909\n",
      "Training loss = 0.23091243349231672\n",
      "Validation accuracy = 0.65625\n",
      "Validation loss = 0.2220950908958912\n",
      "Epoch 0162 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.6207304526748971\n",
      "Training loss = 0.23084602297716794\n",
      "Validation accuracy = 0.6875\n",
      "Validation loss = 0.22156181000173092\n",
      "Epoch 0163 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.6211196319018405\n",
      "Training loss = 0.23066027190940025\n",
      "Validation accuracy = 0.5\n",
      "Validation loss = 0.22561435587704182\n",
      "Epoch 0164 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.6214126016260163\n",
      "Training loss = 0.2305097867247111\n",
      "Validation accuracy = 0.625\n",
      "Validation loss = 0.23093339428305626\n",
      "Epoch 0165 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.621479797979798\n",
      "Training loss = 0.23043688049603894\n",
      "Validation accuracy = 0.71875\n",
      "Validation loss = 0.2142521534115076\n",
      "Epoch 0166 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.6217168674698795\n",
      "Training loss = 0.23032029721339842\n",
      "Validation accuracy = 0.78125\n",
      "Validation loss = 0.2045583901926875\n",
      "Epoch 0167 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.6218962075848303\n",
      "Training loss = 0.23021390590831609\n",
      "Validation accuracy = 0.65625\n",
      "Validation loss = 0.20389534067362547\n",
      "Epoch 0168 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.6220833333333333\n",
      "Training loss = 0.2301338660756185\n",
      "Validation accuracy = 0.78125\n",
      "Validation loss = 0.20287778228521347\n",
      "Epoch 0169 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.62232741617357\n",
      "Training loss = 0.2300330547448358\n",
      "Validation accuracy = 0.8125\n",
      "Validation loss = 0.20029316283762455\n",
      "Epoch 0170 / 0200\n",
      "=====================================\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training accuracy = 0.6226470588235294\n",
      "Training loss = 0.22988167546959776\n",
      "Validation accuracy = 0.71875\n",
      "Validation loss = 0.20772934518754482\n",
      "Epoch 0171 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.6229191033138402\n",
      "Training loss = 0.22975893575523854\n",
      "Validation accuracy = 0.625\n",
      "Validation loss = 0.22284012287855148\n",
      "Epoch 0172 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.6230959302325582\n",
      "Training loss = 0.22968430187141653\n",
      "Validation accuracy = 0.71875\n",
      "Validation loss = 0.20055451430380344\n",
      "Epoch 0173 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.6232369942196532\n",
      "Training loss = 0.2295593855924086\n",
      "Validation accuracy = 0.8125\n",
      "Validation loss = 0.19258786272257566\n",
      "Epoch 0174 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.6234961685823754\n",
      "Training loss = 0.22944015871640652\n",
      "Validation accuracy = 0.78125\n",
      "Validation loss = 0.21878584194928408\n",
      "Epoch 0175 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.6236857142857143\n",
      "Training loss = 0.229353670253853\n",
      "Validation accuracy = 0.65625\n",
      "Validation loss = 0.20418034121394157\n",
      "Epoch 0176 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.6238399621212121\n",
      "Training loss = 0.22921955921122747\n",
      "Validation accuracy = 0.53125\n",
      "Validation loss = 0.22656263038516045\n",
      "Epoch 0177 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.6240395480225989\n",
      "Training loss = 0.22911468191602025\n",
      "Validation accuracy = 0.71875\n",
      "Validation loss = 0.21042096335440874\n",
      "Epoch 0178 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.6243445692883896\n",
      "Training loss = 0.22901176931329545\n",
      "Validation accuracy = 0.78125\n",
      "Validation loss = 0.20055787730962038\n",
      "Epoch 0179 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.6245577281191806\n",
      "Training loss = 0.2289436968765612\n",
      "Validation accuracy = 0.6875\n",
      "Validation loss = 0.20902338810265064\n",
      "Epoch 0180 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.6247083333333333\n",
      "Training loss = 0.22885142879836537\n",
      "Validation accuracy = 0.78125\n",
      "Validation loss = 0.21022405661642551\n",
      "Epoch 0181 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.6249125230202578\n",
      "Training loss = 0.22876283383240467\n",
      "Validation accuracy = 0.75\n",
      "Validation loss = 0.1928195646032691\n",
      "Epoch 0182 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.6251923076923077\n",
      "Training loss = 0.2286254906282511\n",
      "Validation accuracy = 0.6875\n",
      "Validation loss = 0.19931143335998058\n",
      "Epoch 0183 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.6253096539162113\n",
      "Training loss = 0.22852882218199405\n",
      "Validation accuracy = 0.5\n",
      "Validation loss = 0.22645363584160805\n",
      "Epoch 0184 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.6253759057971015\n",
      "Training loss = 0.22849876092848084\n",
      "Validation accuracy = 0.625\n",
      "Validation loss = 0.2166982665657997\n",
      "Epoch 0185 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.6256621621621622\n",
      "Training loss = 0.2283766982880933\n",
      "Validation accuracy = 0.75\n",
      "Validation loss = 0.228762686252594\n",
      "Epoch 0186 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.625828853046595\n",
      "Training loss = 0.22829651228222314\n",
      "Validation accuracy = 0.71875\n",
      "Validation loss = 0.21287868544459343\n",
      "Epoch 0187 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.6260606060606061\n",
      "Training loss = 0.22819661405322653\n",
      "Validation accuracy = 0.6875\n",
      "Validation loss = 0.2232508109882474\n",
      "Epoch 0188 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.6262367021276596\n",
      "Training loss = 0.22811608725702984\n",
      "Validation accuracy = 0.6875\n",
      "Validation loss = 0.2149238958954811\n",
      "Epoch 0189 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.6264065255731922\n",
      "Training loss = 0.22802882361789176\n",
      "Validation accuracy = 0.65625\n",
      "Validation loss = 0.19906579703092575\n",
      "Epoch 0190 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.6266447368421053\n",
      "Training loss = 0.22792146922484563\n",
      "Validation accuracy = 0.625\n",
      "Validation loss = 0.21288817934691906\n",
      "Epoch 0191 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.6269153577661432\n",
      "Training loss = 0.22779099377213505\n",
      "Validation accuracy = 0.59375\n",
      "Validation loss = 0.1963734794408083\n",
      "Epoch 0192 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.6271137152777778\n",
      "Training loss = 0.22770808038359974\n",
      "Validation accuracy = 0.65625\n",
      "Validation loss = 0.2150963842868805\n",
      "Epoch 0193 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.6273834196891191\n",
      "Training loss = 0.22758543226353192\n",
      "Validation accuracy = 0.625\n",
      "Validation loss = 0.22123269457370043\n",
      "Epoch 0194 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.627590206185567\n",
      "Training loss = 0.22749870336796973\n",
      "Validation accuracy = 0.71875\n",
      "Validation loss = 0.19517294131219387\n",
      "Epoch 0195 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.6278076923076923\n",
      "Training loss = 0.22739037446187346\n",
      "Validation accuracy = 0.5\n",
      "Validation loss = 0.2808238249272108\n",
      "Epoch 0196 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.6279761904761905\n",
      "Training loss = 0.22726509893294045\n",
      "Validation accuracy = 0.4375\n",
      "Validation loss = 0.29530100245028734\n",
      "Epoch 0197 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.6283037225042302\n",
      "Training loss = 0.22712192702307263\n",
      "Validation accuracy = 0.53125\n",
      "Validation loss = 0.2250221986323595\n",
      "Epoch 0198 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.6285353535353535\n",
      "Training loss = 0.22702446313800687\n",
      "Validation accuracy = 0.71875\n",
      "Validation loss = 0.20166714675724506\n",
      "Epoch 0199 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.6287939698492462\n",
      "Training loss = 0.22688470147331705\n",
      "Validation accuracy = 0.75\n",
      "Validation loss = 0.20506163872778416\n",
      "Epoch 0200 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.628925\n",
      "Training loss = 0.22684346511395026\n",
      "Validation accuracy = 0.46875\n",
      "Validation loss = 0.2597701605409384\n",
      "Making model for session group 20210310_15:32:48.233-20210319_16:21:59.598\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/imblearn/utils/_validation.py:326: UserWarning: After over-sampling, the number of samples (300) in class car will be larger than the number of samples in the majority class (class #signpost -> 160)\n",
      "  n_samples_majority,\n",
      "/usr/local/lib/python3.6/dist-packages/imblearn/utils/_validation.py:326: UserWarning: After over-sampling, the number of samples (300) in class signpost will be larger than the number of samples in the majority class (class #signpost -> 160)\n",
      "  n_samples_majority,\n",
      "/usr/local/lib/python3.6/dist-packages/imblearn/utils/_validation.py:326: UserWarning: After over-sampling, the number of samples (300) in class tree will be larger than the number of samples in the majority class (class #signpost -> 160)\n",
      "  n_samples_majority,\n",
      "/usr/local/lib/python3.6/dist-packages/imblearn/utils/_validation.py:326: UserWarning: After over-sampling, the number of samples (300) in class wall will be larger than the number of samples in the majority class (class #signpost -> 160)\n",
      "  n_samples_majority,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0001 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.38\n",
      "Training loss = 0.3239862914383411\n",
      "Validation accuracy = 0.25\n",
      "Validation loss = 0.3190297372639179\n",
      "Epoch 0002 / 0200\n",
      "=====================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/_classification.py:1221: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training accuracy = 0.4216666666666667\n",
      "Training loss = 0.31404235258698465\n",
      "Validation accuracy = 0.375\n",
      "Validation loss = 0.3039811737835407\n",
      "Epoch 0003 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.44666666666666666\n",
      "Training loss = 0.3072945794132021\n",
      "Validation accuracy = 0.59375\n",
      "Validation loss = 0.29226637817919254\n",
      "Epoch 0004 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.4608333333333333\n",
      "Training loss = 0.3026074667771657\n",
      "Validation accuracy = 0.53125\n",
      "Validation loss = 0.28697884641587734\n",
      "Epoch 0005 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.476\n",
      "Training loss = 0.29760742144783336\n",
      "Validation accuracy = 0.5\n",
      "Validation loss = 0.29437409713864326\n",
      "Epoch 0006 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.48527777777777775\n",
      "Training loss = 0.2946214328457912\n",
      "Validation accuracy = 0.5625\n",
      "Validation loss = 0.27826367504894733\n",
      "Epoch 0007 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.4925\n",
      "Training loss = 0.29174852614601454\n",
      "Validation accuracy = 0.4375\n",
      "Validation loss = 0.2831177655607462\n",
      "Epoch 0008 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.4984375\n",
      "Training loss = 0.2896107343273858\n",
      "Validation accuracy = 0.5\n",
      "Validation loss = 0.2830420844256878\n",
      "Epoch 0009 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.5050925925925925\n",
      "Training loss = 0.2876971251655508\n",
      "Validation accuracy = 0.59375\n",
      "Validation loss = 0.27107325196266174\n",
      "Epoch 0010 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.5096666666666667\n",
      "Training loss = 0.2857687180638313\n",
      "Validation accuracy = 0.625\n",
      "Validation loss = 0.2603480163961649\n",
      "Epoch 0011 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.5156818181818181\n",
      "Training loss = 0.2832387282857389\n",
      "Validation accuracy = 0.625\n",
      "Validation loss = 0.2470578495413065\n",
      "Epoch 0012 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.5211805555555555\n",
      "Training loss = 0.2812762180467447\n",
      "Validation accuracy = 0.53125\n",
      "Validation loss = 0.2689708787947893\n",
      "Epoch 0013 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.5251923076923077\n",
      "Training loss = 0.27932898445007126\n",
      "Validation accuracy = 0.625\n",
      "Validation loss = 0.2509562708437443\n",
      "Epoch 0014 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.528154761904762\n",
      "Training loss = 0.27751025604350227\n",
      "Validation accuracy = 0.625\n",
      "Validation loss = 0.2503194026648998\n",
      "Epoch 0015 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.5305\n",
      "Training loss = 0.27622465971112253\n",
      "Validation accuracy = 0.5\n",
      "Validation loss = 0.26861835084855556\n",
      "Epoch 0016 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.5318229166666667\n",
      "Training loss = 0.27577397800982\n",
      "Validation accuracy = 0.59375\n",
      "Validation loss = 0.2631407044827938\n",
      "Epoch 0017 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.534607843137255\n",
      "Training loss = 0.2746948545791355\n",
      "Validation accuracy = 0.59375\n",
      "Validation loss = 0.2667149119079113\n",
      "Epoch 0018 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.5371296296296296\n",
      "Training loss = 0.2735782436433214\n",
      "Validation accuracy = 0.6875\n",
      "Validation loss = 0.24873248673975468\n",
      "Epoch 0019 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.5401315789473684\n",
      "Training loss = 0.272312855425111\n",
      "Validation accuracy = 0.59375\n",
      "Validation loss = 0.25433462858200073\n",
      "Epoch 0020 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.54175\n",
      "Training loss = 0.27146588667978844\n",
      "Validation accuracy = 0.65625\n",
      "Validation loss = 0.2525379993021488\n",
      "Epoch 0021 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.5448809523809524\n",
      "Training loss = 0.27039313751317207\n",
      "Validation accuracy = 0.5625\n",
      "Validation loss = 0.26855466701090336\n",
      "Epoch 0022 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.5458333333333333\n",
      "Training loss = 0.26961449346646216\n",
      "Validation accuracy = 0.46875\n",
      "Validation loss = 0.2658583130687475\n",
      "Epoch 0023 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.5469927536231884\n",
      "Training loss = 0.2689402762994818\n",
      "Validation accuracy = 0.625\n",
      "Validation loss = 0.24721931666135788\n",
      "Epoch 0024 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.5487152777777777\n",
      "Training loss = 0.2679604444445835\n",
      "Validation accuracy = 0.6875\n",
      "Validation loss = 0.2460619006305933\n",
      "Epoch 0025 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.5504333333333333\n",
      "Training loss = 0.26710895741184554\n",
      "Validation accuracy = 0.65625\n",
      "Validation loss = 0.2550646439194679\n",
      "Epoch 0026 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.5509294871794872\n",
      "Training loss = 0.2668107823301584\n",
      "Validation accuracy = 0.59375\n",
      "Validation loss = 0.281980162486434\n",
      "Epoch 0027 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.5521296296296296\n",
      "Training loss = 0.2662821078843173\n",
      "Validation accuracy = 0.5\n",
      "Validation loss = 0.2717933915555477\n",
      "Epoch 0028 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.5537797619047619\n",
      "Training loss = 0.265398958293455\n",
      "Validation accuracy = 0.5625\n",
      "Validation loss = 0.2617676444351673\n",
      "Epoch 0029 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.5555459770114942\n",
      "Training loss = 0.26447622117211766\n",
      "Validation accuracy = 0.65625\n",
      "Validation loss = 0.25960720144212246\n",
      "Epoch 0030 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.5571666666666667\n",
      "Training loss = 0.2640548697196775\n",
      "Validation accuracy = 0.59375\n",
      "Validation loss = 0.27924455143511295\n",
      "Epoch 0031 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.5583064516129033\n",
      "Training loss = 0.2634617051041575\n",
      "Validation accuracy = 0.5625\n",
      "Validation loss = 0.26827853731811047\n",
      "Epoch 0032 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.5594270833333334\n",
      "Training loss = 0.2627740176635173\n",
      "Validation accuracy = 0.625\n",
      "Validation loss = 0.2688593417406082\n",
      "Epoch 0033 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.5603535353535354\n",
      "Training loss = 0.26220233542600063\n",
      "Validation accuracy = 0.59375\n",
      "Validation loss = 0.26347619481384754\n",
      "Epoch 0034 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.5614460784313725\n",
      "Training loss = 0.2615814573398116\n",
      "Validation accuracy = 0.65625\n",
      "Validation loss = 0.2578630344942212\n",
      "Epoch 0035 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.5619285714285714\n",
      "Training loss = 0.2613024447333245\n",
      "Validation accuracy = 0.5625\n",
      "Validation loss = 0.2671463619917631\n",
      "Epoch 0036 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.5627546296296296\n",
      "Training loss = 0.2607706018689054\n",
      "Validation accuracy = 0.5625\n",
      "Validation loss = 0.27452961541712284\n",
      "Epoch 0037 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.5636036036036036\n",
      "Training loss = 0.26036794265514024\n",
      "Validation accuracy = 0.625\n",
      "Validation loss = 0.2582388697192073\n",
      "Epoch 0038 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.5645833333333333\n",
      "Training loss = 0.25995541573159003\n",
      "Validation accuracy = 0.65625\n",
      "Validation loss = 0.2663992438465357\n",
      "Epoch 0039 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.5652350427350428\n",
      "Training loss = 0.25950536040796174\n",
      "Validation accuracy = 0.625\n",
      "Validation loss = 0.25585843063890934\n",
      "Epoch 0040 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.5666458333333333\n",
      "Training loss = 0.2588427273761481\n",
      "Validation accuracy = 0.59375\n",
      "Validation loss = 0.25644439831376076\n",
      "Epoch 0041 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.567459349593496\n",
      "Training loss = 0.2584931646123892\n",
      "Validation accuracy = 0.59375\n",
      "Validation loss = 0.26080847904086113\n",
      "Epoch 0042 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.5685714285714286\n",
      "Training loss = 0.2578175677773025\n",
      "Validation accuracy = 0.59375\n",
      "Validation loss = 0.26962414756417274\n",
      "Epoch 0043 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.5698062015503876\n",
      "Training loss = 0.2572454316631075\n",
      "Validation accuracy = 0.625\n",
      "Validation loss = 0.27012703008949757\n",
      "Epoch 0044 / 0200\n",
      "=====================================\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training accuracy = 0.5708143939393939\n",
      "Training loss = 0.25683205046437\n",
      "Validation accuracy = 0.65625\n",
      "Validation loss = 0.2645488902926445\n",
      "Epoch 0045 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.5721481481481482\n",
      "Training loss = 0.25642106951938737\n",
      "Validation accuracy = 0.625\n",
      "Validation loss = 0.2671050038188696\n",
      "Epoch 0046 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.5735688405797101\n",
      "Training loss = 0.25583040712104327\n",
      "Validation accuracy = 0.5625\n",
      "Validation loss = 0.2705767648294568\n",
      "Epoch 0047 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.5742375886524823\n",
      "Training loss = 0.25542279002831336\n",
      "Validation accuracy = 0.5\n",
      "Validation loss = 0.2693111225962639\n",
      "Epoch 0048 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.5751909722222223\n",
      "Training loss = 0.2550561725689719\n",
      "Validation accuracy = 0.5625\n",
      "Validation loss = 0.2752017490565777\n",
      "Epoch 0049 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.5758843537414966\n",
      "Training loss = 0.25466785054577856\n",
      "Validation accuracy = 0.5625\n",
      "Validation loss = 0.27159092016518116\n",
      "Epoch 0050 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.5771833333333334\n",
      "Training loss = 0.2542425022209684\n",
      "Validation accuracy = 0.65625\n",
      "Validation loss = 0.24738439172506332\n",
      "Epoch 0051 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.5780228758169934\n",
      "Training loss = 0.2538652165234089\n",
      "Validation accuracy = 0.59375\n",
      "Validation loss = 0.2619227860122919\n",
      "Epoch 0052 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.5788461538461539\n",
      "Training loss = 0.2535834778071596\n",
      "Validation accuracy = 0.46875\n",
      "Validation loss = 0.29546891152858734\n",
      "Epoch 0053 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.5796383647798742\n",
      "Training loss = 0.2531553667657218\n",
      "Validation accuracy = 0.625\n",
      "Validation loss = 0.2641049474477768\n",
      "Epoch 0054 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.5806018518518519\n",
      "Training loss = 0.25275996359916014\n",
      "Validation accuracy = 0.5\n",
      "Validation loss = 0.25380381755530834\n",
      "Epoch 0055 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.5811363636363637\n",
      "Training loss = 0.2524231251171141\n",
      "Validation accuracy = 0.65625\n",
      "Validation loss = 0.2695180671289563\n",
      "Epoch 0056 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.5816815476190477\n",
      "Training loss = 0.2520738194426078\n",
      "Validation accuracy = 0.625\n",
      "Validation loss = 0.271586861461401\n",
      "Epoch 0057 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.5825\n",
      "Training loss = 0.25158074844345363\n",
      "Validation accuracy = 0.5625\n",
      "Validation loss = 0.2986671160906553\n",
      "Epoch 0058 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.5834770114942529\n",
      "Training loss = 0.2512459866064547\n",
      "Validation accuracy = 0.5\n",
      "Validation loss = 0.2785350289195776\n",
      "Epoch 0059 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.5841525423728814\n",
      "Training loss = 0.25104199493335466\n",
      "Validation accuracy = 0.625\n",
      "Validation loss = 0.25079935137182474\n",
      "Epoch 0060 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.5845833333333333\n",
      "Training loss = 0.2507303027655515\n",
      "Validation accuracy = 0.5625\n",
      "Validation loss = 0.27124111633747816\n",
      "Epoch 0061 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.5849453551912568\n",
      "Training loss = 0.25037589160715296\n",
      "Validation accuracy = 0.59375\n",
      "Validation loss = 0.2638319320976734\n",
      "Epoch 0062 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.5854569892473118\n",
      "Training loss = 0.250064435953735\n",
      "Validation accuracy = 0.59375\n",
      "Validation loss = 0.2581269256770611\n",
      "Epoch 0063 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.5862830687830688\n",
      "Training loss = 0.24962189449362024\n",
      "Validation accuracy = 0.53125\n",
      "Validation loss = 0.2843969725072384\n",
      "Epoch 0064 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.5867317708333334\n",
      "Training loss = 0.24942722874926404\n",
      "Validation accuracy = 0.59375\n",
      "Validation loss = 0.25203197076916695\n",
      "Epoch 0065 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.5872564102564103\n",
      "Training loss = 0.24914531093606582\n",
      "Validation accuracy = 0.59375\n",
      "Validation loss = 0.2648629639297724\n",
      "Epoch 0066 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.5878787878787879\n",
      "Training loss = 0.24885982585901564\n",
      "Validation accuracy = 0.6875\n",
      "Validation loss = 0.24466519244015217\n",
      "Epoch 0067 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.5882960199004975\n",
      "Training loss = 0.24862293826925813\n",
      "Validation accuracy = 0.65625\n",
      "Validation loss = 0.27339200396090746\n",
      "Epoch 0068 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.5884313725490196\n",
      "Training loss = 0.24842330203519442\n",
      "Validation accuracy = 0.65625\n",
      "Validation loss = 0.27002100832760334\n",
      "Epoch 0069 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.5892270531400966\n",
      "Training loss = 0.24806838494352096\n",
      "Validation accuracy = 0.5625\n",
      "Validation loss = 0.2665787599980831\n",
      "Epoch 0070 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.5896785714285714\n",
      "Training loss = 0.24776198357556548\n",
      "Validation accuracy = 0.59375\n",
      "Validation loss = 0.25639083981513977\n",
      "Epoch 0071 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.5900586854460094\n",
      "Training loss = 0.2475001732522333\n",
      "Validation accuracy = 0.59375\n",
      "Validation loss = 0.276430306956172\n",
      "Epoch 0072 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.5904513888888889\n",
      "Training loss = 0.24728706458273034\n",
      "Validation accuracy = 0.59375\n",
      "Validation loss = 0.28663800563663244\n",
      "Epoch 0073 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.5910616438356164\n",
      "Training loss = 0.24697644636919508\n",
      "Validation accuracy = 0.59375\n",
      "Validation loss = 0.273190313950181\n",
      "Epoch 0074 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.5915202702702703\n",
      "Training loss = 0.24671173350768047\n",
      "Validation accuracy = 0.5625\n",
      "Validation loss = 0.28616595827043056\n",
      "Epoch 0075 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.5920111111111112\n",
      "Training loss = 0.24650938307477369\n",
      "Validation accuracy = 0.625\n",
      "Validation loss = 0.26128043234348297\n",
      "Epoch 0076 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.592609649122807\n",
      "Training loss = 0.24622890485614016\n",
      "Validation accuracy = 0.6875\n",
      "Validation loss = 0.25242164358496666\n",
      "Epoch 0077 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.5932251082251082\n",
      "Training loss = 0.24600505651881943\n",
      "Validation accuracy = 0.6875\n",
      "Validation loss = 0.2551569566130638\n",
      "Epoch 0078 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.5938141025641026\n",
      "Training loss = 0.24571035901514385\n",
      "Validation accuracy = 0.5625\n",
      "Validation loss = 0.2752572186291218\n",
      "Epoch 0079 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.5941983122362869\n",
      "Training loss = 0.2454936902080407\n",
      "Validation accuracy = 0.625\n",
      "Validation loss = 0.2478604456409812\n",
      "Epoch 0080 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.5948125\n",
      "Training loss = 0.24520068855428448\n",
      "Validation accuracy = 0.65625\n",
      "Validation loss = 0.25099093560129404\n",
      "Epoch 0081 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.5950205761316872\n",
      "Training loss = 0.24502255039665188\n",
      "Validation accuracy = 0.59375\n",
      "Validation loss = 0.2557910233736038\n",
      "Epoch 0082 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.5955386178861789\n",
      "Training loss = 0.24469391236823748\n",
      "Validation accuracy = 0.5\n",
      "Validation loss = 0.26726791355758905\n",
      "Epoch 0083 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.5963855421686747\n",
      "Training loss = 0.24432856204638997\n",
      "Validation accuracy = 0.40625\n",
      "Validation loss = 0.2798211332410574\n",
      "Epoch 0084 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.5969642857142857\n",
      "Training loss = 0.24407281192610897\n",
      "Validation accuracy = 0.65625\n",
      "Validation loss = 0.2638786919414997\n",
      "Epoch 0085 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.5974019607843137\n",
      "Training loss = 0.24385068480612015\n",
      "Validation accuracy = 0.5625\n",
      "Validation loss = 0.2712441645562649\n",
      "Epoch 0086 / 0200\n",
      "=====================================\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training accuracy = 0.5977228682170542\n",
      "Training loss = 0.24364567395761724\n",
      "Validation accuracy = 0.625\n",
      "Validation loss = 0.27321366779506207\n",
      "Epoch 0087 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.5980938697318008\n",
      "Training loss = 0.24348265639581215\n",
      "Validation accuracy = 0.625\n",
      "Validation loss = 0.27420487999916077\n",
      "Epoch 0088 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.5987594696969697\n",
      "Training loss = 0.24320765304322722\n",
      "Validation accuracy = 0.65625\n",
      "Validation loss = 0.2690266463905573\n",
      "Epoch 0089 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.5990730337078651\n",
      "Training loss = 0.24298308559934076\n",
      "Validation accuracy = 0.625\n",
      "Validation loss = 0.25537451915442944\n",
      "Epoch 0090 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.5993518518518518\n",
      "Training loss = 0.242862259755256\n",
      "Validation accuracy = 0.65625\n",
      "Validation loss = 0.25652534887194633\n",
      "Epoch 0091 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.5997893772893773\n",
      "Training loss = 0.2426692639700659\n",
      "Validation accuracy = 0.4375\n",
      "Validation loss = 0.264367762953043\n",
      "Epoch 0092 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.6000905797101449\n",
      "Training loss = 0.24260168553046557\n",
      "Validation accuracy = 0.5625\n",
      "Validation loss = 0.27086246106773615\n",
      "Epoch 0093 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.6004659498207885\n",
      "Training loss = 0.24239830048734784\n",
      "Validation accuracy = 0.5625\n",
      "Validation loss = 0.2516080066561699\n",
      "Epoch 0094 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.6007978723404256\n",
      "Training loss = 0.24213794713271847\n",
      "Validation accuracy = 0.59375\n",
      "Validation loss = 0.2600060775876045\n",
      "Epoch 0095 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.6012368421052632\n",
      "Training loss = 0.24190833406960754\n",
      "Validation accuracy = 0.65625\n",
      "Validation loss = 0.2841096594929695\n",
      "Epoch 0096 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.6015451388888889\n",
      "Training loss = 0.24172330861730087\n",
      "Validation accuracy = 0.625\n",
      "Validation loss = 0.26233440544456244\n",
      "Epoch 0097 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.6018986254295533\n",
      "Training loss = 0.24156760717738945\n",
      "Validation accuracy = 0.46875\n",
      "Validation loss = 0.28000912070274353\n",
      "Epoch 0098 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.6023129251700681\n",
      "Training loss = 0.24134346258528783\n",
      "Validation accuracy = 0.46875\n",
      "Validation loss = 0.284011660143733\n",
      "Epoch 0099 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.6028198653198653\n",
      "Training loss = 0.24108028366534598\n",
      "Validation accuracy = 0.53125\n",
      "Validation loss = 0.2827506810426712\n",
      "Epoch 0100 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.6032583333333333\n",
      "Training loss = 0.2408739965034028\n",
      "Validation accuracy = 0.625\n",
      "Validation loss = 0.28447198681533337\n",
      "Epoch 0101 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.6035973597359736\n",
      "Training loss = 0.24070955424099275\n",
      "Validation accuracy = 0.53125\n",
      "Validation loss = 0.27487339172512293\n",
      "Epoch 0102 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.6038480392156863\n",
      "Training loss = 0.2405106611282023\n",
      "Validation accuracy = 0.46875\n",
      "Validation loss = 0.30076098814606667\n",
      "Epoch 0103 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.603915857605178\n",
      "Training loss = 0.24044084698588716\n",
      "Validation accuracy = 0.5625\n",
      "Validation loss = 0.282279952429235\n",
      "Epoch 0104 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.6044310897435897\n",
      "Training loss = 0.2401456691453663\n",
      "Validation accuracy = 0.53125\n",
      "Validation loss = 0.26602367404848337\n",
      "Epoch 0105 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.6047460317460317\n",
      "Training loss = 0.23993968718392508\n",
      "Validation accuracy = 0.4375\n",
      "Validation loss = 0.2737810630351305\n",
      "Epoch 0106 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.6053459119496856\n",
      "Training loss = 0.23972173491574872\n",
      "Validation accuracy = 0.5\n",
      "Validation loss = 0.24636892415583134\n",
      "Epoch 0107 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.6055763239875389\n",
      "Training loss = 0.23961108203176584\n",
      "Validation accuracy = 0.65625\n",
      "Validation loss = 0.25854609068483114\n",
      "Epoch 0108 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.6062114197530865\n",
      "Training loss = 0.23932277370037305\n",
      "Validation accuracy = 0.5625\n",
      "Validation loss = 0.27269949950277805\n",
      "Epoch 0109 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.6063455657492355\n",
      "Training loss = 0.2392078586749801\n",
      "Validation accuracy = 0.53125\n",
      "Validation loss = 0.2649509608745575\n",
      "Epoch 0110 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.6065227272727273\n",
      "Training loss = 0.23906558983479487\n",
      "Validation accuracy = 0.5625\n",
      "Validation loss = 0.2776954900473356\n",
      "Epoch 0111 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.6069444444444444\n",
      "Training loss = 0.23884367754755614\n",
      "Validation accuracy = 0.625\n",
      "Validation loss = 0.27138564363121986\n",
      "Epoch 0112 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.6072098214285714\n",
      "Training loss = 0.23868946994965276\n",
      "Validation accuracy = 0.5625\n",
      "Validation loss = 0.2794743934646249\n",
      "Epoch 0113 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.6074705014749262\n",
      "Training loss = 0.23853048385925876\n",
      "Validation accuracy = 0.40625\n",
      "Validation loss = 0.27642406709492207\n",
      "Epoch 0114 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.6077485380116959\n",
      "Training loss = 0.2383716474042127\n",
      "Validation accuracy = 0.625\n",
      "Validation loss = 0.2621564418077469\n",
      "Epoch 0115 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.607927536231884\n",
      "Training loss = 0.2382965498737235\n",
      "Validation accuracy = 0.625\n",
      "Validation loss = 0.2807457819581032\n",
      "Epoch 0116 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.6082255747126437\n",
      "Training loss = 0.23812202522317055\n",
      "Validation accuracy = 0.5\n",
      "Validation loss = 0.2618552688509226\n",
      "Epoch 0117 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.6086752136752137\n",
      "Training loss = 0.23793795841011056\n",
      "Validation accuracy = 0.625\n",
      "Validation loss = 0.25839654356241226\n",
      "Epoch 0118 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.6090889830508475\n",
      "Training loss = 0.23773551207688232\n",
      "Validation accuracy = 0.53125\n",
      "Validation loss = 0.2480119727551937\n",
      "Epoch 0119 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.6094607843137255\n",
      "Training loss = 0.23757497999597998\n",
      "Validation accuracy = 0.625\n",
      "Validation loss = 0.2809628462418914\n",
      "Epoch 0120 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.6097430555555555\n",
      "Training loss = 0.2373893644909064\n",
      "Validation accuracy = 0.59375\n",
      "Validation loss = 0.26413985528051853\n",
      "Epoch 0121 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.6100275482093664\n",
      "Training loss = 0.23723336101460885\n",
      "Validation accuracy = 0.5\n",
      "Validation loss = 0.272966337390244\n",
      "Epoch 0122 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.6104371584699454\n",
      "Training loss = 0.23704839255721843\n",
      "Validation accuracy = 0.625\n",
      "Validation loss = 0.25555533915758133\n",
      "Epoch 0123 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.6107249322493224\n",
      "Training loss = 0.2368954626323408\n",
      "Validation accuracy = 0.59375\n",
      "Validation loss = 0.26308001950383186\n",
      "Epoch 0124 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.6110013440860215\n",
      "Training loss = 0.23674069825339542\n",
      "Validation accuracy = 0.5625\n",
      "Validation loss = 0.2635566331446171\n",
      "Epoch 0125 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.6112733333333333\n",
      "Training loss = 0.236555468659997\n",
      "Validation accuracy = 0.53125\n",
      "Validation loss = 0.25659366976469755\n",
      "Epoch 0126 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.6114748677248677\n",
      "Training loss = 0.23646394220254724\n",
      "Validation accuracy = 0.625\n",
      "Validation loss = 0.25807776115834713\n",
      "Epoch 0127 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.6117847769028871\n",
      "Training loss = 0.23627253422850933\n",
      "Validation accuracy = 0.59375\n",
      "Validation loss = 0.267665171995759\n",
      "Epoch 0128 / 0200\n",
      "=====================================\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training accuracy = 0.6120052083333334\n",
      "Training loss = 0.23611027917737373\n",
      "Validation accuracy = 0.53125\n",
      "Validation loss = 0.28328124713152647\n",
      "Epoch 0129 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.6122609819121447\n",
      "Training loss = 0.23596984896847367\n",
      "Validation accuracy = 0.6875\n",
      "Validation loss = 0.2475056927651167\n",
      "Epoch 0130 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.6127948717948718\n",
      "Training loss = 0.23575338269722385\n",
      "Validation accuracy = 0.5\n",
      "Validation loss = 0.2607864458113909\n",
      "Epoch 0131 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.6129770992366412\n",
      "Training loss = 0.23563914607660535\n",
      "Validation accuracy = 0.5625\n",
      "Validation loss = 0.29404993541538715\n",
      "Epoch 0132 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.6133964646464647\n",
      "Training loss = 0.23540722034711653\n",
      "Validation accuracy = 0.59375\n",
      "Validation loss = 0.2727568745613098\n",
      "Epoch 0133 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.6136152882205513\n",
      "Training loss = 0.23529964051179048\n",
      "Validation accuracy = 0.625\n",
      "Validation loss = 0.2651179935783148\n",
      "Epoch 0134 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.6139987562189054\n",
      "Training loss = 0.23513916978631075\n",
      "Validation accuracy = 0.59375\n",
      "Validation loss = 0.2733665704727173\n",
      "Epoch 0135 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.6143086419753087\n",
      "Training loss = 0.23497920821763482\n",
      "Validation accuracy = 0.59375\n",
      "Validation loss = 0.26025940757244825\n",
      "Epoch 0136 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.6145710784313726\n",
      "Training loss = 0.23480094296501622\n",
      "Validation accuracy = 0.5625\n",
      "Validation loss = 0.2676958702504635\n",
      "Epoch 0137 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.6146715328467153\n",
      "Training loss = 0.23475646822656665\n",
      "Validation accuracy = 0.46875\n",
      "Validation loss = 0.2804207615554333\n",
      "Epoch 0138 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.615036231884058\n",
      "Training loss = 0.23459833414523282\n",
      "Validation accuracy = 0.65625\n",
      "Validation loss = 0.2579629458487034\n",
      "Epoch 0139 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.6153657074340527\n",
      "Training loss = 0.23440858937576592\n",
      "Validation accuracy = 0.5625\n",
      "Validation loss = 0.2769903764128685\n",
      "Epoch 0140 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.6155952380952381\n",
      "Training loss = 0.23427375948916943\n",
      "Validation accuracy = 0.59375\n",
      "Validation loss = 0.26494742650538683\n",
      "Epoch 0141 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.6159338061465721\n",
      "Training loss = 0.23409067341560238\n",
      "Validation accuracy = 0.59375\n",
      "Validation loss = 0.2745260763913393\n",
      "Epoch 0142 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.6161854460093896\n",
      "Training loss = 0.23390576375805786\n",
      "Validation accuracy = 0.59375\n",
      "Validation loss = 0.2767956396564841\n",
      "Epoch 0143 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.6164102564102564\n",
      "Training loss = 0.2337944754519628\n",
      "Validation accuracy = 0.59375\n",
      "Validation loss = 0.29761903546750546\n",
      "Epoch 0144 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.6168518518518519\n",
      "Training loss = 0.2335772892138576\n",
      "Validation accuracy = 0.5\n",
      "Validation loss = 0.26680742390453815\n",
      "Epoch 0145 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.6170459770114942\n",
      "Training loss = 0.23350737440509015\n",
      "Validation accuracy = 0.59375\n",
      "Validation loss = 0.2970234118402004\n",
      "Epoch 0146 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.6171974885844749\n",
      "Training loss = 0.23340978777920615\n",
      "Validation accuracy = 0.5625\n",
      "Validation loss = 0.2947015352547169\n",
      "Epoch 0147 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.6175340136054421\n",
      "Training loss = 0.23325007283101343\n",
      "Validation accuracy = 0.625\n",
      "Validation loss = 0.251201038248837\n",
      "Epoch 0148 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.6177421171171171\n",
      "Training loss = 0.23310245931593215\n",
      "Validation accuracy = 0.5\n",
      "Validation loss = 0.2812748486176133\n",
      "Epoch 0149 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.6179865771812081\n",
      "Training loss = 0.2329479998851016\n",
      "Validation accuracy = 0.625\n",
      "Validation loss = 0.291203236207366\n",
      "Epoch 0150 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.6181111111111111\n",
      "Training loss = 0.2328940749041736\n",
      "Validation accuracy = 0.40625\n",
      "Validation loss = 0.3685869090259075\n",
      "Epoch 0151 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.6182781456953642\n",
      "Training loss = 0.23277062505343826\n",
      "Validation accuracy = 0.40625\n",
      "Validation loss = 0.33781735971570015\n",
      "Epoch 0152 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.6185910087719299\n",
      "Training loss = 0.2326243369994489\n",
      "Validation accuracy = 0.65625\n",
      "Validation loss = 0.24327889271080494\n",
      "Epoch 0153 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.6190359477124183\n",
      "Training loss = 0.2324398888627266\n",
      "Validation accuracy = 0.625\n",
      "Validation loss = 0.25088382326066494\n",
      "Epoch 0154 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.6192478354978355\n",
      "Training loss = 0.2323415513527761\n",
      "Validation accuracy = 0.59375\n",
      "Validation loss = 0.28640653286129236\n",
      "Epoch 0155 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.6195430107526881\n",
      "Training loss = 0.2321949537169709\n",
      "Validation accuracy = 0.625\n",
      "Validation loss = 0.2727069240063429\n",
      "Epoch 0156 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.6198824786324786\n",
      "Training loss = 0.23203311911386112\n",
      "Validation accuracy = 0.5\n",
      "Validation loss = 0.28601582162082195\n",
      "Epoch 0157 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.6201273885350318\n",
      "Training loss = 0.23191629903766697\n",
      "Validation accuracy = 0.5\n",
      "Validation loss = 0.2886196859180927\n",
      "Epoch 0158 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.6203322784810127\n",
      "Training loss = 0.2317282050723045\n",
      "Validation accuracy = 0.59375\n",
      "Validation loss = 0.23854554258286953\n",
      "Epoch 0159 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.6206341719077568\n",
      "Training loss = 0.23158270519523563\n",
      "Validation accuracy = 0.4375\n",
      "Validation loss = 0.2902549058198929\n",
      "Epoch 0160 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.6208333333333333\n",
      "Training loss = 0.23146020147258725\n",
      "Validation accuracy = 0.53125\n",
      "Validation loss = 0.25110012106597424\n",
      "Epoch 0161 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.6211180124223602\n",
      "Training loss = 0.23135878894786596\n",
      "Validation accuracy = 0.625\n",
      "Validation loss = 0.24639929365366697\n",
      "Epoch 0162 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.621358024691358\n",
      "Training loss = 0.2312480640050346\n",
      "Validation accuracy = 0.53125\n",
      "Validation loss = 0.25778499618172646\n",
      "Epoch 0163 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.6215746421267894\n",
      "Training loss = 0.2311457491618084\n",
      "Validation accuracy = 0.625\n",
      "Validation loss = 0.2529733804985881\n",
      "Epoch 0164 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.6219563008130081\n",
      "Training loss = 0.23101824125842896\n",
      "Validation accuracy = 0.625\n",
      "Validation loss = 0.2838515220209956\n",
      "Epoch 0165 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.6222070707070707\n",
      "Training loss = 0.23086223699912578\n",
      "Validation accuracy = 0.53125\n",
      "Validation loss = 0.27942721359431744\n",
      "Epoch 0166 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.6224698795180723\n",
      "Training loss = 0.23070529811600426\n",
      "Validation accuracy = 0.5\n",
      "Validation loss = 0.31446262914687395\n",
      "Epoch 0167 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.6225848303393213\n",
      "Training loss = 0.23064751383839194\n",
      "Validation accuracy = 0.625\n",
      "Validation loss = 0.2602543095126748\n",
      "Epoch 0168 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.6227876984126984\n",
      "Training loss = 0.23055613121779134\n",
      "Validation accuracy = 0.625\n",
      "Validation loss = 0.2725308919325471\n",
      "Epoch 0169 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.6230867850098619\n",
      "Training loss = 0.23041806328894765\n",
      "Validation accuracy = 0.53125\n",
      "Validation loss = 0.2729723621159792\n",
      "Epoch 0170 / 0200\n",
      "=====================================\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training accuracy = 0.6233774509803922\n",
      "Training loss = 0.23027057035172394\n",
      "Validation accuracy = 0.5625\n",
      "Validation loss = 0.27202104311436415\n",
      "Epoch 0171 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.62364522417154\n",
      "Training loss = 0.23015752376716214\n",
      "Validation accuracy = 0.5\n",
      "Validation loss = 0.277399861253798\n",
      "Epoch 0172 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.6239147286821706\n",
      "Training loss = 0.23003571416814486\n",
      "Validation accuracy = 0.59375\n",
      "Validation loss = 0.24308992456644773\n",
      "Epoch 0173 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.6240847784200385\n",
      "Training loss = 0.22992768290580065\n",
      "Validation accuracy = 0.5625\n",
      "Validation loss = 0.24603704549372196\n",
      "Epoch 0174 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.6242576628352491\n",
      "Training loss = 0.2298276570619894\n",
      "Validation accuracy = 0.5625\n",
      "Validation loss = 0.2744233701378107\n",
      "Epoch 0175 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.6245857142857143\n",
      "Training loss = 0.22965118353643588\n",
      "Validation accuracy = 0.65625\n",
      "Validation loss = 0.2677307156845927\n",
      "Epoch 0176 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.6249384469696969\n",
      "Training loss = 0.2294956311280839\n",
      "Validation accuracy = 0.59375\n",
      "Validation loss = 0.27030823193490505\n",
      "Epoch 0177 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.6250706214689266\n",
      "Training loss = 0.2294096207564693\n",
      "Validation accuracy = 0.5625\n",
      "Validation loss = 0.256259199231863\n",
      "Epoch 0178 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.6252059925093633\n",
      "Training loss = 0.2293099064612238\n",
      "Validation accuracy = 0.59375\n",
      "Validation loss = 0.2854597233235836\n",
      "Epoch 0179 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.6254189944134079\n",
      "Training loss = 0.22919200089106292\n",
      "Validation accuracy = 0.5625\n",
      "Validation loss = 0.2878809869289398\n",
      "Epoch 0180 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.6257407407407407\n",
      "Training loss = 0.2290640653355944\n",
      "Validation accuracy = 0.5625\n",
      "Validation loss = 0.2750208452343941\n",
      "Epoch 0181 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.6259254143646409\n",
      "Training loss = 0.2289584941349059\n",
      "Validation accuracy = 0.40625\n",
      "Validation loss = 0.29659236688166857\n",
      "Epoch 0182 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.6262591575091575\n",
      "Training loss = 0.22878916381118009\n",
      "Validation accuracy = 0.4375\n",
      "Validation loss = 0.3000316498801112\n",
      "Epoch 0183 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.6263888888888889\n",
      "Training loss = 0.2286786025194604\n",
      "Validation accuracy = 0.53125\n",
      "Validation loss = 0.2673559784889221\n",
      "Epoch 0184 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.6266802536231884\n",
      "Training loss = 0.22854685333523683\n",
      "Validation accuracy = 0.65625\n",
      "Validation loss = 0.27431947458535433\n",
      "Epoch 0185 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.6268783783783783\n",
      "Training loss = 0.2284447953625171\n",
      "Validation accuracy = 0.53125\n",
      "Validation loss = 0.29009373020380735\n",
      "Epoch 0186 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.6270698924731183\n",
      "Training loss = 0.22834818432294499\n",
      "Validation accuracy = 0.53125\n",
      "Validation loss = 0.26306859124451876\n",
      "Epoch 0187 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.627174688057041\n",
      "Training loss = 0.2282858831215643\n",
      "Validation accuracy = 0.5625\n",
      "Validation loss = 0.26081839948892593\n",
      "Epoch 0188 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.6274778368794326\n",
      "Training loss = 0.22809968078740153\n",
      "Validation accuracy = 0.625\n",
      "Validation loss = 0.272870278917253\n",
      "Epoch 0189 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.6276499118165785\n",
      "Training loss = 0.22796823508413327\n",
      "Validation accuracy = 0.59375\n",
      "Validation loss = 0.26075279153883457\n",
      "Epoch 0190 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.6278859649122807\n",
      "Training loss = 0.22784371051159605\n",
      "Validation accuracy = 0.59375\n",
      "Validation loss = 0.27412156760692596\n",
      "Epoch 0191 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.6282198952879581\n",
      "Training loss = 0.22772277285141732\n",
      "Validation accuracy = 0.59375\n",
      "Validation loss = 0.2764923479408026\n",
      "Epoch 0192 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.6285069444444444\n",
      "Training loss = 0.22757332793533958\n",
      "Validation accuracy = 0.46875\n",
      "Validation loss = 0.2847323790192604\n",
      "Epoch 0193 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.6287564766839379\n",
      "Training loss = 0.2274437828644441\n",
      "Validation accuracy = 0.65625\n",
      "Validation loss = 0.2645435072481632\n",
      "Epoch 0194 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.6289690721649485\n",
      "Training loss = 0.22735126124656538\n",
      "Validation accuracy = 0.53125\n",
      "Validation loss = 0.264679878950119\n",
      "Epoch 0195 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.6290897435897436\n",
      "Training loss = 0.22731360988529065\n",
      "Validation accuracy = 0.53125\n",
      "Validation loss = 0.27976507041603327\n",
      "Epoch 0196 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.6292729591836734\n",
      "Training loss = 0.22722086109518752\n",
      "Validation accuracy = 0.46875\n",
      "Validation loss = 0.2622602516785264\n",
      "Epoch 0197 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.6292893401015228\n",
      "Training loss = 0.22716438332279473\n",
      "Validation accuracy = 0.46875\n",
      "Validation loss = 0.2654581554234028\n",
      "Epoch 0198 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.6294234006734006\n",
      "Training loss = 0.22710523049507025\n",
      "Validation accuracy = 0.5625\n",
      "Validation loss = 0.2864729333668947\n",
      "Epoch 0199 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.6294514237855946\n",
      "Training loss = 0.22705483049410122\n",
      "Validation accuracy = 0.65625\n",
      "Validation loss = 0.27217463590204716\n",
      "Epoch 0200 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.6296083333333333\n",
      "Training loss = 0.22696334690023215\n",
      "Validation accuracy = 0.59375\n",
      "Validation loss = 0.2921090628951788\n",
      "Making model for session group 20210310_15:33:58.721-20210319_16:23:03.444\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/imblearn/utils/_validation.py:326: UserWarning: After over-sampling, the number of samples (300) in class car will be larger than the number of samples in the majority class (class #signpost -> 160)\n",
      "  n_samples_majority,\n",
      "/usr/local/lib/python3.6/dist-packages/imblearn/utils/_validation.py:326: UserWarning: After over-sampling, the number of samples (300) in class signpost will be larger than the number of samples in the majority class (class #signpost -> 160)\n",
      "  n_samples_majority,\n",
      "/usr/local/lib/python3.6/dist-packages/imblearn/utils/_validation.py:326: UserWarning: After over-sampling, the number of samples (300) in class tree will be larger than the number of samples in the majority class (class #signpost -> 160)\n",
      "  n_samples_majority,\n",
      "/usr/local/lib/python3.6/dist-packages/imblearn/utils/_validation.py:326: UserWarning: After over-sampling, the number of samples (300) in class wall will be larger than the number of samples in the majority class (class #signpost -> 160)\n",
      "  n_samples_majority,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0001 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.41333333333333333\n",
      "Training loss = 0.3203127075731754\n",
      "Validation accuracy = 0.71875\n",
      "Validation loss = 0.29479580745100975\n",
      "Epoch 0002 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.45916666666666667\n",
      "Training loss = 0.31104135180513065\n",
      "Validation accuracy = 0.75\n",
      "Validation loss = 0.26659277454018593\n",
      "Epoch 0003 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.4786111111111111\n",
      "Training loss = 0.30244225402673086\n",
      "Validation accuracy = 0.71875\n",
      "Validation loss = 0.2353811301290989\n",
      "Epoch 0004 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.49583333333333335\n",
      "Training loss = 0.29625369153916836\n",
      "Validation accuracy = 0.5625\n",
      "Validation loss = 0.2325711753219366\n",
      "Epoch 0005 / 0200\n",
      "=====================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/_classification.py:1221: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training accuracy = 0.5045\n",
      "Training loss = 0.291996379305919\n",
      "Validation accuracy = 0.65625\n",
      "Validation loss = 0.21472036372870207\n",
      "Epoch 0006 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.5098611111111111\n",
      "Training loss = 0.28828818904028997\n",
      "Validation accuracy = 0.65625\n",
      "Validation loss = 0.19484904874116182\n",
      "Epoch 0007 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.5172619047619048\n",
      "Training loss = 0.28495159122205915\n",
      "Validation accuracy = 0.78125\n",
      "Validation loss = 0.19885887391865253\n",
      "Epoch 0008 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.524375\n",
      "Training loss = 0.28233110982303816\n",
      "Validation accuracy = 0.6875\n",
      "Validation loss = 0.20985047705471516\n",
      "Epoch 0009 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.5298148148148148\n",
      "Training loss = 0.2800774005496943\n",
      "Validation accuracy = 0.8125\n",
      "Validation loss = 0.20033531170338392\n",
      "Epoch 0010 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.5323333333333333\n",
      "Training loss = 0.2785016229227185\n",
      "Validation accuracy = 0.9375\n",
      "Validation loss = 0.1820273958146572\n",
      "Epoch 0011 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.5365909090909091\n",
      "Training loss = 0.2766636589417855\n",
      "Validation accuracy = 0.90625\n",
      "Validation loss = 0.19212114438414574\n",
      "Epoch 0012 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.5384027777777778\n",
      "Training loss = 0.27505643357419307\n",
      "Validation accuracy = 0.65625\n",
      "Validation loss = 0.21477301232516766\n",
      "Epoch 0013 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.5422435897435898\n",
      "Training loss = 0.27335019333622396\n",
      "Validation accuracy = 0.8125\n",
      "Validation loss = 0.1910511450842023\n",
      "Epoch 0014 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.5442857142857143\n",
      "Training loss = 0.272012808915405\n",
      "Validation accuracy = 0.9375\n",
      "Validation loss = 0.18728974275290966\n",
      "Epoch 0015 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.5475555555555556\n",
      "Training loss = 0.27072601498497856\n",
      "Validation accuracy = 0.8125\n",
      "Validation loss = 0.1939658187329769\n",
      "Epoch 0016 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.5488020833333334\n",
      "Training loss = 0.2696856366874029\n",
      "Validation accuracy = 0.6875\n",
      "Validation loss = 0.18704228661954403\n",
      "Epoch 0017 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.5517156862745098\n",
      "Training loss = 0.2682670810789454\n",
      "Validation accuracy = 0.90625\n",
      "Validation loss = 0.18692819215357304\n",
      "Epoch 0018 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.5535185185185185\n",
      "Training loss = 0.2675147905545654\n",
      "Validation accuracy = 0.8125\n",
      "Validation loss = 0.19141612201929092\n",
      "Epoch 0019 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.5549561403508771\n",
      "Training loss = 0.2663905092995418\n",
      "Validation accuracy = 0.6875\n",
      "Validation loss = 0.19080611504614353\n",
      "Epoch 0020 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.5555833333333333\n",
      "Training loss = 0.26582379124810296\n",
      "Validation accuracy = 0.96875\n",
      "Validation loss = 0.17085411865264177\n",
      "Epoch 0021 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.5578174603174603\n",
      "Training loss = 0.2651092250656987\n",
      "Validation accuracy = 0.625\n",
      "Validation loss = 0.1702387062832713\n",
      "Epoch 0022 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.5595454545454546\n",
      "Training loss = 0.26421091023268123\n",
      "Validation accuracy = 0.9375\n",
      "Validation loss = 0.16580708976835012\n",
      "Epoch 0023 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.5614130434782608\n",
      "Training loss = 0.26333310389000436\n",
      "Validation accuracy = 0.9375\n",
      "Validation loss = 0.18162925634533167\n",
      "Epoch 0024 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.5635416666666667\n",
      "Training loss = 0.26237257433123884\n",
      "Validation accuracy = 0.875\n",
      "Validation loss = 0.17002779804170132\n",
      "Epoch 0025 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.5648666666666666\n",
      "Training loss = 0.2615770932565133\n",
      "Validation accuracy = 0.71875\n",
      "Validation loss = 0.19595465250313282\n",
      "Epoch 0026 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.5667948717948718\n",
      "Training loss = 0.2607894620280235\n",
      "Validation accuracy = 0.65625\n",
      "Validation loss = 0.20172217302024364\n",
      "Epoch 0027 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.568179012345679\n",
      "Training loss = 0.2602473752973256\n",
      "Validation accuracy = 0.90625\n",
      "Validation loss = 0.1655135052278638\n",
      "Epoch 0028 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.569375\n",
      "Training loss = 0.2596817413105496\n",
      "Validation accuracy = 0.75\n",
      "Validation loss = 0.1866780612617731\n",
      "Epoch 0029 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.5706034482758621\n",
      "Training loss = 0.25923588248676266\n",
      "Validation accuracy = 0.96875\n",
      "Validation loss = 0.15467951446771622\n",
      "Epoch 0030 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.5708888888888889\n",
      "Training loss = 0.2588314765608973\n",
      "Validation accuracy = 0.65625\n",
      "Validation loss = 0.19372970797121525\n",
      "Epoch 0031 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.5718279569892473\n",
      "Training loss = 0.2583625097372519\n",
      "Validation accuracy = 0.9375\n",
      "Validation loss = 0.16375237237662077\n",
      "Epoch 0032 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.5725260416666667\n",
      "Training loss = 0.25777874746127055\n",
      "Validation accuracy = 0.8125\n",
      "Validation loss = 0.1650664545595646\n",
      "Epoch 0033 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.573459595959596\n",
      "Training loss = 0.25729812584967926\n",
      "Validation accuracy = 0.59375\n",
      "Validation loss = 0.1784950913861394\n",
      "Epoch 0034 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.5744607843137255\n",
      "Training loss = 0.2565557678562461\n",
      "Validation accuracy = 0.65625\n",
      "Validation loss = 0.18650218099355698\n",
      "Epoch 0035 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.5754047619047619\n",
      "Training loss = 0.2560036599905718\n",
      "Validation accuracy = 0.75\n",
      "Validation loss = 0.17549318633973598\n",
      "Epoch 0036 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.5761574074074074\n",
      "Training loss = 0.2555242411233485\n",
      "Validation accuracy = 0.90625\n",
      "Validation loss = 0.14968674909323454\n",
      "Epoch 0037 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.5771621621621622\n",
      "Training loss = 0.25492749413794225\n",
      "Validation accuracy = 0.90625\n",
      "Validation loss = 0.16638474352657795\n",
      "Epoch 0038 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.5776754385964912\n",
      "Training loss = 0.2546030802175141\n",
      "Validation accuracy = 0.8125\n",
      "Validation loss = 0.18808343913406134\n",
      "Epoch 0039 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.5787393162393163\n",
      "Training loss = 0.2540628030947131\n",
      "Validation accuracy = 0.375\n",
      "Validation loss = 0.23097808472812176\n",
      "Epoch 0040 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.5790416666666667\n",
      "Training loss = 0.25387792561451594\n",
      "Validation accuracy = 0.78125\n",
      "Validation loss = 0.17334828712046146\n",
      "Epoch 0041 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.5800813008130081\n",
      "Training loss = 0.2533340868232696\n",
      "Validation accuracy = 0.90625\n",
      "Validation loss = 0.16928976029157639\n",
      "Epoch 0042 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.5801785714285714\n",
      "Training loss = 0.25311148197937106\n",
      "Validation accuracy = 0.90625\n",
      "Validation loss = 0.15171009488403797\n",
      "Epoch 0043 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.5809108527131783\n",
      "Training loss = 0.2526832636232062\n",
      "Validation accuracy = 0.59375\n",
      "Validation loss = 0.2023652419447899\n",
      "Epoch 0044 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.581875\n",
      "Training loss = 0.25223628579328455\n",
      "Validation accuracy = 0.75\n",
      "Validation loss = 0.17420025821775198\n",
      "Epoch 0045 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.5829444444444445\n",
      "Training loss = 0.2517580139156845\n",
      "Validation accuracy = 0.875\n",
      "Validation loss = 0.17453759163618088\n",
      "Epoch 0046 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.5839311594202898\n",
      "Training loss = 0.25135131242536546\n",
      "Validation accuracy = 0.875\n",
      "Validation loss = 0.1602872023358941\n",
      "Epoch 0047 / 0200\n",
      "=====================================\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training accuracy = 0.5839893617021277\n",
      "Training loss = 0.25115698798117064\n",
      "Validation accuracy = 0.59375\n",
      "Validation loss = 0.20113844983279705\n",
      "Epoch 0048 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.5843576388888889\n",
      "Training loss = 0.2509043827171748\n",
      "Validation accuracy = 0.78125\n",
      "Validation loss = 0.1715218061581254\n",
      "Epoch 0049 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.585\n",
      "Training loss = 0.25058903304340485\n",
      "Validation accuracy = 0.65625\n",
      "Validation loss = 0.17547694873064756\n",
      "Epoch 0050 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.5854833333333334\n",
      "Training loss = 0.25039221632480624\n",
      "Validation accuracy = 0.6875\n",
      "Validation loss = 0.1951497085392475\n",
      "Epoch 0051 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.5858169934640522\n",
      "Training loss = 0.25030362414963103\n",
      "Validation accuracy = 0.8125\n",
      "Validation loss = 0.17909533064812422\n",
      "Epoch 0052 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.5863942307692308\n",
      "Training loss = 0.2501187016055561\n",
      "Validation accuracy = 0.8125\n",
      "Validation loss = 0.17417430318892002\n",
      "Epoch 0053 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.5867138364779875\n",
      "Training loss = 0.249903118146478\n",
      "Validation accuracy = 0.96875\n",
      "Validation loss = 0.1666965950280428\n",
      "Epoch 0054 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.5870524691358024\n",
      "Training loss = 0.24969216793039697\n",
      "Validation accuracy = 0.53125\n",
      "Validation loss = 0.21404920145869255\n",
      "Epoch 0055 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.5877878787878787\n",
      "Training loss = 0.249457368437991\n",
      "Validation accuracy = 0.90625\n",
      "Validation loss = 0.1773527879267931\n",
      "Epoch 0056 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.5883184523809524\n",
      "Training loss = 0.24917745719131615\n",
      "Validation accuracy = 0.78125\n",
      "Validation loss = 0.1543786320835352\n",
      "Epoch 0057 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.5885818713450293\n",
      "Training loss = 0.24900348043319775\n",
      "Validation accuracy = 0.9375\n",
      "Validation loss = 0.1457529840990901\n",
      "Epoch 0058 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.5891091954022989\n",
      "Training loss = 0.24875766699898175\n",
      "Validation accuracy = 0.8125\n",
      "Validation loss = 0.16774966940283775\n",
      "Epoch 0059 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.5897598870056497\n",
      "Training loss = 0.2484185167322051\n",
      "Validation accuracy = 0.84375\n",
      "Validation loss = 0.18259768281131983\n",
      "Epoch 0060 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.5905416666666666\n",
      "Training loss = 0.248152222973605\n",
      "Validation accuracy = 0.8125\n",
      "Validation loss = 0.17794019728899002\n",
      "Epoch 0061 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.5908060109289618\n",
      "Training loss = 0.24789246620579822\n",
      "Validation accuracy = 0.875\n",
      "Validation loss = 0.16501471307128668\n",
      "Epoch 0062 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.5911559139784947\n",
      "Training loss = 0.24766911417646434\n",
      "Validation accuracy = 0.84375\n",
      "Validation loss = 0.18754348810762167\n",
      "Epoch 0063 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.5914814814814815\n",
      "Training loss = 0.24750819789827186\n",
      "Validation accuracy = 0.625\n",
      "Validation loss = 0.19044016394764185\n",
      "Epoch 0064 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.59203125\n",
      "Training loss = 0.2473237251583487\n",
      "Validation accuracy = 0.75\n",
      "Validation loss = 0.1804219475015998\n",
      "Epoch 0065 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.5922692307692308\n",
      "Training loss = 0.24728365734372384\n",
      "Validation accuracy = 0.84375\n",
      "Validation loss = 0.16397169046103954\n",
      "Epoch 0066 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.5929040404040404\n",
      "Training loss = 0.24706640907121127\n",
      "Validation accuracy = 0.8125\n",
      "Validation loss = 0.1759163085371256\n",
      "Epoch 0067 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.5933830845771144\n",
      "Training loss = 0.24689525665038853\n",
      "Validation accuracy = 0.90625\n",
      "Validation loss = 0.18168682511895895\n",
      "Epoch 0068 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.5937377450980392\n",
      "Training loss = 0.24664291273765995\n",
      "Validation accuracy = 0.71875\n",
      "Validation loss = 0.17162933386862278\n",
      "Epoch 0069 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.5941304347826087\n",
      "Training loss = 0.24645464597152916\n",
      "Validation accuracy = 0.78125\n",
      "Validation loss = 0.17244200967252254\n",
      "Epoch 0070 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.5947261904761905\n",
      "Training loss = 0.24626687853286663\n",
      "Validation accuracy = 0.46875\n",
      "Validation loss = 0.2417960800230503\n",
      "Epoch 0071 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.5951525821596244\n",
      "Training loss = 0.24609926100488\n",
      "Validation accuracy = 0.75\n",
      "Validation loss = 0.17746793385595083\n",
      "Epoch 0072 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.5958564814814815\n",
      "Training loss = 0.24579250045948559\n",
      "Validation accuracy = 0.625\n",
      "Validation loss = 0.19698917493224144\n",
      "Epoch 0073 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.5965525114155251\n",
      "Training loss = 0.24551829577887166\n",
      "Validation accuracy = 0.8125\n",
      "Validation loss = 0.16767586208879948\n",
      "Epoch 0074 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.597027027027027\n",
      "Training loss = 0.24523230031568993\n",
      "Validation accuracy = 0.90625\n",
      "Validation loss = 0.15715893730521202\n",
      "Epoch 0075 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.5976666666666667\n",
      "Training loss = 0.24492289681831997\n",
      "Validation accuracy = 0.78125\n",
      "Validation loss = 0.1777111180126667\n",
      "Epoch 0076 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.5981469298245614\n",
      "Training loss = 0.24464757174318819\n",
      "Validation accuracy = 0.71875\n",
      "Validation loss = 0.19117469899356365\n",
      "Epoch 0077 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.5986471861471861\n",
      "Training loss = 0.24437806184060903\n",
      "Validation accuracy = 0.75\n",
      "Validation loss = 0.19572733249515295\n",
      "Epoch 0078 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.5990384615384615\n",
      "Training loss = 0.24417182179183786\n",
      "Validation accuracy = 0.71875\n",
      "Validation loss = 0.1776430904865265\n",
      "Epoch 0079 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.5996202531645569\n",
      "Training loss = 0.24389654472910402\n",
      "Validation accuracy = 0.8125\n",
      "Validation loss = 0.17727141082286835\n",
      "Epoch 0080 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.6002395833333334\n",
      "Training loss = 0.24360039469165107\n",
      "Validation accuracy = 0.53125\n",
      "Validation loss = 0.20501489751040936\n",
      "Epoch 0081 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.6002572016460905\n",
      "Training loss = 0.24357919727915844\n",
      "Validation accuracy = 0.5625\n",
      "Validation loss = 0.21108604036271572\n",
      "Epoch 0082 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.6010264227642277\n",
      "Training loss = 0.24326006224999824\n",
      "Validation accuracy = 0.84375\n",
      "Validation loss = 0.15943915862590075\n",
      "Epoch 0083 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.6014658634538153\n",
      "Training loss = 0.24298797388961277\n",
      "Validation accuracy = 0.875\n",
      "Validation loss = 0.1514842426404357\n",
      "Epoch 0084 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.6017857142857143\n",
      "Training loss = 0.24277494644657488\n",
      "Validation accuracy = 0.90625\n",
      "Validation loss = 0.1588966492563486\n",
      "Epoch 0085 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.6020980392156863\n",
      "Training loss = 0.24257178235054017\n",
      "Validation accuracy = 0.625\n",
      "Validation loss = 0.18311321549117565\n",
      "Epoch 0086 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.6023158914728682\n",
      "Training loss = 0.24245013205320104\n",
      "Validation accuracy = 0.8125\n",
      "Validation loss = 0.17822761926800013\n",
      "Epoch 0087 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.6027107279693487\n",
      "Training loss = 0.24227952039989703\n",
      "Validation accuracy = 0.75\n",
      "Validation loss = 0.1954799648374319\n",
      "Epoch 0088 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.6030397727272727\n",
      "Training loss = 0.24206217835121083\n",
      "Validation accuracy = 0.78125\n",
      "Validation loss = 0.1605004109442234\n",
      "Epoch 0089 / 0200\n",
      "=====================================\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training accuracy = 0.603314606741573\n",
      "Training loss = 0.2419136661422275\n",
      "Validation accuracy = 0.875\n",
      "Validation loss = 0.1889835838228464\n",
      "Epoch 0090 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.6037685185185185\n",
      "Training loss = 0.2417104835535089\n",
      "Validation accuracy = 0.4375\n",
      "Validation loss = 0.20628319680690765\n",
      "Epoch 0091 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.6040201465201466\n",
      "Training loss = 0.24152424126235775\n",
      "Validation accuracy = 0.75\n",
      "Validation loss = 0.1957815121859312\n",
      "Epoch 0092 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.6041485507246377\n",
      "Training loss = 0.24136673614571708\n",
      "Validation accuracy = 0.8125\n",
      "Validation loss = 0.15259964764118195\n",
      "Epoch 0093 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.6045878136200716\n",
      "Training loss = 0.24118930807303784\n",
      "Validation accuracy = 0.84375\n",
      "Validation loss = 0.15428908448666334\n",
      "Epoch 0094 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.605195035460993\n",
      "Training loss = 0.2409020970656094\n",
      "Validation accuracy = 0.8125\n",
      "Validation loss = 0.17264928109943867\n",
      "Epoch 0095 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.6055175438596492\n",
      "Training loss = 0.24073648841339246\n",
      "Validation accuracy = 0.78125\n",
      "Validation loss = 0.17396976705640554\n",
      "Epoch 0096 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.6058854166666666\n",
      "Training loss = 0.24051346896552583\n",
      "Validation accuracy = 0.6875\n",
      "Validation loss = 0.18956181779503822\n",
      "Epoch 0097 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.6062371134020619\n",
      "Training loss = 0.24026851909369537\n",
      "Validation accuracy = 0.96875\n",
      "Validation loss = 0.15688347537070513\n",
      "Epoch 0098 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.6065391156462585\n",
      "Training loss = 0.24008437784274622\n",
      "Validation accuracy = 0.625\n",
      "Validation loss = 0.18757049273699522\n",
      "Epoch 0099 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.6067340067340067\n",
      "Training loss = 0.2400041272890086\n",
      "Validation accuracy = 0.78125\n",
      "Validation loss = 0.17784135323017836\n",
      "Epoch 0100 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.6070333333333333\n",
      "Training loss = 0.23978643332968155\n",
      "Validation accuracy = 0.90625\n",
      "Validation loss = 0.16162010561674833\n",
      "Epoch 0101 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.6075577557755776\n",
      "Training loss = 0.23950332748589934\n",
      "Validation accuracy = 0.59375\n",
      "Validation loss = 0.19433279242366552\n",
      "Epoch 0102 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.6080065359477124\n",
      "Training loss = 0.23925906446902387\n",
      "Validation accuracy = 0.875\n",
      "Validation loss = 0.16313840355724096\n",
      "Epoch 0103 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.6082362459546926\n",
      "Training loss = 0.23915289680404184\n",
      "Validation accuracy = 0.78125\n",
      "Validation loss = 0.1833629421889782\n",
      "Epoch 0104 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.6083413461538462\n",
      "Training loss = 0.2390506742039743\n",
      "Validation accuracy = 0.84375\n",
      "Validation loss = 0.18245463632047176\n",
      "Epoch 0105 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.6087380952380952\n",
      "Training loss = 0.23888449186346833\n",
      "Validation accuracy = 0.90625\n",
      "Validation loss = 0.17171768192201853\n",
      "Epoch 0106 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.6089229559748428\n",
      "Training loss = 0.23875576107194588\n",
      "Validation accuracy = 0.65625\n",
      "Validation loss = 0.17816475965082645\n",
      "Epoch 0107 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.6094548286604361\n",
      "Training loss = 0.23857720694693263\n",
      "Validation accuracy = 0.625\n",
      "Validation loss = 0.1995375994592905\n",
      "Epoch 0108 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.6098996913580247\n",
      "Training loss = 0.23841597293170147\n",
      "Validation accuracy = 0.84375\n",
      "Validation loss = 0.14876600168645382\n",
      "Epoch 0109 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.6101758409785932\n",
      "Training loss = 0.23828262332587613\n",
      "Validation accuracy = 0.71875\n",
      "Validation loss = 0.1845314372330904\n",
      "Epoch 0110 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.6104166666666667\n",
      "Training loss = 0.23815672310870706\n",
      "Validation accuracy = 0.5625\n",
      "Validation loss = 0.2637802977114916\n",
      "Epoch 0111 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.6106981981981981\n",
      "Training loss = 0.2380125885687254\n",
      "Validation accuracy = 0.71875\n",
      "Validation loss = 0.1652715401723981\n",
      "Epoch 0112 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.6110342261904762\n",
      "Training loss = 0.23784403937624857\n",
      "Validation accuracy = 0.6875\n",
      "Validation loss = 0.18321663979440928\n",
      "Epoch 0113 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.6113790560471977\n",
      "Training loss = 0.23766833814481894\n",
      "Validation accuracy = 0.875\n",
      "Validation loss = 0.1646980931982398\n",
      "Epoch 0114 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.6113815789473684\n",
      "Training loss = 0.23754706432182363\n",
      "Validation accuracy = 0.875\n",
      "Validation loss = 0.16254110541194677\n",
      "Epoch 0115 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.6116159420289855\n",
      "Training loss = 0.23740401813949363\n",
      "Validation accuracy = 0.9375\n",
      "Validation loss = 0.1586415134370327\n",
      "Epoch 0116 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.6118175287356322\n",
      "Training loss = 0.23724482456350635\n",
      "Validation accuracy = 0.875\n",
      "Validation loss = 0.17305361200124025\n",
      "Epoch 0117 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.6120726495726496\n",
      "Training loss = 0.23713205321052475\n",
      "Validation accuracy = 0.78125\n",
      "Validation loss = 0.1861564666032791\n",
      "Epoch 0118 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.6123375706214689\n",
      "Training loss = 0.2370326372703253\n",
      "Validation accuracy = 0.53125\n",
      "Validation loss = 0.2153602996841073\n",
      "Epoch 0119 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.6126050420168068\n",
      "Training loss = 0.23686461835932665\n",
      "Validation accuracy = 0.75\n",
      "Validation loss = 0.1736051794141531\n",
      "Epoch 0120 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.6127777777777778\n",
      "Training loss = 0.23677391766673989\n",
      "Validation accuracy = 0.8125\n",
      "Validation loss = 0.16776171699166298\n",
      "Epoch 0121 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.6130371900826447\n",
      "Training loss = 0.23666004221055134\n",
      "Validation accuracy = 0.96875\n",
      "Validation loss = 0.15648509841412306\n",
      "Epoch 0122 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.613422131147541\n",
      "Training loss = 0.23647699201917224\n",
      "Validation accuracy = 0.65625\n",
      "Validation loss = 0.19027906563133\n",
      "Epoch 0123 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.6137669376693767\n",
      "Training loss = 0.23630461440883516\n",
      "Validation accuracy = 0.78125\n",
      "Validation loss = 0.17428443673998117\n",
      "Epoch 0124 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.6140255376344086\n",
      "Training loss = 0.2362257365916445\n",
      "Validation accuracy = 0.71875\n",
      "Validation loss = 0.17528825253248215\n",
      "Epoch 0125 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.61426\n",
      "Training loss = 0.23609552128136158\n",
      "Validation accuracy = 0.75\n",
      "Validation loss = 0.18887304235249758\n",
      "Epoch 0126 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.6143915343915344\n",
      "Training loss = 0.2359960355837312\n",
      "Validation accuracy = 0.65625\n",
      "Validation loss = 0.20463490299880505\n",
      "Epoch 0127 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.6147112860892389\n",
      "Training loss = 0.23579690723291297\n",
      "Validation accuracy = 0.6875\n",
      "Validation loss = 0.19503425620496273\n",
      "Epoch 0128 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.6149283854166666\n",
      "Training loss = 0.23563071504827046\n",
      "Validation accuracy = 0.4375\n",
      "Validation loss = 0.22105928882956505\n",
      "Epoch 0129 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.6151937984496124\n",
      "Training loss = 0.23544939925359895\n",
      "Validation accuracy = 0.78125\n",
      "Validation loss = 0.17964819353073835\n",
      "Epoch 0130 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.6154679487179487\n",
      "Training loss = 0.23529516164490427\n",
      "Validation accuracy = 0.6875\n",
      "Validation loss = 0.182101896032691\n",
      "Epoch 0131 / 0200\n",
      "=====================================\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training accuracy = 0.6156361323155216\n",
      "Training loss = 0.23519261575202072\n",
      "Validation accuracy = 0.84375\n",
      "Validation loss = 0.1692278627306223\n",
      "Epoch 0132 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.6159785353535353\n",
      "Training loss = 0.23499424615903108\n",
      "Validation accuracy = 0.78125\n",
      "Validation loss = 0.15876914095133543\n",
      "Epoch 0133 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.6162280701754386\n",
      "Training loss = 0.23483454219558111\n",
      "Validation accuracy = 0.90625\n",
      "Validation loss = 0.1583417085930705\n",
      "Epoch 0134 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.6164427860696517\n",
      "Training loss = 0.23470194854982085\n",
      "Validation accuracy = 0.71875\n",
      "Validation loss = 0.17589252442121506\n",
      "Epoch 0135 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.6166975308641975\n",
      "Training loss = 0.23454579836084152\n",
      "Validation accuracy = 0.84375\n",
      "Validation loss = 0.17118296306580305\n",
      "Epoch 0136 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.6170159313725491\n",
      "Training loss = 0.23440151428210312\n",
      "Validation accuracy = 0.75\n",
      "Validation loss = 0.1838600831106305\n",
      "Epoch 0137 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.6175304136253041\n",
      "Training loss = 0.23415211526318985\n",
      "Validation accuracy = 0.875\n",
      "Validation loss = 0.1698116771876812\n",
      "Epoch 0138 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.6179528985507247\n",
      "Training loss = 0.2339799773440233\n",
      "Validation accuracy = 0.71875\n",
      "Validation loss = 0.197609587572515\n",
      "Epoch 0139 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.6180755395683454\n",
      "Training loss = 0.23385322882447668\n",
      "Validation accuracy = 0.6875\n",
      "Validation loss = 0.18236316367983818\n",
      "Epoch 0140 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.6182738095238095\n",
      "Training loss = 0.2337448124581327\n",
      "Validation accuracy = 0.84375\n",
      "Validation loss = 0.16286993399262428\n",
      "Epoch 0141 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.6186170212765958\n",
      "Training loss = 0.23361015177937336\n",
      "Validation accuracy = 0.8125\n",
      "Validation loss = 0.1686307117342949\n",
      "Epoch 0142 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.6188380281690141\n",
      "Training loss = 0.23348396673789817\n",
      "Validation accuracy = 0.6875\n",
      "Validation loss = 0.16529388073831797\n",
      "Epoch 0143 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.6190617715617716\n",
      "Training loss = 0.2333460959270249\n",
      "Validation accuracy = 0.6875\n",
      "Validation loss = 0.2059775609523058\n",
      "Epoch 0144 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.6192824074074074\n",
      "Training loss = 0.23326732325410746\n",
      "Validation accuracy = 0.65625\n",
      "Validation loss = 0.19309176597744226\n",
      "Epoch 0145 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.6194367816091954\n",
      "Training loss = 0.233113255809179\n",
      "Validation accuracy = 0.84375\n",
      "Validation loss = 0.17461446020752192\n",
      "Epoch 0146 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.6197317351598174\n",
      "Training loss = 0.23294863122145404\n",
      "Validation accuracy = 0.65625\n",
      "Validation loss = 0.2105489019304514\n",
      "Epoch 0147 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.6199489795918367\n",
      "Training loss = 0.23283896028987067\n",
      "Validation accuracy = 0.75\n",
      "Validation loss = 0.1887114755809307\n",
      "Epoch 0148 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.6202252252252253\n",
      "Training loss = 0.23270192971008385\n",
      "Validation accuracy = 0.5625\n",
      "Validation loss = 0.22155913058668375\n",
      "Epoch 0149 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.620430648769575\n",
      "Training loss = 0.23255829419307328\n",
      "Validation accuracy = 0.75\n",
      "Validation loss = 0.19394275825470686\n",
      "Epoch 0150 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.6208277777777778\n",
      "Training loss = 0.23235360167581173\n",
      "Validation accuracy = 0.90625\n",
      "Validation loss = 0.14019974507391453\n",
      "Epoch 0151 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.6209492273730685\n",
      "Training loss = 0.2323002580545892\n",
      "Validation accuracy = 0.71875\n",
      "Validation loss = 0.1907522901892662\n",
      "Epoch 0152 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.6213322368421053\n",
      "Training loss = 0.2321167612913179\n",
      "Validation accuracy = 0.65625\n",
      "Validation loss = 0.18874341808259487\n",
      "Epoch 0153 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.6216721132897604\n",
      "Training loss = 0.23196301876776293\n",
      "Validation accuracy = 0.8125\n",
      "Validation loss = 0.16693275049328804\n",
      "Epoch 0154 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.6220075757575757\n",
      "Training loss = 0.23179671270498658\n",
      "Validation accuracy = 0.90625\n",
      "Validation loss = 0.14822848234325647\n",
      "Epoch 0155 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.6221989247311828\n",
      "Training loss = 0.23170816462983687\n",
      "Validation accuracy = 0.6875\n",
      "Validation loss = 0.176049642264843\n",
      "Epoch 0156 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.6224305555555556\n",
      "Training loss = 0.2316012176593495\n",
      "Validation accuracy = 0.84375\n",
      "Validation loss = 0.1619826927781105\n",
      "Epoch 0157 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.6227229299363057\n",
      "Training loss = 0.2314688649015094\n",
      "Validation accuracy = 0.84375\n",
      "Validation loss = 0.1453824769705534\n",
      "Epoch 0158 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.6229166666666667\n",
      "Training loss = 0.23136185951758853\n",
      "Validation accuracy = 0.46875\n",
      "Validation loss = 0.23790765833109617\n",
      "Epoch 0159 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.6232285115303984\n",
      "Training loss = 0.23118652740372364\n",
      "Validation accuracy = 0.90625\n",
      "Validation loss = 0.14972065668553114\n",
      "Epoch 0160 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.6234479166666667\n",
      "Training loss = 0.23105379145165594\n",
      "Validation accuracy = 0.65625\n",
      "Validation loss = 0.20153641607612371\n",
      "Epoch 0161 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.6236904761904762\n",
      "Training loss = 0.23093383839805118\n",
      "Validation accuracy = 0.875\n",
      "Validation loss = 0.18025775160640478\n",
      "Epoch 0162 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.6239814814814815\n",
      "Training loss = 0.23081466168172873\n",
      "Validation accuracy = 0.75\n",
      "Validation loss = 0.17529594618827105\n",
      "Epoch 0163 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.6241564417177914\n",
      "Training loss = 0.2307212339548093\n",
      "Validation accuracy = 0.71875\n",
      "Validation loss = 0.19047240540385246\n",
      "Epoch 0164 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.624344512195122\n",
      "Training loss = 0.23065276054445866\n",
      "Validation accuracy = 0.65625\n",
      "Validation loss = 0.18019848223775625\n",
      "Epoch 0165 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.6245555555555555\n",
      "Training loss = 0.23053764419626407\n",
      "Validation accuracy = 0.71875\n",
      "Validation loss = 0.20217080041766167\n",
      "Epoch 0166 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.6248644578313253\n",
      "Training loss = 0.23038576480397677\n",
      "Validation accuracy = 0.78125\n",
      "Validation loss = 0.18060683365911245\n",
      "Epoch 0167 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.6251946107784431\n",
      "Training loss = 0.2302304554319459\n",
      "Validation accuracy = 0.71875\n",
      "Validation loss = 0.17886675614863634\n",
      "Epoch 0168 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.6254613095238095\n",
      "Training loss = 0.23008716201343174\n",
      "Validation accuracy = 0.5\n",
      "Validation loss = 0.2361765056848526\n",
      "Epoch 0169 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.6255522682445759\n",
      "Training loss = 0.23000410289725903\n",
      "Validation accuracy = 0.5625\n",
      "Validation loss = 0.25187939032912254\n",
      "Epoch 0170 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.6256911764705883\n",
      "Training loss = 0.2299427562352343\n",
      "Validation accuracy = 0.75\n",
      "Validation loss = 0.17072567902505398\n",
      "Epoch 0171 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.6258723196881092\n",
      "Training loss = 0.2298463137529892\n",
      "Validation accuracy = 0.5625\n",
      "Validation loss = 0.21933810133486986\n",
      "Epoch 0172 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.6261046511627907\n",
      "Training loss = 0.22974257394938563\n",
      "Validation accuracy = 0.78125\n",
      "Validation loss = 0.1753617851063609\n",
      "Epoch 0173 / 0200\n",
      "=====================================\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training accuracy = 0.6263053949903661\n",
      "Training loss = 0.22967209500492136\n",
      "Validation accuracy = 0.71875\n",
      "Validation loss = 0.1958331847563386\n",
      "Epoch 0174 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.6265325670498084\n",
      "Training loss = 0.22955226343160787\n",
      "Validation accuracy = 0.71875\n",
      "Validation loss = 0.1850859746336937\n",
      "Epoch 0175 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.626647619047619\n",
      "Training loss = 0.22944622617725816\n",
      "Validation accuracy = 0.6875\n",
      "Validation loss = 0.1869510468095541\n",
      "Epoch 0176 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.6267897727272728\n",
      "Training loss = 0.22934667462518327\n",
      "Validation accuracy = 0.8125\n",
      "Validation loss = 0.15140045620501041\n",
      "Epoch 0177 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.627015065913371\n",
      "Training loss = 0.22922967107036973\n",
      "Validation accuracy = 0.90625\n",
      "Validation loss = 0.15812944062054157\n",
      "Epoch 0178 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.6272191011235955\n",
      "Training loss = 0.2291267452445509\n",
      "Validation accuracy = 0.90625\n",
      "Validation loss = 0.15204920060932636\n",
      "Epoch 0179 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.6274906890130354\n",
      "Training loss = 0.2290216243810244\n",
      "Validation accuracy = 0.90625\n",
      "Validation loss = 0.15535490214824677\n",
      "Epoch 0180 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.6277592592592592\n",
      "Training loss = 0.22892094947294228\n",
      "Validation accuracy = 0.6875\n",
      "Validation loss = 0.1794899795204401\n",
      "Epoch 0181 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.6280294659300184\n",
      "Training loss = 0.22874705660594266\n",
      "Validation accuracy = 0.78125\n",
      "Validation loss = 0.18448605202138424\n",
      "Epoch 0182 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.6281730769230769\n",
      "Training loss = 0.22867540939230022\n",
      "Validation accuracy = 0.8125\n",
      "Validation loss = 0.19828667119145393\n",
      "Epoch 0183 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.6283879781420765\n",
      "Training loss = 0.2285856902837509\n",
      "Validation accuracy = 0.59375\n",
      "Validation loss = 0.19204435870051384\n",
      "Epoch 0184 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.6286684782608696\n",
      "Training loss = 0.22849107356843254\n",
      "Validation accuracy = 0.71875\n",
      "Validation loss = 0.18312753085047007\n",
      "Epoch 0185 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.6288918918918919\n",
      "Training loss = 0.22837943300611532\n",
      "Validation accuracy = 0.75\n",
      "Validation loss = 0.18137697502970695\n",
      "Epoch 0186 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.6291039426523297\n",
      "Training loss = 0.22827655229230134\n",
      "Validation accuracy = 0.78125\n",
      "Validation loss = 0.1773455161601305\n",
      "Epoch 0187 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.6293048128342246\n",
      "Training loss = 0.22823076040927262\n",
      "Validation accuracy = 0.75\n",
      "Validation loss = 0.21357207465916872\n",
      "Epoch 0188 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.6295301418439716\n",
      "Training loss = 0.22812844538645066\n",
      "Validation accuracy = 0.875\n",
      "Validation loss = 0.15769751369953156\n",
      "Epoch 0189 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.6297178130511464\n",
      "Training loss = 0.22802143591888105\n",
      "Validation accuracy = 0.71875\n",
      "Validation loss = 0.1841227449476719\n",
      "Epoch 0190 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.6298640350877193\n",
      "Training loss = 0.22792552046353617\n",
      "Validation accuracy = 0.75\n",
      "Validation loss = 0.15969826374202967\n",
      "Epoch 0191 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.6299825479930192\n",
      "Training loss = 0.2278564007601735\n",
      "Validation accuracy = 0.78125\n",
      "Validation loss = 0.18104890454560518\n",
      "Epoch 0192 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.6300607638888889\n",
      "Training loss = 0.2278246309439419\n",
      "Validation accuracy = 0.84375\n",
      "Validation loss = 0.16556481551378965\n",
      "Epoch 0193 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.6302288428324698\n",
      "Training loss = 0.22772686968407946\n",
      "Validation accuracy = 0.40625\n",
      "Validation loss = 0.2500400831922889\n",
      "Epoch 0194 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.6303994845360825\n",
      "Training loss = 0.227648300146332\n",
      "Validation accuracy = 0.4375\n",
      "Validation loss = 0.22462235856801271\n",
      "Epoch 0195 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.6306324786324786\n",
      "Training loss = 0.22751210087830695\n",
      "Validation accuracy = 0.78125\n",
      "Validation loss = 0.1827684035524726\n",
      "Epoch 0196 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.6308205782312926\n",
      "Training loss = 0.22740689037304346\n",
      "Validation accuracy = 0.75\n",
      "Validation loss = 0.18043388985097408\n",
      "Epoch 0197 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.6309137055837564\n",
      "Training loss = 0.2273070965302626\n",
      "Validation accuracy = 0.8125\n",
      "Validation loss = 0.19401950296014547\n",
      "Epoch 0198 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.6311910774410774\n",
      "Training loss = 0.22721026321415247\n",
      "Validation accuracy = 0.53125\n",
      "Validation loss = 0.20619933493435383\n",
      "Epoch 0199 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.6313065326633166\n",
      "Training loss = 0.22713090792086157\n",
      "Validation accuracy = 0.90625\n",
      "Validation loss = 0.14506997354328632\n",
      "Epoch 0200 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.631475\n",
      "Training loss = 0.22704566506110133\n",
      "Validation accuracy = 0.84375\n",
      "Validation loss = 0.16688150446861982\n",
      "Making model for session group 20210310_15:34:21.045-20210319_16:23:44.170\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/imblearn/utils/_validation.py:326: UserWarning: After over-sampling, the number of samples (300) in class car will be larger than the number of samples in the majority class (class #signpost -> 160)\n",
      "  n_samples_majority,\n",
      "/usr/local/lib/python3.6/dist-packages/imblearn/utils/_validation.py:326: UserWarning: After over-sampling, the number of samples (300) in class signpost will be larger than the number of samples in the majority class (class #signpost -> 160)\n",
      "  n_samples_majority,\n",
      "/usr/local/lib/python3.6/dist-packages/imblearn/utils/_validation.py:326: UserWarning: After over-sampling, the number of samples (300) in class tree will be larger than the number of samples in the majority class (class #signpost -> 160)\n",
      "  n_samples_majority,\n",
      "/usr/local/lib/python3.6/dist-packages/imblearn/utils/_validation.py:326: UserWarning: After over-sampling, the number of samples (300) in class wall will be larger than the number of samples in the majority class (class #signpost -> 160)\n",
      "  n_samples_majority,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0001 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.4091666666666667\n",
      "Training loss = 0.31222266112764674\n",
      "Validation accuracy = 0.25\n",
      "Validation loss = 0.3141399547457695\n",
      "Epoch 0002 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.43833333333333335\n",
      "Training loss = 0.303940675308307\n",
      "Validation accuracy = 0.375\n",
      "Validation loss = 0.32375040650367737\n",
      "Epoch 0003 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.4686111111111111\n",
      "Training loss = 0.29664985646804176\n",
      "Validation accuracy = 0.46875\n",
      "Validation loss = 0.3010362237691879\n",
      "Epoch 0004 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.4875\n",
      "Training loss = 0.2910345920920372\n",
      "Validation accuracy = 0.40625\n",
      "Validation loss = 0.3146486598998308\n",
      "Epoch 0005 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.5005\n",
      "Training loss = 0.2871911569535732\n",
      "Validation accuracy = 0.75\n",
      "Validation loss = 0.30642075277864933\n",
      "Epoch 0006 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.5091666666666667\n",
      "Training loss = 0.2840223895675606\n",
      "Validation accuracy = 0.625\n",
      "Validation loss = 0.3420639391988516\n",
      "Epoch 0007 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.5186904761904761\n",
      "Training loss = 0.28143274808213825\n",
      "Validation accuracy = 0.6875\n",
      "Validation loss = 0.3100621849298477\n",
      "Epoch 0008 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.5292708333333334\n",
      "Training loss = 0.2781898817482094\n",
      "Validation accuracy = 0.34375\n",
      "Validation loss = 0.37788187339901924\n",
      "Epoch 0009 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.5352777777777777\n",
      "Training loss = 0.27544848278164863\n",
      "Validation accuracy = 0.4375\n",
      "Validation loss = 0.3192432355135679\n",
      "Epoch 0010 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.5399166666666667\n",
      "Training loss = 0.274029228930672\n",
      "Validation accuracy = 0.65625\n",
      "Validation loss = 0.2689086738973856\n",
      "Epoch 0011 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.5436363636363636\n",
      "Training loss = 0.27236164246770467\n",
      "Validation accuracy = 0.6875\n",
      "Validation loss = 0.28533232770860195\n",
      "Epoch 0012 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.5476388888888889\n",
      "Training loss = 0.27069053980211416\n",
      "Validation accuracy = 0.53125\n",
      "Validation loss = 0.29698452167212963\n",
      "Epoch 0013 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.5501282051282051\n",
      "Training loss = 0.26961808796303394\n",
      "Validation accuracy = 0.78125\n",
      "Validation loss = 0.2534228228032589\n",
      "Epoch 0014 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.5522619047619047\n",
      "Training loss = 0.26847671319863625\n",
      "Validation accuracy = 0.53125\n",
      "Validation loss = 0.2682838784530759\n",
      "Epoch 0015 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.5551111111111111\n",
      "Training loss = 0.2668159289641513\n",
      "Validation accuracy = 0.5625\n",
      "Validation loss = 0.3286604741588235\n",
      "Epoch 0016 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.5558333333333333\n",
      "Training loss = 0.2658499720708157\n",
      "Validation accuracy = 0.375\n",
      "Validation loss = 0.29374850913882256\n",
      "Epoch 0017 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.5586274509803921\n",
      "Training loss = 0.264467596283146\n",
      "Validation accuracy = 0.5625\n",
      "Validation loss = 0.28726848028600216\n",
      "Epoch 0018 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.5601851851851852\n",
      "Training loss = 0.26368350120606243\n",
      "Validation accuracy = 0.53125\n",
      "Validation loss = 0.2820266652852297\n",
      "Epoch 0019 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.5616666666666666\n",
      "Training loss = 0.2629787294279065\n",
      "Validation accuracy = 0.5\n",
      "Validation loss = 0.34524388425052166\n",
      "Epoch 0020 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.5624583333333333\n",
      "Training loss = 0.26202460884923734\n",
      "Validation accuracy = 0.625\n",
      "Validation loss = 0.35265520960092545\n",
      "Epoch 0021 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.562936507936508\n",
      "Training loss = 0.2615186507562323\n",
      "Validation accuracy = 0.5625\n",
      "Validation loss = 0.3442244213074446\n",
      "Epoch 0022 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.5652651515151516\n",
      "Training loss = 0.26053966718076754\n",
      "Validation accuracy = 0.78125\n",
      "Validation loss = 0.295156616717577\n",
      "Epoch 0023 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.5670652173913043\n",
      "Training loss = 0.25938369956569396\n",
      "Validation accuracy = 0.53125\n",
      "Validation loss = 0.29697287268936634\n",
      "Epoch 0024 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.5687152777777778\n",
      "Training loss = 0.2586587353857855\n",
      "Validation accuracy = 0.625\n",
      "Validation loss = 0.30354352481663227\n",
      "Epoch 0025 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.5696\n",
      "Training loss = 0.25812759009599684\n",
      "Validation accuracy = 0.5\n",
      "Validation loss = 0.36656731367111206\n",
      "Epoch 0026 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.5715384615384616\n",
      "Training loss = 0.25732889083620064\n",
      "Validation accuracy = 0.5\n",
      "Validation loss = 0.268015643581748\n",
      "Epoch 0027 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.5724691358024692\n",
      "Training loss = 0.25648902173119564\n",
      "Validation accuracy = 0.625\n",
      "Validation loss = 0.3152058180421591\n",
      "Epoch 0028 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.5738988095238096\n",
      "Training loss = 0.25579224380087995\n",
      "Validation accuracy = 0.4375\n",
      "Validation loss = 0.31495076417922974\n",
      "Epoch 0029 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.5754022988505747\n",
      "Training loss = 0.2550979666874327\n",
      "Validation accuracy = 0.5625\n",
      "Validation loss = 0.2965907007455826\n",
      "Epoch 0030 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.5765833333333333\n",
      "Training loss = 0.2543186749832498\n",
      "Validation accuracy = 0.5625\n",
      "Validation loss = 0.3525441959500313\n",
      "Epoch 0031 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.5771505376344086\n",
      "Training loss = 0.25393038527379114\n",
      "Validation accuracy = 0.40625\n",
      "Validation loss = 0.3017803318798542\n",
      "Epoch 0032 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.5775520833333333\n",
      "Training loss = 0.253592659314163\n",
      "Validation accuracy = 0.71875\n",
      "Validation loss = 0.3345390520989895\n",
      "Epoch 0033 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.5788888888888889\n",
      "Training loss = 0.25289804487065837\n",
      "Validation accuracy = 0.5625\n",
      "Validation loss = 0.39621102809906006\n",
      "Epoch 0034 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.5799754901960784\n",
      "Training loss = 0.2524427947898706\n",
      "Validation accuracy = 0.71875\n",
      "Validation loss = 0.3473561117425561\n",
      "Epoch 0035 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.5805\n",
      "Training loss = 0.25199581301992846\n",
      "Validation accuracy = 0.5\n",
      "Validation loss = 0.30877309292554855\n",
      "Epoch 0036 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.5821296296296297\n",
      "Training loss = 0.2513283382501039\n",
      "Validation accuracy = 0.53125\n",
      "Validation loss = 0.3280751183629036\n",
      "Epoch 0037 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.582972972972973\n",
      "Training loss = 0.2509392618018765\n",
      "Validation accuracy = 0.78125\n",
      "Validation loss = 0.36679208651185036\n",
      "Epoch 0038 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.584078947368421\n",
      "Training loss = 0.2502699705736156\n",
      "Validation accuracy = 0.5\n",
      "Validation loss = 0.437692703679204\n",
      "Epoch 0039 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.5847649572649573\n",
      "Training loss = 0.24995451831919516\n",
      "Validation accuracy = 0.5\n",
      "Validation loss = 0.41030931286513805\n",
      "Epoch 0040 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.5861041666666666\n",
      "Training loss = 0.24937441706533234\n",
      "Validation accuracy = 0.5625\n",
      "Validation loss = 0.31417811196297407\n",
      "Epoch 0041 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.5866260162601626\n",
      "Training loss = 0.24913214561900474\n",
      "Validation accuracy = 0.40625\n",
      "Validation loss = 0.4580601453781128\n",
      "Epoch 0042 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.5869642857142857\n",
      "Training loss = 0.24900854963277066\n",
      "Validation accuracy = 0.53125\n",
      "Validation loss = 0.35407746210694313\n",
      "Epoch 0043 / 0200\n",
      "=====================================\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training accuracy = 0.5874031007751938\n",
      "Training loss = 0.2486201815867378\n",
      "Validation accuracy = 0.5\n",
      "Validation loss = 0.34982926584780216\n",
      "Epoch 0044 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.5882386363636364\n",
      "Training loss = 0.2482983531481163\n",
      "Validation accuracy = 0.53125\n",
      "Validation loss = 0.32304622605443\n",
      "Epoch 0045 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.5891481481481482\n",
      "Training loss = 0.24769131231307984\n",
      "Validation accuracy = 0.5625\n",
      "Validation loss = 0.27004282362759113\n",
      "Epoch 0046 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.5897101449275363\n",
      "Training loss = 0.2473595983027548\n",
      "Validation accuracy = 0.28125\n",
      "Validation loss = 0.4569462575018406\n",
      "Epoch 0047 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.5904432624113475\n",
      "Training loss = 0.2468777130100321\n",
      "Validation accuracy = 0.59375\n",
      "Validation loss = 0.3735923767089844\n",
      "Epoch 0048 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.5908854166666667\n",
      "Training loss = 0.24655347112876674\n",
      "Validation accuracy = 0.5625\n",
      "Validation loss = 0.4247588040307164\n",
      "Epoch 0049 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.5914965986394558\n",
      "Training loss = 0.24627425296270117\n",
      "Validation accuracy = 0.375\n",
      "Validation loss = 0.2905931305140257\n",
      "Epoch 0050 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.59195\n",
      "Training loss = 0.24606374407907328\n",
      "Validation accuracy = 0.4375\n",
      "Validation loss = 0.4850805336609483\n",
      "Epoch 0051 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.5923692810457516\n",
      "Training loss = 0.24577595885916084\n",
      "Validation accuracy = 0.5\n",
      "Validation loss = 0.37165391258895397\n",
      "Epoch 0052 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.593125\n",
      "Training loss = 0.24540734308509107\n",
      "Validation accuracy = 0.53125\n",
      "Validation loss = 0.31316874735057354\n",
      "Epoch 0053 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.5937893081761006\n",
      "Training loss = 0.2450645160009651\n",
      "Validation accuracy = 0.5625\n",
      "Validation loss = 0.3956260569393635\n",
      "Epoch 0054 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.5941049382716049\n",
      "Training loss = 0.2447600680819632\n",
      "Validation accuracy = 0.4375\n",
      "Validation loss = 0.4294906072318554\n",
      "Epoch 0055 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.5946515151515152\n",
      "Training loss = 0.24440674593773756\n",
      "Validation accuracy = 0.375\n",
      "Validation loss = 0.3805410601198673\n",
      "Epoch 0056 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.5948511904761905\n",
      "Training loss = 0.24428342928001215\n",
      "Validation accuracy = 0.53125\n",
      "Validation loss = 0.3391408817842603\n",
      "Epoch 0057 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.5955263157894737\n",
      "Training loss = 0.24389474346100937\n",
      "Validation accuracy = 0.5\n",
      "Validation loss = 0.3909025266766548\n",
      "Epoch 0058 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.5959051724137931\n",
      "Training loss = 0.2436356980717559\n",
      "Validation accuracy = 0.4375\n",
      "Validation loss = 0.47205905616283417\n",
      "Epoch 0059 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.5966242937853108\n",
      "Training loss = 0.243315338595523\n",
      "Validation accuracy = 0.65625\n",
      "Validation loss = 0.3776276484131813\n",
      "Epoch 0060 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.5969861111111111\n",
      "Training loss = 0.24313921431203683\n",
      "Validation accuracy = 0.46875\n",
      "Validation loss = 0.3742325231432915\n",
      "Epoch 0061 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.5976229508196721\n",
      "Training loss = 0.24276594103359786\n",
      "Validation accuracy = 0.5625\n",
      "Validation loss = 0.39436337538063526\n",
      "Epoch 0062 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.5982123655913979\n",
      "Training loss = 0.2425394459176929\n",
      "Validation accuracy = 0.5\n",
      "Validation loss = 0.34809450898319483\n",
      "Epoch 0063 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.5989417989417989\n",
      "Training loss = 0.2422186999917819\n",
      "Validation accuracy = 0.625\n",
      "Validation loss = 0.3392849378287792\n",
      "Epoch 0064 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.5991796875\n",
      "Training loss = 0.24203363241278567\n",
      "Validation accuracy = 0.5\n",
      "Validation loss = 0.31167775578796864\n",
      "Epoch 0065 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.5994871794871794\n",
      "Training loss = 0.24183365411636157\n",
      "Validation accuracy = 0.5\n",
      "Validation loss = 0.3661770708858967\n",
      "Epoch 0066 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.6002020202020202\n",
      "Training loss = 0.24154887920151455\n",
      "Validation accuracy = 0.6875\n",
      "Validation loss = 0.3929196931421757\n",
      "Epoch 0067 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.6002860696517412\n",
      "Training loss = 0.24145214789690664\n",
      "Validation accuracy = 0.5\n",
      "Validation loss = 0.3227061200886965\n",
      "Epoch 0068 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.6005514705882353\n",
      "Training loss = 0.2413218963686742\n",
      "Validation accuracy = 0.625\n",
      "Validation loss = 0.3796336632221937\n",
      "Epoch 0069 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.6010990338164252\n",
      "Training loss = 0.24111453420010165\n",
      "Validation accuracy = 0.40625\n",
      "Validation loss = 0.35817581973969936\n",
      "Epoch 0070 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.6017738095238095\n",
      "Training loss = 0.24078992930054666\n",
      "Validation accuracy = 0.5625\n",
      "Validation loss = 0.323603268712759\n",
      "Epoch 0071 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.6024178403755869\n",
      "Training loss = 0.2405269740189605\n",
      "Validation accuracy = 0.5\n",
      "Validation loss = 0.3824714533984661\n",
      "Epoch 0072 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.602662037037037\n",
      "Training loss = 0.24024830204779626\n",
      "Validation accuracy = 0.53125\n",
      "Validation loss = 0.3855166779831052\n",
      "Epoch 0073 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.6030707762557077\n",
      "Training loss = 0.2400751179392071\n",
      "Validation accuracy = 0.4375\n",
      "Validation loss = 0.3796395417302847\n",
      "Epoch 0074 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.6035135135135136\n",
      "Training loss = 0.23988209668647598\n",
      "Validation accuracy = 0.46875\n",
      "Validation loss = 0.4058626163750887\n",
      "Epoch 0075 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.6038\n",
      "Training loss = 0.23967290956377982\n",
      "Validation accuracy = 0.4375\n",
      "Validation loss = 0.45771699864417315\n",
      "Epoch 0076 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.6042543859649123\n",
      "Training loss = 0.23943846737737196\n",
      "Validation accuracy = 0.46875\n",
      "Validation loss = 0.36667474173009396\n",
      "Epoch 0077 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.6045021645021645\n",
      "Training loss = 0.23931538851746234\n",
      "Validation accuracy = 0.53125\n",
      "Validation loss = 0.31410000659525394\n",
      "Epoch 0078 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.6046367521367522\n",
      "Training loss = 0.2392752296382036\n",
      "Validation accuracy = 0.40625\n",
      "Validation loss = 0.36684269551187754\n",
      "Epoch 0079 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.6051160337552742\n",
      "Training loss = 0.23901861545468683\n",
      "Validation accuracy = 0.3125\n",
      "Validation loss = 0.4047929421067238\n",
      "Epoch 0080 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.6056041666666667\n",
      "Training loss = 0.2387826365924751\n",
      "Validation accuracy = 0.5\n",
      "Validation loss = 0.3946474129334092\n",
      "Epoch 0081 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.6062860082304526\n",
      "Training loss = 0.23851049989983134\n",
      "Validation accuracy = 0.34375\n",
      "Validation loss = 0.35457969829440117\n",
      "Epoch 0082 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.6067479674796747\n",
      "Training loss = 0.2382299160854361\n",
      "Validation accuracy = 0.53125\n",
      "Validation loss = 0.3537427559494972\n",
      "Epoch 0083 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.6070783132530121\n",
      "Training loss = 0.23804278740981016\n",
      "Validation accuracy = 0.5\n",
      "Validation loss = 0.41134779527783394\n",
      "Epoch 0084 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.6077678571428572\n",
      "Training loss = 0.2377507581041446\n",
      "Validation accuracy = 0.46875\n",
      "Validation loss = 0.3830980248749256\n",
      "Epoch 0085 / 0200\n",
      "=====================================\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training accuracy = 0.6076666666666667\n",
      "Training loss = 0.23773122942710623\n",
      "Validation accuracy = 0.5\n",
      "Validation loss = 0.3875736854970455\n",
      "Epoch 0086 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.6079360465116279\n",
      "Training loss = 0.23761471831665715\n",
      "Validation accuracy = 0.6875\n",
      "Validation loss = 0.2690329058095813\n",
      "Epoch 0087 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.6081896551724137\n",
      "Training loss = 0.2375386085101471\n",
      "Validation accuracy = 0.5\n",
      "Validation loss = 0.42957678250968456\n",
      "Epoch 0088 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.6086647727272727\n",
      "Training loss = 0.23733884474883477\n",
      "Validation accuracy = 0.4375\n",
      "Validation loss = 0.44142636843025684\n",
      "Epoch 0089 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.6090262172284644\n",
      "Training loss = 0.23722196662665976\n",
      "Validation accuracy = 0.5\n",
      "Validation loss = 0.28966372553259134\n",
      "Epoch 0090 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.6092407407407407\n",
      "Training loss = 0.23703678922713906\n",
      "Validation accuracy = 0.53125\n",
      "Validation loss = 0.2617583256214857\n",
      "Epoch 0091 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.6095970695970696\n",
      "Training loss = 0.23692544565751003\n",
      "Validation accuracy = 0.71875\n",
      "Validation loss = 0.32164888363331556\n",
      "Epoch 0092 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.6099728260869566\n",
      "Training loss = 0.23671083917679347\n",
      "Validation accuracy = 0.53125\n",
      "Validation loss = 0.3141614943742752\n",
      "Epoch 0093 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.6102150537634409\n",
      "Training loss = 0.23657292845348518\n",
      "Validation accuracy = 0.5625\n",
      "Validation loss = 0.30564163718372583\n",
      "Epoch 0094 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.6106737588652482\n",
      "Training loss = 0.23632880289292504\n",
      "Validation accuracy = 0.3125\n",
      "Validation loss = 0.4062277805060148\n",
      "Epoch 0095 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.6110087719298246\n",
      "Training loss = 0.2361972625422896\n",
      "Validation accuracy = 0.6875\n",
      "Validation loss = 0.34273117780685425\n",
      "Epoch 0096 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.6115017361111111\n",
      "Training loss = 0.23605066031967809\n",
      "Validation accuracy = 0.46875\n",
      "Validation loss = 0.38986992463469505\n",
      "Epoch 0097 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.6119845360824743\n",
      "Training loss = 0.23582364518976293\n",
      "Validation accuracy = 0.59375\n",
      "Validation loss = 0.3633133852854371\n",
      "Epoch 0098 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.6122108843537415\n",
      "Training loss = 0.23579265948030212\n",
      "Validation accuracy = 0.625\n",
      "Validation loss = 0.3022630624473095\n",
      "Epoch 0099 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.6123316498316498\n",
      "Training loss = 0.23563668683748254\n",
      "Validation accuracy = 0.4375\n",
      "Validation loss = 0.4825071832165122\n",
      "Epoch 0100 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.61255\n",
      "Training loss = 0.2355116881005466\n",
      "Validation accuracy = 0.46875\n",
      "Validation loss = 0.36428436916321516\n",
      "Epoch 0101 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.612970297029703\n",
      "Training loss = 0.23526681811379718\n",
      "Validation accuracy = 0.5\n",
      "Validation loss = 0.35373286344110966\n",
      "Epoch 0102 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.613218954248366\n",
      "Training loss = 0.23514566097773756\n",
      "Validation accuracy = 0.5\n",
      "Validation loss = 0.3825154583901167\n",
      "Epoch 0103 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.6134870550161813\n",
      "Training loss = 0.23499876988647825\n",
      "Validation accuracy = 0.4375\n",
      "Validation loss = 0.4508479433134198\n",
      "Epoch 0104 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.6138221153846154\n",
      "Training loss = 0.23484696511059808\n",
      "Validation accuracy = 0.5\n",
      "Validation loss = 0.3143033208325505\n",
      "Epoch 0105 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.6141587301587301\n",
      "Training loss = 0.23470987632894327\n",
      "Validation accuracy = 0.46875\n",
      "Validation loss = 0.41242020204663277\n",
      "Epoch 0106 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.6145125786163522\n",
      "Training loss = 0.2345444914501793\n",
      "Validation accuracy = 0.4375\n",
      "Validation loss = 0.37474210746586323\n",
      "Epoch 0107 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.6148130841121495\n",
      "Training loss = 0.23433948926511583\n",
      "Validation accuracy = 0.34375\n",
      "Validation loss = 0.3748658988624811\n",
      "Epoch 0108 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.6150925925925926\n",
      "Training loss = 0.2341543274766041\n",
      "Validation accuracy = 0.53125\n",
      "Validation loss = 0.3193425564095378\n",
      "Epoch 0109 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.615565749235474\n",
      "Training loss = 0.2339904609053689\n",
      "Validation accuracy = 0.28125\n",
      "Validation loss = 0.5002490729093552\n",
      "Epoch 0110 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.6159166666666667\n",
      "Training loss = 0.23385760175527046\n",
      "Validation accuracy = 0.5\n",
      "Validation loss = 0.34313299134373665\n",
      "Epoch 0111 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.6163963963963964\n",
      "Training loss = 0.23358572020947754\n",
      "Validation accuracy = 0.5625\n",
      "Validation loss = 0.33247190713882446\n",
      "Epoch 0112 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.6166964285714286\n",
      "Training loss = 0.23345655507031118\n",
      "Validation accuracy = 0.34375\n",
      "Validation loss = 0.29888729006052017\n",
      "Epoch 0113 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.6172713864306785\n",
      "Training loss = 0.2332344484687467\n",
      "Validation accuracy = 0.59375\n",
      "Validation loss = 0.2705917526036501\n",
      "Epoch 0114 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.6173976608187135\n",
      "Training loss = 0.2331165647195184\n",
      "Validation accuracy = 0.40625\n",
      "Validation loss = 0.2867091428488493\n",
      "Epoch 0115 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.617768115942029\n",
      "Training loss = 0.23296048935729524\n",
      "Validation accuracy = 0.40625\n",
      "Validation loss = 0.3718572361394763\n",
      "Epoch 0116 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.618103448275862\n",
      "Training loss = 0.23281707208389524\n",
      "Validation accuracy = 0.40625\n",
      "Validation loss = 0.396170062944293\n",
      "Epoch 0117 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.6184259259259259\n",
      "Training loss = 0.23271344800981192\n",
      "Validation accuracy = 0.40625\n",
      "Validation loss = 0.3140923250466585\n",
      "Epoch 0118 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.6187288135593221\n",
      "Training loss = 0.23257663028661982\n",
      "Validation accuracy = 0.4375\n",
      "Validation loss = 0.3430152088403702\n",
      "Epoch 0119 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.6189355742296919\n",
      "Training loss = 0.23245865096940713\n",
      "Validation accuracy = 0.625\n",
      "Validation loss = 0.34685765393078327\n",
      "Epoch 0120 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.6193541666666667\n",
      "Training loss = 0.23227861845131137\n",
      "Validation accuracy = 0.3125\n",
      "Validation loss = 0.3673187866806984\n",
      "Epoch 0121 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.6196005509641873\n",
      "Training loss = 0.23220137416238873\n",
      "Validation accuracy = 0.53125\n",
      "Validation loss = 0.3207869231700897\n",
      "Epoch 0122 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.619938524590164\n",
      "Training loss = 0.23205697002276127\n",
      "Validation accuracy = 0.375\n",
      "Validation loss = 0.3819495216012001\n",
      "Epoch 0123 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.6202845528455284\n",
      "Training loss = 0.2319121748333176\n",
      "Validation accuracy = 0.4375\n",
      "Validation loss = 0.40396552346646786\n",
      "Epoch 0124 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.6205981182795699\n",
      "Training loss = 0.23174444747237508\n",
      "Validation accuracy = 0.59375\n",
      "Validation loss = 0.3790687695145607\n",
      "Epoch 0125 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.6208333333333333\n",
      "Training loss = 0.23163823383202156\n",
      "Validation accuracy = 0.4375\n",
      "Validation loss = 0.4029883127659559\n",
      "Epoch 0126 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.6209986772486773\n",
      "Training loss = 0.2315072587825279\n",
      "Validation accuracy = 0.5\n",
      "Validation loss = 0.3893785197287798\n",
      "Epoch 0127 / 0200\n",
      "=====================================\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training accuracy = 0.6214173228346457\n",
      "Training loss = 0.23128977441285148\n",
      "Validation accuracy = 0.53125\n",
      "Validation loss = 0.3208890249952674\n",
      "Epoch 0128 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.6216927083333333\n",
      "Training loss = 0.23111926686940326\n",
      "Validation accuracy = 0.375\n",
      "Validation loss = 0.41909049823880196\n",
      "Epoch 0129 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.621970284237726\n",
      "Training loss = 0.23100925178442738\n",
      "Validation accuracy = 0.5\n",
      "Validation loss = 0.35954286344349384\n",
      "Epoch 0130 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.6221410256410257\n",
      "Training loss = 0.2309176894482703\n",
      "Validation accuracy = 0.5625\n",
      "Validation loss = 0.4492466636002064\n",
      "Epoch 0131 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.6225636132315522\n",
      "Training loss = 0.23075655703563197\n",
      "Validation accuracy = 0.59375\n",
      "Validation loss = 0.3936814721673727\n",
      "Epoch 0132 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.6226136363636363\n",
      "Training loss = 0.2306709189951006\n",
      "Validation accuracy = 0.34375\n",
      "Validation loss = 0.40044493321329355\n",
      "Epoch 0133 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.6229949874686717\n",
      "Training loss = 0.23051390534775673\n",
      "Validation accuracy = 0.46875\n",
      "Validation loss = 0.4282647389918566\n",
      "Epoch 0134 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.623320895522388\n",
      "Training loss = 0.23032874245724794\n",
      "Validation accuracy = 0.4375\n",
      "Validation loss = 0.40284393541514874\n",
      "Epoch 0135 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.6236481481481482\n",
      "Training loss = 0.2301601367275472\n",
      "Validation accuracy = 0.625\n",
      "Validation loss = 0.3328522741794586\n",
      "Epoch 0136 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.6239276960784313\n",
      "Training loss = 0.2300386203369856\n",
      "Validation accuracy = 0.5\n",
      "Validation loss = 0.3308834359049797\n",
      "Epoch 0137 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.624257907542579\n",
      "Training loss = 0.22990749455417378\n",
      "Validation accuracy = 0.53125\n",
      "Validation loss = 0.3143994528800249\n",
      "Epoch 0138 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.6244625603864734\n",
      "Training loss = 0.22977670327035918\n",
      "Validation accuracy = 0.5625\n",
      "Validation loss = 0.43594866897910833\n",
      "Epoch 0139 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.6247541966426858\n",
      "Training loss = 0.22964807631416645\n",
      "Validation accuracy = 0.625\n",
      "Validation loss = 0.3096480052918196\n",
      "Epoch 0140 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.625172619047619\n",
      "Training loss = 0.22943242008833303\n",
      "Validation accuracy = 0.5625\n",
      "Validation loss = 0.34705174528062344\n",
      "Epoch 0141 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.6254255319148936\n",
      "Training loss = 0.22929066586085808\n",
      "Validation accuracy = 0.4375\n",
      "Validation loss = 0.3870136607438326\n",
      "Epoch 0142 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.6255457746478873\n",
      "Training loss = 0.22922566539105116\n",
      "Validation accuracy = 0.53125\n",
      "Validation loss = 0.3732845038175583\n",
      "Epoch 0143 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.6257284382284383\n",
      "Training loss = 0.22910716219034505\n",
      "Validation accuracy = 0.6875\n",
      "Validation loss = 0.30937149934470654\n",
      "Epoch 0144 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.6259375\n",
      "Training loss = 0.2290178873743517\n",
      "Validation accuracy = 0.5625\n",
      "Validation loss = 0.2891184687614441\n",
      "Epoch 0145 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.6261954022988506\n",
      "Training loss = 0.2288704008466896\n",
      "Validation accuracy = 0.53125\n",
      "Validation loss = 0.3443576702848077\n",
      "Epoch 0146 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.6264326484018264\n",
      "Training loss = 0.22879068339218014\n",
      "Validation accuracy = 0.4375\n",
      "Validation loss = 0.42549080960452557\n",
      "Epoch 0147 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.6267460317460317\n",
      "Training loss = 0.2286577013400204\n",
      "Validation accuracy = 0.46875\n",
      "Validation loss = 0.4018706167116761\n",
      "Epoch 0148 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.6269538288288288\n",
      "Training loss = 0.22853718602073353\n",
      "Validation accuracy = 0.59375\n",
      "Validation loss = 0.3008424639701843\n",
      "Epoch 0149 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.627248322147651\n",
      "Training loss = 0.22840175168676263\n",
      "Validation accuracy = 0.4375\n",
      "Validation loss = 0.3202380072325468\n",
      "Epoch 0150 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.6275444444444445\n",
      "Training loss = 0.22827585583196747\n",
      "Validation accuracy = 0.5\n",
      "Validation loss = 0.3857962042093277\n",
      "Epoch 0151 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.627924944812362\n",
      "Training loss = 0.22811914477168396\n",
      "Validation accuracy = 0.5\n",
      "Validation loss = 0.3573264107108116\n",
      "Epoch 0152 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.6281304824561403\n",
      "Training loss = 0.2279821756471504\n",
      "Validation accuracy = 0.40625\n",
      "Validation loss = 0.32027371786534786\n",
      "Epoch 0153 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.6284694989106754\n",
      "Training loss = 0.22783757928677698\n",
      "Validation accuracy = 0.4375\n",
      "Validation loss = 0.44480058923363686\n",
      "Epoch 0154 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.6286904761904762\n",
      "Training loss = 0.2277026636123625\n",
      "Validation accuracy = 0.375\n",
      "Validation loss = 0.48649522848427296\n",
      "Epoch 0155 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.6289193548387096\n",
      "Training loss = 0.22759943477977668\n",
      "Validation accuracy = 0.4375\n",
      "Validation loss = 0.48355057649314404\n",
      "Epoch 0156 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.6292574786324786\n",
      "Training loss = 0.22745739914691793\n",
      "Validation accuracy = 0.375\n",
      "Validation loss = 0.4526188299059868\n",
      "Epoch 0157 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.6295276008492569\n",
      "Training loss = 0.22729824355524628\n",
      "Validation accuracy = 0.5\n",
      "Validation loss = 0.36557640321552753\n",
      "Epoch 0158 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.6296360759493671\n",
      "Training loss = 0.2271766578774695\n",
      "Validation accuracy = 0.65625\n",
      "Validation loss = 0.32582067139446735\n",
      "Epoch 0159 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.630020964360587\n",
      "Training loss = 0.22703880464693285\n",
      "Validation accuracy = 0.53125\n",
      "Validation loss = 0.31581197679042816\n",
      "Epoch 0160 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.6301666666666667\n",
      "Training loss = 0.226899234229854\n",
      "Validation accuracy = 0.375\n",
      "Validation loss = 0.4950180985033512\n",
      "Epoch 0161 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.6304037267080745\n",
      "Training loss = 0.22678313743978676\n",
      "Validation accuracy = 0.46875\n",
      "Validation loss = 0.4377977279946208\n",
      "Epoch 0162 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.6305658436213992\n",
      "Training loss = 0.22667646083551546\n",
      "Validation accuracy = 0.59375\n",
      "Validation loss = 0.314131498336792\n",
      "Epoch 0163 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.6308895705521472\n",
      "Training loss = 0.22650381288569277\n",
      "Validation accuracy = 0.40625\n",
      "Validation loss = 0.3083739448338747\n",
      "Epoch 0164 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.631204268292683\n",
      "Training loss = 0.2263562654614509\n",
      "Validation accuracy = 0.5625\n",
      "Validation loss = 0.41453393176198006\n",
      "Epoch 0165 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.6314191919191919\n",
      "Training loss = 0.22625278397340967\n",
      "Validation accuracy = 0.625\n",
      "Validation loss = 0.41390151157975197\n",
      "Epoch 0166 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.6316415662650603\n",
      "Training loss = 0.22611319128229437\n",
      "Validation accuracy = 0.40625\n",
      "Validation loss = 0.37526689656078815\n",
      "Epoch 0167 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.6318662674650699\n",
      "Training loss = 0.22598298383211185\n",
      "Validation accuracy = 0.4375\n",
      "Validation loss = 0.3620690293610096\n",
      "Epoch 0168 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.6320535714285714\n",
      "Training loss = 0.22584964214454567\n",
      "Validation accuracy = 0.53125\n",
      "Validation loss = 0.5027094651013613\n",
      "Epoch 0169 / 0200\n",
      "=====================================\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training accuracy = 0.6322879684418146\n",
      "Training loss = 0.2257539243518542\n",
      "Validation accuracy = 0.4375\n",
      "Validation loss = 0.3830203302204609\n",
      "Epoch 0170 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.6325049019607843\n",
      "Training loss = 0.2256560913524499\n",
      "Validation accuracy = 0.40625\n",
      "Validation loss = 0.3701843935996294\n",
      "Epoch 0171 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.632719298245614\n",
      "Training loss = 0.2255403542355952\n",
      "Validation accuracy = 0.5625\n",
      "Validation loss = 0.29916591476649046\n",
      "Epoch 0172 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.6330959302325582\n",
      "Training loss = 0.22536941286782886\n",
      "Validation accuracy = 0.375\n",
      "Validation loss = 0.33054573088884354\n",
      "Epoch 0173 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.6334296724470135\n",
      "Training loss = 0.22525550657341362\n",
      "Validation accuracy = 0.40625\n",
      "Validation loss = 0.46360207349061966\n",
      "Epoch 0174 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.6336925287356322\n",
      "Training loss = 0.22509977512275692\n",
      "Validation accuracy = 0.53125\n",
      "Validation loss = 0.3338869158178568\n",
      "Epoch 0175 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.6340523809523809\n",
      "Training loss = 0.22494560909072558\n",
      "Validation accuracy = 0.53125\n",
      "Validation loss = 0.3757219985127449\n",
      "Epoch 0176 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.6341903409090909\n",
      "Training loss = 0.22490350893247082\n",
      "Validation accuracy = 0.4375\n",
      "Validation loss = 0.5388940628618002\n",
      "Epoch 0177 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.6344256120527307\n",
      "Training loss = 0.22477100876947467\n",
      "Validation accuracy = 0.40625\n",
      "Validation loss = 0.4285025391727686\n",
      "Epoch 0178 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.6346956928838952\n",
      "Training loss = 0.22466153536284908\n",
      "Validation accuracy = 0.40625\n",
      "Validation loss = 0.42283332254737616\n",
      "Epoch 0179 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.6349115456238361\n",
      "Training loss = 0.22452749463363622\n",
      "Validation accuracy = 0.5\n",
      "Validation loss = 0.40050376392900944\n",
      "Epoch 0180 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.6352592592592593\n",
      "Training loss = 0.22433233709923095\n",
      "Validation accuracy = 0.25\n",
      "Validation loss = 0.3817216642200947\n",
      "Epoch 0181 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.6353729281767956\n",
      "Training loss = 0.2242988063652981\n",
      "Validation accuracy = 0.59375\n",
      "Validation loss = 0.3498990209773183\n",
      "Epoch 0182 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.6356639194139194\n",
      "Training loss = 0.22416941049457578\n",
      "Validation accuracy = 0.46875\n",
      "Validation loss = 0.36194164119660854\n",
      "Epoch 0183 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.6358287795992714\n",
      "Training loss = 0.22407173008093093\n",
      "Validation accuracy = 0.46875\n",
      "Validation loss = 0.33368486911058426\n",
      "Epoch 0184 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.635991847826087\n",
      "Training loss = 0.22398157183647804\n",
      "Validation accuracy = 0.59375\n",
      "Validation loss = 0.30589087679982185\n",
      "Epoch 0185 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.6362567567567567\n",
      "Training loss = 0.22383131486915792\n",
      "Validation accuracy = 0.28125\n",
      "Validation loss = 0.35502522252500057\n",
      "Epoch 0186 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.6364829749103943\n",
      "Training loss = 0.22370456006257763\n",
      "Validation accuracy = 0.4375\n",
      "Validation loss = 0.48788379691541195\n",
      "Epoch 0187 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.636849376114082\n",
      "Training loss = 0.2235418219991865\n",
      "Validation accuracy = 0.375\n",
      "Validation loss = 0.36287451907992363\n",
      "Epoch 0188 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.6372118794326241\n",
      "Training loss = 0.22337085740944596\n",
      "Validation accuracy = 0.625\n",
      "Validation loss = 0.47997220419347286\n",
      "Epoch 0189 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.6373059964726632\n",
      "Training loss = 0.22331050488631352\n",
      "Validation accuracy = 0.46875\n",
      "Validation loss = 0.4794471953064203\n",
      "Epoch 0190 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.6374912280701754\n",
      "Training loss = 0.22319637215947896\n",
      "Validation accuracy = 0.59375\n",
      "Validation loss = 0.3331148028373718\n",
      "Epoch 0191 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.6378184991273996\n",
      "Training loss = 0.22308871380490677\n",
      "Validation accuracy = 0.53125\n",
      "Validation loss = 0.39173518121242523\n",
      "Epoch 0192 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.6380598958333333\n",
      "Training loss = 0.22294790993884414\n",
      "Validation accuracy = 0.5625\n",
      "Validation loss = 0.38623454980552197\n",
      "Epoch 0193 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.6382944732297063\n",
      "Training loss = 0.2228560912371042\n",
      "Validation accuracy = 0.4375\n",
      "Validation loss = 0.3991570472717285\n",
      "Epoch 0194 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.6384965635738832\n",
      "Training loss = 0.22274227632484894\n",
      "Validation accuracy = 0.4375\n",
      "Validation loss = 0.3713808245956898\n",
      "Epoch 0195 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.6388247863247863\n",
      "Training loss = 0.22258235853630254\n",
      "Validation accuracy = 0.5\n",
      "Validation loss = 0.32524308003485203\n",
      "Epoch 0196 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.6391113945578232\n",
      "Training loss = 0.2224445373208902\n",
      "Validation accuracy = 0.5\n",
      "Validation loss = 0.39865682274103165\n",
      "Epoch 0197 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.6393401015228426\n",
      "Training loss = 0.22236023723013862\n",
      "Validation accuracy = 0.5625\n",
      "Validation loss = 0.3316159974783659\n",
      "Epoch 0198 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.6394865319865319\n",
      "Training loss = 0.2222737772346973\n",
      "Validation accuracy = 0.375\n",
      "Validation loss = 0.3930103536695242\n",
      "Epoch 0199 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.6394388609715242\n",
      "Training loss = 0.22226278281485165\n",
      "Validation accuracy = 0.4375\n",
      "Validation loss = 0.41736587788909674\n",
      "Epoch 0200 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.6395\n",
      "Training loss = 0.22223126712112376\n",
      "Validation accuracy = 0.59375\n",
      "Validation loss = 0.34968004561960697\n",
      "Making model for session group 20210310_15:34:48.696-20210319_16:26:08.675\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/imblearn/utils/_validation.py:326: UserWarning: After over-sampling, the number of samples (300) in class car will be larger than the number of samples in the majority class (class #signpost -> 160)\n",
      "  n_samples_majority,\n",
      "/usr/local/lib/python3.6/dist-packages/imblearn/utils/_validation.py:326: UserWarning: After over-sampling, the number of samples (300) in class signpost will be larger than the number of samples in the majority class (class #signpost -> 160)\n",
      "  n_samples_majority,\n",
      "/usr/local/lib/python3.6/dist-packages/imblearn/utils/_validation.py:326: UserWarning: After over-sampling, the number of samples (300) in class tree will be larger than the number of samples in the majority class (class #signpost -> 160)\n",
      "  n_samples_majority,\n",
      "/usr/local/lib/python3.6/dist-packages/imblearn/utils/_validation.py:326: UserWarning: After over-sampling, the number of samples (300) in class wall will be larger than the number of samples in the majority class (class #signpost -> 160)\n",
      "  n_samples_majority,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0001 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.4175\n",
      "Training loss = 0.3222255389392376\n",
      "Validation accuracy = 0.2916666666666667\n",
      "Validation loss = 0.34824733436107635\n",
      "Epoch 0002 / 0200\n",
      "=====================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/_classification.py:1221: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/_classification.py:1221: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training accuracy = 0.47625\n",
      "Training loss = 0.3078232333312432\n",
      "Validation accuracy = 0.375\n",
      "Validation loss = 0.3185838262240092\n",
      "Epoch 0003 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.49527777777777776\n",
      "Training loss = 0.30081380292773247\n",
      "Validation accuracy = 0.2916666666666667\n",
      "Validation loss = 0.34046559035778046\n",
      "Epoch 0004 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.506875\n",
      "Training loss = 0.29532951350013414\n",
      "Validation accuracy = 0.375\n",
      "Validation loss = 0.3196326593557994\n",
      "Epoch 0005 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.5178333333333334\n",
      "Training loss = 0.2902121285200119\n",
      "Validation accuracy = 0.5\n",
      "Validation loss = 0.3291367292404175\n",
      "Epoch 0006 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.5281944444444444\n",
      "Training loss = 0.28592800638741916\n",
      "Validation accuracy = 0.4166666666666667\n",
      "Validation loss = 0.31920649856328964\n",
      "Epoch 0007 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.5380952380952381\n",
      "Training loss = 0.2819555484893776\n",
      "Validation accuracy = 0.5416666666666666\n",
      "Validation loss = 0.3228764782349269\n",
      "Epoch 0008 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.5410416666666666\n",
      "Training loss = 0.2795651992596686\n",
      "Validation accuracy = 0.4166666666666667\n",
      "Validation loss = 0.3158538614710172\n",
      "Epoch 0009 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.5460185185185186\n",
      "Training loss = 0.27667974571111026\n",
      "Validation accuracy = 0.20833333333333334\n",
      "Validation loss = 0.37634284794330597\n",
      "Epoch 0010 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.54925\n",
      "Training loss = 0.27450050074855487\n",
      "Validation accuracy = 0.5833333333333334\n",
      "Validation loss = 0.30452847977479297\n",
      "Epoch 0011 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.5516666666666666\n",
      "Training loss = 0.2731008928833586\n",
      "Validation accuracy = 0.3333333333333333\n",
      "Validation loss = 0.327010340988636\n",
      "Epoch 0012 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.5545138888888889\n",
      "Training loss = 0.27162041944969034\n",
      "Validation accuracy = 0.5\n",
      "Validation loss = 0.3176140785217285\n",
      "Epoch 0013 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.5579487179487179\n",
      "Training loss = 0.26946334610191675\n",
      "Validation accuracy = 0.08333333333333333\n",
      "Validation loss = 0.3731667548418045\n",
      "Epoch 0014 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.5602976190476191\n",
      "Training loss = 0.26810729119039717\n",
      "Validation accuracy = 0.4583333333333333\n",
      "Validation loss = 0.3080838546156883\n",
      "Epoch 0015 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.5616666666666666\n",
      "Training loss = 0.26718277072906493\n",
      "Validation accuracy = 0.5\n",
      "Validation loss = 0.3134348268310229\n",
      "Epoch 0016 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.56359375\n",
      "Training loss = 0.2658939925751959\n",
      "Validation accuracy = 0.375\n",
      "Validation loss = 0.32114064941803616\n",
      "Epoch 0017 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.5664705882352942\n",
      "Training loss = 0.2646271569588605\n",
      "Validation accuracy = 0.375\n",
      "Validation loss = 0.3257660319407781\n",
      "Epoch 0018 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.5675462962962963\n",
      "Training loss = 0.26373652784222806\n",
      "Validation accuracy = 0.4583333333333333\n",
      "Validation loss = 0.3280390078822772\n",
      "Epoch 0019 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.5691228070175438\n",
      "Training loss = 0.2627706394122358\n",
      "Validation accuracy = 0.4583333333333333\n",
      "Validation loss = 0.30037738382816315\n",
      "Epoch 0020 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.5710416666666667\n",
      "Training loss = 0.2621395641180376\n",
      "Validation accuracy = 0.4583333333333333\n",
      "Validation loss = 0.3215540448824565\n",
      "Epoch 0021 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.5715476190476191\n",
      "Training loss = 0.2612055132857391\n",
      "Validation accuracy = 0.4583333333333333\n",
      "Validation loss = 0.31598734110593796\n",
      "Epoch 0022 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.5719318181818182\n",
      "Training loss = 0.26061731293120166\n",
      "Validation accuracy = 0.3333333333333333\n",
      "Validation loss = 0.3309615006049474\n",
      "Epoch 0023 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.5730434782608695\n",
      "Training loss = 0.2599458869535854\n",
      "Validation accuracy = 0.5416666666666666\n",
      "Validation loss = 0.31259352962176007\n",
      "Epoch 0024 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.5746527777777778\n",
      "Training loss = 0.25906571467096606\n",
      "Validation accuracy = 0.375\n",
      "Validation loss = 0.32403839379549026\n",
      "Epoch 0025 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.5758\n",
      "Training loss = 0.25839649778505164\n",
      "Validation accuracy = 0.3333333333333333\n",
      "Validation loss = 0.3278605292240779\n",
      "Epoch 0026 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.5774038461538461\n",
      "Training loss = 0.257670904381726\n",
      "Validation accuracy = 0.4166666666666667\n",
      "Validation loss = 0.3022342622280121\n",
      "Epoch 0027 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.5783333333333334\n",
      "Training loss = 0.2571634671533549\n",
      "Validation accuracy = 0.4583333333333333\n",
      "Validation loss = 0.29643315076828003\n",
      "Epoch 0028 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.5791071428571428\n",
      "Training loss = 0.25654050184236393\n",
      "Validation accuracy = 0.0\n",
      "Validation loss = 0.43755274017651874\n",
      "Epoch 0029 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.5797126436781609\n",
      "Training loss = 0.2559791362045825\n",
      "Validation accuracy = 0.3333333333333333\n",
      "Validation loss = 0.32662886132796604\n",
      "Epoch 0030 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.5805833333333333\n",
      "Training loss = 0.2557317149978545\n",
      "Validation accuracy = 0.375\n",
      "Validation loss = 0.34146088113387424\n",
      "Epoch 0031 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.580994623655914\n",
      "Training loss = 0.2553714218679615\n",
      "Validation accuracy = 0.375\n",
      "Validation loss = 0.3438296392560005\n",
      "Epoch 0032 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.5811458333333334\n",
      "Training loss = 0.254876529284132\n",
      "Validation accuracy = 0.4166666666666667\n",
      "Validation loss = 0.314978430668513\n",
      "Epoch 0033 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.5821212121212122\n",
      "Training loss = 0.2543920515033633\n",
      "Validation accuracy = 0.375\n",
      "Validation loss = 0.308635671933492\n",
      "Epoch 0034 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.5829411764705882\n",
      "Training loss = 0.25370069350901187\n",
      "Validation accuracy = 0.125\n",
      "Validation loss = 0.3548795034488042\n",
      "Epoch 0035 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.5834761904761905\n",
      "Training loss = 0.25331843724279174\n",
      "Validation accuracy = 0.4583333333333333\n",
      "Validation loss = 0.3217727889617284\n",
      "Epoch 0036 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.5843055555555555\n",
      "Training loss = 0.25286984376402366\n",
      "Validation accuracy = 0.3333333333333333\n",
      "Validation loss = 0.33098676552375156\n",
      "Epoch 0037 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.5853153153153153\n",
      "Training loss = 0.2524831224239624\n",
      "Validation accuracy = 0.2916666666666667\n",
      "Validation loss = 0.33280693739652634\n",
      "Epoch 0038 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.58625\n",
      "Training loss = 0.25214320903480575\n",
      "Validation accuracy = 0.5\n",
      "Validation loss = 0.3078937754034996\n",
      "Epoch 0039 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.5873717948717949\n",
      "Training loss = 0.25159214907668087\n",
      "Validation accuracy = 0.20833333333333334\n",
      "Validation loss = 0.35206980506579083\n",
      "Epoch 0040 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.5879791666666667\n",
      "Training loss = 0.2512253988242398\n",
      "Validation accuracy = 0.4583333333333333\n",
      "Validation loss = 0.3256208300590515\n",
      "Epoch 0041 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.5884552845528456\n",
      "Training loss = 0.25088334505272103\n",
      "Validation accuracy = 0.4583333333333333\n",
      "Validation loss = 0.31088217347860336\n",
      "Epoch 0042 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.5890277777777778\n",
      "Training loss = 0.25063792972515025\n",
      "Validation accuracy = 0.2916666666666667\n",
      "Validation loss = 0.3186282093326251\n",
      "Epoch 0043 / 0200\n",
      "=====================================\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training accuracy = 0.5899612403100776\n",
      "Training loss = 0.25026983444947143\n",
      "Validation accuracy = 0.4583333333333333\n",
      "Validation loss = 0.30769042670726776\n",
      "Epoch 0044 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.5907386363636363\n",
      "Training loss = 0.2498953015772118\n",
      "Validation accuracy = 0.25\n",
      "Validation loss = 0.3474733034769694\n",
      "Epoch 0045 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.5911296296296297\n",
      "Training loss = 0.24962982869727743\n",
      "Validation accuracy = 0.375\n",
      "Validation loss = 0.3127606213092804\n",
      "Epoch 0046 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.5916485507246377\n",
      "Training loss = 0.24924055232544956\n",
      "Validation accuracy = 0.375\n",
      "Validation loss = 0.3022252768278122\n",
      "Epoch 0047 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.5919148936170213\n",
      "Training loss = 0.2488986634476282\n",
      "Validation accuracy = 0.4583333333333333\n",
      "Validation loss = 0.2978833044568698\n",
      "Epoch 0048 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.5926736111111112\n",
      "Training loss = 0.24839744625742444\n",
      "Validation accuracy = 0.08333333333333333\n",
      "Validation loss = 0.3791673133770625\n",
      "Epoch 0049 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.5930102040816326\n",
      "Training loss = 0.24804272847237432\n",
      "Validation accuracy = 0.4166666666666667\n",
      "Validation loss = 0.35128441949685413\n",
      "Epoch 0050 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.59375\n",
      "Training loss = 0.24759264344250162\n",
      "Validation accuracy = 0.375\n",
      "Validation loss = 0.3160010700424512\n",
      "Epoch 0051 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.5938562091503268\n",
      "Training loss = 0.24735601164571017\n",
      "Validation accuracy = 0.375\n",
      "Validation loss = 0.30796123047669727\n",
      "Epoch 0052 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.5940705128205128\n",
      "Training loss = 0.24715317107474383\n",
      "Validation accuracy = 0.4166666666666667\n",
      "Validation loss = 0.3065811445315679\n",
      "Epoch 0053 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.5947327044025157\n",
      "Training loss = 0.24682460320844027\n",
      "Validation accuracy = 0.3333333333333333\n",
      "Validation loss = 0.3323839008808136\n",
      "Epoch 0054 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.5952623456790124\n",
      "Training loss = 0.24659090889065907\n",
      "Validation accuracy = 0.4583333333333333\n",
      "Validation loss = 0.30688421179850894\n",
      "Epoch 0055 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.5959545454545454\n",
      "Training loss = 0.24630996505035596\n",
      "Validation accuracy = 0.4166666666666667\n",
      "Validation loss = 0.3508208890755971\n",
      "Epoch 0056 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.5965327380952381\n",
      "Training loss = 0.24603208615821565\n",
      "Validation accuracy = 0.4583333333333333\n",
      "Validation loss = 0.3017467086513837\n",
      "Epoch 0057 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.5969883040935673\n",
      "Training loss = 0.24577807070371527\n",
      "Validation accuracy = 0.375\n",
      "Validation loss = 0.28107697268327075\n",
      "Epoch 0058 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.5973275862068965\n",
      "Training loss = 0.24546247601444865\n",
      "Validation accuracy = 0.4583333333333333\n",
      "Validation loss = 0.3520271231730779\n",
      "Epoch 0059 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.5979943502824858\n",
      "Training loss = 0.24512462513152994\n",
      "Validation accuracy = 0.3333333333333333\n",
      "Validation loss = 0.31102851529916126\n",
      "Epoch 0060 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.5983888888888889\n",
      "Training loss = 0.24486997884160114\n",
      "Validation accuracy = 0.375\n",
      "Validation loss = 0.32651055852572125\n",
      "Epoch 0061 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.5988251366120219\n",
      "Training loss = 0.24460914137157425\n",
      "Validation accuracy = 0.3333333333333333\n",
      "Validation loss = 0.30280566960573196\n",
      "Epoch 0062 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.5994758064516129\n",
      "Training loss = 0.24426117838851066\n",
      "Validation accuracy = 0.4583333333333333\n",
      "Validation loss = 0.35063229004542035\n",
      "Epoch 0063 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.5996031746031746\n",
      "Training loss = 0.24406250891448172\n",
      "Validation accuracy = 0.3333333333333333\n",
      "Validation loss = 0.2979956865310669\n",
      "Epoch 0064 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.6001302083333333\n",
      "Training loss = 0.243773991841396\n",
      "Validation accuracy = 0.4583333333333333\n",
      "Validation loss = 0.35492661595344543\n",
      "Epoch 0065 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.6007948717948718\n",
      "Training loss = 0.243435711253721\n",
      "Validation accuracy = 0.4583333333333333\n",
      "Validation loss = 0.32136180996894836\n",
      "Epoch 0066 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.6008838383838384\n",
      "Training loss = 0.24329859807729873\n",
      "Validation accuracy = 0.4166666666666667\n",
      "Validation loss = 0.32669777423143387\n",
      "Epoch 0067 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.6014925373134329\n",
      "Training loss = 0.24302012036596216\n",
      "Validation accuracy = 0.25\n",
      "Validation loss = 0.301512951652209\n",
      "Epoch 0068 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.6020588235294118\n",
      "Training loss = 0.24273516421827177\n",
      "Validation accuracy = 0.3333333333333333\n",
      "Validation loss = 0.3067603756984075\n",
      "Epoch 0069 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.6026690821256039\n",
      "Training loss = 0.2424281803837073\n",
      "Validation accuracy = 0.4166666666666667\n",
      "Validation loss = 0.2848812093337377\n",
      "Epoch 0070 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.603047619047619\n",
      "Training loss = 0.24220832176737134\n",
      "Validation accuracy = 0.5\n",
      "Validation loss = 0.3161061704158783\n",
      "Epoch 0071 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.6033450704225352\n",
      "Training loss = 0.24210968249543033\n",
      "Validation accuracy = 0.5\n",
      "Validation loss = 0.31452726572752\n",
      "Epoch 0072 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.6037962962962963\n",
      "Training loss = 0.24188099439859528\n",
      "Validation accuracy = 0.3333333333333333\n",
      "Validation loss = 0.33713152011235553\n",
      "Epoch 0073 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.6042009132420091\n",
      "Training loss = 0.2415527173606296\n",
      "Validation accuracy = 0.2916666666666667\n",
      "Validation loss = 0.37979373584191006\n",
      "Epoch 0074 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.604740990990991\n",
      "Training loss = 0.2412896149983076\n",
      "Validation accuracy = 0.5833333333333334\n",
      "Validation loss = 0.3159363071123759\n",
      "Epoch 0075 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.6049888888888889\n",
      "Training loss = 0.24111444608949953\n",
      "Validation accuracy = 0.3333333333333333\n",
      "Validation loss = 0.32040336231390637\n",
      "Epoch 0076 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.6054166666666667\n",
      "Training loss = 0.24087726851614813\n",
      "Validation accuracy = 0.20833333333333334\n",
      "Validation loss = 0.3673568864663442\n",
      "Epoch 0077 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.6056277056277056\n",
      "Training loss = 0.24057570860515554\n",
      "Validation accuracy = 0.4583333333333333\n",
      "Validation loss = 0.32117001463969547\n",
      "Epoch 0078 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.6061538461538462\n",
      "Training loss = 0.24030625134563216\n",
      "Validation accuracy = 0.2916666666666667\n",
      "Validation loss = 0.3626630703608195\n",
      "Epoch 0079 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.6064662447257384\n",
      "Training loss = 0.24012508289283338\n",
      "Validation accuracy = 0.5833333333333334\n",
      "Validation loss = 0.3039497286081314\n",
      "Epoch 0080 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.6068020833333333\n",
      "Training loss = 0.2398721277223279\n",
      "Validation accuracy = 0.20833333333333334\n",
      "Validation loss = 0.3428359776735306\n",
      "Epoch 0081 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.6074485596707819\n",
      "Training loss = 0.23957304308811825\n",
      "Validation accuracy = 0.5\n",
      "Validation loss = 0.32368089507023495\n",
      "Epoch 0082 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.6079573170731707\n",
      "Training loss = 0.2394496554875277\n",
      "Validation accuracy = 0.4583333333333333\n",
      "Validation loss = 0.3062766914566358\n",
      "Epoch 0083 / 0200\n",
      "=====================================\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training accuracy = 0.6086546184738956\n",
      "Training loss = 0.23916207467082395\n",
      "Validation accuracy = 0.4166666666666667\n",
      "Validation loss = 0.3394714444875717\n",
      "Epoch 0084 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.6090674603174603\n",
      "Training loss = 0.2389679672511383\n",
      "Validation accuracy = 0.4583333333333333\n",
      "Validation loss = 0.28683100392421085\n",
      "Epoch 0085 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.6093333333333333\n",
      "Training loss = 0.23875273314965706\n",
      "Validation accuracy = 0.5833333333333334\n",
      "Validation loss = 0.305230679611365\n",
      "Epoch 0086 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.609874031007752\n",
      "Training loss = 0.2385469923800854\n",
      "Validation accuracy = 0.375\n",
      "Validation loss = 0.29123689234256744\n",
      "Epoch 0087 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.6102873563218391\n",
      "Training loss = 0.23838783996129745\n",
      "Validation accuracy = 0.20833333333333334\n",
      "Validation loss = 0.30837297439575195\n",
      "Epoch 0088 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.6106439393939394\n",
      "Training loss = 0.23819090928600142\n",
      "Validation accuracy = 0.4166666666666667\n",
      "Validation loss = 0.31966817130645114\n",
      "Epoch 0089 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.6108707865168539\n",
      "Training loss = 0.23800738379080197\n",
      "Validation accuracy = 0.4166666666666667\n",
      "Validation loss = 0.3106932044029236\n",
      "Epoch 0090 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.6115092592592593\n",
      "Training loss = 0.2377642569006593\n",
      "Validation accuracy = 0.5416666666666666\n",
      "Validation loss = 0.2919604033231735\n",
      "Epoch 0091 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.611904761904762\n",
      "Training loss = 0.23752746343912878\n",
      "Validation accuracy = 0.20833333333333334\n",
      "Validation loss = 0.4025632118185361\n",
      "Epoch 0092 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.6123188405797102\n",
      "Training loss = 0.23739012060066064\n",
      "Validation accuracy = 0.4583333333333333\n",
      "Validation loss = 0.3166484187046687\n",
      "Epoch 0093 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.6125985663082437\n",
      "Training loss = 0.23720637279505905\n",
      "Validation accuracy = 0.375\n",
      "Validation loss = 0.36526254564523697\n",
      "Epoch 0094 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.6130407801418439\n",
      "Training loss = 0.237031572507232\n",
      "Validation accuracy = 0.4166666666666667\n",
      "Validation loss = 0.3442399303118388\n",
      "Epoch 0095 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.6135438596491228\n",
      "Training loss = 0.2368257203398828\n",
      "Validation accuracy = 0.3333333333333333\n",
      "Validation loss = 0.29971780627965927\n",
      "Epoch 0096 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.6140451388888889\n",
      "Training loss = 0.23657192596117965\n",
      "Validation accuracy = 0.5\n",
      "Validation loss = 0.3090241352717082\n",
      "Epoch 0097 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.6144415807560137\n",
      "Training loss = 0.23634977934069137\n",
      "Validation accuracy = 0.4166666666666667\n",
      "Validation loss = 0.3060339664419492\n",
      "Epoch 0098 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.6147448979591836\n",
      "Training loss = 0.23609839014696324\n",
      "Validation accuracy = 0.375\n",
      "Validation loss = 0.312705693145593\n",
      "Epoch 0099 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.61489898989899\n",
      "Training loss = 0.23594815646884618\n",
      "Validation accuracy = 0.5416666666666666\n",
      "Validation loss = 0.29703837633132935\n",
      "Epoch 0100 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.6153666666666666\n",
      "Training loss = 0.23573702829579513\n",
      "Validation accuracy = 0.375\n",
      "Validation loss = 0.2977195158600807\n",
      "Epoch 0101 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.6158910891089109\n",
      "Training loss = 0.23553665493273795\n",
      "Validation accuracy = 0.3333333333333333\n",
      "Validation loss = 0.3026008556286494\n",
      "Epoch 0102 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.6160539215686275\n",
      "Training loss = 0.23540615700428782\n",
      "Validation accuracy = 0.3333333333333333\n",
      "Validation loss = 0.2903619532783826\n",
      "Epoch 0103 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.6163592233009709\n",
      "Training loss = 0.23522332509840962\n",
      "Validation accuracy = 0.3333333333333333\n",
      "Validation loss = 0.30292708426713943\n",
      "Epoch 0104 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.6166426282051282\n",
      "Training loss = 0.235082389246553\n",
      "Validation accuracy = 0.5416666666666666\n",
      "Validation loss = 0.28184371689955395\n",
      "Epoch 0105 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.6169920634920635\n",
      "Training loss = 0.23486082573471562\n",
      "Validation accuracy = 0.4166666666666667\n",
      "Validation loss = 0.30536577602227527\n",
      "Epoch 0106 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.6173349056603774\n",
      "Training loss = 0.23469702452186894\n",
      "Validation accuracy = 0.4166666666666667\n",
      "Validation loss = 0.3206760759154956\n",
      "Epoch 0107 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.6178426791277258\n",
      "Training loss = 0.23447933774824453\n",
      "Validation accuracy = 0.2916666666666667\n",
      "Validation loss = 0.2802746345599492\n",
      "Epoch 0108 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.618016975308642\n",
      "Training loss = 0.23430344559907637\n",
      "Validation accuracy = 0.4583333333333333\n",
      "Validation loss = 0.2980017215013504\n",
      "Epoch 0109 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.6181957186544342\n",
      "Training loss = 0.23424865290921307\n",
      "Validation accuracy = 0.5833333333333334\n",
      "Validation loss = 0.33276525636514026\n",
      "Epoch 0110 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.61825\n",
      "Training loss = 0.2341739451388518\n",
      "Validation accuracy = 0.5\n",
      "Validation loss = 0.3256545116504033\n",
      "Epoch 0111 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.6186411411411411\n",
      "Training loss = 0.2339810517492953\n",
      "Validation accuracy = 0.4583333333333333\n",
      "Validation loss = 0.29814816017945606\n",
      "Epoch 0112 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.6190104166666667\n",
      "Training loss = 0.23383222999006864\n",
      "Validation accuracy = 0.2916666666666667\n",
      "Validation loss = 0.2982926517724991\n",
      "Epoch 0113 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.6192256637168142\n",
      "Training loss = 0.23369976679989546\n",
      "Validation accuracy = 0.375\n",
      "Validation loss = 0.3200269291798274\n",
      "Epoch 0114 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.6195175438596491\n",
      "Training loss = 0.23354555762988347\n",
      "Validation accuracy = 0.375\n",
      "Validation loss = 0.32339028269052505\n",
      "Epoch 0115 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.6198623188405797\n",
      "Training loss = 0.23329622722417115\n",
      "Validation accuracy = 0.375\n",
      "Validation loss = 0.3041307677825292\n",
      "Epoch 0116 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.6203663793103448\n",
      "Training loss = 0.2330334224287506\n",
      "Validation accuracy = 0.4583333333333333\n",
      "Validation loss = 0.3116355861226718\n",
      "Epoch 0117 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.6207051282051282\n",
      "Training loss = 0.2328254730138726\n",
      "Validation accuracy = 0.375\n",
      "Validation loss = 0.349793404340744\n",
      "Epoch 0118 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.6209322033898305\n",
      "Training loss = 0.2326454899770518\n",
      "Validation accuracy = 0.08333333333333333\n",
      "Validation loss = 0.35737940669059753\n",
      "Epoch 0119 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.6215126050420168\n",
      "Training loss = 0.23241604055405832\n",
      "Validation accuracy = 0.16666666666666666\n",
      "Validation loss = 0.35475673774878186\n",
      "Epoch 0120 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.6217291666666667\n",
      "Training loss = 0.2323198546330548\n",
      "Validation accuracy = 0.375\n",
      "Validation loss = 0.3654525801539421\n",
      "Epoch 0121 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.6220110192837466\n",
      "Training loss = 0.23221137655647497\n",
      "Validation accuracy = 0.375\n",
      "Validation loss = 0.3095358858505885\n",
      "Epoch 0122 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.6221379781420765\n",
      "Training loss = 0.2321012870153117\n",
      "Validation accuracy = 0.5833333333333334\n",
      "Validation loss = 0.2935340454181035\n",
      "Epoch 0123 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.6224254742547426\n",
      "Training loss = 0.2319781071755298\n",
      "Validation accuracy = 0.5416666666666666\n",
      "Validation loss = 0.31322429080804187\n",
      "Epoch 0124 / 0200\n",
      "=====================================\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training accuracy = 0.6226142473118279\n",
      "Training loss = 0.23184665564958368\n",
      "Validation accuracy = 0.3333333333333333\n",
      "Validation loss = 0.3054959451158841\n",
      "Epoch 0125 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.6228466666666667\n",
      "Training loss = 0.23173344421188036\n",
      "Validation accuracy = 0.4583333333333333\n",
      "Validation loss = 0.35956655194362\n",
      "Epoch 0126 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.6231283068783069\n",
      "Training loss = 0.2315663106027971\n",
      "Validation accuracy = 0.2916666666666667\n",
      "Validation loss = 0.32801420986652374\n",
      "Epoch 0127 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.6234514435695538\n",
      "Training loss = 0.231390090282234\n",
      "Validation accuracy = 0.375\n",
      "Validation loss = 0.29536360998948413\n",
      "Epoch 0128 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.6236653645833333\n",
      "Training loss = 0.23121739804919345\n",
      "Validation accuracy = 0.4166666666666667\n",
      "Validation loss = 0.32070616135994595\n",
      "Epoch 0129 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.6237726098191214\n",
      "Training loss = 0.2310914717722463\n",
      "Validation accuracy = 0.375\n",
      "Validation loss = 0.3123416503270467\n",
      "Epoch 0130 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.6239807692307693\n",
      "Training loss = 0.2309537309809373\n",
      "Validation accuracy = 0.375\n",
      "Validation loss = 0.29912267873684567\n",
      "Epoch 0131 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.6245229007633588\n",
      "Training loss = 0.23073238521046538\n",
      "Validation accuracy = 0.3333333333333333\n",
      "Validation loss = 0.3128490497668584\n",
      "Epoch 0132 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.6249305555555555\n",
      "Training loss = 0.23056023470333054\n",
      "Validation accuracy = 0.2916666666666667\n",
      "Validation loss = 0.2810347229242325\n",
      "Epoch 0133 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.6251817042606517\n",
      "Training loss = 0.23042160020034788\n",
      "Validation accuracy = 0.5416666666666666\n",
      "Validation loss = 0.29511373738447827\n",
      "Epoch 0134 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.6253793532338309\n",
      "Training loss = 0.2303093941202063\n",
      "Validation accuracy = 0.25\n",
      "Validation loss = 0.3267071545124054\n",
      "Epoch 0135 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.625679012345679\n",
      "Training loss = 0.23012259282245312\n",
      "Validation accuracy = 0.5833333333333334\n",
      "Validation loss = 0.2937457486987114\n",
      "Epoch 0136 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.6259252450980393\n",
      "Training loss = 0.2300272632575612\n",
      "Validation accuracy = 0.5\n",
      "Validation loss = 0.29609378675619763\n",
      "Epoch 0137 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.626125304136253\n",
      "Training loss = 0.22993578201200623\n",
      "Validation accuracy = 0.5833333333333334\n",
      "Validation loss = 0.2918163637320201\n",
      "Epoch 0138 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.626225845410628\n",
      "Training loss = 0.22991554827523836\n",
      "Validation accuracy = 0.4583333333333333\n",
      "Validation loss = 0.30570290982723236\n",
      "Epoch 0139 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.6265347721822542\n",
      "Training loss = 0.22979514205841708\n",
      "Validation accuracy = 0.5833333333333334\n",
      "Validation loss = 0.32159346838792163\n",
      "Epoch 0140 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.6268571428571429\n",
      "Training loss = 0.22963165878770606\n",
      "Validation accuracy = 0.3333333333333333\n",
      "Validation loss = 0.32654256125291187\n",
      "Epoch 0141 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.627080378250591\n",
      "Training loss = 0.22951362596890817\n",
      "Validation accuracy = 0.2916666666666667\n",
      "Validation loss = 0.34412919481595355\n",
      "Epoch 0142 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.6273767605633803\n",
      "Training loss = 0.22933980538855206\n",
      "Validation accuracy = 0.3333333333333333\n",
      "Validation loss = 0.3403485491871834\n",
      "Epoch 0143 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.6276048951048951\n",
      "Training loss = 0.2291900329461152\n",
      "Validation accuracy = 0.375\n",
      "Validation loss = 0.28075966238975525\n",
      "Epoch 0144 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.6279918981481482\n",
      "Training loss = 0.22902471533726418\n",
      "Validation accuracy = 0.625\n",
      "Validation loss = 0.2738116681575775\n",
      "Epoch 0145 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.6281666666666667\n",
      "Training loss = 0.22894003241868882\n",
      "Validation accuracy = 0.5416666666666666\n",
      "Validation loss = 0.2927968353033066\n",
      "Epoch 0146 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.6282819634703196\n",
      "Training loss = 0.2288587735001355\n",
      "Validation accuracy = 0.375\n",
      "Validation loss = 0.3070031056801478\n",
      "Epoch 0147 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.6284977324263038\n",
      "Training loss = 0.2287706002932625\n",
      "Validation accuracy = 0.375\n",
      "Validation loss = 0.34200310458739597\n",
      "Epoch 0148 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.6288231981981982\n",
      "Training loss = 0.2286336526815016\n",
      "Validation accuracy = 0.4166666666666667\n",
      "Validation loss = 0.3585415706038475\n",
      "Epoch 0149 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.6290492170022371\n",
      "Training loss = 0.22848584566840388\n",
      "Validation accuracy = 0.25\n",
      "Validation loss = 0.3120399738351504\n",
      "Epoch 0150 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.6292722222222222\n",
      "Training loss = 0.22837313378850618\n",
      "Validation accuracy = 0.4166666666666667\n",
      "Validation loss = 0.2920799454053243\n",
      "Epoch 0151 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.6293598233995585\n",
      "Training loss = 0.22831734227144035\n",
      "Validation accuracy = 0.5\n",
      "Validation loss = 0.3026299700140953\n",
      "Epoch 0152 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.6295833333333334\n",
      "Training loss = 0.22819777919829154\n",
      "Validation accuracy = 0.4166666666666667\n",
      "Validation loss = 0.31840060154596966\n",
      "Epoch 0153 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.6296949891067538\n",
      "Training loss = 0.2281303489448458\n",
      "Validation accuracy = 0.4166666666666667\n",
      "Validation loss = 0.2970834821462631\n",
      "Epoch 0154 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.6299567099567099\n",
      "Training loss = 0.22801649184889478\n",
      "Validation accuracy = 0.375\n",
      "Validation loss = 0.3021594360470772\n",
      "Epoch 0155 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.6301720430107527\n",
      "Training loss = 0.22791334546381428\n",
      "Validation accuracy = 0.4166666666666667\n",
      "Validation loss = 0.2788449029127757\n",
      "Epoch 0156 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.6303044871794872\n",
      "Training loss = 0.22782555551682082\n",
      "Validation accuracy = 0.375\n",
      "Validation loss = 0.32179225484530133\n",
      "Epoch 0157 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.6305891719745222\n",
      "Training loss = 0.2276856690455394\n",
      "Validation accuracy = 0.4583333333333333\n",
      "Validation loss = 0.3194034869472186\n",
      "Epoch 0158 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.6309440928270043\n",
      "Training loss = 0.22756987304603563\n",
      "Validation accuracy = 0.5\n",
      "Validation loss = 0.3272767911354701\n",
      "Epoch 0159 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.6310534591194968\n",
      "Training loss = 0.22748409746562284\n",
      "Validation accuracy = 0.4583333333333333\n",
      "Validation loss = 0.31136544545491535\n",
      "Epoch 0160 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.6313125\n",
      "Training loss = 0.22738363711815326\n",
      "Validation accuracy = 0.375\n",
      "Validation loss = 0.3358348334829013\n",
      "Epoch 0161 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.6314337474120083\n",
      "Training loss = 0.2272576610375327\n",
      "Validation accuracy = 0.5416666666666666\n",
      "Validation loss = 0.32373911639054614\n",
      "Epoch 0162 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.6316255144032922\n",
      "Training loss = 0.2271193809742913\n",
      "Validation accuracy = 0.2916666666666667\n",
      "Validation loss = 0.32724181562662125\n",
      "Epoch 0163 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.6318762781186094\n",
      "Training loss = 0.22701549734745044\n",
      "Validation accuracy = 0.2916666666666667\n",
      "Validation loss = 0.32344963649908703\n",
      "Epoch 0164 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.6322154471544715\n",
      "Training loss = 0.22686853795357775\n",
      "Validation accuracy = 0.5\n",
      "Validation loss = 0.3017958079775174\n",
      "Epoch 0165 / 0200\n",
      "=====================================\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training accuracy = 0.6326414141414142\n",
      "Training loss = 0.22666563665603448\n",
      "Validation accuracy = 0.2916666666666667\n",
      "Validation loss = 0.3459725504120191\n",
      "Epoch 0166 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.632956827309237\n",
      "Training loss = 0.22650528436496734\n",
      "Validation accuracy = 0.4583333333333333\n",
      "Validation loss = 0.2897732083996137\n",
      "Epoch 0167 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.6332235528942116\n",
      "Training loss = 0.22635017153931533\n",
      "Validation accuracy = 0.4166666666666667\n",
      "Validation loss = 0.32699984808762866\n",
      "Epoch 0168 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.6336160714285715\n",
      "Training loss = 0.22621752276004012\n",
      "Validation accuracy = 0.3333333333333333\n",
      "Validation loss = 0.30262863884369534\n",
      "Epoch 0169 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.6340285996055227\n",
      "Training loss = 0.2260938730596379\n",
      "Validation accuracy = 0.4583333333333333\n",
      "Validation loss = 0.3067976360519727\n",
      "Epoch 0170 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.6343235294117647\n",
      "Training loss = 0.22593512935264437\n",
      "Validation accuracy = 0.375\n",
      "Validation loss = 0.3404332821567853\n",
      "Epoch 0171 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.6345565302144249\n",
      "Training loss = 0.22582812261918367\n",
      "Validation accuracy = 0.2916666666666667\n",
      "Validation loss = 0.29091207434733707\n",
      "Epoch 0172 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.6347238372093024\n",
      "Training loss = 0.2257224083666567\n",
      "Validation accuracy = 0.4583333333333333\n",
      "Validation loss = 0.3223640074332555\n",
      "Epoch 0173 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.6350289017341041\n",
      "Training loss = 0.22553299043830016\n",
      "Validation accuracy = 0.375\n",
      "Validation loss = 0.2990371584892273\n",
      "Epoch 0174 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.635191570881226\n",
      "Training loss = 0.2254812286525137\n",
      "Validation accuracy = 0.3333333333333333\n",
      "Validation loss = 0.33554060260454815\n",
      "Epoch 0175 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.6354095238095238\n",
      "Training loss = 0.2253785358480045\n",
      "Validation accuracy = 0.5\n",
      "Validation loss = 0.32807276397943497\n",
      "Epoch 0176 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.6357623106060606\n",
      "Training loss = 0.22525692312703044\n",
      "Validation accuracy = 0.4166666666666667\n",
      "Validation loss = 0.2740471859773\n",
      "Epoch 0177 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.6359745762711865\n",
      "Training loss = 0.22515184620419856\n",
      "Validation accuracy = 0.4166666666666667\n",
      "Validation loss = 0.2932981625199318\n",
      "Epoch 0178 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.6361704119850188\n",
      "Training loss = 0.22502947637699683\n",
      "Validation accuracy = 0.3333333333333333\n",
      "Validation loss = 0.293131743868192\n",
      "Epoch 0179 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.6364897579143389\n",
      "Training loss = 0.22486167929442236\n",
      "Validation accuracy = 0.2916666666666667\n",
      "Validation loss = 0.320199191570282\n",
      "Epoch 0180 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.6366018518518518\n",
      "Training loss = 0.22477799969911574\n",
      "Validation accuracy = 0.3333333333333333\n",
      "Validation loss = 0.3558350329597791\n",
      "Epoch 0181 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.6368186003683242\n",
      "Training loss = 0.2246769385323834\n",
      "Validation accuracy = 0.375\n",
      "Validation loss = 0.4144022688269615\n",
      "Epoch 0182 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.6371108058608058\n",
      "Training loss = 0.2245425896425032\n",
      "Validation accuracy = 0.2916666666666667\n",
      "Validation loss = 0.3220975150664647\n",
      "Epoch 0183 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.6373360655737705\n",
      "Training loss = 0.22441011669090483\n",
      "Validation accuracy = 0.5833333333333334\n",
      "Validation loss = 0.3298711876074473\n",
      "Epoch 0184 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.6374864130434783\n",
      "Training loss = 0.2243002204975599\n",
      "Validation accuracy = 0.25\n",
      "Validation loss = 0.33549843231836957\n",
      "Epoch 0185 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.6377567567567568\n",
      "Training loss = 0.22414855868141126\n",
      "Validation accuracy = 0.2916666666666667\n",
      "Validation loss = 0.36579931527376175\n",
      "Epoch 0186 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.6379390681003584\n",
      "Training loss = 0.22401978954719545\n",
      "Validation accuracy = 0.4166666666666667\n",
      "Validation loss = 0.36522458493709564\n",
      "Epoch 0187 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.6380926916221034\n",
      "Training loss = 0.22394455161131585\n",
      "Validation accuracy = 0.3333333333333333\n",
      "Validation loss = 0.43842484305302304\n",
      "Epoch 0188 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.6383732269503546\n",
      "Training loss = 0.22383164577390866\n",
      "Validation accuracy = 0.5416666666666666\n",
      "Validation loss = 0.3220437591274579\n",
      "Epoch 0189 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.6385978835978836\n",
      "Training loss = 0.22371346191412766\n",
      "Validation accuracy = 0.4166666666666667\n",
      "Validation loss = 0.3661930436889331\n",
      "Epoch 0190 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.6387631578947368\n",
      "Training loss = 0.223644453495022\n",
      "Validation accuracy = 0.2916666666666667\n",
      "Validation loss = 0.3299658124645551\n",
      "Epoch 0191 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.6389267015706807\n",
      "Training loss = 0.2235638790629661\n",
      "Validation accuracy = 0.2916666666666667\n",
      "Validation loss = 0.3282417158285777\n",
      "Epoch 0192 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.6391579861111111\n",
      "Training loss = 0.22341560923740164\n",
      "Validation accuracy = 0.4583333333333333\n",
      "Validation loss = 0.3037322536110878\n",
      "Epoch 0193 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.6394602763385147\n",
      "Training loss = 0.22324320478914933\n",
      "Validation accuracy = 0.4583333333333333\n",
      "Validation loss = 0.31191988786061603\n",
      "Epoch 0194 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.6396950171821306\n",
      "Training loss = 0.2230963311274616\n",
      "Validation accuracy = 0.375\n",
      "Validation loss = 0.3249222661058108\n",
      "Epoch 0195 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.639940170940171\n",
      "Training loss = 0.22296791868402152\n",
      "Validation accuracy = 0.5\n",
      "Validation loss = 0.276642066737016\n",
      "Epoch 0196 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.6400170068027211\n",
      "Training loss = 0.22291252480598078\n",
      "Validation accuracy = 0.4166666666666667\n",
      "Validation loss = 0.3356470316648483\n",
      "Epoch 0197 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.6401692047377326\n",
      "Training loss = 0.222837058301328\n",
      "Validation accuracy = 0.4583333333333333\n",
      "Validation loss = 0.3138255700469017\n",
      "Epoch 0198 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.6403156565656566\n",
      "Training loss = 0.2227548691788406\n",
      "Validation accuracy = 0.375\n",
      "Validation loss = 0.28768615672985715\n",
      "Epoch 0199 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.6404815745393635\n",
      "Training loss = 0.22267162039969585\n",
      "Validation accuracy = 0.4583333333333333\n",
      "Validation loss = 0.25442156940698624\n",
      "Epoch 0200 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.6405625\n",
      "Training loss = 0.22262162476436545\n",
      "Validation accuracy = 0.375\n",
      "Validation loss = 0.29320691774288815\n",
      "Making model for session group 20210319_16:26:51.249-20210319_16:26:51.249\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/imblearn/utils/_validation.py:326: UserWarning: After over-sampling, the number of samples (300) in class car will be larger than the number of samples in the majority class (class #signpost -> 160)\n",
      "  n_samples_majority,\n",
      "/usr/local/lib/python3.6/dist-packages/imblearn/utils/_validation.py:326: UserWarning: After over-sampling, the number of samples (300) in class signpost will be larger than the number of samples in the majority class (class #signpost -> 160)\n",
      "  n_samples_majority,\n",
      "/usr/local/lib/python3.6/dist-packages/imblearn/utils/_validation.py:326: UserWarning: After over-sampling, the number of samples (300) in class tree will be larger than the number of samples in the majority class (class #signpost -> 160)\n",
      "  n_samples_majority,\n",
      "/usr/local/lib/python3.6/dist-packages/imblearn/utils/_validation.py:326: UserWarning: After over-sampling, the number of samples (300) in class wall will be larger than the number of samples in the majority class (class #signpost -> 160)\n",
      "  n_samples_majority,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0001 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.42333333333333334\n",
      "Training loss = 0.30809121842185655\n",
      "Validation accuracy = 0.625\n",
      "Validation loss = 0.3019251823425293\n",
      "Epoch 0002 / 0200\n",
      "=====================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/_classification.py:1221: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training accuracy = 0.4558333333333333\n",
      "Training loss = 0.29930106972654663\n",
      "Validation accuracy = 0.75\n",
      "Validation loss = 0.2562650293111801\n",
      "Epoch 0003 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.4741666666666667\n",
      "Training loss = 0.2936153267655108\n",
      "Validation accuracy = 0.625\n",
      "Validation loss = 0.2980261743068695\n",
      "Epoch 0004 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.49083333333333334\n",
      "Training loss = 0.2882095305373271\n",
      "Validation accuracy = 0.75\n",
      "Validation loss = 0.2659829556941986\n",
      "Epoch 0005 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.506\n",
      "Training loss = 0.2830293647448222\n",
      "Validation accuracy = 1.0\n",
      "Validation loss = 0.2874303162097931\n",
      "Epoch 0006 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.5141666666666667\n",
      "Training loss = 0.2803113050427702\n",
      "Validation accuracy = 1.0\n",
      "Validation loss = 0.24473412334918976\n",
      "Epoch 0007 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.5238095238095238\n",
      "Training loss = 0.2766634988678353\n",
      "Validation accuracy = 1.0\n",
      "Validation loss = 0.19587037712335587\n",
      "Epoch 0008 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.52875\n",
      "Training loss = 0.2750135998396824\n",
      "Validation accuracy = 1.0\n",
      "Validation loss = 0.25420476496219635\n",
      "Epoch 0009 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.532962962962963\n",
      "Training loss = 0.27344475904272664\n",
      "Validation accuracy = 1.0\n",
      "Validation loss = 0.22350113093852997\n",
      "Epoch 0010 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.5385833333333333\n",
      "Training loss = 0.27164849573622146\n",
      "Validation accuracy = 1.0\n",
      "Validation loss = 0.2046215608716011\n",
      "Epoch 0011 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.5422727272727272\n",
      "Training loss = 0.269750309658773\n",
      "Validation accuracy = 1.0\n",
      "Validation loss = 0.18725844472646713\n",
      "Epoch 0012 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.5432638888888889\n",
      "Training loss = 0.2689836668098966\n",
      "Validation accuracy = 0.625\n",
      "Validation loss = 0.2454296052455902\n",
      "Epoch 0013 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.5457692307692308\n",
      "Training loss = 0.26762355177639385\n",
      "Validation accuracy = 1.0\n",
      "Validation loss = 0.16461703181266785\n",
      "Epoch 0014 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.5480952380952381\n",
      "Training loss = 0.2666777694296269\n",
      "Validation accuracy = 0.875\n",
      "Validation loss = 0.22901083528995514\n",
      "Epoch 0015 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.551\n",
      "Training loss = 0.26531344610121516\n",
      "Validation accuracy = 1.0\n",
      "Validation loss = 0.16282115131616592\n",
      "Epoch 0016 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.554375\n",
      "Training loss = 0.2637879654066637\n",
      "Validation accuracy = 0.0\n",
      "Validation loss = 0.3107100874185562\n",
      "Epoch 0017 / 0200\n",
      "=====================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/_classification.py:1221: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training accuracy = 0.5561764705882353\n",
      "Training loss = 0.2629075435344495\n",
      "Validation accuracy = 1.0\n",
      "Validation loss = 0.16800421476364136\n",
      "Epoch 0018 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.5569907407407407\n",
      "Training loss = 0.26249470795470253\n",
      "Validation accuracy = 1.0\n",
      "Validation loss = 0.18270661681890488\n",
      "Epoch 0019 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.5591666666666667\n",
      "Training loss = 0.2616321818295278\n",
      "Validation accuracy = 1.0\n",
      "Validation loss = 0.27892620861530304\n",
      "Epoch 0020 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.560125\n",
      "Training loss = 0.2611460020144781\n",
      "Validation accuracy = 1.0\n",
      "Validation loss = 0.2317136824131012\n",
      "Epoch 0021 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.5609920634920635\n",
      "Training loss = 0.26069983058269064\n",
      "Validation accuracy = 1.0\n",
      "Validation loss = 0.16193361580371857\n",
      "Epoch 0022 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.5624242424242424\n",
      "Training loss = 0.2598916600362369\n",
      "Validation accuracy = 0.0\n",
      "Validation loss = 0.3018410950899124\n",
      "Epoch 0023 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.5636231884057971\n",
      "Training loss = 0.2593432711712692\n",
      "Validation accuracy = 1.0\n",
      "Validation loss = 0.18198469281196594\n",
      "Epoch 0024 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.5649652777777778\n",
      "Training loss = 0.2586781059122748\n",
      "Validation accuracy = 0.875\n",
      "Validation loss = 0.22122472524642944\n",
      "Epoch 0025 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.5659666666666666\n",
      "Training loss = 0.25807086657981076\n",
      "Validation accuracy = 0.5\n",
      "Validation loss = 0.26406173408031464\n",
      "Epoch 0026 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.5665384615384615\n",
      "Training loss = 0.2576423960331923\n",
      "Validation accuracy = 0.875\n",
      "Validation loss = 0.21071390807628632\n",
      "Epoch 0027 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.5674382716049383\n",
      "Training loss = 0.25737630803000044\n",
      "Validation accuracy = 0.375\n",
      "Validation loss = 0.2541002407670021\n",
      "Epoch 0028 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.5686309523809524\n",
      "Training loss = 0.25669525687183653\n",
      "Validation accuracy = 1.0\n",
      "Validation loss = 0.14203578978776932\n",
      "Epoch 0029 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.5702011494252873\n",
      "Training loss = 0.2561362731730801\n",
      "Validation accuracy = 0.875\n",
      "Validation loss = 0.206922709941864\n",
      "Epoch 0030 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.5720555555555555\n",
      "Training loss = 0.25542837075392405\n",
      "Validation accuracy = 0.75\n",
      "Validation loss = 0.2188396453857422\n",
      "Epoch 0031 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.5731182795698925\n",
      "Training loss = 0.25496309145403806\n",
      "Validation accuracy = 0.375\n",
      "Validation loss = 0.2642252445220947\n",
      "Epoch 0032 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.5734114583333333\n",
      "Training loss = 0.2546118162549101\n",
      "Validation accuracy = 1.0\n",
      "Validation loss = 0.16657429933547974\n",
      "Epoch 0033 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.5748232323232323\n",
      "Training loss = 0.2539345565393116\n",
      "Validation accuracy = 1.0\n",
      "Validation loss = 0.18012919276952744\n",
      "Epoch 0034 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.5759803921568627\n",
      "Training loss = 0.2534127948498901\n",
      "Validation accuracy = 0.375\n",
      "Validation loss = 0.2648865580558777\n",
      "Epoch 0035 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.5768333333333333\n",
      "Training loss = 0.252736960668649\n",
      "Validation accuracy = 1.0\n",
      "Validation loss = 0.1822420284152031\n",
      "Epoch 0036 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.5773611111111111\n",
      "Training loss = 0.2523294835537672\n",
      "Validation accuracy = 0.125\n",
      "Validation loss = 0.3716431260108948\n",
      "Epoch 0037 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.5779279279279279\n",
      "Training loss = 0.25210583855238583\n",
      "Validation accuracy = 0.625\n",
      "Validation loss = 0.2440764158964157\n",
      "Epoch 0038 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.5784649122807017\n",
      "Training loss = 0.25193211512476726\n",
      "Validation accuracy = 1.0\n",
      "Validation loss = 0.17062534391880035\n",
      "Epoch 0039 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.5792948717948718\n",
      "Training loss = 0.25173759347990027\n",
      "Validation accuracy = 1.0\n",
      "Validation loss = 0.1775534674525261\n",
      "Epoch 0040 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.5798958333333334\n",
      "Training loss = 0.25148447315519057\n",
      "Validation accuracy = 1.0\n",
      "Validation loss = 0.18116187304258347\n",
      "Epoch 0041 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.5802845528455285\n",
      "Training loss = 0.2511877345935843\n",
      "Validation accuracy = 0.75\n",
      "Validation loss = 0.19559577107429504\n",
      "Epoch 0042 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.5812896825396825\n",
      "Training loss = 0.2508928756788373\n",
      "Validation accuracy = 0.375\n",
      "Validation loss = 0.2562369704246521\n",
      "Epoch 0043 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.5816085271317829\n",
      "Training loss = 0.2505994770329359\n",
      "Validation accuracy = 0.0\n",
      "Validation loss = 0.3230498433113098\n",
      "Epoch 0044 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.5826325757575758\n",
      "Training loss = 0.2501590729674155\n",
      "Validation accuracy = 0.75\n",
      "Validation loss = 0.1941440999507904\n",
      "Epoch 0045 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.5830555555555555\n",
      "Training loss = 0.24990575084697317\n",
      "Validation accuracy = 1.0\n",
      "Validation loss = 0.1653350591659546\n",
      "Epoch 0046 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.5841847826086957\n",
      "Training loss = 0.2494754199343531\n",
      "Validation accuracy = 0.875\n",
      "Validation loss = 0.18478184193372726\n",
      "Epoch 0047 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.5847163120567376\n",
      "Training loss = 0.24917599727393042\n",
      "Validation accuracy = 0.625\n",
      "Validation loss = 0.199919693171978\n",
      "Epoch 0048 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.5848958333333333\n",
      "Training loss = 0.2491145401686016\n",
      "Validation accuracy = 0.625\n",
      "Validation loss = 0.22001802921295166\n",
      "Epoch 0049 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.5857312925170068\n",
      "Training loss = 0.24873265830128372\n",
      "Validation accuracy = 0.375\n",
      "Validation loss = 0.21966250240802765\n",
      "Epoch 0050 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.5863666666666667\n",
      "Training loss = 0.24848094554444153\n",
      "Validation accuracy = 0.25\n",
      "Validation loss = 0.2715618312358856\n",
      "Epoch 0051 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.586781045751634\n",
      "Training loss = 0.24832240197344932\n",
      "Validation accuracy = 1.0\n",
      "Validation loss = 0.179717019200325\n",
      "Epoch 0052 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.587275641025641\n",
      "Training loss = 0.24804226523599562\n",
      "Validation accuracy = 1.0\n",
      "Validation loss = 0.1660396009683609\n",
      "Epoch 0053 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.5875314465408805\n",
      "Training loss = 0.24783107832449036\n",
      "Validation accuracy = 0.25\n",
      "Validation loss = 0.27064329385757446\n",
      "Epoch 0054 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.5883487654320988\n",
      "Training loss = 0.24748936818981612\n",
      "Validation accuracy = 1.0\n",
      "Validation loss = 0.13863155990839005\n",
      "Epoch 0055 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.5887727272727272\n",
      "Training loss = 0.2471477359686837\n",
      "Validation accuracy = 1.0\n",
      "Validation loss = 0.15866811573505402\n",
      "Epoch 0056 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.5892708333333333\n",
      "Training loss = 0.24687236347102692\n",
      "Validation accuracy = 1.0\n",
      "Validation loss = 0.1325768530368805\n",
      "Epoch 0057 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.5894444444444444\n",
      "Training loss = 0.2467221599220358\n",
      "Validation accuracy = 0.625\n",
      "Validation loss = 0.2150498554110527\n",
      "Epoch 0058 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.5902155172413793\n",
      "Training loss = 0.24649526942135958\n",
      "Validation accuracy = 0.0\n",
      "Validation loss = 0.3386196047067642\n",
      "Epoch 0059 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.5908050847457628\n",
      "Training loss = 0.24612689241472274\n",
      "Validation accuracy = 1.0\n",
      "Validation loss = 0.1057242825627327\n",
      "Epoch 0060 / 0200\n",
      "=====================================\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training accuracy = 0.5917222222222223\n",
      "Training loss = 0.24578978364086812\n",
      "Validation accuracy = 1.0\n",
      "Validation loss = 0.13264299929141998\n",
      "Epoch 0061 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.5922677595628415\n",
      "Training loss = 0.24541295678197034\n",
      "Validation accuracy = 0.125\n",
      "Validation loss = 0.30403707921504974\n",
      "Epoch 0062 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.5927016129032258\n",
      "Training loss = 0.24515222312822457\n",
      "Validation accuracy = 1.0\n",
      "Validation loss = 0.10423372685909271\n",
      "Epoch 0063 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.5932539682539683\n",
      "Training loss = 0.2448777084218131\n",
      "Validation accuracy = 1.0\n",
      "Validation loss = 0.1745924949645996\n",
      "Epoch 0064 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.5936328125\n",
      "Training loss = 0.24470993469508054\n",
      "Validation accuracy = 0.625\n",
      "Validation loss = 0.22567074745893478\n",
      "Epoch 0065 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.5941923076923077\n",
      "Training loss = 0.24437901807671938\n",
      "Validation accuracy = 0.875\n",
      "Validation loss = 0.17904793471097946\n",
      "Epoch 0066 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.5943308080808081\n",
      "Training loss = 0.2442802996098092\n",
      "Validation accuracy = 1.0\n",
      "Validation loss = 0.15070054680109024\n",
      "Epoch 0067 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.5949378109452736\n",
      "Training loss = 0.2440344051975961\n",
      "Validation accuracy = 0.75\n",
      "Validation loss = 0.20990866422653198\n",
      "Epoch 0068 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.5952941176470589\n",
      "Training loss = 0.24391642594709992\n",
      "Validation accuracy = 1.0\n",
      "Validation loss = 0.1769312545657158\n",
      "Epoch 0069 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.5958695652173913\n",
      "Training loss = 0.2436154520587213\n",
      "Validation accuracy = 0.875\n",
      "Validation loss = 0.18158306926488876\n",
      "Epoch 0070 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.5962261904761905\n",
      "Training loss = 0.24346988887055998\n",
      "Validation accuracy = 0.75\n",
      "Validation loss = 0.2238364815711975\n",
      "Epoch 0071 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.596830985915493\n",
      "Training loss = 0.24322920348232901\n",
      "Validation accuracy = 1.0\n",
      "Validation loss = 0.12060398608446121\n",
      "Epoch 0072 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.5977083333333333\n",
      "Training loss = 0.24286496592444126\n",
      "Validation accuracy = 0.5\n",
      "Validation loss = 0.24877482652664185\n",
      "Epoch 0073 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.5983333333333334\n",
      "Training loss = 0.24262306137546286\n",
      "Validation accuracy = 0.375\n",
      "Validation loss = 0.23606936633586884\n",
      "Epoch 0074 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.5989414414414415\n",
      "Training loss = 0.24244134626980568\n",
      "Validation accuracy = 1.0\n",
      "Validation loss = 0.19113685190677643\n",
      "Epoch 0075 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.5994666666666667\n",
      "Training loss = 0.24218376812140147\n",
      "Validation accuracy = 1.0\n",
      "Validation loss = 0.18135449290275574\n",
      "Epoch 0076 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.5998793859649123\n",
      "Training loss = 0.24203881775208733\n",
      "Validation accuracy = 1.0\n",
      "Validation loss = 0.17811479419469833\n",
      "Epoch 0077 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.6001515151515151\n",
      "Training loss = 0.2420212346783061\n",
      "Validation accuracy = 0.25\n",
      "Validation loss = 0.24405282735824585\n",
      "Epoch 0078 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.6006623931623931\n",
      "Training loss = 0.24170675395709326\n",
      "Validation accuracy = 1.0\n",
      "Validation loss = 0.17423167824745178\n",
      "Epoch 0079 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.6014662447257384\n",
      "Training loss = 0.2413557426691181\n",
      "Validation accuracy = 0.375\n",
      "Validation loss = 0.2335323989391327\n",
      "Epoch 0080 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.6017395833333333\n",
      "Training loss = 0.2411021158689012\n",
      "Validation accuracy = 1.0\n",
      "Validation loss = 0.13461384922266006\n",
      "Epoch 0081 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.6021296296296297\n",
      "Training loss = 0.24091024325861607\n",
      "Validation accuracy = 1.0\n",
      "Validation loss = 0.1521204560995102\n",
      "Epoch 0082 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.6029776422764228\n",
      "Training loss = 0.2406602200408413\n",
      "Validation accuracy = 1.0\n",
      "Validation loss = 0.08259468898177147\n",
      "Epoch 0083 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.6034236947791165\n",
      "Training loss = 0.24040597778277464\n",
      "Validation accuracy = 0.75\n",
      "Validation loss = 0.20407652854919434\n",
      "Epoch 0084 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.60375\n",
      "Training loss = 0.24021613182736531\n",
      "Validation accuracy = 0.25\n",
      "Validation loss = 0.24487458914518356\n",
      "Epoch 0085 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.6039313725490196\n",
      "Training loss = 0.24012677564077517\n",
      "Validation accuracy = 1.0\n",
      "Validation loss = 0.18755926936864853\n",
      "Epoch 0086 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.6042829457364342\n",
      "Training loss = 0.23990097546877787\n",
      "Validation accuracy = 1.0\n",
      "Validation loss = 0.08462987467646599\n",
      "Epoch 0087 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.6045402298850575\n",
      "Training loss = 0.23974119391477886\n",
      "Validation accuracy = 1.0\n",
      "Validation loss = 0.06946621835231781\n",
      "Epoch 0088 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.6051704545454546\n",
      "Training loss = 0.23954276373384126\n",
      "Validation accuracy = 1.0\n",
      "Validation loss = 0.17583897709846497\n",
      "Epoch 0089 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.6058052434456929\n",
      "Training loss = 0.23931792926392081\n",
      "Validation accuracy = 0.875\n",
      "Validation loss = 0.19482959806919098\n",
      "Epoch 0090 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.6062685185185185\n",
      "Training loss = 0.23918543091085223\n",
      "Validation accuracy = 1.0\n",
      "Validation loss = 0.1293945275247097\n",
      "Epoch 0091 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.6068498168498169\n",
      "Training loss = 0.23890510547155644\n",
      "Validation accuracy = 0.75\n",
      "Validation loss = 0.18865333497524261\n",
      "Epoch 0092 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.6070108695652174\n",
      "Training loss = 0.23877415229552898\n",
      "Validation accuracy = 0.25\n",
      "Validation loss = 0.2660125195980072\n",
      "Epoch 0093 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.6072670250896057\n",
      "Training loss = 0.23865048521388602\n",
      "Validation accuracy = 1.0\n",
      "Validation loss = 0.1442958265542984\n",
      "Epoch 0094 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.607677304964539\n",
      "Training loss = 0.23845128575828692\n",
      "Validation accuracy = 1.0\n",
      "Validation loss = 0.1626790165901184\n",
      "Epoch 0095 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.6082631578947368\n",
      "Training loss = 0.23820312609745745\n",
      "Validation accuracy = 1.0\n",
      "Validation loss = 0.1679525151848793\n",
      "Epoch 0096 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.6085590277777778\n",
      "Training loss = 0.23811421734565455\n",
      "Validation accuracy = 1.0\n",
      "Validation loss = 0.1567496657371521\n",
      "Epoch 0097 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.608848797250859\n",
      "Training loss = 0.23797701555198617\n",
      "Validation accuracy = 0.875\n",
      "Validation loss = 0.17120349407196045\n",
      "Epoch 0098 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.6092176870748299\n",
      "Training loss = 0.23779143695117666\n",
      "Validation accuracy = 0.875\n",
      "Validation loss = 0.18441327661275864\n",
      "Epoch 0099 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.6092087542087542\n",
      "Training loss = 0.2377149341892614\n",
      "Validation accuracy = 1.0\n",
      "Validation loss = 0.1766357123851776\n",
      "Epoch 0100 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.60965\n",
      "Training loss = 0.23753498883917928\n",
      "Validation accuracy = 0.75\n",
      "Validation loss = 0.21009857952594757\n",
      "Epoch 0101 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.6104042904290429\n",
      "Training loss = 0.23717649697052567\n",
      "Validation accuracy = 0.75\n",
      "Validation loss = 0.21139569580554962\n",
      "Epoch 0102 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.6107761437908497\n",
      "Training loss = 0.23698608462887458\n",
      "Validation accuracy = 0.75\n",
      "Validation loss = 0.20787549763917923\n",
      "Epoch 0103 / 0200\n",
      "=====================================\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training accuracy = 0.6111569579288025\n",
      "Training loss = 0.23680038772065276\n",
      "Validation accuracy = 1.0\n",
      "Validation loss = 0.17008710652589798\n",
      "Epoch 0104 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.6113701923076923\n",
      "Training loss = 0.23667728258631168\n",
      "Validation accuracy = 0.5\n",
      "Validation loss = 0.2311459630727768\n",
      "Epoch 0105 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.6117857142857143\n",
      "Training loss = 0.23645255582483987\n",
      "Validation accuracy = 0.125\n",
      "Validation loss = 0.2512509152293205\n",
      "Epoch 0106 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.6119575471698113\n",
      "Training loss = 0.23633195882253114\n",
      "Validation accuracy = 0.625\n",
      "Validation loss = 0.2136440947651863\n",
      "Epoch 0107 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.6124221183800623\n",
      "Training loss = 0.23613496750871713\n",
      "Validation accuracy = 0.5\n",
      "Validation loss = 0.20226410776376724\n",
      "Epoch 0108 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.6127700617283951\n",
      "Training loss = 0.2359752658283177\n",
      "Validation accuracy = 1.0\n",
      "Validation loss = 0.11929744854569435\n",
      "Epoch 0109 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.6131727828746177\n",
      "Training loss = 0.2357741929853865\n",
      "Validation accuracy = 1.0\n",
      "Validation loss = 0.09839189052581787\n",
      "Epoch 0110 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.6133712121212122\n",
      "Training loss = 0.23569514147880855\n",
      "Validation accuracy = 0.875\n",
      "Validation loss = 0.1928151547908783\n",
      "Epoch 0111 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.6138138138138138\n",
      "Training loss = 0.2355645218432263\n",
      "Validation accuracy = 0.625\n",
      "Validation loss = 0.21869754791259766\n",
      "Epoch 0112 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.6140550595238096\n",
      "Training loss = 0.23541653653684383\n",
      "Validation accuracy = 0.0\n",
      "Validation loss = 0.39229172468185425\n",
      "Epoch 0113 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.6142330383480826\n",
      "Training loss = 0.23532535724550663\n",
      "Validation accuracy = 0.0\n",
      "Validation loss = 0.30027636885643005\n",
      "Epoch 0114 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.6146418128654971\n",
      "Training loss = 0.23520013324121197\n",
      "Validation accuracy = 0.5\n",
      "Validation loss = 0.22235659509897232\n",
      "Epoch 0115 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.615108695652174\n",
      "Training loss = 0.23499402557885732\n",
      "Validation accuracy = 0.625\n",
      "Validation loss = 0.19866255670785904\n",
      "Epoch 0116 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.6155962643678161\n",
      "Training loss = 0.23480019101369912\n",
      "Validation accuracy = 0.0\n",
      "Validation loss = 0.3071550279855728\n",
      "Epoch 0117 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.6160256410256411\n",
      "Training loss = 0.23460040293750684\n",
      "Validation accuracy = 1.0\n",
      "Validation loss = 0.1510893926024437\n",
      "Epoch 0118 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.6165112994350282\n",
      "Training loss = 0.23441961751892995\n",
      "Validation accuracy = 1.0\n",
      "Validation loss = 0.1289721168577671\n",
      "Epoch 0119 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.6167156862745098\n",
      "Training loss = 0.23429712195867666\n",
      "Validation accuracy = 1.0\n",
      "Validation loss = 0.06494814157485962\n",
      "Epoch 0120 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.6170555555555556\n",
      "Training loss = 0.23410229276834676\n",
      "Validation accuracy = 1.0\n",
      "Validation loss = 0.14749149978160858\n",
      "Epoch 0121 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.6175275482093664\n",
      "Training loss = 0.23392448583838452\n",
      "Validation accuracy = 1.0\n",
      "Validation loss = 0.09487288072705269\n",
      "Epoch 0122 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.6178483606557377\n",
      "Training loss = 0.23375617408046062\n",
      "Validation accuracy = 0.875\n",
      "Validation loss = 0.21006011962890625\n",
      "Epoch 0123 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.6180623306233062\n",
      "Training loss = 0.23358999510131634\n",
      "Validation accuracy = 0.375\n",
      "Validation loss = 0.2387455701828003\n",
      "Epoch 0124 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.6184072580645161\n",
      "Training loss = 0.23337710433940012\n",
      "Validation accuracy = 1.0\n",
      "Validation loss = 0.14918135106563568\n",
      "Epoch 0125 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.6187666666666667\n",
      "Training loss = 0.23316719134579103\n",
      "Validation accuracy = 1.0\n",
      "Validation loss = 0.13987424224615097\n",
      "Epoch 0126 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.6189550264550264\n",
      "Training loss = 0.23305720330634838\n",
      "Validation accuracy = 1.0\n",
      "Validation loss = 0.1859012246131897\n",
      "Epoch 0127 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.6192060367454069\n",
      "Training loss = 0.23292441176842127\n",
      "Validation accuracy = 1.0\n",
      "Validation loss = 0.19405734539031982\n",
      "Epoch 0128 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.6193815104166667\n",
      "Training loss = 0.23284354210433472\n",
      "Validation accuracy = 1.0\n",
      "Validation loss = 0.13106438145041466\n",
      "Epoch 0129 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.6195348837209302\n",
      "Training loss = 0.23270767469055353\n",
      "Validation accuracy = 0.5\n",
      "Validation loss = 0.23264671117067337\n",
      "Epoch 0130 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.6195641025641025\n",
      "Training loss = 0.23258937271713065\n",
      "Validation accuracy = 1.0\n",
      "Validation loss = 0.13833129405975342\n",
      "Epoch 0131 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.6197837150127227\n",
      "Training loss = 0.23249004071763227\n",
      "Validation accuracy = 0.5\n",
      "Validation loss = 0.2686730772256851\n",
      "Epoch 0132 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.6199368686868687\n",
      "Training loss = 0.23238954676117635\n",
      "Validation accuracy = 1.0\n",
      "Validation loss = 0.1523958146572113\n",
      "Epoch 0133 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.6201566416040101\n",
      "Training loss = 0.23229247659696897\n",
      "Validation accuracy = 0.375\n",
      "Validation loss = 0.24387452006340027\n",
      "Epoch 0134 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.6204726368159204\n",
      "Training loss = 0.23215106979614838\n",
      "Validation accuracy = 1.0\n",
      "Validation loss = 0.1624346598982811\n",
      "Epoch 0135 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.6206111111111111\n",
      "Training loss = 0.23207340589450834\n",
      "Validation accuracy = 0.75\n",
      "Validation loss = 0.19941304624080658\n",
      "Epoch 0136 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.6210110294117647\n",
      "Training loss = 0.23188954212291935\n",
      "Validation accuracy = 1.0\n",
      "Validation loss = 0.12489448860287666\n",
      "Epoch 0137 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.621161800486618\n",
      "Training loss = 0.2317751832055313\n",
      "Validation accuracy = 0.375\n",
      "Validation loss = 0.23634175956249237\n",
      "Epoch 0138 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.6213285024154589\n",
      "Training loss = 0.2317292985756508\n",
      "Validation accuracy = 1.0\n",
      "Validation loss = 0.13767004013061523\n",
      "Epoch 0139 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.6213249400479617\n",
      "Training loss = 0.2316990511522269\n",
      "Validation accuracy = 0.375\n",
      "Validation loss = 0.22118617594242096\n",
      "Epoch 0140 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.6214880952380952\n",
      "Training loss = 0.23159155962252545\n",
      "Validation accuracy = 1.0\n",
      "Validation loss = 0.15966659784317017\n",
      "Epoch 0141 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.6217316784869976\n",
      "Training loss = 0.23145881195642917\n",
      "Validation accuracy = 0.375\n",
      "Validation loss = 0.2257692888379097\n",
      "Epoch 0142 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.6219776995305164\n",
      "Training loss = 0.23138498363859006\n",
      "Validation accuracy = 0.5\n",
      "Validation loss = 0.24184687435626984\n",
      "Epoch 0143 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.6222668997668998\n",
      "Training loss = 0.23123114820500285\n",
      "Validation accuracy = 0.875\n",
      "Validation loss = 0.17857123166322708\n",
      "Epoch 0144 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.6225752314814815\n",
      "Training loss = 0.23109341722766488\n",
      "Validation accuracy = 0.875\n",
      "Validation loss = 0.16321074217557907\n",
      "Epoch 0145 / 0200\n",
      "=====================================\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training accuracy = 0.6228563218390805\n",
      "Training loss = 0.23096865550043255\n",
      "Validation accuracy = 0.0\n",
      "Validation loss = 0.3005113750696182\n",
      "Epoch 0146 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.6232248858447489\n",
      "Training loss = 0.23081598108846985\n",
      "Validation accuracy = 0.375\n",
      "Validation loss = 0.24941978603601456\n",
      "Epoch 0147 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.6233106575963718\n",
      "Training loss = 0.23080047109601448\n",
      "Validation accuracy = 1.0\n",
      "Validation loss = 0.1336974799633026\n",
      "Epoch 0148 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.6235698198198198\n",
      "Training loss = 0.23069140903047614\n",
      "Validation accuracy = 0.875\n",
      "Validation loss = 0.18657147884368896\n",
      "Epoch 0149 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.6239261744966443\n",
      "Training loss = 0.23056506820423092\n",
      "Validation accuracy = 1.0\n",
      "Validation loss = 0.13591322302818298\n",
      "Epoch 0150 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.6241555555555556\n",
      "Training loss = 0.23043169836319155\n",
      "Validation accuracy = 0.25\n",
      "Validation loss = 0.25914160907268524\n",
      "Epoch 0151 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.6244646799116997\n",
      "Training loss = 0.23028768675414144\n",
      "Validation accuracy = 0.125\n",
      "Validation loss = 0.26149074733257294\n",
      "Epoch 0152 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.6246765350877193\n",
      "Training loss = 0.23017069293872305\n",
      "Validation accuracy = 0.375\n",
      "Validation loss = 0.2259853556752205\n",
      "Epoch 0153 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.6249400871459695\n",
      "Training loss = 0.23003589894857931\n",
      "Validation accuracy = 1.0\n",
      "Validation loss = 0.12961288914084435\n",
      "Epoch 0154 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.6251461038961039\n",
      "Training loss = 0.22996129250210343\n",
      "Validation accuracy = 1.0\n",
      "Validation loss = 0.15389429032802582\n",
      "Epoch 0155 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.6254569892473119\n",
      "Training loss = 0.22985029655598824\n",
      "Validation accuracy = 1.0\n",
      "Validation loss = 0.17158271372318268\n",
      "Epoch 0156 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.6256997863247863\n",
      "Training loss = 0.22977598521747014\n",
      "Validation accuracy = 0.375\n",
      "Validation loss = 0.25090790539979935\n",
      "Epoch 0157 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.6259872611464968\n",
      "Training loss = 0.22962075311809207\n",
      "Validation accuracy = 1.0\n",
      "Validation loss = 0.14039462804794312\n",
      "Epoch 0158 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.6263291139240507\n",
      "Training loss = 0.2294748762202791\n",
      "Validation accuracy = 0.875\n",
      "Validation loss = 0.21988384425640106\n",
      "Epoch 0159 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.6265566037735849\n",
      "Training loss = 0.22936234157352828\n",
      "Validation accuracy = 0.5\n",
      "Validation loss = 0.24266347289085388\n",
      "Epoch 0160 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.6267604166666667\n",
      "Training loss = 0.2292456672891664\n",
      "Validation accuracy = 1.0\n",
      "Validation loss = 0.17257772386074066\n",
      "Epoch 0161 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.626899585921325\n",
      "Training loss = 0.22918860811701597\n",
      "Validation accuracy = 0.5\n",
      "Validation loss = 0.21732089668512344\n",
      "Epoch 0162 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.627119341563786\n",
      "Training loss = 0.22908336609341357\n",
      "Validation accuracy = 1.0\n",
      "Validation loss = 0.13889998197555542\n",
      "Epoch 0163 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.6274233128834356\n",
      "Training loss = 0.22894149316311005\n",
      "Validation accuracy = 0.875\n",
      "Validation loss = 0.20572791248559952\n",
      "Epoch 0164 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.6274390243902439\n",
      "Training loss = 0.22890452502037936\n",
      "Validation accuracy = 0.5\n",
      "Validation loss = 0.23619753122329712\n",
      "Epoch 0165 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.6275454545454545\n",
      "Training loss = 0.22884466312058044\n",
      "Validation accuracy = 0.875\n",
      "Validation loss = 0.21462362259626389\n",
      "Epoch 0166 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.6278915662650603\n",
      "Training loss = 0.22866678075812547\n",
      "Validation accuracy = 0.625\n",
      "Validation loss = 0.194755420088768\n",
      "Epoch 0167 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.6281487025948104\n",
      "Training loss = 0.22856327144953306\n",
      "Validation accuracy = 0.625\n",
      "Validation loss = 0.21778414398431778\n",
      "Epoch 0168 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.6283779761904762\n",
      "Training loss = 0.22842031202042504\n",
      "Validation accuracy = 1.0\n",
      "Validation loss = 0.1329779215157032\n",
      "Epoch 0169 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.6287228796844182\n",
      "Training loss = 0.22826778209259407\n",
      "Validation accuracy = 1.0\n",
      "Validation loss = 0.15637529641389847\n",
      "Epoch 0170 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.628906862745098\n",
      "Training loss = 0.22817486188020192\n",
      "Validation accuracy = 0.625\n",
      "Validation loss = 0.21905824542045593\n",
      "Epoch 0171 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.6290789473684211\n",
      "Training loss = 0.2280685917623559\n",
      "Validation accuracy = 0.0\n",
      "Validation loss = 0.28053297102451324\n",
      "Epoch 0172 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.6292587209302326\n",
      "Training loss = 0.2279714099756738\n",
      "Validation accuracy = 1.0\n",
      "Validation loss = 0.12596217170357704\n",
      "Epoch 0173 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.6296098265895954\n",
      "Training loss = 0.22780784426152936\n",
      "Validation accuracy = 0.5\n",
      "Validation loss = 0.21019254624843597\n",
      "Epoch 0174 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.6298515325670498\n",
      "Training loss = 0.2276706255734024\n",
      "Validation accuracy = 0.25\n",
      "Validation loss = 0.22377897053956985\n",
      "Epoch 0175 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.6300380952380953\n",
      "Training loss = 0.22758868424778894\n",
      "Validation accuracy = 0.5\n",
      "Validation loss = 0.20857713371515274\n",
      "Epoch 0176 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.6302556818181818\n",
      "Training loss = 0.22746976324025486\n",
      "Validation accuracy = 0.875\n",
      "Validation loss = 0.1980774998664856\n",
      "Epoch 0177 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.6305414312617702\n",
      "Training loss = 0.22737100539942975\n",
      "Validation accuracy = 0.75\n",
      "Validation loss = 0.18952403217554092\n",
      "Epoch 0178 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.6307397003745319\n",
      "Training loss = 0.22728882802859618\n",
      "Validation accuracy = 0.125\n",
      "Validation loss = 0.27730177342891693\n",
      "Epoch 0179 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.6309217877094973\n",
      "Training loss = 0.227181290101808\n",
      "Validation accuracy = 0.25\n",
      "Validation loss = 0.23688650131225586\n",
      "Epoch 0180 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.6312222222222222\n",
      "Training loss = 0.22704961877806043\n",
      "Validation accuracy = 1.0\n",
      "Validation loss = 0.09914734587073326\n",
      "Epoch 0181 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.6314502762430939\n",
      "Training loss = 0.22695804278035245\n",
      "Validation accuracy = 1.0\n",
      "Validation loss = 0.16672905534505844\n",
      "Epoch 0182 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.6315979853479854\n",
      "Training loss = 0.22688903971940225\n",
      "Validation accuracy = 1.0\n",
      "Validation loss = 0.18892157822847366\n",
      "Epoch 0183 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.6317577413479053\n",
      "Training loss = 0.22680849961576838\n",
      "Validation accuracy = 0.5\n",
      "Validation loss = 0.2094874158501625\n",
      "Epoch 0184 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.6319655797101449\n",
      "Training loss = 0.22669265821866313\n",
      "Validation accuracy = 0.25\n",
      "Validation loss = 0.2538246363401413\n",
      "Epoch 0185 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.6321171171171172\n",
      "Training loss = 0.2266079303283278\n",
      "Validation accuracy = 0.875\n",
      "Validation loss = 0.16427428275346756\n",
      "Epoch 0186 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.6322983870967742\n",
      "Training loss = 0.22648613887695482\n",
      "Validation accuracy = 1.0\n",
      "Validation loss = 0.15093345195055008\n",
      "Epoch 0187 / 0200\n",
      "=====================================\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training accuracy = 0.6325\n",
      "Training loss = 0.22635617868851957\n",
      "Validation accuracy = 0.0\n",
      "Validation loss = 0.42123010754585266\n",
      "Epoch 0188 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.6326418439716313\n",
      "Training loss = 0.22628845314620763\n",
      "Validation accuracy = 0.5\n",
      "Validation loss = 0.2243156060576439\n",
      "Epoch 0189 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.6328439153439154\n",
      "Training loss = 0.22617498020790977\n",
      "Validation accuracy = 1.0\n",
      "Validation loss = 0.17968953400850296\n",
      "Epoch 0190 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.6329736842105264\n",
      "Training loss = 0.2260747196203784\n",
      "Validation accuracy = 0.5\n",
      "Validation loss = 0.2145598903298378\n",
      "Epoch 0191 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.6332068062827225\n",
      "Training loss = 0.2259689008257308\n",
      "Validation accuracy = 0.5\n",
      "Validation loss = 0.22273136675357819\n",
      "Epoch 0192 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.6333333333333333\n",
      "Training loss = 0.22588847938756873\n",
      "Validation accuracy = 1.0\n",
      "Validation loss = 0.07005386054515839\n",
      "Epoch 0193 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.6334758203799654\n",
      "Training loss = 0.2258018695426677\n",
      "Validation accuracy = 0.625\n",
      "Validation loss = 0.20095724612474442\n",
      "Epoch 0194 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.6336383161512027\n",
      "Training loss = 0.22567135060481291\n",
      "Validation accuracy = 0.875\n",
      "Validation loss = 0.18152689188718796\n",
      "Epoch 0195 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.6338376068376068\n",
      "Training loss = 0.2255705016080895\n",
      "Validation accuracy = 1.0\n",
      "Validation loss = 0.16965998709201813\n",
      "Epoch 0196 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.6340348639455783\n",
      "Training loss = 0.22545272789502732\n",
      "Validation accuracy = 1.0\n",
      "Validation loss = 0.12184393033385277\n",
      "Epoch 0197 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.6342597292724196\n",
      "Training loss = 0.22538583922229846\n",
      "Validation accuracy = 0.375\n",
      "Validation loss = 0.22417432069778442\n",
      "Epoch 0198 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.634436026936027\n",
      "Training loss = 0.22528443250554278\n",
      "Validation accuracy = 0.375\n",
      "Validation loss = 0.21883540600538254\n",
      "Epoch 0199 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.6347110552763819\n",
      "Training loss = 0.22520682017208143\n",
      "Validation accuracy = 1.0\n",
      "Validation loss = 0.16483180969953537\n",
      "Epoch 0200 / 0200\n",
      "=====================================\n",
      "Training accuracy = 0.6348291666666667\n",
      "Training loss = 0.22511954438152412\n",
      "Validation accuracy = 0.375\n",
      "Validation loss = 0.24049295485019684\n"
     ]
    }
   ],
   "source": [
    "from sklearn import preprocessing\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "import os.path\n",
    "\n",
    "version = 'v12'\n",
    "model_path = './models/' + version + '/'\n",
    "visual_path = './visual/' + version + '/'\n",
    "\n",
    "make_folder_structure()\n",
    "\n",
    "temp_session_list = session_list\n",
    "nb_classes = 4\n",
    "batch_size = 4\n",
    "while len(temp_session_list)>0:\n",
    "    #print(len(session_list))\n",
    "    sess_labels = label_sessions(temp_session_list)\n",
    "\n",
    "    df_session_list = pd.DataFrame(temp_session_list)\n",
    "    df_session_list.index = sess_labels\n",
    "\n",
    "    test_list = []\n",
    "    for sl in set(sess_labels):\n",
    "        try:\n",
    "            test_list.extend(df_session_list.loc[df_session_list.index == sl].sort_values(by=[0]).iloc[0].values.tolist())\n",
    "        except: continue\n",
    "    test_list.sort()\n",
    "    filename = test_list[0].split(\"-\")[0] + \"-\" + test_list[-1].split(\"-\")[0]\n",
    "    PATH = model_path+ filename +'.pth'\n",
    "    write_test_list(filename,test_list)\n",
    "    print(\"Making model for session group \" + test_list[0].split(\"-\")[0] + \"-\" + test_list[-1].split(\"-\")[0])\n",
    "    if os.path.exists(PATH): print(\"    Model already exists.\")\n",
    "        \n",
    "    train_list = list(set(session_list) - set(test_list))#[x for x in session_list if x != test_list]\n",
    "    #print(len(train_list))\n",
    "    temp_session_list = list(set(temp_session_list) - set(test_list))#[x for x in temp_session_list if x != test_list]\n",
    "    if not os.path.exists(PATH): #Do this only if the model is not properly saved\n",
    "        test_data = pd.DataFrame()\n",
    "        train_data = pd.DataFrame()\n",
    "\n",
    "        #test_list.extend(df_session_list.loc[df_session_list.index == sl].sample(1).values.tolist()[0])\n",
    "        count = 0\n",
    "        for ts in test_list:\n",
    "            #print(\"|\" + \"*\"*(count+1) + ' '*(len(train_list)-1-count)+ \"| \" +str(format((count+1)/len(train_list)*100,'.3f')) + \"% is complete...\" ,end=\"\\r\")\n",
    "            try:\n",
    "                tr = read_data(dates, ts)\n",
    "                test_data = pd.concat([test_data,tr],axis=0,ignore_index=False)\n",
    "                count = count+1\n",
    "\n",
    "                test_data.dropna(inplace=True, axis=0)\n",
    "            except: continue\n",
    "            #test_data = one_class_svm(test_data)\n",
    "            #test_data = pd.concat(diff_calc(test_data.iloc[:,0:94]))\n",
    "\n",
    "        #break\n",
    "        train_data = pd.DataFrame()\n",
    "        #count = 0\n",
    "        for ts in train_list:\n",
    "            #print(\"|\" + \"*\"*(count+1) + ' '*(len(train_list)-1-count)+ \"| \" +str(format((count+1)/len(train_list)*100,'.3f')) + \"% is complete...\" ,end=\"\\r\")\n",
    "            #tr = pd.read_csv(\"processed/\" + \"spectrum/\" + date + \"/right/\" + ts, index_col=False, header=None)\n",
    "        #         tr_feature1 = pd.read_csv(\"processed/\" + \"spectrum/\" + date + \"/right/\" + ts, index_col=False, header=None)\n",
    "        #         tr_feature2 = pd.read_csv(\"processed/\" + \"spectrum/\" + date + \"/left/\" + ts, index_col=False, header=None)\n",
    "        #         tr_feature3 =pd.read_csv(\"processed/\" + \"mfcc/\" + date + \"/right/\" + ts, index_col=False, header=None)\n",
    "        #         tr_feature4 = pd.read_csv(\"processed/\" + \"mfcc/\" + date + \"/left/\" + ts, index_col=False, header=None)\n",
    "        #         tr = pd.concat([tr_feature1,tr_feature2,tr_feature3,tr_feature4],axis=1)\n",
    "        #         tr = label_data(ts,tr)\n",
    "            try: #This is necessary as the session_list may differ from actual feature files stored\n",
    "                tr = read_data(dates, ts)\n",
    "                train_data = pd.concat([train_data,tr],axis=0,ignore_index=False)\n",
    "            except: continue\n",
    "        count = count+1\n",
    "        \n",
    "        #break\n",
    "        #print(np.unique(train_data.index, return_counts=True))\n",
    "        #train_data = random_undersampling(train_data)\n",
    "        #print(np.unique(train_data.index, return_counts=True))\n",
    "        train_data.dropna(inplace=True, axis=0)\n",
    "        test_feat = test_data#extract_mfcc_feat(test_data)\n",
    "        train_feat = train_data#extract_mfcc_feat(train_data)\n",
    "        test_feat.dropna(axis=0,inplace=True)\n",
    "        train_feat.dropna(axis=0,inplace=True)\n",
    "        X_train, y_train = make_data(train_feat)\n",
    "        X_test, y_test = make_data(test_feat)\n",
    "        \n",
    "        #Smote oversampling\n",
    "        X_train,y_train = SMOTE_oversampling(X_train,y_train)\n",
    "\n",
    "        #def prep_data(X_train, y_train, X_test, y_test):\n",
    "        label_encoder = preprocessing.LabelEncoder()\n",
    "        training_targets = label_encoder.fit_transform(y_train)\n",
    "\n",
    "        #Read testing data\n",
    "        #testing_timestamps,testing_labels,testing_data = read_test_data(test_list)\n",
    "\n",
    "        #Encode\n",
    "        testing_targets = label_encoder.transform(y_test)\n",
    "\n",
    "        #Make training dataloader\n",
    "        train_dataloader = make_train_dataloader(training_targets, X_train)\n",
    "\n",
    "        #Make test dataloader\n",
    "        test_dataloader = make_test_dataloader(testing_targets, X_test)\n",
    "\n",
    "        #return train_dataloader, test_dataloader\n",
    "\n",
    "        \n",
    "        model,val_accuracies,val_losses,train_accuracies,train_losses = train_nn_model()\n",
    "        #break\n",
    "\n",
    "        torch.save(model.state_dict(), PATH)\n",
    "\n",
    "        plt.ylabel(\"accuracy\")\n",
    "        plt.xlabel(\"epoch\")\n",
    "        plt.plot(train_accuracies, label=\"train\")\n",
    "        plt.plot(val_accuracies, label=\"test\")\n",
    "        plt.legend()\n",
    "        plt.savefig(visual_path+ \"accuracy_\"+ filename + \".png\")\n",
    "        plt.close()\n",
    "\n",
    "        plt.ylabel(\"loss\")\n",
    "        plt.xlabel(\"epoch\")\n",
    "        plt.plot(train_losses, label=\"train\")\n",
    "        plt.plot(val_losses, label=\"test\")\n",
    "        plt.legend()\n",
    "        plt.savefig(visual_path+ \"loss_\"+ filename + \".png\")\n",
    "        plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x7f8a21fa30f0>"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.ylabel(\"accuracy\")\n",
    "plt.xlabel(\"epoch\")\n",
    "plt.plot(train_accuracies, label=\"train\")\n",
    "plt.plot(val_accuracies, label=\"test\")\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x7f8a10344dd8>"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.ylabel(\"loss\")\n",
    "plt.xlabel(\"epoch\")\n",
    "plt.plot(train_losses, label=\"train\")\n",
    "plt.plot(val_losses, label=\"test\")\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "631"
      ]
     },
     "execution_count": 144,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "def majority_vote(y_pred):\n",
    "    #print(y_pred)\n",
    "#     delete_list = []\n",
    "#     c = 0\n",
    "#     for p in prob:\n",
    "#         if p.max() < 0.5:\n",
    "#             delete_list.append(c)\n",
    "#         c = c + 1\n",
    "#     y_pred = np.delete(y_pred,delete_list)\n",
    "#     if y_pred.size > 0:\n",
    "    maj = Counter(y_pred).most_common(1)[0][0]\n",
    "#     else: return []\n",
    "    return maj "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test the saved models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "def make_model_list():\n",
    "    model_list = []\n",
    "    for file in os.listdir(model_path):\n",
    "        if file.endswith(\".txt\"):\n",
    "            model_list.append(file[:-4])\n",
    "    return model_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_test_list(model):\n",
    "    with open(model_path + model + \".txt\") as f:\n",
    "        content = f.readlines()\n",
    "    content = [x.strip() for x in content] \n",
    "    return content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Making model for session group 20210310_15:26:59.160-20210319_16:13:09.655\n",
      "tensor([[4., 0., 4., 0.],\n",
      "        [0., 5., 0., 3.],\n",
      "        [1., 0., 7., 0.],\n",
      "        [0., 0., 0., 8.]])\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         car       0.80      0.50      0.62         8\n",
      "    signpost       1.00      0.62      0.77         8\n",
      "        tree       0.64      0.88      0.74         8\n",
      "        wall       0.73      1.00      0.84         8\n",
      "\n",
      "    accuracy                           0.75        32\n",
      "   macro avg       0.79      0.75      0.74        32\n",
      "weighted avg       0.79      0.75      0.74        32\n",
      "\n",
      "Overall results...\n",
      "[[4 0 4 0]\n",
      " [0 5 0 3]\n",
      " [1 0 7 0]\n",
      " [0 0 0 8]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         car       0.80      0.50      0.62         8\n",
      "    signpost       1.00      0.62      0.77         8\n",
      "        tree       0.64      0.88      0.74         8\n",
      "        wall       0.73      1.00      0.84         8\n",
      "\n",
      "    accuracy                           0.75        32\n",
      "   macro avg       0.79      0.75      0.74        32\n",
      "weighted avg       0.79      0.75      0.74        32\n",
      "\n",
      "Making model for session group 20210310_15:25:26.159-20210319_16:08:41.692\n",
      "tensor([[6., 0., 2., 0.],\n",
      "        [0., 8., 0., 0.],\n",
      "        [0., 1., 7., 0.],\n",
      "        [0., 4., 2., 2.]])\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         car       1.00      0.75      0.86         8\n",
      "    signpost       0.62      1.00      0.76         8\n",
      "        tree       0.64      0.88      0.74         8\n",
      "        wall       1.00      0.25      0.40         8\n",
      "\n",
      "    accuracy                           0.72        32\n",
      "   macro avg       0.81      0.72      0.69        32\n",
      "weighted avg       0.81      0.72      0.69        32\n",
      "\n",
      "Overall results...\n",
      "[[10  0  6  0]\n",
      " [ 0 13  0  3]\n",
      " [ 1  1 14  0]\n",
      " [ 0  4  2 10]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         car       0.91      0.62      0.74        16\n",
      "    signpost       0.72      0.81      0.76        16\n",
      "        tree       0.64      0.88      0.74        16\n",
      "        wall       0.77      0.62      0.69        16\n",
      "\n",
      "    accuracy                           0.73        64\n",
      "   macro avg       0.76      0.73      0.73        64\n",
      "weighted avg       0.76      0.73      0.73        64\n",
      "\n",
      "Making model for session group 20210310_15:32:48.233-20210319_16:21:59.598\n",
      "tensor([[1., 0., 0., 7.],\n",
      "        [0., 6., 0., 2.],\n",
      "        [0., 0., 5., 3.],\n",
      "        [0., 1., 0., 7.]])\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         car       1.00      0.12      0.22         8\n",
      "    signpost       0.86      0.75      0.80         8\n",
      "        tree       1.00      0.62      0.77         8\n",
      "        wall       0.37      0.88      0.52         8\n",
      "\n",
      "    accuracy                           0.59        32\n",
      "   macro avg       0.81      0.59      0.58        32\n",
      "weighted avg       0.81      0.59      0.58        32\n",
      "\n",
      "Overall results...\n",
      "[[11  0  6  7]\n",
      " [ 0 19  0  5]\n",
      " [ 1  1 19  3]\n",
      " [ 0  5  2 17]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         car       0.92      0.46      0.61        24\n",
      "    signpost       0.76      0.79      0.78        24\n",
      "        tree       0.70      0.79      0.75        24\n",
      "        wall       0.53      0.71      0.61        24\n",
      "\n",
      "    accuracy                           0.69        96\n",
      "   macro avg       0.73      0.69      0.68        96\n",
      "weighted avg       0.73      0.69      0.68        96\n",
      "\n",
      "Making model for session group 20210310_15:30:50.167-20210319_16:17:22.477\n",
      "tensor([[5., 0., 3., 0.],\n",
      "        [0., 8., 0., 0.],\n",
      "        [2., 0., 6., 0.],\n",
      "        [2., 0., 0., 6.]])\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         car       0.56      0.62      0.59         8\n",
      "    signpost       1.00      1.00      1.00         8\n",
      "        tree       0.67      0.75      0.71         8\n",
      "        wall       1.00      0.75      0.86         8\n",
      "\n",
      "    accuracy                           0.78        32\n",
      "   macro avg       0.81      0.78      0.79        32\n",
      "weighted avg       0.81      0.78      0.79        32\n",
      "\n",
      "Overall results...\n",
      "[[16  0  9  7]\n",
      " [ 0 27  0  5]\n",
      " [ 3  1 25  3]\n",
      " [ 2  5  2 23]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         car       0.76      0.50      0.60        32\n",
      "    signpost       0.82      0.84      0.83        32\n",
      "        tree       0.69      0.78      0.74        32\n",
      "        wall       0.61      0.72      0.66        32\n",
      "\n",
      "    accuracy                           0.71       128\n",
      "   macro avg       0.72      0.71      0.71       128\n",
      "weighted avg       0.72      0.71      0.71       128\n",
      "\n",
      "Making model for session group 20210310_15:29:41.711-20210319_16:15:55.217\n",
      "tensor([[5., 0., 3., 0.],\n",
      "        [0., 0., 8., 0.],\n",
      "        [1., 0., 2., 5.],\n",
      "        [0., 1., 1., 6.]])\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         car       0.83      0.62      0.71         8\n",
      "    signpost       0.00      0.00      0.00         8\n",
      "        tree       0.14      0.25      0.18         8\n",
      "        wall       0.55      0.75      0.63         8\n",
      "\n",
      "    accuracy                           0.41        32\n",
      "   macro avg       0.38      0.41      0.38        32\n",
      "weighted avg       0.38      0.41      0.38        32\n",
      "\n",
      "Overall results...\n",
      "[[21  0 12  7]\n",
      " [ 0 27  8  5]\n",
      " [ 4  1 27  8]\n",
      " [ 2  6  3 29]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         car       0.78      0.53      0.63        40\n",
      "    signpost       0.79      0.68      0.73        40\n",
      "        tree       0.54      0.68      0.60        40\n",
      "        wall       0.59      0.72      0.65        40\n",
      "\n",
      "    accuracy                           0.65       160\n",
      "   macro avg       0.68      0.65      0.65       160\n",
      "weighted avg       0.68      0.65      0.65       160\n",
      "\n",
      "Making model for session group 20210310_15:31:57.174-20210319_16:18:28.688\n",
      "tensor([[5., 0., 0., 3.],\n",
      "        [0., 8., 0., 0.],\n",
      "        [3., 0., 5., 0.],\n",
      "        [1., 0., 0., 7.]])\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         car       0.56      0.62      0.59         8\n",
      "    signpost       1.00      1.00      1.00         8\n",
      "        tree       1.00      0.62      0.77         8\n",
      "        wall       0.70      0.88      0.78         8\n",
      "\n",
      "    accuracy                           0.78        32\n",
      "   macro avg       0.81      0.78      0.78        32\n",
      "weighted avg       0.81      0.78      0.78        32\n",
      "\n",
      "Overall results...\n",
      "[[26  0 12 10]\n",
      " [ 0 35  8  5]\n",
      " [ 7  1 32  8]\n",
      " [ 3  6  3 36]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         car       0.72      0.54      0.62        48\n",
      "    signpost       0.83      0.73      0.78        48\n",
      "        tree       0.58      0.67      0.62        48\n",
      "        wall       0.61      0.75      0.67        48\n",
      "\n",
      "    accuracy                           0.67       192\n",
      "   macro avg       0.69      0.67      0.67       192\n",
      "weighted avg       0.69      0.67      0.67       192\n",
      "\n",
      "Making model for session group 20210310_15:29:00.353-20210319_16:14:50.583\n",
      "tensor([[3., 3., 0., 2.],\n",
      "        [1., 3., 4., 0.],\n",
      "        [0., 0., 8., 0.],\n",
      "        [0., 2., 0., 6.]])\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         car       0.75      0.38      0.50         8\n",
      "    signpost       0.38      0.38      0.38         8\n",
      "        tree       0.67      1.00      0.80         8\n",
      "        wall       0.75      0.75      0.75         8\n",
      "\n",
      "    accuracy                           0.62        32\n",
      "   macro avg       0.64      0.62      0.61        32\n",
      "weighted avg       0.64      0.62      0.61        32\n",
      "\n",
      "Overall results...\n",
      "[[29  3 12 12]\n",
      " [ 1 38 12  5]\n",
      " [ 7  1 40  8]\n",
      " [ 3  8  3 42]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         car       0.72      0.52      0.60        56\n",
      "    signpost       0.76      0.68      0.72        56\n",
      "        tree       0.60      0.71      0.65        56\n",
      "        wall       0.63      0.75      0.68        56\n",
      "\n",
      "    accuracy                           0.67       224\n",
      "   macro avg       0.68      0.67      0.66       224\n",
      "weighted avg       0.68      0.67      0.66       224\n",
      "\n",
      "Making model for session group 20210310_15:31:09.318-20210319_16:17:45.271\n",
      "tensor([[6., 0., 0., 2.],\n",
      "        [0., 6., 0., 2.],\n",
      "        [5., 0., 3., 0.],\n",
      "        [3., 0., 2., 3.]])\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         car       0.43      0.75      0.55         8\n",
      "    signpost       1.00      0.75      0.86         8\n",
      "        tree       0.60      0.38      0.46         8\n",
      "        wall       0.43      0.38      0.40         8\n",
      "\n",
      "    accuracy                           0.56        32\n",
      "   macro avg       0.61      0.56      0.57        32\n",
      "weighted avg       0.61      0.56      0.57        32\n",
      "\n",
      "Overall results...\n",
      "[[35  3 12 14]\n",
      " [ 1 44 12  7]\n",
      " [12  1 43  8]\n",
      " [ 6  8  5 45]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         car       0.65      0.55      0.59        64\n",
      "    signpost       0.79      0.69      0.73        64\n",
      "        tree       0.60      0.67      0.63        64\n",
      "        wall       0.61      0.70      0.65        64\n",
      "\n",
      "    accuracy                           0.65       256\n",
      "   macro avg       0.66      0.65      0.65       256\n",
      "weighted avg       0.66      0.65      0.65       256\n",
      "\n",
      "Making model for session group 20210310_15:32:32.730-20210319_16:21:29.421\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[4., 0., 3., 1.],\n",
      "        [0., 0., 0., 8.],\n",
      "        [0., 0., 3., 5.],\n",
      "        [0., 0., 0., 8.]])\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         car       1.00      0.50      0.67         8\n",
      "    signpost       0.00      0.00      0.00         8\n",
      "        tree       0.50      0.38      0.43         8\n",
      "        wall       0.36      1.00      0.53         8\n",
      "\n",
      "    accuracy                           0.47        32\n",
      "   macro avg       0.47      0.47      0.41        32\n",
      "weighted avg       0.47      0.47      0.41        32\n",
      "\n",
      "Overall results...\n",
      "[[39  3 15 15]\n",
      " [ 1 44 12 15]\n",
      " [12  1 46 13]\n",
      " [ 6  8  5 53]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         car       0.67      0.54      0.60        72\n",
      "    signpost       0.79      0.61      0.69        72\n",
      "        tree       0.59      0.64      0.61        72\n",
      "        wall       0.55      0.74      0.63        72\n",
      "\n",
      "    accuracy                           0.63       288\n",
      "   macro avg       0.65      0.63      0.63       288\n",
      "weighted avg       0.65      0.63      0.63       288\n",
      "\n",
      "Making model for session group 20210310_15:25:48.350-20210319_16:10:10.704\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/_classification.py:1221: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[7., 0., 1., 0.],\n",
      "        [0., 8., 0., 0.],\n",
      "        [0., 1., 7., 0.],\n",
      "        [0., 8., 0., 0.]])\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         car       1.00      0.88      0.93         8\n",
      "    signpost       0.47      1.00      0.64         8\n",
      "        tree       0.88      0.88      0.88         8\n",
      "        wall       0.00      0.00      0.00         8\n",
      "\n",
      "    accuracy                           0.69        32\n",
      "   macro avg       0.59      0.69      0.61        32\n",
      "weighted avg       0.59      0.69      0.61        32\n",
      "\n",
      "Overall results...\n",
      "[[46  3 16 15]\n",
      " [ 1 52 12 15]\n",
      " [12  2 53 13]\n",
      " [ 6 16  5 53]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         car       0.71      0.57      0.63        80\n",
      "    signpost       0.71      0.65      0.68        80\n",
      "        tree       0.62      0.66      0.64        80\n",
      "        wall       0.55      0.66      0.60        80\n",
      "\n",
      "    accuracy                           0.64       320\n",
      "   macro avg       0.65      0.64      0.64       320\n",
      "weighted avg       0.65      0.64      0.64       320\n",
      "\n",
      "Making model for session group 20210310_15:33:58.721-20210319_16:23:03.444\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/_classification.py:1221: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[8., 0., 0., 0.],\n",
      "        [0., 5., 0., 3.],\n",
      "        [0., 0., 6., 2.],\n",
      "        [0., 0., 0., 8.]])\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         car       1.00      1.00      1.00         8\n",
      "    signpost       1.00      0.62      0.77         8\n",
      "        tree       1.00      0.75      0.86         8\n",
      "        wall       0.62      1.00      0.76         8\n",
      "\n",
      "    accuracy                           0.84        32\n",
      "   macro avg       0.90      0.84      0.85        32\n",
      "weighted avg       0.90      0.84      0.85        32\n",
      "\n",
      "Overall results...\n",
      "[[54  3 16 15]\n",
      " [ 1 57 12 18]\n",
      " [12  2 59 15]\n",
      " [ 6 16  5 61]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         car       0.74      0.61      0.67        88\n",
      "    signpost       0.73      0.65      0.69        88\n",
      "        tree       0.64      0.67      0.66        88\n",
      "        wall       0.56      0.69      0.62        88\n",
      "\n",
      "    accuracy                           0.66       352\n",
      "   macro avg       0.67      0.66      0.66       352\n",
      "weighted avg       0.67      0.66      0.66       352\n",
      "\n",
      "Making model for session group 20210319_16:26:51.249-20210319_16:26:51.249\n",
      "tensor([[0., 0., 0., 0.],\n",
      "        [0., 3., 0., 5.],\n",
      "        [0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0.]])\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    signpost       1.00      0.38      0.55         8\n",
      "        wall       0.00      0.00      0.00         0\n",
      "\n",
      "    accuracy                           0.38         8\n",
      "   macro avg       0.50      0.19      0.27         8\n",
      "weighted avg       1.00      0.38      0.55         8\n",
      "\n",
      "Overall results...\n",
      "[[54  3 16 15]\n",
      " [ 1 60 12 23]\n",
      " [12  2 59 15]\n",
      " [ 6 16  5 61]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         car       0.74      0.61      0.67        88\n",
      "    signpost       0.74      0.62      0.68        96\n",
      "        tree       0.64      0.67      0.66        88\n",
      "        wall       0.54      0.69      0.60        88\n",
      "\n",
      "    accuracy                           0.65       360\n",
      "   macro avg       0.66      0.65      0.65       360\n",
      "weighted avg       0.67      0.65      0.65       360\n",
      "\n",
      "Making model for session group 20210310_15:29:25.107-20210319_16:15:18.712\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/_classification.py:1221: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[5., 0., 3., 0.],\n",
      "        [0., 1., 7., 0.],\n",
      "        [0., 0., 8., 0.],\n",
      "        [0., 0., 3., 5.]])\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         car       1.00      0.62      0.77         8\n",
      "    signpost       1.00      0.12      0.22         8\n",
      "        tree       0.38      1.00      0.55         8\n",
      "        wall       1.00      0.62      0.77         8\n",
      "\n",
      "    accuracy                           0.59        32\n",
      "   macro avg       0.85      0.59      0.58        32\n",
      "weighted avg       0.85      0.59      0.58        32\n",
      "\n",
      "Overall results...\n",
      "[[59  3 19 15]\n",
      " [ 1 61 19 23]\n",
      " [12  2 67 15]\n",
      " [ 6 16  8 66]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         car       0.76      0.61      0.68        96\n",
      "    signpost       0.74      0.59      0.66       104\n",
      "        tree       0.59      0.70      0.64        96\n",
      "        wall       0.55      0.69      0.61        96\n",
      "\n",
      "    accuracy                           0.65       392\n",
      "   macro avg       0.66      0.65      0.65       392\n",
      "weighted avg       0.66      0.65      0.65       392\n",
      "\n",
      "Making model for session group 20210310_15:26:14.684-20210319_16:10:32.051\n",
      "tensor([[6., 0., 2., 0.],\n",
      "        [0., 5., 1., 2.],\n",
      "        [0., 0., 4., 4.],\n",
      "        [0., 2., 1., 5.]])\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         car       1.00      0.75      0.86         8\n",
      "    signpost       0.71      0.62      0.67         8\n",
      "        tree       0.50      0.50      0.50         8\n",
      "        wall       0.45      0.62      0.53         8\n",
      "\n",
      "    accuracy                           0.62        32\n",
      "   macro avg       0.67      0.62      0.64        32\n",
      "weighted avg       0.67      0.62      0.64        32\n",
      "\n",
      "Overall results...\n",
      "[[65  3 21 15]\n",
      " [ 1 66 20 25]\n",
      " [12  2 71 19]\n",
      " [ 6 18  9 71]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         car       0.77      0.62      0.69       104\n",
      "    signpost       0.74      0.59      0.66       112\n",
      "        tree       0.59      0.68      0.63       104\n",
      "        wall       0.55      0.68      0.61       104\n",
      "\n",
      "    accuracy                           0.64       424\n",
      "   macro avg       0.66      0.64      0.65       424\n",
      "weighted avg       0.66      0.64      0.65       424\n",
      "\n",
      "Making model for session group 20210310_15:30:21.964-20210319_16:16:47.785\n",
      "tensor([[5., 0., 3., 0.],\n",
      "        [0., 6., 0., 2.],\n",
      "        [1., 1., 0., 6.],\n",
      "        [0., 2., 0., 6.]])\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         car       0.83      0.62      0.71         8\n",
      "    signpost       0.67      0.75      0.71         8\n",
      "        tree       0.00      0.00      0.00         8\n",
      "        wall       0.43      0.75      0.55         8\n",
      "\n",
      "    accuracy                           0.53        32\n",
      "   macro avg       0.48      0.53      0.49        32\n",
      "weighted avg       0.48      0.53      0.49        32\n",
      "\n",
      "Overall results...\n",
      "[[70  3 24 15]\n",
      " [ 1 72 20 27]\n",
      " [13  3 71 25]\n",
      " [ 6 20  9 77]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         car       0.78      0.62      0.69       112\n",
      "    signpost       0.73      0.60      0.66       120\n",
      "        tree       0.57      0.63      0.60       112\n",
      "        wall       0.53      0.69      0.60       112\n",
      "\n",
      "    accuracy                           0.64       456\n",
      "   macro avg       0.65      0.64      0.64       456\n",
      "weighted avg       0.66      0.64      0.64       456\n",
      "\n",
      "Making model for session group 20210310_15:34:48.696-20210319_16:26:08.675\n",
      "tensor([[0., 0., 0., 0.],\n",
      "        [0., 5., 0., 3.],\n",
      "        [0., 0., 1., 7.],\n",
      "        [2., 0., 3., 3.]])\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         car       0.00      0.00      0.00         0\n",
      "    signpost       1.00      0.62      0.77         8\n",
      "        tree       0.25      0.12      0.17         8\n",
      "        wall       0.23      0.38      0.29         8\n",
      "\n",
      "    accuracy                           0.38        24\n",
      "   macro avg       0.37      0.28      0.31        24\n",
      "weighted avg       0.49      0.38      0.41        24\n",
      "\n",
      "Overall results...\n",
      "[[70  3 24 15]\n",
      " [ 1 77 20 30]\n",
      " [13  3 72 32]\n",
      " [ 8 20 12 80]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         car       0.76      0.62      0.69       112\n",
      "    signpost       0.75      0.60      0.67       128\n",
      "        tree       0.56      0.60      0.58       120\n",
      "        wall       0.51      0.67      0.58       120\n",
      "\n",
      "    accuracy                           0.62       480\n",
      "   macro avg       0.65      0.62      0.63       480\n",
      "weighted avg       0.64      0.62      0.63       480\n",
      "\n",
      "Making model for session group 20210310_15:34:21.045-20210319_16:23:44.170\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/_classification.py:1221: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[3., 3., 2., 0.],\n",
      "        [0., 6., 0., 2.],\n",
      "        [3., 0., 5., 0.],\n",
      "        [3., 0., 0., 5.]])\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         car       0.33      0.38      0.35         8\n",
      "    signpost       0.67      0.75      0.71         8\n",
      "        tree       0.71      0.62      0.67         8\n",
      "        wall       0.71      0.62      0.67         8\n",
      "\n",
      "    accuracy                           0.59        32\n",
      "   macro avg       0.61      0.59      0.60        32\n",
      "weighted avg       0.61      0.59      0.60        32\n",
      "\n",
      "Overall results...\n",
      "[[73  6 26 15]\n",
      " [ 1 83 20 32]\n",
      " [16  3 77 32]\n",
      " [11 20 12 85]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         car       0.72      0.61      0.66       120\n",
      "    signpost       0.74      0.61      0.67       136\n",
      "        tree       0.57      0.60      0.59       128\n",
      "        wall       0.52      0.66      0.58       128\n",
      "\n",
      "    accuracy                           0.62       512\n",
      "   macro avg       0.64      0.62      0.62       512\n",
      "weighted avg       0.64      0.62      0.62       512\n",
      "\n",
      "Making model for session group 20210310_15:30:04.369-20210319_16:16:17.283\n",
      "tensor([[6., 0., 2., 0.],\n",
      "        [0., 5., 0., 3.],\n",
      "        [0., 0., 8., 0.],\n",
      "        [0., 0., 0., 8.]])\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         car       1.00      0.75      0.86         8\n",
      "    signpost       1.00      0.62      0.77         8\n",
      "        tree       0.80      1.00      0.89         8\n",
      "        wall       0.73      1.00      0.84         8\n",
      "\n",
      "    accuracy                           0.84        32\n",
      "   macro avg       0.88      0.84      0.84        32\n",
      "weighted avg       0.88      0.84      0.84        32\n",
      "\n",
      "Overall results...\n",
      "[[79  6 28 15]\n",
      " [ 1 88 20 35]\n",
      " [16  3 85 32]\n",
      " [11 20 12 93]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         car       0.74      0.62      0.67       128\n",
      "    signpost       0.75      0.61      0.67       144\n",
      "        tree       0.59      0.62      0.60       136\n",
      "        wall       0.53      0.68      0.60       136\n",
      "\n",
      "    accuracy                           0.63       544\n",
      "   macro avg       0.65      0.63      0.64       544\n",
      "weighted avg       0.65      0.63      0.64       544\n",
      "\n",
      "Making model for session group 20210310_15:32:14.252-20210319_16:19:24.958\n",
      "tensor([[3., 0., 1., 4.],\n",
      "        [0., 7., 0., 1.],\n",
      "        [1., 0., 7., 0.],\n",
      "        [1., 0., 2., 5.]])\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         car       0.60      0.38      0.46         8\n",
      "    signpost       1.00      0.88      0.93         8\n",
      "        tree       0.70      0.88      0.78         8\n",
      "        wall       0.50      0.62      0.56         8\n",
      "\n",
      "    accuracy                           0.69        32\n",
      "   macro avg       0.70      0.69      0.68        32\n",
      "weighted avg       0.70      0.69      0.68        32\n",
      "\n",
      "Overall results...\n",
      "[[82  6 29 19]\n",
      " [ 1 95 20 36]\n",
      " [17  3 92 32]\n",
      " [12 20 14 98]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         car       0.73      0.60      0.66       136\n",
      "    signpost       0.77      0.62      0.69       152\n",
      "        tree       0.59      0.64      0.62       144\n",
      "        wall       0.53      0.68      0.60       144\n",
      "\n",
      "    accuracy                           0.64       576\n",
      "   macro avg       0.66      0.64      0.64       576\n",
      "weighted avg       0.66      0.64      0.64       576\n",
      "\n",
      "Making model for session group 20210310_15:27:20.548-20210319_16:14:28.970\n",
      "tensor([[3., 0., 1., 3.],\n",
      "        [0., 0., 0., 5.],\n",
      "        [1., 0., 6., 1.],\n",
      "        [0., 0., 0., 8.]])\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         car       0.75      0.43      0.55         7\n",
      "    signpost       0.00      0.00      0.00         5\n",
      "        tree       0.86      0.75      0.80         8\n",
      "        wall       0.47      1.00      0.64         8\n",
      "\n",
      "    accuracy                           0.61        28\n",
      "   macro avg       0.52      0.54      0.50        28\n",
      "weighted avg       0.57      0.61      0.55        28\n",
      "\n",
      "Overall results...\n",
      "[[ 85   6  30  22]\n",
      " [  1  95  20  41]\n",
      " [ 18   3  98  33]\n",
      " [ 12  20  14 106]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         car       0.73      0.59      0.66       143\n",
      "    signpost       0.77      0.61      0.68       157\n",
      "        tree       0.60      0.64      0.62       152\n",
      "        wall       0.52      0.70      0.60       152\n",
      "\n",
      "    accuracy                           0.64       604\n",
      "   macro avg       0.66      0.64      0.64       604\n",
      "weighted avg       0.66      0.64      0.64       604\n",
      "\n",
      "Making model for session group 20210310_15:26:36.351-20210319_16:11:12.300\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/_classification.py:1221: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[6., 0., 1., 1.],\n",
      "        [0., 5., 3., 0.],\n",
      "        [0., 0., 2., 6.],\n",
      "        [0., 7., 0., 1.]])\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         car       1.00      0.75      0.86         8\n",
      "    signpost       0.42      0.62      0.50         8\n",
      "        tree       0.33      0.25      0.29         8\n",
      "        wall       0.12      0.12      0.12         8\n",
      "\n",
      "    accuracy                           0.44        32\n",
      "   macro avg       0.47      0.44      0.44        32\n",
      "weighted avg       0.47      0.44      0.44        32\n",
      "\n",
      "Overall results...\n",
      "[[ 91   6  31  23]\n",
      " [  1 100  23  41]\n",
      " [ 18   3 100  39]\n",
      " [ 12  27  14 107]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         car       0.75      0.60      0.67       151\n",
      "    signpost       0.74      0.61      0.66       165\n",
      "        tree       0.60      0.62      0.61       160\n",
      "        wall       0.51      0.67      0.58       160\n",
      "\n",
      "    accuracy                           0.63       636\n",
      "   macro avg       0.65      0.63      0.63       636\n",
      "weighted avg       0.65      0.63      0.63       636\n",
      "\n"
     ]
    }
   ],
   "source": [
    "temp_session_list = session_list\n",
    "nb_classes = 4\n",
    "batch_size = 4\n",
    "predicted_labels = []\n",
    "true_labels = []\n",
    "model_list = make_model_list()\n",
    "\n",
    "for m in model_list:\n",
    "    test_list = get_test_list(m)\n",
    "    test_data = pd.DataFrame()\n",
    "    for ts in test_list:\n",
    "        #print(\"|\" + \"*\"*(count+1) + ' '*(len(train_list)-1-count)+ \"| \" +str(format((count+1)/len(train_list)*100,'.3f')) + \"% is complete...\" ,end=\"\\r\")\n",
    "        tr = read_data(dates, ts)\n",
    "        test_data = pd.concat([test_data,tr],axis=0,ignore_index=False)\n",
    "\n",
    "    test_data.dropna(inplace=True, axis=0)\n",
    "    test_feat = test_data#extract_mfcc_feat(test_data)\n",
    "    \n",
    "    test_feat.dropna(axis=0,inplace=True)\n",
    "    \n",
    "    \n",
    "    X_test, y_test = make_data(test_feat)\n",
    "    \n",
    "    #def prep_data(X_train, y_train, X_test, y_test):\n",
    "    label_encoder = preprocessing.LabelEncoder()\n",
    "    training_targets = label_encoder.fit_transform(y_train)\n",
    "\n",
    "    #Read testing data\n",
    "    #testing_timestamps,testing_labels,testing_data = read_test_data(test_list)\n",
    "\n",
    "    #Encode\n",
    "    testing_targets = label_encoder.transform(y_test)\n",
    "\n",
    "    #Make training dataloader\n",
    "    #train_dataloader = make_train_dataloader(training_targets, X_train)\n",
    "\n",
    "    #Make test dataloader\n",
    "    test_dataloader = make_test_dataloader(testing_targets, X_test)\n",
    "\n",
    "    #return train_dataloader, test_dataloader\n",
    "    \n",
    "    print(\"Making model for session group \" + test_list[0].split(\"-\")[0] + \"-\" + test_list[-1].split(\"-\")[0])\n",
    "    \n",
    "    #model,val_accuracies,val_losses,train_accuracies,train_losses = train_nn_model()\n",
    "    model = DACNN()\n",
    "    device = torch.device('cuda:1')\n",
    "    model = model.to(device)\n",
    "\n",
    "    filename = m#test_list[0].split(\"-\")[0] + \"-\" + test_list[-1].split(\"-\")[0]\n",
    "    PATH1 = model_path+ filename +'.pth'\n",
    "    model.load_state_dict(torch.load(PATH1))\n",
    "    \n",
    "    test_lbl, test_cpred,val_acc, val_loss, test_confusion_matrix = test_nn_model(model)\n",
    "    #print(\"Validation accuracy = \",val_acc)\n",
    "    #print(\"Validation loss = \",val_loss)\n",
    "    print(test_confusion_matrix)\n",
    "    class_report = classification_report(test_lbl, test_cpred)\n",
    "    print(class_report)\n",
    "    \n",
    "    predicted_labels.extend(test_cpred)\n",
    "    true_labels.extend(test_lbl)\n",
    "    \n",
    "    print(\"Overall results...\")   \n",
    "    print(confusion_matrix(true_labels, predicted_labels))\n",
    "    print(classification_report(true_labels, predicted_labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>922</th>\n",
       "      <th>923</th>\n",
       "      <th>924</th>\n",
       "      <th>925</th>\n",
       "      <th>926</th>\n",
       "      <th>927</th>\n",
       "      <th>928</th>\n",
       "      <th>929</th>\n",
       "      <th>930</th>\n",
       "      <th>931</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>tree</th>\n",
       "      <td>26.565042</td>\n",
       "      <td>27.877067</td>\n",
       "      <td>29.160591</td>\n",
       "      <td>29.922146</td>\n",
       "      <td>29.414932</td>\n",
       "      <td>28.456536</td>\n",
       "      <td>27.155752</td>\n",
       "      <td>28.218552</td>\n",
       "      <td>29.551389</td>\n",
       "      <td>28.657420</td>\n",
       "      <td>...</td>\n",
       "      <td>32.812588</td>\n",
       "      <td>49.548979</td>\n",
       "      <td>66.549976</td>\n",
       "      <td>83.566775</td>\n",
       "      <td>97.351812</td>\n",
       "      <td>104.862090</td>\n",
       "      <td>103.635693</td>\n",
       "      <td>92.211460</td>\n",
       "      <td>70.408011</td>\n",
       "      <td>40.942587</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>tree</th>\n",
       "      <td>24.858779</td>\n",
       "      <td>25.650046</td>\n",
       "      <td>26.494723</td>\n",
       "      <td>27.296816</td>\n",
       "      <td>27.103787</td>\n",
       "      <td>26.627991</td>\n",
       "      <td>26.113707</td>\n",
       "      <td>26.904797</td>\n",
       "      <td>28.208807</td>\n",
       "      <td>27.811381</td>\n",
       "      <td>...</td>\n",
       "      <td>41.077333</td>\n",
       "      <td>57.728539</td>\n",
       "      <td>75.777473</td>\n",
       "      <td>91.723414</td>\n",
       "      <td>104.530831</td>\n",
       "      <td>110.770017</td>\n",
       "      <td>108.275807</td>\n",
       "      <td>95.033571</td>\n",
       "      <td>72.723932</td>\n",
       "      <td>43.976719</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>tree</th>\n",
       "      <td>24.479948</td>\n",
       "      <td>25.152260</td>\n",
       "      <td>25.828762</td>\n",
       "      <td>26.430686</td>\n",
       "      <td>26.479890</td>\n",
       "      <td>25.690950</td>\n",
       "      <td>25.628889</td>\n",
       "      <td>26.957333</td>\n",
       "      <td>28.496878</td>\n",
       "      <td>27.848683</td>\n",
       "      <td>...</td>\n",
       "      <td>42.851206</td>\n",
       "      <td>59.636731</td>\n",
       "      <td>73.401656</td>\n",
       "      <td>87.968092</td>\n",
       "      <td>101.510328</td>\n",
       "      <td>113.437571</td>\n",
       "      <td>120.234882</td>\n",
       "      <td>119.194596</td>\n",
       "      <td>107.328880</td>\n",
       "      <td>84.722631</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>tree</th>\n",
       "      <td>23.630652</td>\n",
       "      <td>24.515125</td>\n",
       "      <td>25.747852</td>\n",
       "      <td>26.890994</td>\n",
       "      <td>27.231208</td>\n",
       "      <td>26.852609</td>\n",
       "      <td>26.647254</td>\n",
       "      <td>27.219844</td>\n",
       "      <td>28.089644</td>\n",
       "      <td>27.128751</td>\n",
       "      <td>...</td>\n",
       "      <td>43.849499</td>\n",
       "      <td>62.303363</td>\n",
       "      <td>80.957065</td>\n",
       "      <td>98.689295</td>\n",
       "      <td>114.661085</td>\n",
       "      <td>125.830351</td>\n",
       "      <td>129.502343</td>\n",
       "      <td>122.720595</td>\n",
       "      <td>104.643673</td>\n",
       "      <td>76.250312</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>tree</th>\n",
       "      <td>24.613127</td>\n",
       "      <td>25.362440</td>\n",
       "      <td>26.588936</td>\n",
       "      <td>27.748888</td>\n",
       "      <td>27.885174</td>\n",
       "      <td>27.001231</td>\n",
       "      <td>26.211379</td>\n",
       "      <td>27.175178</td>\n",
       "      <td>28.110261</td>\n",
       "      <td>27.863020</td>\n",
       "      <td>...</td>\n",
       "      <td>26.238810</td>\n",
       "      <td>45.523646</td>\n",
       "      <td>66.991444</td>\n",
       "      <td>89.261202</td>\n",
       "      <td>108.763183</td>\n",
       "      <td>121.474487</td>\n",
       "      <td>123.606996</td>\n",
       "      <td>113.132902</td>\n",
       "      <td>90.104495</td>\n",
       "      <td>57.732460</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>tree</th>\n",
       "      <td>26.217357</td>\n",
       "      <td>27.032163</td>\n",
       "      <td>27.875596</td>\n",
       "      <td>28.780300</td>\n",
       "      <td>28.322886</td>\n",
       "      <td>27.431954</td>\n",
       "      <td>26.139936</td>\n",
       "      <td>27.034513</td>\n",
       "      <td>28.462683</td>\n",
       "      <td>27.843682</td>\n",
       "      <td>...</td>\n",
       "      <td>26.247148</td>\n",
       "      <td>40.968663</td>\n",
       "      <td>61.770370</td>\n",
       "      <td>82.932252</td>\n",
       "      <td>104.579073</td>\n",
       "      <td>120.512800</td>\n",
       "      <td>128.280520</td>\n",
       "      <td>123.336534</td>\n",
       "      <td>105.677497</td>\n",
       "      <td>76.464599</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>tree</th>\n",
       "      <td>25.952134</td>\n",
       "      <td>26.774763</td>\n",
       "      <td>27.485832</td>\n",
       "      <td>27.959304</td>\n",
       "      <td>28.023807</td>\n",
       "      <td>27.029709</td>\n",
       "      <td>26.181381</td>\n",
       "      <td>27.334481</td>\n",
       "      <td>28.887557</td>\n",
       "      <td>28.600194</td>\n",
       "      <td>...</td>\n",
       "      <td>28.546275</td>\n",
       "      <td>42.803529</td>\n",
       "      <td>60.654843</td>\n",
       "      <td>77.894886</td>\n",
       "      <td>94.210216</td>\n",
       "      <td>104.722337</td>\n",
       "      <td>107.521988</td>\n",
       "      <td>99.430445</td>\n",
       "      <td>81.023020</td>\n",
       "      <td>54.038892</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>tree</th>\n",
       "      <td>24.684816</td>\n",
       "      <td>25.729166</td>\n",
       "      <td>26.773379</td>\n",
       "      <td>27.098647</td>\n",
       "      <td>27.548620</td>\n",
       "      <td>26.865185</td>\n",
       "      <td>26.423687</td>\n",
       "      <td>27.488097</td>\n",
       "      <td>28.686854</td>\n",
       "      <td>28.925519</td>\n",
       "      <td>...</td>\n",
       "      <td>37.242045</td>\n",
       "      <td>57.352373</td>\n",
       "      <td>76.017109</td>\n",
       "      <td>95.475497</td>\n",
       "      <td>110.718317</td>\n",
       "      <td>120.074494</td>\n",
       "      <td>119.588900</td>\n",
       "      <td>108.403220</td>\n",
       "      <td>85.925556</td>\n",
       "      <td>55.371641</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>car</th>\n",
       "      <td>27.039164</td>\n",
       "      <td>27.558897</td>\n",
       "      <td>27.861797</td>\n",
       "      <td>27.863333</td>\n",
       "      <td>27.356722</td>\n",
       "      <td>25.534693</td>\n",
       "      <td>24.717599</td>\n",
       "      <td>26.554471</td>\n",
       "      <td>27.849935</td>\n",
       "      <td>26.392971</td>\n",
       "      <td>...</td>\n",
       "      <td>8.059176</td>\n",
       "      <td>19.432884</td>\n",
       "      <td>44.692748</td>\n",
       "      <td>71.114882</td>\n",
       "      <td>99.441935</td>\n",
       "      <td>119.664015</td>\n",
       "      <td>129.575439</td>\n",
       "      <td>123.474638</td>\n",
       "      <td>103.228289</td>\n",
       "      <td>70.716286</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>car</th>\n",
       "      <td>26.604520</td>\n",
       "      <td>28.005289</td>\n",
       "      <td>29.229857</td>\n",
       "      <td>30.207236</td>\n",
       "      <td>30.140608</td>\n",
       "      <td>28.937045</td>\n",
       "      <td>27.555838</td>\n",
       "      <td>28.327777</td>\n",
       "      <td>29.885197</td>\n",
       "      <td>28.313275</td>\n",
       "      <td>...</td>\n",
       "      <td>29.255736</td>\n",
       "      <td>44.097239</td>\n",
       "      <td>61.009433</td>\n",
       "      <td>78.597051</td>\n",
       "      <td>95.113801</td>\n",
       "      <td>107.322614</td>\n",
       "      <td>112.186210</td>\n",
       "      <td>106.933462</td>\n",
       "      <td>91.302410</td>\n",
       "      <td>66.890687</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>car</th>\n",
       "      <td>24.398436</td>\n",
       "      <td>24.896068</td>\n",
       "      <td>25.413213</td>\n",
       "      <td>25.782384</td>\n",
       "      <td>25.216561</td>\n",
       "      <td>24.523934</td>\n",
       "      <td>24.338185</td>\n",
       "      <td>25.790223</td>\n",
       "      <td>27.054387</td>\n",
       "      <td>25.982298</td>\n",
       "      <td>...</td>\n",
       "      <td>37.335034</td>\n",
       "      <td>53.565686</td>\n",
       "      <td>71.831284</td>\n",
       "      <td>89.362618</td>\n",
       "      <td>105.581457</td>\n",
       "      <td>116.599760</td>\n",
       "      <td>120.259502</td>\n",
       "      <td>113.615116</td>\n",
       "      <td>96.654379</td>\n",
       "      <td>70.749368</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>car</th>\n",
       "      <td>25.359516</td>\n",
       "      <td>26.261337</td>\n",
       "      <td>27.355153</td>\n",
       "      <td>28.295285</td>\n",
       "      <td>28.359779</td>\n",
       "      <td>27.297548</td>\n",
       "      <td>26.363066</td>\n",
       "      <td>27.364091</td>\n",
       "      <td>28.213019</td>\n",
       "      <td>27.431914</td>\n",
       "      <td>...</td>\n",
       "      <td>27.250922</td>\n",
       "      <td>44.703921</td>\n",
       "      <td>67.157880</td>\n",
       "      <td>90.581897</td>\n",
       "      <td>112.701830</td>\n",
       "      <td>128.372299</td>\n",
       "      <td>133.973972</td>\n",
       "      <td>126.267795</td>\n",
       "      <td>105.808478</td>\n",
       "      <td>75.286177</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>car</th>\n",
       "      <td>27.194414</td>\n",
       "      <td>27.639409</td>\n",
       "      <td>28.372907</td>\n",
       "      <td>28.882551</td>\n",
       "      <td>27.834942</td>\n",
       "      <td>25.727717</td>\n",
       "      <td>23.921921</td>\n",
       "      <td>24.648979</td>\n",
       "      <td>25.934208</td>\n",
       "      <td>23.701916</td>\n",
       "      <td>...</td>\n",
       "      <td>26.270541</td>\n",
       "      <td>42.911474</td>\n",
       "      <td>63.206038</td>\n",
       "      <td>84.506198</td>\n",
       "      <td>103.981842</td>\n",
       "      <td>117.431234</td>\n",
       "      <td>121.250636</td>\n",
       "      <td>112.934067</td>\n",
       "      <td>92.999160</td>\n",
       "      <td>64.207243</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>car</th>\n",
       "      <td>24.480877</td>\n",
       "      <td>25.408217</td>\n",
       "      <td>27.052958</td>\n",
       "      <td>29.018907</td>\n",
       "      <td>29.942497</td>\n",
       "      <td>29.610092</td>\n",
       "      <td>28.762318</td>\n",
       "      <td>29.571159</td>\n",
       "      <td>30.998741</td>\n",
       "      <td>30.342225</td>\n",
       "      <td>...</td>\n",
       "      <td>20.482679</td>\n",
       "      <td>37.725157</td>\n",
       "      <td>58.553694</td>\n",
       "      <td>80.848854</td>\n",
       "      <td>100.012843</td>\n",
       "      <td>111.952965</td>\n",
       "      <td>112.765525</td>\n",
       "      <td>100.927558</td>\n",
       "      <td>77.626185</td>\n",
       "      <td>47.108573</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>car</th>\n",
       "      <td>26.205520</td>\n",
       "      <td>26.951324</td>\n",
       "      <td>27.532793</td>\n",
       "      <td>28.124931</td>\n",
       "      <td>27.405663</td>\n",
       "      <td>25.471024</td>\n",
       "      <td>24.796786</td>\n",
       "      <td>26.889207</td>\n",
       "      <td>28.441708</td>\n",
       "      <td>27.765676</td>\n",
       "      <td>...</td>\n",
       "      <td>23.054437</td>\n",
       "      <td>38.409813</td>\n",
       "      <td>59.831432</td>\n",
       "      <td>81.845105</td>\n",
       "      <td>102.921666</td>\n",
       "      <td>117.306732</td>\n",
       "      <td>121.973937</td>\n",
       "      <td>113.511323</td>\n",
       "      <td>93.031836</td>\n",
       "      <td>63.031600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>car</th>\n",
       "      <td>25.404033</td>\n",
       "      <td>26.310839</td>\n",
       "      <td>26.987994</td>\n",
       "      <td>27.305162</td>\n",
       "      <td>26.829063</td>\n",
       "      <td>25.545275</td>\n",
       "      <td>24.270065</td>\n",
       "      <td>26.060995</td>\n",
       "      <td>27.367462</td>\n",
       "      <td>26.074994</td>\n",
       "      <td>...</td>\n",
       "      <td>24.905763</td>\n",
       "      <td>40.928708</td>\n",
       "      <td>61.434973</td>\n",
       "      <td>83.105225</td>\n",
       "      <td>103.956459</td>\n",
       "      <td>119.111072</td>\n",
       "      <td>125.094440</td>\n",
       "      <td>118.539593</td>\n",
       "      <td>99.612567</td>\n",
       "      <td>70.574933</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>wall</th>\n",
       "      <td>27.678246</td>\n",
       "      <td>28.840733</td>\n",
       "      <td>29.422302</td>\n",
       "      <td>29.724505</td>\n",
       "      <td>29.747211</td>\n",
       "      <td>29.099712</td>\n",
       "      <td>27.492129</td>\n",
       "      <td>28.325928</td>\n",
       "      <td>30.454167</td>\n",
       "      <td>30.122406</td>\n",
       "      <td>...</td>\n",
       "      <td>32.197550</td>\n",
       "      <td>63.590756</td>\n",
       "      <td>64.990691</td>\n",
       "      <td>86.283693</td>\n",
       "      <td>86.365615</td>\n",
       "      <td>96.591991</td>\n",
       "      <td>87.826897</td>\n",
       "      <td>81.942004</td>\n",
       "      <td>58.464866</td>\n",
       "      <td>35.962126</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>wall</th>\n",
       "      <td>25.451181</td>\n",
       "      <td>26.465608</td>\n",
       "      <td>27.201245</td>\n",
       "      <td>27.484650</td>\n",
       "      <td>27.601694</td>\n",
       "      <td>27.086610</td>\n",
       "      <td>26.534889</td>\n",
       "      <td>27.712985</td>\n",
       "      <td>28.924081</td>\n",
       "      <td>28.508548</td>\n",
       "      <td>...</td>\n",
       "      <td>26.952643</td>\n",
       "      <td>50.653745</td>\n",
       "      <td>63.122999</td>\n",
       "      <td>84.036534</td>\n",
       "      <td>98.181202</td>\n",
       "      <td>111.246916</td>\n",
       "      <td>113.741219</td>\n",
       "      <td>107.735223</td>\n",
       "      <td>88.377882</td>\n",
       "      <td>60.469140</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>wall</th>\n",
       "      <td>25.086245</td>\n",
       "      <td>25.741249</td>\n",
       "      <td>26.495514</td>\n",
       "      <td>27.362946</td>\n",
       "      <td>27.716558</td>\n",
       "      <td>27.202009</td>\n",
       "      <td>26.778332</td>\n",
       "      <td>27.926304</td>\n",
       "      <td>29.042115</td>\n",
       "      <td>28.252603</td>\n",
       "      <td>...</td>\n",
       "      <td>32.237031</td>\n",
       "      <td>59.014377</td>\n",
       "      <td>67.738394</td>\n",
       "      <td>88.441865</td>\n",
       "      <td>99.024471</td>\n",
       "      <td>111.705931</td>\n",
       "      <td>112.892116</td>\n",
       "      <td>108.037270</td>\n",
       "      <td>89.334072</td>\n",
       "      <td>63.034933</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>wall</th>\n",
       "      <td>24.704201</td>\n",
       "      <td>25.161193</td>\n",
       "      <td>25.916804</td>\n",
       "      <td>26.648516</td>\n",
       "      <td>26.859758</td>\n",
       "      <td>26.431151</td>\n",
       "      <td>26.421849</td>\n",
       "      <td>27.504260</td>\n",
       "      <td>28.721699</td>\n",
       "      <td>27.906860</td>\n",
       "      <td>...</td>\n",
       "      <td>40.738601</td>\n",
       "      <td>59.155933</td>\n",
       "      <td>74.918781</td>\n",
       "      <td>90.938454</td>\n",
       "      <td>104.442400</td>\n",
       "      <td>113.946865</td>\n",
       "      <td>116.187041</td>\n",
       "      <td>109.237676</td>\n",
       "      <td>91.215927</td>\n",
       "      <td>64.221543</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>wall</th>\n",
       "      <td>22.043251</td>\n",
       "      <td>22.848130</td>\n",
       "      <td>24.924925</td>\n",
       "      <td>26.612050</td>\n",
       "      <td>27.433058</td>\n",
       "      <td>27.703360</td>\n",
       "      <td>27.813493</td>\n",
       "      <td>28.451966</td>\n",
       "      <td>29.182554</td>\n",
       "      <td>28.704424</td>\n",
       "      <td>...</td>\n",
       "      <td>33.388174</td>\n",
       "      <td>51.674080</td>\n",
       "      <td>68.089271</td>\n",
       "      <td>86.037522</td>\n",
       "      <td>101.348015</td>\n",
       "      <td>112.247845</td>\n",
       "      <td>114.945145</td>\n",
       "      <td>107.559358</td>\n",
       "      <td>88.538726</td>\n",
       "      <td>60.572407</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>wall</th>\n",
       "      <td>25.229183</td>\n",
       "      <td>26.269253</td>\n",
       "      <td>27.171011</td>\n",
       "      <td>27.787541</td>\n",
       "      <td>27.712729</td>\n",
       "      <td>26.985219</td>\n",
       "      <td>26.403808</td>\n",
       "      <td>27.243110</td>\n",
       "      <td>28.720460</td>\n",
       "      <td>28.426411</td>\n",
       "      <td>...</td>\n",
       "      <td>34.527961</td>\n",
       "      <td>53.832477</td>\n",
       "      <td>69.387717</td>\n",
       "      <td>87.572182</td>\n",
       "      <td>102.050464</td>\n",
       "      <td>112.695706</td>\n",
       "      <td>114.660597</td>\n",
       "      <td>107.069296</td>\n",
       "      <td>87.832864</td>\n",
       "      <td>59.813149</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>wall</th>\n",
       "      <td>24.291280</td>\n",
       "      <td>25.108654</td>\n",
       "      <td>26.218744</td>\n",
       "      <td>27.463409</td>\n",
       "      <td>27.752457</td>\n",
       "      <td>27.142521</td>\n",
       "      <td>26.815289</td>\n",
       "      <td>27.577430</td>\n",
       "      <td>28.515775</td>\n",
       "      <td>28.162382</td>\n",
       "      <td>...</td>\n",
       "      <td>48.311012</td>\n",
       "      <td>79.749655</td>\n",
       "      <td>80.871029</td>\n",
       "      <td>97.719295</td>\n",
       "      <td>96.615120</td>\n",
       "      <td>104.667258</td>\n",
       "      <td>98.395199</td>\n",
       "      <td>93.882609</td>\n",
       "      <td>74.706132</td>\n",
       "      <td>53.730628</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>wall</th>\n",
       "      <td>25.257648</td>\n",
       "      <td>26.668304</td>\n",
       "      <td>27.947329</td>\n",
       "      <td>28.564113</td>\n",
       "      <td>28.386049</td>\n",
       "      <td>27.279125</td>\n",
       "      <td>26.229750</td>\n",
       "      <td>27.178516</td>\n",
       "      <td>28.259641</td>\n",
       "      <td>27.101874</td>\n",
       "      <td>...</td>\n",
       "      <td>31.320471</td>\n",
       "      <td>51.581966</td>\n",
       "      <td>67.154016</td>\n",
       "      <td>86.985354</td>\n",
       "      <td>104.327350</td>\n",
       "      <td>119.538525</td>\n",
       "      <td>126.468563</td>\n",
       "      <td>123.381176</td>\n",
       "      <td>106.531691</td>\n",
       "      <td>78.604866</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>signpost</th>\n",
       "      <td>26.770279</td>\n",
       "      <td>27.901871</td>\n",
       "      <td>29.001301</td>\n",
       "      <td>29.871436</td>\n",
       "      <td>29.804353</td>\n",
       "      <td>28.950209</td>\n",
       "      <td>27.988268</td>\n",
       "      <td>29.091310</td>\n",
       "      <td>30.554782</td>\n",
       "      <td>29.518801</td>\n",
       "      <td>...</td>\n",
       "      <td>26.526920</td>\n",
       "      <td>42.951878</td>\n",
       "      <td>60.533328</td>\n",
       "      <td>78.953897</td>\n",
       "      <td>94.553046</td>\n",
       "      <td>103.912545</td>\n",
       "      <td>104.074298</td>\n",
       "      <td>93.377499</td>\n",
       "      <td>71.594443</td>\n",
       "      <td>41.587655</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>signpost</th>\n",
       "      <td>24.253770</td>\n",
       "      <td>24.840018</td>\n",
       "      <td>25.495298</td>\n",
       "      <td>25.969060</td>\n",
       "      <td>26.026538</td>\n",
       "      <td>25.451207</td>\n",
       "      <td>25.324863</td>\n",
       "      <td>26.388085</td>\n",
       "      <td>27.320756</td>\n",
       "      <td>26.426846</td>\n",
       "      <td>...</td>\n",
       "      <td>38.828406</td>\n",
       "      <td>56.166773</td>\n",
       "      <td>73.828800</td>\n",
       "      <td>91.248479</td>\n",
       "      <td>107.192324</td>\n",
       "      <td>118.454149</td>\n",
       "      <td>122.172102</td>\n",
       "      <td>115.349788</td>\n",
       "      <td>97.021512</td>\n",
       "      <td>68.573736</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>signpost</th>\n",
       "      <td>22.289953</td>\n",
       "      <td>23.229275</td>\n",
       "      <td>24.922165</td>\n",
       "      <td>26.581354</td>\n",
       "      <td>27.381884</td>\n",
       "      <td>27.592318</td>\n",
       "      <td>27.321409</td>\n",
       "      <td>27.826968</td>\n",
       "      <td>28.476645</td>\n",
       "      <td>27.807478</td>\n",
       "      <td>...</td>\n",
       "      <td>44.495687</td>\n",
       "      <td>59.681178</td>\n",
       "      <td>72.944373</td>\n",
       "      <td>83.323672</td>\n",
       "      <td>90.685146</td>\n",
       "      <td>92.907789</td>\n",
       "      <td>88.909279</td>\n",
       "      <td>77.175513</td>\n",
       "      <td>58.084765</td>\n",
       "      <td>33.238076</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>signpost</th>\n",
       "      <td>22.536171</td>\n",
       "      <td>22.304833</td>\n",
       "      <td>21.417429</td>\n",
       "      <td>24.252232</td>\n",
       "      <td>24.266140</td>\n",
       "      <td>21.760358</td>\n",
       "      <td>23.290172</td>\n",
       "      <td>25.636606</td>\n",
       "      <td>27.609391</td>\n",
       "      <td>28.530637</td>\n",
       "      <td>...</td>\n",
       "      <td>31.632048</td>\n",
       "      <td>50.821421</td>\n",
       "      <td>70.923501</td>\n",
       "      <td>92.929352</td>\n",
       "      <td>112.980729</td>\n",
       "      <td>127.913535</td>\n",
       "      <td>133.346235</td>\n",
       "      <td>126.562421</td>\n",
       "      <td>106.490377</td>\n",
       "      <td>75.208317</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>signpost</th>\n",
       "      <td>25.592717</td>\n",
       "      <td>26.390574</td>\n",
       "      <td>27.377707</td>\n",
       "      <td>28.382057</td>\n",
       "      <td>29.218243</td>\n",
       "      <td>28.858934</td>\n",
       "      <td>28.928807</td>\n",
       "      <td>29.975054</td>\n",
       "      <td>31.460370</td>\n",
       "      <td>31.083440</td>\n",
       "      <td>...</td>\n",
       "      <td>12.481454</td>\n",
       "      <td>28.850345</td>\n",
       "      <td>52.574124</td>\n",
       "      <td>80.593905</td>\n",
       "      <td>109.861753</td>\n",
       "      <td>133.895798</td>\n",
       "      <td>147.930270</td>\n",
       "      <td>147.062863</td>\n",
       "      <td>129.598573</td>\n",
       "      <td>97.557180</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>signpost</th>\n",
       "      <td>23.208269</td>\n",
       "      <td>22.269315</td>\n",
       "      <td>23.938266</td>\n",
       "      <td>26.397856</td>\n",
       "      <td>28.200631</td>\n",
       "      <td>28.773363</td>\n",
       "      <td>28.919966</td>\n",
       "      <td>29.836766</td>\n",
       "      <td>30.889988</td>\n",
       "      <td>30.427136</td>\n",
       "      <td>...</td>\n",
       "      <td>16.501621</td>\n",
       "      <td>33.305268</td>\n",
       "      <td>54.616378</td>\n",
       "      <td>79.592984</td>\n",
       "      <td>104.467091</td>\n",
       "      <td>124.546450</td>\n",
       "      <td>134.964601</td>\n",
       "      <td>132.024350</td>\n",
       "      <td>114.040097</td>\n",
       "      <td>83.525361</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>signpost</th>\n",
       "      <td>26.424185</td>\n",
       "      <td>27.416757</td>\n",
       "      <td>28.465810</td>\n",
       "      <td>29.127021</td>\n",
       "      <td>29.196689</td>\n",
       "      <td>28.543867</td>\n",
       "      <td>28.151828</td>\n",
       "      <td>29.413927</td>\n",
       "      <td>30.918441</td>\n",
       "      <td>30.405030</td>\n",
       "      <td>...</td>\n",
       "      <td>3.226050</td>\n",
       "      <td>23.224886</td>\n",
       "      <td>40.042096</td>\n",
       "      <td>70.066427</td>\n",
       "      <td>96.593103</td>\n",
       "      <td>123.895827</td>\n",
       "      <td>139.460366</td>\n",
       "      <td>144.078708</td>\n",
       "      <td>131.340982</td>\n",
       "      <td>106.081633</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>signpost</th>\n",
       "      <td>26.071512</td>\n",
       "      <td>26.879925</td>\n",
       "      <td>27.902063</td>\n",
       "      <td>28.830514</td>\n",
       "      <td>28.505412</td>\n",
       "      <td>26.767260</td>\n",
       "      <td>25.966196</td>\n",
       "      <td>27.026845</td>\n",
       "      <td>28.748343</td>\n",
       "      <td>28.502960</td>\n",
       "      <td>...</td>\n",
       "      <td>24.260382</td>\n",
       "      <td>41.945151</td>\n",
       "      <td>63.084391</td>\n",
       "      <td>86.636535</td>\n",
       "      <td>109.566585</td>\n",
       "      <td>127.280834</td>\n",
       "      <td>135.668852</td>\n",
       "      <td>131.184657</td>\n",
       "      <td>112.552549</td>\n",
       "      <td>82.011781</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>32 rows  932 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                0          1          2          3          4          5    \\\n",
       "tree      26.565042  27.877067  29.160591  29.922146  29.414932  28.456536   \n",
       "tree      24.858779  25.650046  26.494723  27.296816  27.103787  26.627991   \n",
       "tree      24.479948  25.152260  25.828762  26.430686  26.479890  25.690950   \n",
       "tree      23.630652  24.515125  25.747852  26.890994  27.231208  26.852609   \n",
       "tree      24.613127  25.362440  26.588936  27.748888  27.885174  27.001231   \n",
       "tree      26.217357  27.032163  27.875596  28.780300  28.322886  27.431954   \n",
       "tree      25.952134  26.774763  27.485832  27.959304  28.023807  27.029709   \n",
       "tree      24.684816  25.729166  26.773379  27.098647  27.548620  26.865185   \n",
       "car       27.039164  27.558897  27.861797  27.863333  27.356722  25.534693   \n",
       "car       26.604520  28.005289  29.229857  30.207236  30.140608  28.937045   \n",
       "car       24.398436  24.896068  25.413213  25.782384  25.216561  24.523934   \n",
       "car       25.359516  26.261337  27.355153  28.295285  28.359779  27.297548   \n",
       "car       27.194414  27.639409  28.372907  28.882551  27.834942  25.727717   \n",
       "car       24.480877  25.408217  27.052958  29.018907  29.942497  29.610092   \n",
       "car       26.205520  26.951324  27.532793  28.124931  27.405663  25.471024   \n",
       "car       25.404033  26.310839  26.987994  27.305162  26.829063  25.545275   \n",
       "wall      27.678246  28.840733  29.422302  29.724505  29.747211  29.099712   \n",
       "wall      25.451181  26.465608  27.201245  27.484650  27.601694  27.086610   \n",
       "wall      25.086245  25.741249  26.495514  27.362946  27.716558  27.202009   \n",
       "wall      24.704201  25.161193  25.916804  26.648516  26.859758  26.431151   \n",
       "wall      22.043251  22.848130  24.924925  26.612050  27.433058  27.703360   \n",
       "wall      25.229183  26.269253  27.171011  27.787541  27.712729  26.985219   \n",
       "wall      24.291280  25.108654  26.218744  27.463409  27.752457  27.142521   \n",
       "wall      25.257648  26.668304  27.947329  28.564113  28.386049  27.279125   \n",
       "signpost  26.770279  27.901871  29.001301  29.871436  29.804353  28.950209   \n",
       "signpost  24.253770  24.840018  25.495298  25.969060  26.026538  25.451207   \n",
       "signpost  22.289953  23.229275  24.922165  26.581354  27.381884  27.592318   \n",
       "signpost  22.536171  22.304833  21.417429  24.252232  24.266140  21.760358   \n",
       "signpost  25.592717  26.390574  27.377707  28.382057  29.218243  28.858934   \n",
       "signpost  23.208269  22.269315  23.938266  26.397856  28.200631  28.773363   \n",
       "signpost  26.424185  27.416757  28.465810  29.127021  29.196689  28.543867   \n",
       "signpost  26.071512  26.879925  27.902063  28.830514  28.505412  26.767260   \n",
       "\n",
       "                6          7          8          9    ...        922  \\\n",
       "tree      27.155752  28.218552  29.551389  28.657420  ...  32.812588   \n",
       "tree      26.113707  26.904797  28.208807  27.811381  ...  41.077333   \n",
       "tree      25.628889  26.957333  28.496878  27.848683  ...  42.851206   \n",
       "tree      26.647254  27.219844  28.089644  27.128751  ...  43.849499   \n",
       "tree      26.211379  27.175178  28.110261  27.863020  ...  26.238810   \n",
       "tree      26.139936  27.034513  28.462683  27.843682  ...  26.247148   \n",
       "tree      26.181381  27.334481  28.887557  28.600194  ...  28.546275   \n",
       "tree      26.423687  27.488097  28.686854  28.925519  ...  37.242045   \n",
       "car       24.717599  26.554471  27.849935  26.392971  ...   8.059176   \n",
       "car       27.555838  28.327777  29.885197  28.313275  ...  29.255736   \n",
       "car       24.338185  25.790223  27.054387  25.982298  ...  37.335034   \n",
       "car       26.363066  27.364091  28.213019  27.431914  ...  27.250922   \n",
       "car       23.921921  24.648979  25.934208  23.701916  ...  26.270541   \n",
       "car       28.762318  29.571159  30.998741  30.342225  ...  20.482679   \n",
       "car       24.796786  26.889207  28.441708  27.765676  ...  23.054437   \n",
       "car       24.270065  26.060995  27.367462  26.074994  ...  24.905763   \n",
       "wall      27.492129  28.325928  30.454167  30.122406  ...  32.197550   \n",
       "wall      26.534889  27.712985  28.924081  28.508548  ...  26.952643   \n",
       "wall      26.778332  27.926304  29.042115  28.252603  ...  32.237031   \n",
       "wall      26.421849  27.504260  28.721699  27.906860  ...  40.738601   \n",
       "wall      27.813493  28.451966  29.182554  28.704424  ...  33.388174   \n",
       "wall      26.403808  27.243110  28.720460  28.426411  ...  34.527961   \n",
       "wall      26.815289  27.577430  28.515775  28.162382  ...  48.311012   \n",
       "wall      26.229750  27.178516  28.259641  27.101874  ...  31.320471   \n",
       "signpost  27.988268  29.091310  30.554782  29.518801  ...  26.526920   \n",
       "signpost  25.324863  26.388085  27.320756  26.426846  ...  38.828406   \n",
       "signpost  27.321409  27.826968  28.476645  27.807478  ...  44.495687   \n",
       "signpost  23.290172  25.636606  27.609391  28.530637  ...  31.632048   \n",
       "signpost  28.928807  29.975054  31.460370  31.083440  ...  12.481454   \n",
       "signpost  28.919966  29.836766  30.889988  30.427136  ...  16.501621   \n",
       "signpost  28.151828  29.413927  30.918441  30.405030  ...   3.226050   \n",
       "signpost  25.966196  27.026845  28.748343  28.502960  ...  24.260382   \n",
       "\n",
       "                923        924        925         926         927         928  \\\n",
       "tree      49.548979  66.549976  83.566775   97.351812  104.862090  103.635693   \n",
       "tree      57.728539  75.777473  91.723414  104.530831  110.770017  108.275807   \n",
       "tree      59.636731  73.401656  87.968092  101.510328  113.437571  120.234882   \n",
       "tree      62.303363  80.957065  98.689295  114.661085  125.830351  129.502343   \n",
       "tree      45.523646  66.991444  89.261202  108.763183  121.474487  123.606996   \n",
       "tree      40.968663  61.770370  82.932252  104.579073  120.512800  128.280520   \n",
       "tree      42.803529  60.654843  77.894886   94.210216  104.722337  107.521988   \n",
       "tree      57.352373  76.017109  95.475497  110.718317  120.074494  119.588900   \n",
       "car       19.432884  44.692748  71.114882   99.441935  119.664015  129.575439   \n",
       "car       44.097239  61.009433  78.597051   95.113801  107.322614  112.186210   \n",
       "car       53.565686  71.831284  89.362618  105.581457  116.599760  120.259502   \n",
       "car       44.703921  67.157880  90.581897  112.701830  128.372299  133.973972   \n",
       "car       42.911474  63.206038  84.506198  103.981842  117.431234  121.250636   \n",
       "car       37.725157  58.553694  80.848854  100.012843  111.952965  112.765525   \n",
       "car       38.409813  59.831432  81.845105  102.921666  117.306732  121.973937   \n",
       "car       40.928708  61.434973  83.105225  103.956459  119.111072  125.094440   \n",
       "wall      63.590756  64.990691  86.283693   86.365615   96.591991   87.826897   \n",
       "wall      50.653745  63.122999  84.036534   98.181202  111.246916  113.741219   \n",
       "wall      59.014377  67.738394  88.441865   99.024471  111.705931  112.892116   \n",
       "wall      59.155933  74.918781  90.938454  104.442400  113.946865  116.187041   \n",
       "wall      51.674080  68.089271  86.037522  101.348015  112.247845  114.945145   \n",
       "wall      53.832477  69.387717  87.572182  102.050464  112.695706  114.660597   \n",
       "wall      79.749655  80.871029  97.719295   96.615120  104.667258   98.395199   \n",
       "wall      51.581966  67.154016  86.985354  104.327350  119.538525  126.468563   \n",
       "signpost  42.951878  60.533328  78.953897   94.553046  103.912545  104.074298   \n",
       "signpost  56.166773  73.828800  91.248479  107.192324  118.454149  122.172102   \n",
       "signpost  59.681178  72.944373  83.323672   90.685146   92.907789   88.909279   \n",
       "signpost  50.821421  70.923501  92.929352  112.980729  127.913535  133.346235   \n",
       "signpost  28.850345  52.574124  80.593905  109.861753  133.895798  147.930270   \n",
       "signpost  33.305268  54.616378  79.592984  104.467091  124.546450  134.964601   \n",
       "signpost  23.224886  40.042096  70.066427   96.593103  123.895827  139.460366   \n",
       "signpost  41.945151  63.084391  86.636535  109.566585  127.280834  135.668852   \n",
       "\n",
       "                 929         930         931  \n",
       "tree       92.211460   70.408011   40.942587  \n",
       "tree       95.033571   72.723932   43.976719  \n",
       "tree      119.194596  107.328880   84.722631  \n",
       "tree      122.720595  104.643673   76.250312  \n",
       "tree      113.132902   90.104495   57.732460  \n",
       "tree      123.336534  105.677497   76.464599  \n",
       "tree       99.430445   81.023020   54.038892  \n",
       "tree      108.403220   85.925556   55.371641  \n",
       "car       123.474638  103.228289   70.716286  \n",
       "car       106.933462   91.302410   66.890687  \n",
       "car       113.615116   96.654379   70.749368  \n",
       "car       126.267795  105.808478   75.286177  \n",
       "car       112.934067   92.999160   64.207243  \n",
       "car       100.927558   77.626185   47.108573  \n",
       "car       113.511323   93.031836   63.031600  \n",
       "car       118.539593   99.612567   70.574933  \n",
       "wall       81.942004   58.464866   35.962126  \n",
       "wall      107.735223   88.377882   60.469140  \n",
       "wall      108.037270   89.334072   63.034933  \n",
       "wall      109.237676   91.215927   64.221543  \n",
       "wall      107.559358   88.538726   60.572407  \n",
       "wall      107.069296   87.832864   59.813149  \n",
       "wall       93.882609   74.706132   53.730628  \n",
       "wall      123.381176  106.531691   78.604866  \n",
       "signpost   93.377499   71.594443   41.587655  \n",
       "signpost  115.349788   97.021512   68.573736  \n",
       "signpost   77.175513   58.084765   33.238076  \n",
       "signpost  126.562421  106.490377   75.208317  \n",
       "signpost  147.062863  129.598573   97.557180  \n",
       "signpost  132.024350  114.040097   83.525361  \n",
       "signpost  144.078708  131.340982  106.081633  \n",
       "signpost  131.184657  112.552549   82.011781  \n",
       "\n",
       "[32 rows x 932 columns]"
      ]
     },
     "execution_count": 120,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['wall', 'wall', 'wall', 'wall', 'wall', 'wall', 'wall', 'wall',\n",
       "       'car', 'car', 'car', 'car', 'car', 'car', 'car', 'tree', 'wall',\n",
       "       'signpost', 'signpost', 'wall', 'signpost', 'wall', 'signpost',\n",
       "       'wall', 'wall', 'signpost', 'signpost', 'signpost', 'signpost',\n",
       "       'signpost', 'wall', 'wall'], dtype=object)"
      ]
     },
     "execution_count": 121,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_cpred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Making model for session group 20210319_16:08:41.692-20210310_15:25:26.159\n"
     ]
    },
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: './models/v8/20210319_16:08:41.692-20210310_15:25:26.159.pth'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0mTraceback (most recent call last)",
      "\u001b[0;32m<ipython-input-117-0d7db5f99f45>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     62\u001b[0m     \u001b[0mfilename\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtest_list\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"-\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m\"-\"\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mtest_list\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"-\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     63\u001b[0m     \u001b[0mPATH1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'./models/v8/'\u001b[0m\u001b[0;34m+\u001b[0m \u001b[0mfilename\u001b[0m \u001b[0;34m+\u001b[0m\u001b[0;34m'.pth'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 64\u001b[0;31m     \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_state_dict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mPATH1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     65\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     66\u001b[0m     \u001b[0mtest_lbl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_cpred\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mval_acc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_loss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_confusion_matrix\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtest_nn_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/serialization.py\u001b[0m in \u001b[0;36mload\u001b[0;34m(f, map_location, pickle_module, **pickle_load_args)\u001b[0m\n\u001b[1;32m    380\u001b[0m             \u001b[0;34m(\u001b[0m\u001b[0msys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mversion_info\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m2\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0municode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    381\u001b[0m         \u001b[0mnew_fd\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 382\u001b[0;31m         \u001b[0mf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'rb'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    383\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0msys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mversion_info\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m3\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpathlib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mPath\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    384\u001b[0m         \u001b[0mnew_fd\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: './models/v8/20210319_16:08:41.692-20210310_15:25:26.159.pth'"
     ]
    }
   ],
   "source": [
    "temp_session_list = session_list\n",
    "nb_classes = 4\n",
    "batch_size = 4\n",
    "predicted_labels = []\n",
    "true_labels = []\n",
    "while len(temp_session_list)>0:\n",
    "    #print(len(session_list))\n",
    "    sess_labels = label_sessions(temp_session_list)\n",
    "\n",
    "    df_session_list = pd.DataFrame(temp_session_list)\n",
    "    df_session_list.index = sess_labels\n",
    "\n",
    "    test_list = []\n",
    "    for sl in set(sess_labels):\n",
    "        try:\n",
    "            test_list.extend(df_session_list.loc[df_session_list.index == sl].sort_values(by=[0]).iloc[0].values.tolist())\n",
    "        except: continue\n",
    "    #print(test_list)\n",
    "    #for sl in set(sess_labels):\n",
    "    test_data = pd.DataFrame()\n",
    "    train_data = pd.DataFrame()\n",
    "    #test_list.extend(df_session_list.loc[df_session_list.index == sl].sample(1).values.tolist()[0])\n",
    "    count = 0\n",
    "    \n",
    "    temp_session_list = list(set(temp_session_list) - set(test_list))\n",
    "    for ts in test_list:\n",
    "        #print(\"|\" + \"*\"*(count+1) + ' '*(len(train_list)-1-count)+ \"| \" +str(format((count+1)/len(train_list)*100,'.3f')) + \"% is complete...\" ,end=\"\\r\")\n",
    "        tr = read_data(dates, ts)\n",
    "        test_data = pd.concat([test_data,tr],axis=0,ignore_index=False)\n",
    "        count = count+1\n",
    "\n",
    "        test_data.dropna(inplace=True, axis=0)\n",
    "\n",
    "    test_feat = test_data#extract_mfcc_feat(test_data)\n",
    "    \n",
    "    test_feat.dropna(axis=0,inplace=True)\n",
    "    \n",
    "    \n",
    "    X_test, y_test = make_data(test_feat)\n",
    "    \n",
    "    #def prep_data(X_train, y_train, X_test, y_test):\n",
    "    label_encoder = preprocessing.LabelEncoder()\n",
    "    training_targets = label_encoder.fit_transform(y_train)\n",
    "\n",
    "    #Read testing data\n",
    "    #testing_timestamps,testing_labels,testing_data = read_test_data(test_list)\n",
    "\n",
    "    #Encode\n",
    "    testing_targets = label_encoder.transform(y_test)\n",
    "\n",
    "    #Make training dataloader\n",
    "    #train_dataloader = make_train_dataloader(training_targets, X_train)\n",
    "\n",
    "    #Make test dataloader\n",
    "    test_dataloader = make_test_dataloader(testing_targets, X_test)\n",
    "\n",
    "    #return train_dataloader, test_dataloader\n",
    "    \n",
    "    print(\"Making model for session group \" + test_list[0].split(\"-\")[0] + \"-\" + test_list[-1].split(\"-\")[0])\n",
    "    \n",
    "    #model,val_accuracies,val_losses,train_accuracies,train_losses = train_nn_model()\n",
    "    filename = test_list[0].split(\"-\")[0] + \"-\" + test_list[-1].split(\"-\")[0]\n",
    "    PATH1 = './models/v8/'+ filename +'.pth'\n",
    "    model.load_state_dict(torch.load(PATH1))\n",
    "    \n",
    "    test_lbl, test_cpred,val_acc, val_loss, test_confusion_matrix = test_nn_model(model)\n",
    "    #print(\"Validation accuracy = \",val_acc)\n",
    "    #print(\"Validation loss = \",val_loss)\n",
    "    print(test_confusion_matrix)\n",
    "    class_report = classification_report(test_lbl, test_cpred)\n",
    "    print(class_report)\n",
    "    \n",
    "    predicted_labels.extend(test_cpred)\n",
    "    true_labels.extend(test_lbl)\n",
    "    \n",
    "    print(\"Overall results...\")   \n",
    "    print(confusion_matrix(true_labels, predicted_labels))\n",
    "    print(classification_report(true_labels, predicted_labels))\n",
    "    #break\n",
    "    \n",
    "#     plt.ylabel(\"accuracy\")\n",
    "#     plt.xlabel(\"epoch\")\n",
    "#     plt.plot(train_accuracies, label=\"train\")\n",
    "#     plt.plot(val_accuracies, label=\"test\")\n",
    "#     plt.legend()\n",
    "#     plt.savefig('./visual/'+ \"accuracy_\"+ filename + \".png\")\n",
    "#     plt.close()\n",
    "    \n",
    "#     plt.ylabel(\"loss\")\n",
    "#     plt.xlabel(\"epoch\")\n",
    "#     plt.plot(train_losses, label=\"train\")\n",
    "#     plt.plot(val_losses, label=\"test\")\n",
    "#     plt.legend()\n",
    "#     plt.savefig('./visual/'+ \"loss_\"+ filename + \".png\")\n",
    "#     plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['20210310_15:26:59.160-20210319_16:13:09.655',\n",
       " '20210310_15:25:26.159-20210319_16:08:41.692',\n",
       " '20210310_15:32:48.233-20210319_16:21:59.598',\n",
       " '20210310_15:30:50.167-20210319_16:17:22.477',\n",
       " '20210310_15:29:41.711-20210319_16:15:55.217',\n",
       " '20210310_15:31:57.174-20210319_16:18:28.688',\n",
       " '20210310_15:29:00.353-20210319_16:14:50.583',\n",
       " '20210310_15:31:09.318-20210319_16:17:45.271',\n",
       " '20210310_15:32:32.730-20210319_16:21:29.421',\n",
       " '20210310_15:25:48.350-20210319_16:10:10.704',\n",
       " '20210310_15:33:58.721-20210319_16:23:03.444',\n",
       " '20210319_16:26:51.249-20210319_16:26:51.249',\n",
       " '20210310_15:29:25.107-20210319_16:15:18.712',\n",
       " '20210310_15:26:14.684-20210319_16:10:32.051',\n",
       " '20210310_15:30:21.964-20210319_16:16:47.785',\n",
       " '20210310_15:34:48.696-20210319_16:26:08.675',\n",
       " '20210310_15:34:21.045-20210319_16:23:44.170',\n",
       " '20210310_15:30:04.369-20210319_16:16:17.283',\n",
       " '20210310_15:32:14.252-20210319_16:19:24.958',\n",
       " '20210310_15:27:20.548-20210319_16:14:28.970',\n",
       " '20210310_15:26:36.351-20210319_16:11:12.300']"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20210310_15:26:59.160-20210310_15:27:08.845\n",
      "20210310_15:44:04.924-20210310_15:44:15.189\n",
      "20210315_17:07:38.925-20210315_17:07:48.142\n",
      "20210319_16:13:09.655-20210319_16:13:20.391\n",
      "\n",
      "20210310_15:25:26.159-20210310_15:25:39.816\n",
      "20210310_15:42:00.571-20210310_15:42:11.946\n",
      "20210315_17:05:24.467-20210315_17:05:35.463\n",
      "20210319_16:08:41.692-20210319_16:08:51.649\n",
      "\n",
      "20210310_15:32:48.233-20210310_15:32:58.401\n",
      "20210310_15:52:48.777-20210310_15:52:58.321\n",
      "20210315_17:20:38.369-20210315_17:20:48.298\n",
      "20210319_16:21:59.598-20210319_16:22:09.200\n",
      "\n",
      "20210310_15:30:50.167-20210310_15:31:01.015\n",
      "20210310_15:51:04.495-20210310_15:51:14.504\n",
      "20210315_17:11:54.379-20210315_17:12:04.246\n",
      "20210319_16:17:22.477-20210319_16:17:32.588\n",
      "\n",
      "20210310_15:29:41.711-20210310_15:29:51.347\n",
      "20210310_15:49:41.258-20210310_15:49:51.348\n",
      "20210315_17:09:47.785-20210315_17:09:56.866\n",
      "20210319_16:15:55.217-20210319_16:16:06.432\n",
      "\n",
      "20210310_15:31:57.174-20210310_15:32:07.006\n",
      "20210310_15:51:45.847-20210310_15:51:55.083\n",
      "20210315_17:13:29.822-20210315_17:13:40.619\n",
      "20210319_16:18:28.688-20210319_16:18:39.650\n",
      "\n",
      "20210310_15:29:00.353-20210310_15:29:09.829\n",
      "20210310_15:46:20.984-20210310_15:46:32.410\n",
      "20210315_17:08:39.633-20210315_17:08:48.837\n",
      "20210319_16:14:50.583-20210319_16:15:00.821\n",
      "\n",
      "20210310_15:31:09.318-20210310_15:31:20.694\n",
      "20210310_15:51:22.201-20210310_15:51:34.120\n",
      "20210315_17:12:13.407-20210315_17:12:23.341\n",
      "20210319_16:17:45.271-20210319_16:17:57.477\n",
      "\n",
      "20210310_15:32:32.730-20210310_15:32:42.915\n",
      "20210310_15:52:24.012-20210310_15:52:34.588\n",
      "20210315_17:19:31.337-20210315_17:19:40.940\n",
      "20210319_16:21:29.421-20210319_16:21:39.386\n",
      "\n",
      "20210310_15:25:48.350-20210310_15:25:58.158\n",
      "20210310_15:42:19.717-20210310_15:42:31.077\n",
      "20210315_17:05:51.089-20210315_17:06:00.494\n",
      "20210319_16:10:10.704-20210319_16:10:21.506\n",
      "\n",
      "20210310_15:33:58.721-20210310_15:34:08.178\n",
      "20210310_15:54:24.829-20210310_15:54:36.180\n",
      "20210315_17:21:29.553-20210315_17:21:39.505\n",
      "20210319_16:23:03.444-20210319_16:23:13.463\n",
      "\n",
      "20210319_16:26:51.249-20210319_16:27:02.576\n",
      "\n",
      "20210310_15:29:25.107-20210310_15:29:34.689\n",
      "20210310_15:47:27.823-20210310_15:47:37.342\n",
      "20210315_17:09:10.210-20210315_17:09:20.081\n",
      "20210319_16:15:18.712-20210319_16:15:29.511\n",
      "\n",
      "20210310_15:26:14.684-20210310_15:26:25.036\n",
      "20210310_15:42:43.374-20210310_15:42:54.045\n",
      "20210315_17:06:18.458-20210315_17:06:28.282\n",
      "20210319_16:10:32.051-20210319_16:10:42.621\n",
      "\n",
      "20210310_15:30:21.964-20210310_15:30:32.030\n",
      "20210310_15:50:19.873-20210310_15:50:29.207\n",
      "20210315_17:10:40.285-20210315_17:10:49.683\n",
      "20210319_16:16:47.785-20210319_16:16:57.626\n",
      "\n",
      "20210310_15:34:48.696-20210310_15:34:57.898\n",
      "20210315_17:23:00.273-20210315_17:23:09.830\n",
      "20210319_16:26:08.675-20210319_16:26:18.199\n",
      "\n",
      "20210310_15:34:21.045-20210310_15:34:32.102\n",
      "20210310_15:58:17.102-20210310_15:58:34.089\n",
      "20210315_17:21:47.752-20210315_17:21:57.917\n",
      "20210319_16:23:44.170-20210319_16:23:54.026\n",
      "\n",
      "20210310_15:30:04.369-20210310_15:30:13.898\n",
      "20210310_15:50:03.345-20210310_15:50:15.186\n",
      "20210315_17:10:08.695-20210315_17:10:18.533\n",
      "20210319_16:16:17.283-20210319_16:16:28.357\n",
      "\n",
      "20210310_15:32:14.252-20210310_15:32:24.462\n",
      "20210310_15:52:00.814-20210310_15:52:11.246\n",
      "20210315_17:17:00.289-20210315_17:17:10.236\n",
      "20210319_16:19:24.958-20210319_16:19:34.607\n",
      "\n",
      "20210310_15:27:20.548-20210310_15:27:30.566\n",
      "20210310_15:45:59.889-20210310_15:46:12.812\n",
      "20210315_17:08:00.532-20210315_17:08:09.611\n",
      "20210319_16:14:28.970-20210319_16:14:38.999\n",
      "\n",
      "20210310_15:26:36.351-20210310_15:26:45.720\n",
      "20210310_15:43:03.762-20210310_15:43:16.249\n",
      "20210315_17:07:11.513-20210315_17:07:20.684\n",
      "20210319_16:11:12.300-20210319_16:11:24.827\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "    #for m in model_list:\n",
    "    f = open(\"models/v8/\" + model + \".txt\", \"r\")\n",
    "    print(f.read())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['20210310_15:26:36.351-20210310_15:26:45.720',\n",
       " '20210310_15:43:03.762-20210310_15:43:16.249',\n",
       " '20210315_17:07:11.513-20210315_17:07:20.684',\n",
       " '20210319_16:11:12.300-20210319_16:11:24.827']"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 576x396 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 576x396 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "for x in range(10):\n",
    "    p = [0,1,2,3,4,5,6,7,8,9]\n",
    "    plt.ylabel(\"loss\")\n",
    "    plt.xlabel(\"epoch\")\n",
    "    plt.plot(p, label=\"train\")\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "    plt.close()\n",
    "    \n",
    "    p = [0,1,2,3,4,5,6,7,8,9]\n",
    "    plt.ylabel(\"loss\")\n",
    "    plt.xlabel(\"epoch\")\n",
    "    plt.plot(p[::-1], label=\"train\")\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "    plt.close()\n",
    "    #plt.savefig('./visual/'+ \"loss_\"+ filename + \".png\")\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test = X_test.iloc[:28]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test = y_test[:28]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {},
   "outputs": [],
   "source": [
    "testing_targets = label_encoder.transform(y_test)\n",
    "test_dataloader = make_test_dataloader(testing_targets, X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_acc, val_loss, test_confusion_matrix = test_nn_model(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = test_list[0].split(\"-\")[0] + \"-\" + test_list[-1].split(\"-\")[0]\n",
    "PATH = './models/'+ filename +'.pth'\n",
    "torch.save(model.state_dict(), PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'20210319_16:10:10.704-20210310_15:42:19.717'"
      ]
     },
     "execution_count": 152,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "filename = test_list[0].split(\"-\")[0] + \"-\" + test_list[-1].split(\"-\")[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "test_feat = test_data#extract_mfcc_feat(test_data)\n",
    "train_feat = train_data#extract_mfcc_feat(train_data)\n",
    "test_feat.dropna(axis=0,inplace=True)\n",
    "train_feat.dropna(axis=0,inplace=True)\n",
    "X_train, y_train = make_data(train_feat)\n",
    "X_test, y_test = make_data(test_feat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 527,
   "metadata": {},
   "outputs": [],
   "source": [
    "sess_labels = label_sessions(session_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 528,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_session_list = pd.DataFrame(session_list)\n",
    "df_session_list.index = sess_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 529,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>tree</th>\n",
       "      <td>20210310_15:25:26.159-20210310_15:25:39.816</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>tree</th>\n",
       "      <td>20210310_15:25:48.350-20210310_15:25:58.158</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>tree</th>\n",
       "      <td>20210310_15:26:14.684-20210310_15:26:25.036</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>tree</th>\n",
       "      <td>20210310_15:26:36.351-20210310_15:26:45.720</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>tree</th>\n",
       "      <td>20210310_15:26:59.160-20210310_15:27:08.845</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>signpost</th>\n",
       "      <td>20210319_16:21:59.598-20210319_16:22:09.200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>signpost</th>\n",
       "      <td>20210319_16:23:03.444-20210319_16:23:13.463</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>signpost</th>\n",
       "      <td>20210319_16:23:44.170-20210319_16:23:54.026</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>signpost</th>\n",
       "      <td>20210319_16:26:08.675-20210319_16:26:18.199</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>signpost</th>\n",
       "      <td>20210319_16:26:51.249-20210319_16:27:02.576</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>80 rows  1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                    0\n",
       "tree      20210310_15:25:26.159-20210310_15:25:39.816\n",
       "tree      20210310_15:25:48.350-20210310_15:25:58.158\n",
       "tree      20210310_15:26:14.684-20210310_15:26:25.036\n",
       "tree      20210310_15:26:36.351-20210310_15:26:45.720\n",
       "tree      20210310_15:26:59.160-20210310_15:27:08.845\n",
       "...                                               ...\n",
       "signpost  20210319_16:21:59.598-20210319_16:22:09.200\n",
       "signpost  20210319_16:23:03.444-20210319_16:23:13.463\n",
       "signpost  20210319_16:23:44.170-20210319_16:23:54.026\n",
       "signpost  20210319_16:26:08.675-20210319_16:26:18.199\n",
       "signpost  20210319_16:26:51.249-20210319_16:27:02.576\n",
       "\n",
       "[80 rows x 1 columns]"
      ]
     },
     "execution_count": 529,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_session_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 537,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_list = []\n",
    "for sl in set(sess_labels):\n",
    "    try:\n",
    "        test_list.extend(df_session_list.loc[df_session_list.index == sl].sort_values(by=[0]).iloc[0].values.tolist())\n",
    "    except: continue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 538,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_list.sort()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 539,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['20210310_15:25:26.159-20210310_15:25:39.816',\n",
       " '20210310_15:42:00.571-20210310_15:42:11.946',\n",
       " '20210315_17:05:24.467-20210315_17:05:35.463',\n",
       " '20210319_16:08:41.692-20210319_16:08:51.649']"
      ]
     },
     "execution_count": 539,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 480,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    20210319_16:08:41.692-20210319_16:08:51.649\n",
       "Name: signpost, dtype: object"
      ]
     },
     "execution_count": 480,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_session_list.loc[df_session_list.index == sl].iloc[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'test_list' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m\u001b[0m",
      "\u001b[0;31mNameError\u001b[0mTraceback (most recent call last)",
      "\u001b[0;32m<ipython-input-61-593766006ef7>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtest_list\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'test_list' is not defined"
     ]
    }
   ],
   "source": [
    "test_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'train_accuracies' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m\u001b[0m",
      "\u001b[0;31mNameError\u001b[0mTraceback (most recent call last)",
      "\u001b[0;32m<ipython-input-154-9cb0f1343365>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mylabel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"accuracy\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mxlabel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"epoch\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_accuracies\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"train\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mval_accuracies\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"test\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlegend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'train_accuracies' is not defined"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 576x396 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.ylabel(\"accuracy\")\n",
    "plt.xlabel(\"epoch\")\n",
    "plt.plot(train_accuracies, label=\"train\")\n",
    "plt.plot(val_accuracies, label=\"test\")\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'train_losses' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m\u001b[0m",
      "\u001b[0;31mNameError\u001b[0mTraceback (most recent call last)",
      "\u001b[0;32m<ipython-input-159-fc6968928560>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mylabel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"loss\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mxlabel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"epoch\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_losses\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"train\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mval_losses\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"test\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlegend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'train_losses' is not defined"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 576x396 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.ylabel(\"loss\")\n",
    "plt.xlabel(\"epoch\")\n",
    "plt.plot(train_losses, label=\"train\")\n",
    "plt.plot(val_losses, label=\"test\")\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 401,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAikAAAHVCAYAAAA0K2vhAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDMuMC4zLCBodHRwOi8vbWF0cGxvdGxpYi5vcmcvnQurowAAIABJREFUeJzt3XuYlOV9//H3F4mKBzDrgUWkFTA1FiKWoL/aQKPrD1gVFQ2JpZpGJaWp6WUiJQGPSUyNtdHmZ1I1QWM9VNOoQdFgDAejqFkTUEQNMaaiVjmZiogKMRzu3x8z0FU5zB5mnueZfb+ua66dueeZeb7DsLuf/d7380yklJAkScqbblkXIEmStDWGFEmSlEuGFEmSlEuGFEmSlEuGFEmSlEuGFEmSlEuGFEmSlEuGFEmSlEuGFEmSlEvdq72Dvn37ekrbglq6dGnWJUhdlmcDL7aIiBrvr9P/w6SUavoatsZOiiRJyqWqd1IkSVJ11bhxUzN2UiRJUi7ZSZEkqeDspEiSJNWQnRRJkgquXjsphhRJkgquW7f6nBipz1clSZIKz06KJEkFV6/TPXZSJElSLtlJkSSp4Oq1k2JIkSSp4Oo1pDjdI0mScslOiiRJBWcnRZIkqYbspEiSVHD12kkxpEiSVHCecVaSJKmG7KRIklRw9TrdYydFkiTlkp0USZIKzk6KJElSDdlJkSSp4Oq1k2JIkSSp4Oo1pDjdI0mScslOiiRJBWcnRZIkqYbspEiSVHD1elp8Q4okSQXndI8kSVIN2UmRJKng7KRIkiTVkJ0USZIKrl47KYYUSZIKrl5DitM9kiQpl+ykSJJUcHZSJEmSashOiiRJBecZZyVJUi453SNJklRDdlIkSSo4OymSJEk1ZCdFkqSCs5MiSZJUQ3ZSJEkquHrtpBhSJEkquHoNKU73SJKkXLKTIklSwdXrGWfr81VJkqTCM6TswJVXXsmiRYuYO3fulrEvfelLzJ49m1mzZnHbbbfRu3fvLfddcsklPPLII8yePZvBgwdnUbIqsGbNGs455xyam5s59thjWbhwYdYlqUJLlizhpJNO2nIZOnQoN954Y9ZlqUI33ngjY8aM4YQTTmDSpEm88847WZdUFyKi0y95YEjZgdtvv53TTjvtXWPXXnstI0eOZNSoUcyZM4dzzz0XgKamJvr378/w4cOZMmUKl112WRYlqwKXXnopI0aM4P7772fGjBkMHDgw65JUoQEDBjBjxgxmzJjB9OnT6dGjByNHjsy6LFVg5cqV3HLLLdx5553ce++9bNq0iZkzZ2ZdVl3IIqRExA0R8WpEPNNq7JsR8WxEPBURd0XEXuXxAyNiXUQ8Wb58t5LXZUjZgV/84hesXr36XWNvvfXWluu77bYbKSUARo8ezZ133gnAE088Qa9evdhvv/1qV6wq8uabbzJ//nzGjRsHwM4770zPnj0zrkrt0dLSQr9+/ejbt2/WpahCGzdu5Pe//z0bNmxg3bp1/owsthuB5veMzQYGp5QOBZ4Dzmt13/MppcPKl89VsoMdLpyNiJ2Am1NKp+1o265kypQpjBs3jjVr1vDJT34SgMbGRpYtW7Zlm+XLl9PY2Mirr76aVZnaildeeYWGhgbOO+88nn32WQYNGsQFF1zAbrvtlnVpaqOZM2cyZsyYrMtQhXr37s1ZZ51FU1MTu+yyCx/72McYPnx41mXVhSymZ1JK8yLiwPeMzWp18zFgXEf2scNOSkppI/DHEbFzpU8aERMjYkFELHj77bc7Ul9uXX755Rx++OHcddddnHnmmVmXozbYsGEDixcvZvz48dx999306NGDadOmZV2W2ugPf/gDDzzwAM3N7/1DTnn1xhtvMHfuXObMmcO8efNYt24d99xzT9ZlaRta/y4vXya28SnOAn7S6nb/iFgYEQ9FxIhKnqDS6Z4lwKMRcVFETNp82dbGKaVpKaVhKaVhu+++e4W7KKbp06dz3HHHAbBixQr233//Lff16dOHFStWZFWatqGxsZHGxkaGDBkCQHNzM4sXL864KrXVvHnzGDRoEPvss0/WpahCLS0tHHDAATQ0NPCBD3yAkSNHumi9k1RjTUrr3+XlS8V/zUXEBcAG4Nby0HLgj1JKfwZMAm6LiB3Os1caUp4Hflzefs9Wly6pf//+W66PHj2a559/HoBZs2ZtWecwdOhQ1qxZ41RPDu277740NjayZMkSoPSD04WzxTNz5kyOP/74rMtQG/Tp04dFixaxbt06Ukq0tLQwYMCArMuqC926dev0S3tFxBnAGOC0VF60mVJ6J6X0Wvn645RyxZ/s6LkqOplbSulr7a624K6++mqOPPJIGhoaWLBgAVdccQVNTU0MHDiQTZs2sXTpUqZOnQrA3LlzaWpq4tFHH2XdunVMmrTNZpMydtFFFzF58mTWr19Pv379PBKrYNauXcvPf/5zLrnkkqxLURsMGTKEUaNGccopp9C9e3cOOeQQTj311KzLUieKiGbgy8DHU0prW43vC6xKKW2MiAHAhyjN0mz/+TYfmbKDne5b3ukgYNfN4ymlph09tm/fvjvegXJp6dKlWZcgdVmV/GxWfkWNV7Iecsghnf4f5te//vV2X0NE/AA4CtgHWAl8hdLRPLsAr5U3eyyl9LmI+ARwCbAe2AR8JaV0745qqPS0+LcCP6TUvvkc8BngdxU+VpIk1ZmU0vitDH9/G9v+CPhRW/dR6aTT3iml7wPrU0oPpZTOAnbYRZEkSdVXr2ecrbSTsr78dXlEHA8sAxqqU5IkSVLlIeWfIqIX8I/Ad4CewBerVpUkSapYV/8U5E9SWmT7TErpaGAkcHL1ypIkSZWq1+meSkPKoSmlLR9gk1JaBfxZdUqSJEmqfLqnW0R8MKX0OkBENLThsZIkqYrqdbqn0qBxJdASEXeUb38SuLQ6JUmSJFV+xtmbI2IB/3vY8SkpJT/sRJKkHMjLGpLOVvGUTTmUGEwkScqZeg0p9TmJJUmSCs/Fr5IkFVy9Lpytz1clSZIKz06KJEkFV69rUgwpkiQVnNM9kiRJNWQnRZKkgqvX6R47KZIkKZfspEiSVHCuSZEkSaohOymSJBVcva5JMaRIklRw9RpSnO6RJEm5ZCdFkqSCc+GsJElSDdlJkSSp4Op1TYohRZKkgnO6R5IkqYbspEiSVHD1Ot1jJ0WSJOWSnRRJkgquXjsphhRJkgrOhbOSJEk1ZCdFkqSCq9fpHjspkiQpl+ykSJJUcK5JkSRJqiE7KZIkFVy9rkkxpEiSVHD1GlKc7pEkSblkJ0WSpIJz4awkSVIN2UmRJKng6nVNiiFFkqSCc7pHkiSphuykSJJUcPU63WMnRZIk5ZKdFEmSCq5e16QYUiRJKrh6ne6pekhZunRptXehKqnX//RdxaZNm7IuQR2wcePGrEtQB3Tvbg+gM/ivKElSwdXrH5X1OYklSZIKz06KJEkFZydFkiSphuykSJJUcPXaSTGkSJJUcPUaUpzukSRJuWQnRZKkgrOTIkmSVEN2UiRJKrh67aQYUiRJKrh6DSlO90iSpFyykyJJUsF161afPYf6fFWSJKnw7KRIklRw9bomxZAiSVLB1WtIcbpHkiTlkp0USZIKzk6KJElSDdlJkSSp4OykSJIk1ZCdFEmSCs5OiiRJyqWI6PRLBfu8ISJejYhnWo01RMTsiPht+esHy+MREd+OiP+KiKciYmglr8uQIkmS2uNGoPk9Y1OBuSmlDwFzy7cBjgU+VL5MBK6tZAeGFEmSCi6LTkpKaR6w6j3DJwE3la/fBIxtNX5zKnkM2Csi+uxoH4YUSZL0PhExMSIWtLpMrOBhvVNKy8vXVwC9y9f7Ai+32u6V8th2uXBWkqSCq8bC2ZTSNGBaBx6fIiJ1pAZDiiRJBZejo3tWRkSflNLy8nTOq+XxpUC/VtsdUB7bLqd7JElSZ7kH+Ez5+meAGa3G/6Z8lM+fA2+0mhbaJjspkiQVXBadlIj4AXAUsE9EvAJ8Bfhn4PaImAC8BHyqvPl9wHHAfwFrgTMr2YchRZIktVlKafw27jpmK9sm4PNt3YchRZKkgsvRmpROZUiRJKng6jWkuHBWkiTlkp0USZIKzk6KJElSDdlJkSSp4OykSJIk1ZCdFEmSCq5eOymGFEmSCq5eQ4rTPZIkKZfspEiSVHB2UiRJkmrITookSQVXr50UQ4okSQVXryHF6R5JkpRLdlIkSSo4OymSJEk1ZCdFkqSCq9dOiiFFkqSCq9eQ4nRPB6xZs4ZzzjmH5uZmjj32WBYuXJh1SWrl+9//PitXruTpp59+332TJk0ipcTee+8NwF//9V+zaNEinnrqKR599FEOPfTQWperNrjxxhsZM2YMJ5xwApMmTeKdd97JuiRtx4UXXsiIESM46aSTtoz99Kc/5cQTT2Tw4ME888wzGVanPDOkdMCll17KiBEjuP/++5kxYwYDBw7MuiS1cuONN9Lc3Py+8QMOOIBRo0bx0ksvbRl74YUX+PjHP86hhx7K17/+daZNm1bLUtUGK1eu5JZbbuHOO+/k3nvvZdOmTcycOTPrsrQdY8eO5Xvf+967xg466CCuuuoqhg0bllFV9SUiOv2SBxWFlIjYpZKxruTNN99k/vz5jBs3DoCdd96Znj17ZlyVWnv44YdZtWrV+8a/9a1v8eUvf5mU0paxlpYWVq9eDcBjjz3GAQccULM61XYbN27k97//PRs2bGDdunXst99+WZek7Rg2bBi9evV619jAgQPp379/RhWpKCrtpLRUONZlvPLKKzQ0NHDeeecxduxYLrjgAtauXZt1WdqBE088kaVLl/LUU09tc5sJEybwk5/8pIZVqS169+7NWWedRVNTEyNGjGDPPfdk+PDhWZclZapLdlIiojEiPgr0iIg/i4ih5ctRwG7bedzEiFgQEQvqtW2+YcMGFi9ezPjx47n77rvp0aOHUwQ516NHD84//3wuvvjibW5z1FFHMWHCBKZMmVLDytQWb7zxBnPnzmXOnDnMmzePdevWcc8992RdlpSpeg0pOzq6ZzRwBnAAcCWwueo3gfO39aCU0jRg82/stK3tiqyxsZHGxkaGDBkCQHNzsyEl5za3lxctWgSU1qY88cQTHHHEEaxcuZKPfOQjXH/99Rx77LFbnSZSPrS0tHDAAQfQ0NAAwMiRI1m4cCEnnnhixpVJ6mzbDSkppZuAmyLiEymlH9WopkLYd999aWxsZMmSJQwYMICWlhYXzubcM888Q+/evbfcfuGFFxg2bBivvfYa/fr1Y/r06Xz605/mt7/9bYZVakf69OnDokWLWLduHbvuuistLS0MHjw467KkTHXrVp/HwVR6npQDIqInpQ7KdcBQYGpKaVbVKiuAiy66iMmTJ7N+/Xr69evHZZddlnVJauW2227jqKOOYp999uHll1/mK1/5CjfccMNWt7344ovZe++9ueaaa4DSdN7hhx9ey3JVoSFDhjBq1ChOOeUUunfvziGHHMKpp56adVnajsmTJzN//nxWr15NU1MTn//85+nVqxff+MY3WLVqFWeffTYHH3ww1113XdalKmei9REO29woYlFKaUhEjAY+B1wI3JJSGlrBPupyuqcryMucpNpn06ZNWZegDti4cWPWJagDunfvXtMfoFOmTOn037WXX3555r8EKu0PbS70OODmlNKvWo1JkiR1ukqnex6PiFlAf+C8iNgT8M80SZJyoF4735WGlAnAYcCSlNLaiNgbOLN6ZUmSpEp16ZCSUtoUEQcAf13+h3gopXRvVSuTJEldWkUhJSL+GTgcuLU8dE5EHJlS2ua5UiRJUm106U4KpQWzh6WUNgFExE3AQrZzQjdJkqSOqDSkAOwFbD4NZ6/tbShJkmqnq3dSLgMWRsTPKB16/JfA1KpVJUmSKtalQ0pK6QcR8SCldSkJmJJSWlHNwiRJUtfWlumeI4HhlEJKd+CuqlQkSZLapF47KRWdcTYirqF0OvyngWeAv4uIq6tZmCRJ6toq7aQ0AYek8gf9lI/u+VXVqpIkSRWr105KpSHlv4A/Al4q3+5XHpMkSRnr6iFlT+DXEfFLSmtSjgAWRMQ9ACmlE6tUnyRJ6qIqDSkXV7UKSZLUbl26k5JSeqjahUiSJLVW6Wf3nAJcDuxH6WRuAaSUUs8q1iZJkirQrVtFB+sWTqXTPf8CnJBS+nU1i5EkSdqs0pCy0oAiSVI+dek1KZSO5PkhcDfwzubBlNL0qlQlSZIq1tVDSk9gLTCq1VgCDCmSJKkqKj2658xqFyJJktqnS3dSIuLbWxl+A1iQUprRuSVJkiRV+AGDwK7AYcBvy5dDgQOACRHx/6pUmyRJqkBEdPolDypdk3Io8LGU0kaAiLgWeBgYTumTkSVJUkbyEio6W6WdlA8Ce7S6vTvQUA4t72z9IZIkSe3XlpO5PRkRD1I62+xfAt+IiN2BOVWqTZIkVaBeOymVHt3z/Yi4j9KnHwOcn1JaVr7+papUJkmSurTthpSI+HBK6dmIGFoeern8tTEiGlNKT1S3PEmStCNdtZMyCZgIXNlqLLW63tTpFUmSpDap15Cy3YWzKaWJ5avXAiellI4GfkbpHCmTq1ybJEnqwio9uufClNKaiBhOqXtyPaXgIkmSMlav50mpNKRsLH89HrgupTQT2Lk6JUmSJFV+CPLSiPgeMBK4PCJ2ofKAI0mSqqhbt/r8lVzpq/oU8FNgdEppNdCAhx5LkqQqqvQ8KWuB6a1uLweWV6soSZJUubysIelslU73SJKknKrXkFKfk1iSJKnw7KRIklRwdlIkSZJqyE6KJEkFV6+dFEOKJEkFV68hxekeSZKUS3ZSJEkquCw6KRFxMPDDVkMDgIuBvYC/BX5XHj8/pXRfe/ZhSJEkSW2WUvoNcBhAROwELAXuAs4EvpVSuqKj+zCkSJJUcDlYk3IM8HxK6aXOrMU1KZIkFVxEVOMyMSIWtLpM3E4JfwX8oNXtf4iIpyLihoj4YHtflyFFkiS9T0ppWkppWKvLtK1tFxE7AycCd5SHrgUGUpoKWg5c2d4anO6RJKngMp7uORZ4IqW0EmDzV4CIuA74cXuf2JCibUopZV2COqBv375Zl6AOePnll7MuQarUeFpN9UREn5TS8vLNk4Fn2vvEhhRJkgquW7dsVm9ExO7ASODvWg3/S0QcBiTgxffc1yaGFEmS1C4ppbeBvd8z9unOen5DiiRJBZeDQ5CrwpAiSVLB1WtI8RBkSZKUS3ZSJEkqODspkiRJNWQnRZKkgsvqEORqM6RIklRwTvdIkiTVkJ0USZIKzk6KJElSDdlJkSSp4Oq1k2JIkSSp4Oo1pDjdI0mScslOiiRJBVev50mpz1clSZIKz06KJEkF55oUSZKkGrKTIklSwdVrJ8WQIklSwdVrSHG6R5Ik5ZKdFEmSCs5DkCVJkmrITookSQVXr2tSDCmSJBVcvYYUp3skSVIu2UmRJKng7KRIkiTVkJ0USZIKrl47KYYUSZIKzvOkSJIk1ZCdFEmSCq5ep3vspEiSpFyykyJJUsHZSZEkSaohOymSJBVcvXZSDCmSJBWchyBLkiTVkJ0USZIKrl6ne+ykSJKkXLKTIklSwdVrJ8WQIklSwdVrSHG6R5Ik5ZKdFEmSCs5OiiRJUg3ZSZEkqeDq9WRuhhRJkgrO6R5JkqQaspMiSVLB2UnR+6xZs4ZzzjmH5uZmjj32WBYuXJh1SaqQ713+XXnllSxatIi5c+duGfvSl77E7NmzmTVrFrfddhu9e/fect8ll1zCI488wuzZsxk8eHAWJasCN998MyeccAJjxozhpptuyroc5ZwhpQMuvfRSRowYwf3338+MGTMYOHBg1iWpQr53+Xf77bdz2mmnvWvs2muvZeTIkYwaNYo5c+Zw7rnnAtDU1ET//v0ZPnw4U6ZM4bLLLsuiZO3Ac889xx133MHtt9/O3XffzYMPPshLL72UdVl1ISI6/ZIHhpR2evPNN5k/fz7jxo0DYOedd6Znz54ZV6VK+N4Vwy9+8QtWr179rrG33npry/XddtuNlBIAo0eP5s477wTgiSeeoFevXuy33361K1YVWbJkCYceeig9evSge/fuHH744cyePTvrspRjOwwpEbFbRFwUEdeVb38oIsZUv7R8e+WVV2hoaOC8885j7NixXHDBBaxduzbrslQB37timzJlCvPnz+fkk0/mm9/8JgCNjY0sW7ZsyzbLly+nsbExqxK1DR/60Id4/PHHef3111m3bh3z5s1jxYoVWZdVF7p169bplzyopIp/B94BjizfXgr80/YeEBETI2JBRCyYNm1aB0vMpw0bNrB48WLGjx/P3XffTY8ePajX11pvfO+K7fLLL+fwww/nrrvu4swzz8y6HLXBwIED+exnP8tnP/tZ/vZv/5YPf/jDufllWHRdebpnYErpX4D1ACmltcB2q08pTUspDUspDZs4cWInlJk/jY2NNDY2MmTIEACam5tZvHhxxlWpEr539WH69Okcd9xxAKxYsYL9999/y319+vTxL/ScGjduHD/60Y/4j//4D3r16sWBBx6YdUnKsUpCyh8iogeQACJiIKXOSpe277770tjYyJIlSwBoaWlx8WVB+N4VV//+/bdcHz16NM8//zwAs2bN2rLGaOjQoaxZs4ZXX301kxq1fa+99hoAy5YtY/bs2YwZ0+VXD2g7KjlPyleA+4F+EXEr8DHgjGoWVRQXXXQRkydPZv369fTr188jCgrE9y7/rr76ao488kgaGhpYsGABV1xxBU1NTQwcOJBNmzaxdOlSpk6dCsDcuXNpamri0UcfZd26dUyaNCnj6rUtX/jCF1i9ejXdu3fnoosuctG6tis2r47f7kYRewN/Tmma57GU0v+0YR873oGkTte3b9+sS1AHvPzyy1mXoA7o1q1bTRd1PPjgg53+u/aoo47KfGFKJUf3BHAs8NGU0o+B3SLiiKpXJkmSKtKVF85eQ+nInvHl228CV1etIkmSJCpbk/J/UkpDI2IhQErp9YjYucp1SZKkCuWl89HZKumkrI+Infjfo3v2BTZVtSpJktTlVdJJ+TZwF7BfRFwKjAMurGpVkiSpYvXaSdlhSEkp3RoRjwPHUDq6Z2xK6ddVr0ySJFWkS4aU8jTPr1JKHwaerU1JkiRJOwgpKaWNEfGbiPijlNJ/16ooSZJUuS7ZSSn7IPCriPgl8PbmwZTSiVWrSpIkdXmVhJRdgdYfrhDA5dUpR5IktVVX7qR0Tyk91Hqg/IGDkiRJVbPNkBIRfw+cDQyIiKda3bUn8Gi1C5MkSV3b9joptwE/AS4DprYafzOltKqqVUmSpIp1uemelNIbwBv872f2SJIk1Uwla1IkSVKOZdVJiYgXKX3w8EZgQ0ppWEQ0AD8EDgReBD6VUnq9Pc9fyWf3SJIkbcvRKaXDUkrDyrenAnNTSh8C5vLuJSNtYkiRJKngIqLTLx1wEnBT+fpNwNj2PpEhRZKkgqtGSImIiRGxoNVl4lZ2nYBZEfF4q/t7p5SWl6+vAHq393W5JkWSJL1PSmkaMG0Hmw1PKS2NiP2A2RHxrs/5SymliEjtrcGQIklSwWW1cDaltLT89dWIuAs4AlgZEX1SSssjog/wanuf3+keSZLUZhGxe0Tsufk6MAp4BrgH+Ex5s88AM9q7DzspkiQVXEadlN7AXeV9dwduSyndHxHzgdsjYgLwEvCp9u7AkCJJUsFlEVJSSkuAIVsZfw04pjP24XSPJEnKJUOKJEnKJUOKJEnKJdekSJJUcF3uU5AlSVIx1GtIcbpHkiTlkp0USZIKzk6KJElSDdlJkSSp4OykSJIk1ZCdFEmSCq5eOymGFEmSCq5eQ4rTPZIkKZfspEiSVHB2UiRJkmrITookSQVnJ0WSJKmGDCmSJCmXnO6RJKngnO6RJEmqITspkiQVXL12UgwpkiQVXL2GFKd7JElSLtlJkSSp4OykSJIk1ZCdFEmSCq5eOylVDykbNmyo9i5UJW+//XbWJagDli5dmnUJ6oAjjzwy6xLUAS0tLVmXUBfspEiSVHD12klxTYokScolQ4okScolp3skSSo4p3skSZJqyE6KJEkFZydFkiSphgwpkiQpl5zukSSp4JzukSRJqiE7KZIkFVy9dlIMKZIkFVy9hhSneyRJUi4ZUiRJUi4ZUiRJUi65JkWSpIJzTYokSVIN2UmRJKng7KRIkiTVkCFFkiTlktM9kiQVnNM9kiRJNWQnRZKkgqvXToohRZKkgqvXkOJ0jyRJyiVDiiRJyiVDiiRJyiXXpEiSVHD1uibFkCJJUsHVa0hxukeSJOWSnRRJkgrOTookSVINGVIkSVIuGVIkSVIuuSZFkqSCq9c1KYYUSZIKrl5DitM9kiQplwwpkiQplwwpkiQpl1yTIklSwdXrmhRDiiRJBVevIcXpHkmSlEt2UiRJKjg7KZIkSTVkSJEkSW0WEf0i4mcRsTgifhURXyiPfzUilkbEk+XLce3dh9M9kiQVXEbTPRuAf0wpPRERewKPR8Ts8n3fSild0dEdGFIkSVKbpZSWA8vL19+MiF8DfTtzH073SJJUcBFRjcvEiFjQ6jJxO/s/EPgz4BfloX+IiKci4oaI+GB7X5chRZIkvU9KaVpKaViry7StbRcRewA/Ar6YUloDXAsMBA6j1Gm5sr01ON3TBhdeeCEPPfQQDQ0NzJgxA4Cf/vSnXH311SxZsoT//M//ZPDgwRlXqa1ZuXIlX/3qV1m1ahUAJ598Mn/1V3/Fd7/7XebNm0dE0NDQwMUXX8y+++6bcbXaniVLlnDuueduuf3yyy9zzjnncMYZZ2RXlN7lggsu4C/+4i94/fXXOf300wFoampiwoQJHHjggUyYMIFnn30WgJ122onzzz+fgw8+mJ122omf/OQn3HzzzVmWrzaIiA9QCii3ppSmA6SUVra6/zrgx+19fjspbTB27Fi+973vvWvsoIMO4qqrrmLYsGEZVaVK7LTTTnzhC1/ghz/8ITfccAN33HEHS5Ys4fTTT+e2227j1ltvZfjw4Vx//fVZl6odGDBgADNmzGDGjBlMnz6dHj16MHLkyKzLUiszZ858V5AEeP755znvvPN48smj5YvgAAAKnElEQVQn3zV+zDHH8IEPfIDTTz+dM844g7Fjx9LY2FjLctVOUVqt+33g1ymlf2013qfVZicDz7R3H3ZS2mDYsGEsXbr0XWMDBw7MqBq1xT777MM+++wDwO67707//v353e9+x4ABA7Zss27duro9IVK9amlpoV+/fvTt26lr9dRBTz755PuCxksvvbTVbVNK9OjRg5122olddtmF9evXs3bt2lqUWVcy+tn1MeDTwNMRsTl9ng+Mj4jDgAS8CPxde3ew3ZASEQ3buz+ltKq9O5aysmzZMn7zm98waNAgAK655hruu+8+9thjD6699tqMq1NbzJw5kzFjxmRdhjrggQceYMSIEdx7773suuuuXHXVVaxZsybrsgoni5CSUnoE2NqO7+usfexouudxYEH563svC7b1oNYrgq+77rrOqlXqsLVr1zJ16lQmTZrEHnvsAcDZZ5/Nj3/8Y5qbm7njjjsyrlCV+sMf/sADDzxAc3Nz1qWoAwYNGsSmTZs44YQT+MQnPsH48ePZf//9sy5LObHdTkpKqX97nrS8AngawIYNG1J7nkPqbBs2bGDKlCmMHj2ao48++n33Nzc388UvfpGJE7d5lJ1yZN68eQwaNGjLNJ6KadSoUTz22GNs3LiR119/naeffppDDjmEZcuWZV2acmC7nZSIGLq9S62KlDoqpcTXv/51+vfvz2mnnbZl/L//+7+3XH/ooYc48MADM6hO7TFz5kyOP/74rMtQB61YsYKPfvSjAOy6664MGjSIF198MduilBuR0rYbHRHxs+08NqWUmna0g3rqpEyePJn58+ezevVq9t57bz7/+c/Tq1cvvvGNb7Bq1Sp69uzJwQcfTL1Mcb399ttZl9BpnnzySSZOnMhBBx20Ze727LPP5p577uGll16iW7duNDY2MnXqVPbbb7+Mq+0cvXr1yrqEqlm7di1HH300c+bMYc8998y6nKo48sgjsy6h3b72ta8xdOhQ9tprL1atWsX111/PmjVrmDRpEnvttRdvvfUWzz33HOeeey49evTgwgsv5MADDyQimDlzJrfeemvWL6HDWlpaarpIZM2aNZ3+u7Znz56ZH0mw3ZDSGeoppHQ19RRSuqJ6DildQZFDigwpnaXiQ5AjYjDwp8Cum8dSSp5xR5IkVUVFISUivgIcRSmk3AccCzwCGFIkScpYvZ7jqdIzzo4DjgFWpJTOBIYA9pIlSVLVVBpSfp9S2gRsiIiewKtAv+qVJUmSurpK16TMj4i9gOsoncjtLaClalVJkqSK1et0T6UhpSfwSeBB4H6gZ0rpqWoVJUmSVGlI+T4wAvgOMBBYGBHzUkpXVa0ySZLUpVUUUlJKP4uIecDhwNHA54BBgCFFkiRVRaWHIM8Fdqe0DuVh4PCU0qvVLEySJFWmXtekVHp0z1PAH4DBwKHA4IjoUbWqJElSl1fpdM+5ABGxJ3AG8O9AI7BL1SqTJEldWqXTPf9AaeHsR4EXgRsoTftIkqSM1et0T6VH9+wK/CvweEppQxXrkSRJAiqf7rmi2oVIkiS1VunCWUmSpJqqdLpHkiTlVL2uSbGTIkmScsmQIkmScsnpHkmSCs7pHkmSpBoypEiSpFwypEiSpFwypEiSpFxy4awkSQXnwllJkqQaMqRIkqRcMqRIkqRcck2KJEkF55oUSZKkGjKkSJKkXHK6R5KkgnO6R5IkqYYMKZIkKZec7pEkqeCc7pEkSaohQ4okScolQ4okScol16RIklRwrkmRJEmqIUOKJEnKJad7JEkqOKd7JEmSasiQIkmScsmQIkmScsk1KZIkFZxrUiRJkmrIkCJJknLJ6R5JkgrO6R5JkqQaMqRIkqRcipRS1jUUWkRMTClNy7oOtY/vX3H53hWb758qYSel4yZmXYA6xPevuHzvis33TztkSJEkSblkSJEkSblkSOk451SLzfevuHzvis33TzvkwllJkpRLdlIkSVIuGVIkSVIuGVJUaBFxfUT8acY1nBER+2dZQz2JiL0i4uys61BtRcSDETGsfP3FiNgn65qUPUNKFUWEn41UZSmlz6aUFmdcxhmAIaXz7AW8L6T4/SR1PYaUCkXE30TEUxGxKCJuiYgTIuIXEbEwIuZERO/ydl8t3/8ocEvGZdeViNg9ImaW34NnIuLU9/z1NSEinouIX0bEdRHxb+XxGyPi2xHx84hYEhHjyuNHRcS88nP+JiK+GxHdyveNj4iny/u5vDy2U/m5ninfd275uYYBt0bEkxHRI5t/nbryz8DA8r/n/Ih4OCLuARYDRMTp5ff4yYj4XkTsVB4fFREtEfFERNwREXtk+SK6qoj4UkScU77+rYh4oHy9KSJujYhrI2JBRPwqIr6WbbXKO/8yqUBEDAIuBP4ipfQ/EdEAJODPU0opIj4LfBn4x/JD/hQYnlJal03FdasZWJZSOh4gInoBf1++vj9wETAUeBN4AFjU6rF9gOHAh4F7gDvL40dQer9eAu4HTomInwOXAx8FXgdmRcRY4GWgb0ppcHmfe6WUVkfEPwCTU0oLqvXCu5ipwOCU0mERcRQws3z7hYg4BDgV+FhKaX1EXAOcFhH3Ufoe/b8ppbcjYgowCbgko9fQlT1M6WfhtykF+F0i4gPACGAecEdKaVU5XM6NiENTSk9lV67yzJBSmSZK31j/A1D+BvsI8MOI6APsDLzQavt7DChV8TRwZbmz8eOU0sOtPp78COChlNIqgIi4A/iTVo+9O6W0CVi8uetV9suU0pLyY35AKcisBx5MKf2uPH4r8JfA14EBEfEdSr84Z1XpderdfplS2vz9dQyl8Di//N73AF4F/pxS2Hy0PL4z0FL7UgU8Dnw0InoC7wBPUAorI4BzgE9FxERKv3/6UHrfDCnaKkNK+30H+NeU0j3lv/a+2uq+tzOpqM6llJ6LiKHAccA/RcTcNjz8nVbXo9X1954oaJsnDkopvR4RQ4DRwOeATwFntaEGtU/r76cAbkopndd6g4g4AZidUhpf08r0PuUO1wuU1mr9nFIAORo4CFgHTAYOL38/3QjsmlGpKgDXpFTmAeCTEbE3QHm6pxewtHz/Z7IqrCspT+msTSn9B/BNSlM7m80HPh4RHywvsPxEhU97RET0L69FORV4BPhl+bn2KbekxwMPlY826JZS+hGlqYXN+38T2LOjr09bbO/fcy4wLiL2g9L3YkT8MfAY8LGIOKg8vntE/Mk2nkPV9zClMDKvfP1zwEKgJ6XQ+Ua5o3lsZhWqEOykVCCl9KuIuJTSL6qNlL7ZvgrcERGvUwox/TMssav4CPDNiNhEaUrm74ErAFJKSyPiG5QCxirgWeCNCp5zPvBvlP7K+xlwV0ppU0RMLd8OYGZKaUa5i/LvmxfXApv/mr8R+G5ErAOOdKqvY1JKr0XEoxHxDKW/vFe2um9xRFxIaZ1QN0r/Dz6fUnosIs4AfhARu5Q3vxB4rsblq+Rh4AKgpbxG6PfAwymlRRGxkNL358vAo1kWqfzztPiqGxGxR0rprXIn5S7ghpTSXdvZ/ihKC17H1KpGSVLlnO5RPflqRDwJPENpIfPdGdcjSeoAOymSJCmX7KRIkqRcMqRIkqRcMqRIkqRcMqRIkqRcMqRIkqRc+v/iqFhG+JAu0gAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 720x576 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot_cm(confusion_matrix,label_encoder.classes_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def diff_calc(df_slize):\n",
    "    df_diff = df_slize.diff(axis=1)\n",
    "    df_diff.dropna(inplace=True,axis=1)\n",
    "    #norm_diff = df_diff / df_diff.max(axis=1).values\n",
    "    norm_diff = df_diff.divide(df_diff.max(axis=1).values, axis=0)\n",
    "    return norm_diff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'test_data' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m\u001b[0m",
      "\u001b[0;31mNameError\u001b[0mTraceback (most recent call last)",
      "\u001b[0;32m<ipython-input-28-384699c12a4a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mdiff_calc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_data\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'test_data' is not defined"
     ]
    }
   ],
   "source": [
    "diff_calc(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 511,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test session =  20210310_15:25:26.159-20210310_15:25:39.816\n",
      "|*******************************************************************************| 100.000% is complete...\n",
      "\n",
      "[[0 0]\n",
      " [8 0]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    signpost       0.00      0.00      0.00       0.0\n",
      "        tree       0.00      0.00      0.00       8.0\n",
      "\n",
      "    accuracy                           0.00       8.0\n",
      "   macro avg       0.00      0.00      0.00       8.0\n",
      "weighted avg       0.00      0.00      0.00       8.0\n",
      "\n",
      "Overall results...\n",
      "[[0 0]\n",
      " [8 0]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    signpost       0.00      0.00      0.00       0.0\n",
      "        tree       0.00      0.00      0.00       8.0\n",
      "\n",
      "    accuracy                           0.00       8.0\n",
      "   macro avg       0.00      0.00      0.00       8.0\n",
      "weighted avg       0.00      0.00      0.00       8.0\n",
      "\n",
      "Majority vote results...\n",
      "[[0 0]\n",
      " [1 0]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    signpost       0.00      0.00      0.00       0.0\n",
      "        tree       0.00      0.00      0.00       1.0\n",
      "\n",
      "    accuracy                           0.00       1.0\n",
      "   macro avg       0.00      0.00      0.00       1.0\n",
      "weighted avg       0.00      0.00      0.00       1.0\n",
      "\n",
      "Weighted majority vote results...\n",
      "[[0 0]\n",
      " [1 0]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    signpost       0.00      0.00      0.00       0.0\n",
      "        tree       0.00      0.00      0.00       1.0\n",
      "\n",
      "    accuracy                           0.00       1.0\n",
      "   macro avg       0.00      0.00      0.00       1.0\n",
      "weighted avg       0.00      0.00      0.00       1.0\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/_classification.py:1221: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/_classification.py:1221: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "#dates = [\"20210315\"]\n",
    "predicted_labels = []\n",
    "true_labels = []\n",
    "pred_prob = []\n",
    "maj_pre_lab =[]\n",
    "maj_true_lab = []\n",
    "w_maj_pre_lab = []\n",
    "w_maj_true_lab = []\n",
    "\n",
    "for session in session_list:\n",
    "\n",
    "    #test_data = pd.concat(pd.read_csv(\"processed/\" + \"spectrum/\" + date + \"/right/\" + session, index_col=False, header=None))\n",
    "\n",
    "    \n",
    "    #display(test_data.head)\n",
    "    print(\"Test session = \", session)\n",
    "    test_data = read_data(dates,session)\n",
    "    test_data.dropna(inplace=True, axis=0)\n",
    "    #test_data = one_class_svm(test_data)\n",
    "    #test_data = pd.concat(diff_calc(test_data.iloc[:,0:94]))\n",
    "    train_list = [x for x in session_list if x != session]\n",
    "    train_data = pd.DataFrame()\n",
    "    count = 0\n",
    "    for ts in train_list:\n",
    "        print(\"|\" + \"*\"*(count+1) + ' '*(len(train_list)-1-count)+ \"| \" +str(format((count+1)/len(train_list)*100,'.3f')) + \"% is complete...\" ,end=\"\\r\")\n",
    "        #tr = pd.read_csv(\"processed/\" + \"spectrum/\" + date + \"/right/\" + ts, index_col=False, header=None)\n",
    "#         tr_feature1 = pd.read_csv(\"processed/\" + \"spectrum/\" + date + \"/right/\" + ts, index_col=False, header=None)\n",
    "#         tr_feature2 = pd.read_csv(\"processed/\" + \"spectrum/\" + date + \"/left/\" + ts, index_col=False, header=None)\n",
    "#         tr_feature3 =pd.read_csv(\"processed/\" + \"mfcc/\" + date + \"/right/\" + ts, index_col=False, header=None)\n",
    "#         tr_feature4 = pd.read_csv(\"processed/\" + \"mfcc/\" + date + \"/left/\" + ts, index_col=False, header=None)\n",
    "#         tr = pd.concat([tr_feature1,tr_feature2,tr_feature3,tr_feature4],axis=1)\n",
    "#         tr = label_data(ts,tr)\n",
    "        tr = read_data(dates, ts)\n",
    "        train_data = pd.concat([train_data,tr],axis=0,ignore_index=False)\n",
    "        count = count+1\n",
    "        #break\n",
    "    #print(np.unique(train_data.index, return_counts=True))\n",
    "    #train_data = random_undersampling(train_data)\n",
    "    #print(np.unique(train_data.index, return_counts=True))\n",
    "    train_data.dropna(inplace=True, axis=0)\n",
    "    #train_data = diff_calc(train_data.iloc[:,0:94])\n",
    "    #train_data = one_class_svm(train_data)\n",
    "    #train_data, test_data = pca_calc(train_data,test_data)\n",
    "    test_feat = test_data#extract_mfcc_feat(test_data)\n",
    "    train_feat = train_data#extract_mfcc_feat(train_data)\n",
    "    test_feat.dropna(axis=0,inplace=True)\n",
    "    train_feat.dropna(axis=0,inplace=True)\n",
    "    X_train, y_train = make_data(train_feat)\n",
    "    X_test, y_test = make_data(test_feat)\n",
    "    model = randomForest(X_train, y_train.tolist())\n",
    "    y_pred = model.predict(X_test)\n",
    "    prob = model.predict_proba(X_test)\n",
    "    \n",
    "    maj_pre_lab.append(majority_vote(y_pred))\n",
    "    maj_true_lab.append(majority_vote(y_test))\n",
    "    \n",
    "    w_maj_pre_lab.append(weighted_majority_vote(y_pred, prob))\n",
    "    w_maj_true_lab.append(weighted_majority_vote(y_test, prob))\n",
    "    \n",
    "    if y_test.all() == \"car\":\n",
    "        pred_prob.append([\"car\",prob[:,0].tolist()])\n",
    "    elif y_test.all() == \"signpost\":\n",
    "        pred_prob.append([\"signpost\",prob[:,1].tolist()])\n",
    "    elif y_test.all() == \"tree\":\n",
    "        pred_prob.append([\"tree\",prob[:,2].tolist()])\n",
    "    elif y_test.all() == \"wall\":\n",
    "        pred_prob.append([\"wall\",prob[:,3].tolist()])\n",
    "    conf_mat = confusion_matrix(y_test, y_pred)\n",
    "    class_report = classification_report(y_test, y_pred)\n",
    "    print(\"\\n\")\n",
    "    print(conf_mat)\n",
    "    print(class_report)\n",
    "    predicted_labels.extend(y_pred)\n",
    "    true_labels.extend(y_test)\n",
    "    break\n",
    "print(\"Overall results...\")   \n",
    "print(confusion_matrix(true_labels, predicted_labels))\n",
    "print(classification_report(true_labels, predicted_labels))\n",
    "\n",
    "print(\"Majority vote results...\")\n",
    "print(confusion_matrix(maj_true_lab, maj_pre_lab))\n",
    "print(classification_report(maj_true_lab, maj_pre_lab))\n",
    "\n",
    "print(\"Weighted majority vote results...\")\n",
    "print(confusion_matrix(w_maj_true_lab, w_maj_pre_lab))\n",
    "print(classification_report(w_maj_true_lab, w_maj_pre_lab))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
